{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "181bca2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state\n",
        "import optax\n",
        "import orbax.checkpoint as ocp\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.collections import LineCollection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "558de4e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1766269760.411342     462 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2240 MB memory:  -> device: 0, name: Quadro T2000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST from TensorFlow Datasets\n",
        "data_dir = '/tmp/tfds' # data_dir = './data/tfds'\n",
        "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fb40841",
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalise(x, x_max=255.0):\n",
        "    return x / x_max\n",
        "\n",
        "def convert_to_jax(data_np, data_type):\n",
        "    if data_type == \"image\":\n",
        "        data_jax = normalise(jnp.array(data_np, dtype=jnp.float32))\n",
        "    elif data_type == \"label\":\n",
        "        data_jax = jnp.array(data_np)\n",
        "    else:\n",
        "        raise ValueError(\"not image or label\")\n",
        "    return data_jax\n",
        "\n",
        "def flatten_image_for_mlp(data_jax):\n",
        "    \"\"\"Produces one greyscale vector per sample\"\"\"\n",
        "    n_batch, n_pixels_vertical, n_pixels_horizontal, n_channels = data_jax.shape\n",
        "    data_flattened = data_jax.reshape(n_batch, -1)\n",
        "    return data_flattened\n",
        "\n",
        "def prepare_data(data_dict: dict, subsample_size: int=0):\n",
        "    data_jax = {}\n",
        "    for data_type, data_tf in data_dict.items():\n",
        "        data_numpy = data_tf.numpy()\n",
        "        data = convert_to_jax(data_numpy, data_type)\n",
        "        if data_type == \"image\":\n",
        "            data = flatten_image_for_mlp(data)\n",
        "        if subsample_size > 0:\n",
        "            data = data[:subsample_size]\n",
        "        data_jax[data_type] = data\n",
        "\n",
        "    return data_jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9813eac5",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    layer_sizes: Sequence[int]\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, activations):\n",
        "        for layer_number, layer_size in enumerate(self.layer_sizes):\n",
        "            activations = nn.Dense(\n",
        "                layer_size,\n",
        "                kernel_init=nn.initializers.normal(0.1),\n",
        "                bias_init=nn.initializers.normal(0.1)\n",
        "            )(activations)\n",
        "\n",
        "            if layer_number != (len(self.layer_sizes) - 1):\n",
        "                activations = nn.relu(activations)\n",
        "\n",
        "        return activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "275f18e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "class LowRankDense(nn.Module):\n",
        "    \"\"\"Low-rank dense layer implemented with two factors and einsum.\n",
        "\n",
        "    Parameters are U in R^{in_features x rank} and V in R^{rank x features}.\n",
        "    The forward pass computes y = (x @ U) @ V + b using einsum.\n",
        "    \"\"\"\n",
        "    features: int\n",
        "    rank: int\n",
        "    use_bias: bool = True\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs):\n",
        "        # inputs: [batch, in_features]\n",
        "        in_features = inputs.shape[-1]\n",
        "\n",
        "        U = self.param(\n",
        "            \"U\",\n",
        "            nn.initializers.normal(0.1),\n",
        "            (in_features, self.rank),\n",
        "        )\n",
        "        V = self.param(\n",
        "            \"V\",\n",
        "            nn.initializers.normal(0.1),\n",
        "            (self.rank, self.features),\n",
        "        )\n",
        "\n",
        "        hidden = jnp.einsum(\"bi,ir->br\", inputs, U)\n",
        "        y = jnp.einsum(\"br,rf->bf\", hidden, V)\n",
        "\n",
        "        if self.use_bias:\n",
        "            bias = self.param(\n",
        "                \"bias\",\n",
        "                nn.initializers.normal(0.1),\n",
        "                (self.features,),\n",
        "            )\n",
        "            y = y + bias\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class LowRankMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Every layer uses the same low-rank dimension rank (=\"rank\")\n",
        "    \"\"\"\n",
        "    layer_sizes: Sequence[int]\n",
        "    rank: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, activations):\n",
        "        for layer_number, layer_size in enumerate(self.layer_sizes):\n",
        "            activations = LowRankDense(\n",
        "                features=layer_size,\n",
        "                rank=self.rank,\n",
        "                use_bias=True,\n",
        "            )(activations)\n",
        "\n",
        "            if layer_number != (len(self.layer_sizes) - 1):\n",
        "                activations = nn.relu(activations)\n",
        "\n",
        "        return activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "35a91c33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialise_network_params(model, input_layer_size, key):\n",
        "    \"\"\"Initialize all layers for a fully-connected neural network\"\"\"\n",
        "    input_shape_dummy = jnp.ones((1, input_layer_size))\n",
        "    params = model.init(key, input_shape_dummy)[\"params\"]\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8f245d13",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_training_state(layer_sizes, optimizer, key, use_lowrank: bool = False, rank: int | None = None):\n",
        "    input_layer_size = layer_sizes[0]\n",
        "    network_layer_sizes = layer_sizes[1:]\n",
        "\n",
        "    if use_lowrank:\n",
        "        if rank is None:\n",
        "            raise ValueError(\"rank must be provided when use_lowrank=True\")\n",
        "        model = LowRankMLP(layer_sizes=network_layer_sizes, rank=rank)\n",
        "    else:\n",
        "        model = MLP(layer_sizes=network_layer_sizes)\n",
        "\n",
        "    apply_fn = model.apply\n",
        "    params = initialise_network_params(model, input_layer_size, key)\n",
        "    training_state = train_state.TrainState.create(\n",
        "        apply_fn=apply_fn,\n",
        "        params=params,\n",
        "        tx=optimizer,\n",
        "    )\n",
        "    return training_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "15a25657",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_entropy_loss_single_label(logits, label):\n",
        "    targets = jnp.full_like(logits, label)\n",
        "    return optax.sigmoid_binary_cross_entropy(logits, targets).mean()\n",
        "\n",
        "def generator_loss_nonsaturating(logits_real_given_fake):\n",
        "    \"\"\"Objective: maximise p(predicted real | fake)\"\"\"\n",
        "    return + cross_entropy_loss_single_label(logits=logits_real_given_fake, label=1)\n",
        "\n",
        "def generator_loss_saturating(logits_real_given_fake):\n",
        "    \"\"\"Objective: minimise p(predicted fake | fake)\"\"\"\n",
        "    return - cross_entropy_loss_single_label(logits=logits_real_given_fake, label=0)\n",
        "\n",
        "def discriminator_loss(logits_real_given_real, logits_real_given_fake):\n",
        "    loss_given_real = cross_entropy_loss_single_label(logits=logits_real_given_real, label=1)\n",
        "    loss_given_fake = cross_entropy_loss_single_label(logits=logits_real_given_fake, label=0)\n",
        "    return (loss_given_real + loss_given_fake) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b22555e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_generator_loss(generator_params, discriminator_params, generator_apply_fn, discriminator_apply_fn, z_vector, loss_type=\"nonsaturating\"):\n",
        "    fake_images = generator_apply_fn({\"params\": generator_params}, z_vector)\n",
        "    logits_real_given_fake = discriminator_apply_fn({\"params\": discriminator_params}, fake_images)\n",
        "    if loss_type == \"nonsaturating\":\n",
        "        return generator_loss_nonsaturating(logits_real_given_fake)\n",
        "    elif loss_type == \"saturating\":\n",
        "        return generator_loss_saturating(logits_real_given_fake)\n",
        "    else:\n",
        "        raise ValueError(f\"incorrect loss type specified: {loss_type}\")\n",
        "\n",
        "\n",
        "def calculate_discriminator_loss(discriminator_params, generator_params, generator_apply_fn, discriminator_apply_fn, z_vector, real_images):\n",
        "    fake_images = generator_apply_fn({\"params\": generator_params}, z_vector)\n",
        "    logits_real_given_fake = discriminator_apply_fn({\"params\": discriminator_params}, fake_images)\n",
        "    logits_real_given_real = discriminator_apply_fn({\"params\": discriminator_params}, real_images)\n",
        "    return discriminator_loss(logits_real_given_real, logits_real_given_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "efbab3ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def take_generator_step_nonsaturating(generator, discriminator, z_vector):\n",
        "    grads_by_params_fn = jax.grad(calculate_generator_loss)\n",
        "    grads_by_params = grads_by_params_fn(\n",
        "        generator.params,\n",
        "        discriminator.params,\n",
        "        generator.apply_fn,\n",
        "        discriminator.apply_fn,\n",
        "        z_vector,\n",
        "        \"nonsaturating\",\n",
        "    )\n",
        "    return generator.apply_gradients(grads=grads_by_params)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def take_generator_step_saturating(generator, discriminator, z_vector):\n",
        "    grads_by_params_fn = jax.grad(calculate_generator_loss)\n",
        "    grads_by_params = grads_by_params_fn(\n",
        "        generator.params,\n",
        "        discriminator.params,\n",
        "        generator.apply_fn,\n",
        "        discriminator.apply_fn,\n",
        "        z_vector,\n",
        "        \"saturating\",\n",
        "    )\n",
        "    return generator.apply_gradients(grads=grads_by_params)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def take_discriminator_step(generator, discriminator, z_vector, real_images):\n",
        "    grads_by_params_fn = jax.grad(calculate_discriminator_loss)\n",
        "    grads_by_params = grads_by_params_fn(\n",
        "        discriminator.params,\n",
        "        generator.params,\n",
        "        generator.apply_fn,\n",
        "        discriminator.apply_fn,\n",
        "        z_vector,\n",
        "        real_images,\n",
        "    )\n",
        "    return discriminator.apply_gradients(grads=grads_by_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a156d045",
      "metadata": {},
      "outputs": [],
      "source": [
        "def subsample_images_for_batch(key, images_full_sample, batch_size):\n",
        "    image_ids = jax.random.randint(key, (batch_size,), 0, images_full_sample.shape[0])\n",
        "    return images_full_sample[image_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e79102c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_training_gan(\n",
        "    train_data,\n",
        "    n_steps,\n",
        "    generator_training_state,\n",
        "    discriminator_training_state,\n",
        "    key,\n",
        "    steps_per_save,\n",
        "    checkpoint_manager,\n",
        "    batch_size: int,\n",
        "    latent_dim: int,\n",
        "    loss_type: str = \"nonsaturating\",\n",
        "):\n",
        "    \"\"\"Train a GAN using random mini-batches of real images.\n",
        "\n",
        "    Shapes:\n",
        "      - train_data[\"image\"]: (N, n_pixels)\n",
        "      - real_images_batch:   (batch_size, n_pixels)\n",
        "      - z_vectors:           (batch_size, latent_dim)\n",
        "    \"\"\"\n",
        "    real_images = train_data[\"image\"]\n",
        "\n",
        "    if loss_type == \"nonsaturating\":\n",
        "        take_generator_step = take_generator_step_nonsaturating\n",
        "    elif loss_type == \"saturating\":\n",
        "        take_generator_step = take_generator_step_saturating\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown loss_type: {loss_type}\")\n",
        "\n",
        "    for step in range(1, n_steps + 1):\n",
        "        key, key_z_generation, key_real_subsample = jax.random.split(key, 3)\n",
        "\n",
        "        # Random mini-batch of real images\n",
        "        real_images_batch = subsample_images_for_batch(\n",
        "            key_real_subsample,\n",
        "            real_images,\n",
        "            batch_size,\n",
        "        )\n",
        "\n",
        "        # Latent vectors for generator\n",
        "        z_vectors = jax.random.normal(\n",
        "            key_z_generation,\n",
        "            (batch_size, latent_dim),\n",
        "        )\n",
        "\n",
        "        # Update discriminator then generator\n",
        "        discriminator_training_state = take_discriminator_step(\n",
        "            generator_training_state,\n",
        "            discriminator_training_state,\n",
        "            z_vectors,\n",
        "            real_images_batch,\n",
        "        )\n",
        "        generator_training_state = take_generator_step(\n",
        "            generator_training_state,\n",
        "            discriminator_training_state,\n",
        "            z_vectors,\n",
        "        )\n",
        "\n",
        "        # Monitor losses\n",
        "        generator_loss_value = calculate_generator_loss(\n",
        "            generator_training_state.params,\n",
        "            discriminator_training_state.params,\n",
        "            generator_training_state.apply_fn,\n",
        "            discriminator_training_state.apply_fn,\n",
        "            z_vectors,\n",
        "            loss_type=loss_type,\n",
        "        )\n",
        "        discriminator_loss_value = calculate_discriminator_loss(\n",
        "            discriminator_training_state.params,\n",
        "            generator_training_state.params,\n",
        "            generator_training_state.apply_fn,\n",
        "            discriminator_training_state.apply_fn,\n",
        "            z_vectors,\n",
        "            real_images_batch,\n",
        "        )\n",
        "        print(\n",
        "            f\"step {step}: generator_loss={generator_loss_value}, \"\n",
        "            f\"discriminator_loss={discriminator_loss_value}\"\n",
        "        )\n",
        "\n",
        "        if step == 1 or step % steps_per_save == 0:\n",
        "            checkpoint_manager.save(\n",
        "                step,\n",
        "                args=ocp.args.StandardSave(\n",
        "                    {\n",
        "                        \"generator\": generator_training_state,\n",
        "                        \"discriminator\": discriminator_training_state,\n",
        "                    }\n",
        "                ),\n",
        "            )\n",
        "\n",
        "    return generator_training_state, discriminator_training_state, key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d4d625f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_batch(images, labels, n_batches):\n",
        "    \"\"\"Drops the last set of samples if they're not the right length\"\"\"\n",
        "    n_samples = len(images)\n",
        "    assert len(images) == len(labels)\n",
        "    assert n_samples >= n_batches\n",
        "    assert n_batches > 0\n",
        "    n_samples_per_batch = n_samples // n_batches\n",
        "    start = 0\n",
        "    end = n_samples_per_batch\n",
        "    while end <= n_samples: \n",
        "        yield (images[start:end], labels[start:end])\n",
        "        start += n_samples_per_batch\n",
        "        end += n_samples_per_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4b0c85d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_gan_training(optimizer, key, latent_dim):\n",
        "    N_PIXELS = 784\n",
        "    N_HIDDEN_LAYER = 128\n",
        "    N_BINARY_CATEGORIES = 1\n",
        "\n",
        "    # Generator maps from latent space (latent_dim) to image space (N_PIXELS)\n",
        "    layer_sizes_generator = [latent_dim, N_HIDDEN_LAYER, N_PIXELS]\n",
        "    layer_sizes_discriminator = [N_PIXELS, N_HIDDEN_LAYER, N_BINARY_CATEGORIES]\n",
        "\n",
        "    g_key, d_key = jax.random.split(key)\n",
        "    generator_training_state = create_training_state(layer_sizes_generator, optimizer, g_key)\n",
        "    discriminator_training_state = create_training_state(layer_sizes_discriminator, optimizer, d_key)\n",
        "    return generator_training_state, discriminator_training_state, key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6007df0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_experiment_name(optimizer):\n",
        "    opt_name = optimizer.__class__.__name__\n",
        "    return f\"gan_{opt_name}\"\n",
        "\n",
        "\n",
        "def initialise_checkpoint_manager(experiment_name: str = \"gan\", max_to_keep=20):\n",
        "    project_root = Path().resolve()\n",
        "    base_dir = project_root / \"checkpoints\"\n",
        "    checkpoint_dir = base_dir / experiment_name\n",
        "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
        "    checkpoint_manager = ocp.CheckpointManager(\n",
        "        directory=str(checkpoint_dir),\n",
        "        options=ocp.CheckpointManagerOptions(max_to_keep=max_to_keep),\n",
        "    )\n",
        "    return checkpoint_manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "42aaa206",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W1220 22:29:23.394317     727 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
            "W1220 22:29:23.397267     462 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n"
          ]
        }
      ],
      "source": [
        "def train_gan(\n",
        "    train_data, \n",
        "    optimizer, \n",
        "    n_steps=10**3, \n",
        "    steps_per_save=100, \n",
        "    key=jax.random.key(0),\n",
        "    batch_size: int = 128,\n",
        "    latent_dim: int = 64,\n",
        "    loss_type: str = \"nonsaturating\",\n",
        "    ):\n",
        "    experiment_name = make_experiment_name(optimizer) + f\"_{loss_type}\"\n",
        "    checkpoint_manager = initialise_checkpoint_manager(experiment_name)\n",
        "\n",
        "    generator_training_state, discriminator_training_state, key = setup_gan_training(\n",
        "        optimizer=optimizer,\n",
        "        key=key,\n",
        "        latent_dim=latent_dim,\n",
        "    )\n",
        "\n",
        "    generator_training_state, discriminator_training_state, key = run_training_gan(\n",
        "        train_data=train_data,\n",
        "        n_steps=n_steps,\n",
        "        generator_training_state=generator_training_state,\n",
        "        discriminator_training_state=discriminator_training_state,\n",
        "        key=key,\n",
        "        steps_per_save=steps_per_save,\n",
        "        checkpoint_manager=checkpoint_manager,\n",
        "        batch_size=batch_size,\n",
        "        latent_dim=latent_dim,\n",
        "        loss_type=loss_type,\n",
        "    )\n",
        "    return generator_training_state, discriminator_training_state, key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4575e629",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = prepare_data(mnist_data[\"train\"], subsample_size=10**4) \n",
        "test_data = prepare_data(mnist_data[\"test\"], subsample_size=10**3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fb76bbaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment_for_loss_type(\n",
        "    loss_type: str,\n",
        "    train_data,\n",
        "    learning_rate: float = 1e-3,\n",
        "    batch_size: int = 128,\n",
        "    latent_dim: int = 64,\n",
        "    n_steps: int = 5_000,\n",
        "    steps_per_save: int = 250,\n",
        "    seed: int = 0,\n",
        "):\n",
        "    \"\"\"Train GAN and save checkpoints for a given loss_type.\n",
        "\n",
        "    This function returns training results; plotting is handled separately.\n",
        "\n",
        "    loss_type: \"nonsaturating\" or \"saturating\".\n",
        "    \"\"\"\n",
        "    print(f\"=== Running experiment with loss_type={loss_type} ===\")\n",
        "\n",
        "    # Optimizer and PRNG key\n",
        "    optimizer = optax.adam(learning_rate)\n",
        "    key = jax.random.key(seed)\n",
        "\n",
        "    # Train GAN and save checkpoints\n",
        "    generator_training_state, discriminator_training_state, key = train_gan(\n",
        "        train_data=train_data,\n",
        "        optimizer=optimizer,\n",
        "        n_steps=n_steps,\n",
        "        steps_per_save=steps_per_save,\n",
        "        key=key,\n",
        "        batch_size=batch_size,\n",
        "        latent_dim=latent_dim,\n",
        "        loss_type=loss_type,\n",
        "    )\n",
        "\n",
        "    # --- Loss curves over checkpoints for this loss_type ---\n",
        "    gen_tmpl, disc_tmpl, _ = setup_gan_training(\n",
        "        optimizer,\n",
        "        key=jax.random.key(0),\n",
        "        latent_dim=latent_dim,\n",
        "    )\n",
        "    experiment_name = make_experiment_name(optimizer) + f\"_{loss_type}\"\n",
        "    ckpt_manager = initialise_checkpoint_manager(experiment_name)\n",
        "    steps = sorted(ckpt_manager.all_steps())\n",
        "\n",
        "    g_losses, d_losses = [], []\n",
        "    real_images = train_data[\"image\"]\n",
        "\n",
        "    for step in steps:\n",
        "        restored = ckpt_manager.restore(\n",
        "            step,\n",
        "            args=ocp.args.StandardRestore(\n",
        "                item={\"generator\": gen_tmpl, \"discriminator\": disc_tmpl}\n",
        "            ),\n",
        "        )\n",
        "        gen_state = restored[\"generator\"]\n",
        "        disc_state = restored[\"discriminator\"]\n",
        "\n",
        "        key = jax.random.key(0)\n",
        "        key, z_key = jax.random.split(key)\n",
        "        z_vectors = jax.random.normal(\n",
        "            z_key,\n",
        "            (real_images.shape[0], latent_dim),\n",
        "        )\n",
        "\n",
        "        g_loss = calculate_generator_loss(\n",
        "            gen_state.params,\n",
        "            disc_state.params,\n",
        "            gen_state.apply_fn,\n",
        "            disc_state.apply_fn,\n",
        "            z_vectors,\n",
        "            loss_type=loss_type,\n",
        "        )\n",
        "        d_loss = calculate_discriminator_loss(\n",
        "            disc_state.params,\n",
        "            gen_state.params,\n",
        "            gen_state.apply_fn,\n",
        "            disc_state.apply_fn,\n",
        "            z_vectors,\n",
        "            real_images,\n",
        "        )\n",
        "\n",
        "        g_losses.append(float(g_loss))\n",
        "        d_losses.append(float(d_loss))\n",
        "\n",
        "    # Collect results (plotting handled separately)\n",
        "    return {\n",
        "        \"generator_state\": generator_training_state,\n",
        "        \"discriminator_state\": discriminator_training_state,\n",
        "        \"steps\": steps,\n",
        "        \"g_losses\": g_losses,\n",
        "        \"d_losses\": d_losses,\n",
        "        \"loss_type\": loss_type,\n",
        "        \"latent_dim\": latent_dim,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fda4c1e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_experiment_for_loss_type(results, train_data):\n",
        "    \"\"\"Plot sample images and loss dynamics for a single loss_type run.\n",
        "\n",
        "    Expects the dict returned by `run_experiment_for_loss_type` and the\n",
        "    corresponding `train_data` used for training.\n",
        "    \"\"\"\n",
        "    loss_type = results[\"loss_type\"]\n",
        "    generator_training_state = results[\"generator_state\"]\n",
        "    steps = results[\"steps\"]\n",
        "    g_losses = results[\"g_losses\"]\n",
        "    d_losses = results[\"d_losses\"]\n",
        "    latent_dim = results.get(\"latent_dim\", 64)\n",
        "\n",
        "    # --- Plot a sample real vs fake image ---\n",
        "    key = jax.random.key(0)\n",
        "    key, z_key, real_image_key = jax.random.split(key, 3)\n",
        "    z_vector = jax.random.normal(z_key, (1, latent_dim))\n",
        "    real_idx = jax.random.randint(\n",
        "        real_image_key, shape=(), minval=0, maxval=train_data[\"image\"].shape[0]\n",
        "    )\n",
        "\n",
        "    fake_image_flat = generator_training_state.apply_fn(\n",
        "        {\"params\": generator_training_state.params},\n",
        "        z_vector,\n",
        "    )\n",
        "    fake_image = fake_image_flat[0].reshape(28, 28)\n",
        "\n",
        "    real_image_flat = train_data[\"image\"][real_idx]\n",
        "    real_image = real_image_flat.reshape(28, 28)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(4, 2))\n",
        "    axes[0].imshow(real_image, cmap=\"gray\"); axes[0].set_title(f\"Real ({loss_type})\"); axes[0].axis(\"off\")\n",
        "    axes[1].imshow(fake_image, cmap=\"gray\"); axes[1].set_title(f\"Fake ({loss_type})\"); axes[1].axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    # --- Plot loss curves over checkpoints for this loss_type ---\n",
        "    plt.figure()\n",
        "    plt.plot(steps, g_losses, label=f\"generator ({loss_type})\")\n",
        "    plt.plot(steps, d_losses, label=f\"discriminator ({loss_type})\")\n",
        "    plt.xlabel(\"training step\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.title(f\"GAN losses ({loss_type})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # --- Plot training dynamics in (g, d) loss space ---\n",
        "    g = np.array(g_losses)\n",
        "    d = np.array(d_losses)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    points = np.column_stack([g, d])\n",
        "    segments = np.stack([points[:-1], points[1:]], axis=1)\n",
        "\n",
        "    t = np.linspace(0.0, 1.0, len(points) - 1)\n",
        "    colors = cm.coolwarm(t)\n",
        "\n",
        "    lc = LineCollection(segments, colors=colors, linewidths=1.5)\n",
        "    ax.add_collection(lc)\n",
        "\n",
        "    ax.scatter(g, d, c=t.tolist() + [1.0], cmap=\"coolwarm\", s=8, alpha=0.7)\n",
        "    ax.scatter(g[0], d[0], color=\"blue\", s=50, label=\"start\")\n",
        "    ax.scatter(g[-1], d[-1], color=\"red\", s=50, label=\"end\")\n",
        "\n",
        "    ax.set_xlabel(\"Generator loss\")\n",
        "    ax.set_ylabel(\"Discriminator loss\")\n",
        "    ax.set_title(f\"GAN training dynamics in loss space ({loss_type})\")\n",
        "    ax.grid(True)\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6610b8cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Running experiment with loss_type=saturating ===\n",
            "step 1: generator_loss=-2.1513190269470215, discriminator_loss=1.2680836915969849\n",
            "step 2: generator_loss=-2.574666976928711, discriminator_loss=1.4624947309494019\n",
            "step 3: generator_loss=-2.907804489135742, discriminator_loss=1.6043462753295898\n",
            "step 4: generator_loss=-3.0833139419555664, discriminator_loss=1.683457851409912\n",
            "step 5: generator_loss=-3.5509586334228516, discriminator_loss=1.888504147529602\n",
            "step 6: generator_loss=-4.230525970458984, discriminator_loss=2.2254726886749268\n",
            "step 7: generator_loss=-4.963939666748047, discriminator_loss=2.570420742034912\n",
            "step 8: generator_loss=-5.347384452819824, discriminator_loss=2.7596426010131836\n",
            "step 9: generator_loss=-5.342500686645508, discriminator_loss=2.751652956008911\n",
            "step 10: generator_loss=-5.551156044006348, discriminator_loss=2.8435750007629395\n",
            "step 11: generator_loss=-5.927734851837158, discriminator_loss=3.0209474563598633\n",
            "step 12: generator_loss=-6.205704689025879, discriminator_loss=3.155567169189453\n",
            "step 13: generator_loss=-6.542835235595703, discriminator_loss=3.3312320709228516\n",
            "step 14: generator_loss=-6.277724266052246, discriminator_loss=3.1856911182403564\n",
            "step 15: generator_loss=-6.601086616516113, discriminator_loss=3.3524811267852783\n",
            "step 16: generator_loss=-6.391912460327148, discriminator_loss=3.235809087753296\n",
            "step 17: generator_loss=-6.144571304321289, discriminator_loss=3.112070322036743\n",
            "step 18: generator_loss=-5.957680702209473, discriminator_loss=3.0186049938201904\n",
            "step 19: generator_loss=-5.5265727043151855, discriminator_loss=2.793438196182251\n",
            "step 20: generator_loss=-4.8652496337890625, discriminator_loss=2.4606356620788574\n",
            "step 21: generator_loss=-4.274508476257324, discriminator_loss=2.170980930328369\n",
            "step 22: generator_loss=-3.534813642501831, discriminator_loss=1.7977648973464966\n",
            "step 23: generator_loss=-2.940530300140381, discriminator_loss=1.4977879524230957\n",
            "step 24: generator_loss=-1.977867603302002, discriminator_loss=1.0133962631225586\n",
            "step 25: generator_loss=-1.1141537427902222, discriminator_loss=0.5835578441619873\n",
            "step 26: generator_loss=-0.42667219042778015, discriminator_loss=0.24049243330955505\n",
            "step 27: generator_loss=-0.16256821155548096, discriminator_loss=0.09930869936943054\n",
            "step 28: generator_loss=-0.034666866064071655, discriminator_loss=0.03928123414516449\n",
            "step 29: generator_loss=-0.0056469617411494255, discriminator_loss=0.025729114189743996\n",
            "step 30: generator_loss=-0.0017005216795951128, discriminator_loss=0.023480543866753578\n",
            "step 31: generator_loss=-0.0004876058083027601, discriminator_loss=0.02063393034040928\n",
            "step 32: generator_loss=-0.00014918878150638193, discriminator_loss=0.016438916325569153\n",
            "step 33: generator_loss=-3.141975321341306e-05, discriminator_loss=0.024002671241760254\n",
            "step 34: generator_loss=-1.61530842888169e-05, discriminator_loss=0.014242352917790413\n",
            "step 35: generator_loss=-1.7188253877975512e-06, discriminator_loss=0.013243244029581547\n",
            "step 36: generator_loss=-1.608490606486157e-06, discriminator_loss=0.016498832032084465\n",
            "step 37: generator_loss=-1.1637039278866723e-06, discriminator_loss=0.011462568305432796\n",
            "step 38: generator_loss=-2.155365024236744e-07, discriminator_loss=0.01323523186147213\n",
            "step 39: generator_loss=-1.736656258799485e-07, discriminator_loss=0.012972401455044746\n",
            "step 40: generator_loss=-7.716118233247471e-08, discriminator_loss=0.009592409245669842\n",
            "step 41: generator_loss=-8.60473107877624e-07, discriminator_loss=0.010868994519114494\n",
            "step 42: generator_loss=-6.082018444431014e-08, discriminator_loss=0.009793523699045181\n",
            "step 43: generator_loss=-7.568195314888726e-08, discriminator_loss=0.0077350023202598095\n",
            "step 44: generator_loss=-8.465072198760026e-09, discriminator_loss=0.009312775917351246\n",
            "step 45: generator_loss=-2.2549610179112278e-08, discriminator_loss=0.005501102656126022\n",
            "step 46: generator_loss=-2.1803499006267657e-09, discriminator_loss=0.008126048371195793\n",
            "step 47: generator_loss=-2.7193589602347856e-09, discriminator_loss=0.0047163148410618305\n",
            "step 48: generator_loss=-9.508390741430617e-10, discriminator_loss=0.006261978764086962\n",
            "step 49: generator_loss=-3.4441280938324326e-09, discriminator_loss=0.005884813144803047\n",
            "step 50: generator_loss=-7.427048975827688e-10, discriminator_loss=0.004282785579562187\n",
            "step 51: generator_loss=-3.6568619243837475e-09, discriminator_loss=0.00579261127859354\n",
            "step 52: generator_loss=-3.7944656305910485e-09, discriminator_loss=0.005355429835617542\n",
            "step 53: generator_loss=-8.162221454277585e-10, discriminator_loss=0.004377433098852634\n",
            "step 54: generator_loss=-1.1647974140771566e-08, discriminator_loss=0.004342373460531235\n",
            "step 55: generator_loss=-4.104468709353881e-10, discriminator_loss=0.0033711607102304697\n",
            "step 56: generator_loss=-1.8419693548210603e-09, discriminator_loss=0.004906869493424892\n",
            "step 57: generator_loss=-4.060198288691197e-10, discriminator_loss=0.003172831377014518\n",
            "step 58: generator_loss=-1.0476992606811564e-09, discriminator_loss=0.004595105070620775\n",
            "step 59: generator_loss=-7.663317203032705e-11, discriminator_loss=0.0030095528345555067\n",
            "step 60: generator_loss=-1.3113124475161442e-10, discriminator_loss=0.003256887663155794\n",
            "step 61: generator_loss=-1.1352914164319827e-09, discriminator_loss=0.0027593562845140696\n",
            "step 62: generator_loss=-5.571144101601533e-10, discriminator_loss=0.0031390085350722075\n",
            "step 63: generator_loss=-9.668312817012747e-10, discriminator_loss=0.0036122070159763098\n",
            "step 64: generator_loss=-1.7592294287993582e-10, discriminator_loss=0.0026331970002502203\n",
            "step 65: generator_loss=-1.183430714535305e-10, discriminator_loss=0.0033181444741785526\n",
            "step 66: generator_loss=-3.4108793567355633e-10, discriminator_loss=0.0019363855244591832\n",
            "step 67: generator_loss=-1.7574840194267694e-10, discriminator_loss=0.0014904079725965858\n",
            "step 68: generator_loss=-3.985970928321869e-11, discriminator_loss=0.003593357978388667\n",
            "step 69: generator_loss=-1.415828287942844e-10, discriminator_loss=0.0016150946030393243\n",
            "step 70: generator_loss=-1.0947474038403016e-09, discriminator_loss=0.002296024700626731\n",
            "step 71: generator_loss=-2.552029698676961e-10, discriminator_loss=0.002274280646815896\n",
            "step 72: generator_loss=-3.559444683443047e-10, discriminator_loss=0.0016909096157178283\n",
            "step 73: generator_loss=-4.1765446656683025e-10, discriminator_loss=0.0023863466922193766\n",
            "step 74: generator_loss=-1.0799077188039519e-09, discriminator_loss=0.0019658016972243786\n",
            "step 75: generator_loss=-1.7520399020476418e-10, discriminator_loss=0.0019657143857330084\n",
            "step 76: generator_loss=-6.817245379320269e-11, discriminator_loss=0.0015566269867122173\n",
            "step 77: generator_loss=-9.531939126894429e-11, discriminator_loss=0.0024099815636873245\n",
            "step 78: generator_loss=-1.0999460370308967e-10, discriminator_loss=0.0015583410859107971\n",
            "step 79: generator_loss=-1.0031174502156404e-10, discriminator_loss=0.0018271058797836304\n",
            "step 80: generator_loss=-9.606391376815182e-11, discriminator_loss=0.0013301557628437877\n",
            "step 81: generator_loss=-3.3461421133917923e-11, discriminator_loss=0.002569884527474642\n",
            "step 82: generator_loss=-1.4157897076927384e-10, discriminator_loss=0.0012922020396217704\n",
            "step 83: generator_loss=-2.7951512632240494e-11, discriminator_loss=0.002283059060573578\n",
            "step 84: generator_loss=-1.0927125176918295e-10, discriminator_loss=0.0010483814403414726\n",
            "step 85: generator_loss=-1.5209697390439203e-10, discriminator_loss=0.0022313860245049\n",
            "step 86: generator_loss=-3.190628872218326e-10, discriminator_loss=0.0016437842277809978\n",
            "step 87: generator_loss=-1.774430741230404e-10, discriminator_loss=0.0012415263336151838\n",
            "step 88: generator_loss=-6.492582027561866e-10, discriminator_loss=0.00227488880045712\n",
            "step 89: generator_loss=-3.4964184325581016e-10, discriminator_loss=0.001594092114828527\n",
            "step 90: generator_loss=-1.0033426173228222e-10, discriminator_loss=0.002138173207640648\n",
            "step 91: generator_loss=-2.0614445706002016e-09, discriminator_loss=0.0013916451716795564\n",
            "step 92: generator_loss=-2.4392921016413993e-10, discriminator_loss=0.0010273655643686652\n",
            "step 93: generator_loss=-2.5701862860216806e-10, discriminator_loss=0.0012328841257840395\n",
            "step 94: generator_loss=-1.1580422731860551e-10, discriminator_loss=0.0013721005525439978\n",
            "step 95: generator_loss=-7.022579046056521e-11, discriminator_loss=0.0010479954071342945\n",
            "step 96: generator_loss=-8.360549474950574e-10, discriminator_loss=0.001039872644469142\n",
            "step 97: generator_loss=-8.008771423817507e-11, discriminator_loss=0.0008910549804568291\n",
            "step 98: generator_loss=-1.4735741793447943e-10, discriminator_loss=0.0010222411947324872\n",
            "step 99: generator_loss=-6.964201992865071e-10, discriminator_loss=0.0019661264959722757\n",
            "step 100: generator_loss=-6.023476717409437e-10, discriminator_loss=0.0017217232380062342\n",
            "step 101: generator_loss=-5.266191038799661e-09, discriminator_loss=0.0010031271958723664\n",
            "step 102: generator_loss=-1.0590536225763003e-09, discriminator_loss=0.0007118096109479666\n",
            "step 103: generator_loss=-3.04179292864859e-10, discriminator_loss=0.0013373164692893624\n",
            "step 104: generator_loss=-1.6661344526269772e-10, discriminator_loss=0.001121821696870029\n",
            "step 105: generator_loss=-3.24147264585406e-10, discriminator_loss=0.0015449601924046874\n",
            "step 106: generator_loss=-9.609802953391977e-10, discriminator_loss=0.0015083092730492353\n",
            "step 107: generator_loss=-1.0155647156562253e-10, discriminator_loss=0.0007954399916343391\n",
            "step 108: generator_loss=-3.252625252470054e-11, discriminator_loss=0.0009612331632524729\n",
            "step 109: generator_loss=-1.5012623089116772e-10, discriminator_loss=0.0010677727404981852\n",
            "step 110: generator_loss=-8.362289749541674e-10, discriminator_loss=0.0007023726939223707\n",
            "step 111: generator_loss=-1.3234599527400803e-10, discriminator_loss=0.0010955907637253404\n",
            "step 112: generator_loss=-8.916977711770357e-10, discriminator_loss=0.00090342469047755\n",
            "step 113: generator_loss=-6.335797997358839e-10, discriminator_loss=0.0009203766821883619\n",
            "step 114: generator_loss=-6.314831990650305e-11, discriminator_loss=0.0006629243725910783\n",
            "step 115: generator_loss=-2.329915149701378e-10, discriminator_loss=0.001664725597947836\n",
            "step 116: generator_loss=-1.0826189250634499e-10, discriminator_loss=0.0006323736160993576\n",
            "step 117: generator_loss=-2.7866819962696354e-10, discriminator_loss=0.0006991823320277035\n",
            "step 118: generator_loss=-6.164790206097948e-11, discriminator_loss=0.0010571407619863749\n",
            "step 119: generator_loss=-7.184777772728523e-11, discriminator_loss=0.0012923816684633493\n",
            "step 120: generator_loss=-1.4068909925946116e-10, discriminator_loss=0.0008560208952985704\n",
            "step 121: generator_loss=-1.1449058368029341e-10, discriminator_loss=0.0008495833026245236\n",
            "step 122: generator_loss=-7.119159151081078e-10, discriminator_loss=0.000888031383510679\n",
            "step 123: generator_loss=-1.3621915817552122e-09, discriminator_loss=0.0010352241806685925\n",
            "step 124: generator_loss=-2.9948599156170985e-11, discriminator_loss=0.0008374181925319135\n",
            "step 125: generator_loss=-3.1886632223532274e-10, discriminator_loss=0.0008697768789716065\n",
            "step 126: generator_loss=-7.430739357161542e-11, discriminator_loss=0.0005996633553877473\n",
            "step 127: generator_loss=-4.0854067351325796e-10, discriminator_loss=0.0007058092160150409\n",
            "step 128: generator_loss=-2.2413673694821057e-10, discriminator_loss=0.0005803974345326424\n",
            "step 129: generator_loss=-9.694305080909515e-11, discriminator_loss=0.0006597180035896599\n",
            "step 130: generator_loss=-9.177175686048145e-11, discriminator_loss=0.0008819172508083284\n",
            "step 131: generator_loss=-2.834368018067579e-10, discriminator_loss=0.0009043547324836254\n",
            "step 132: generator_loss=-1.2869311172281073e-09, discriminator_loss=0.0006707725115120411\n",
            "step 133: generator_loss=-1.8243809241091924e-10, discriminator_loss=0.0009148368844762444\n",
            "step 134: generator_loss=-6.40319255951205e-11, discriminator_loss=0.0011993739753961563\n",
            "step 135: generator_loss=-3.94738020048635e-09, discriminator_loss=0.0008126102620735765\n",
            "step 136: generator_loss=-9.014298751885974e-10, discriminator_loss=0.0007603938574902713\n",
            "step 137: generator_loss=-5.949597481347269e-10, discriminator_loss=0.00042474071960896254\n",
            "step 138: generator_loss=-2.0913810960809798e-10, discriminator_loss=0.0011793205048888922\n",
            "step 139: generator_loss=-3.7879183123479265e-10, discriminator_loss=0.000578239792957902\n",
            "step 140: generator_loss=-9.099722364513951e-11, discriminator_loss=0.0004359351587481797\n",
            "step 141: generator_loss=-2.5349647381212037e-10, discriminator_loss=0.0008260143222287297\n",
            "step 142: generator_loss=-7.307396909794761e-10, discriminator_loss=0.00035937162465415895\n",
            "step 143: generator_loss=-4.698423872184776e-10, discriminator_loss=0.001536225201562047\n",
            "step 144: generator_loss=-2.462994252994122e-10, discriminator_loss=0.00047227778122760355\n",
            "step 145: generator_loss=-1.0645286735444515e-10, discriminator_loss=0.00044805140350945294\n",
            "step 146: generator_loss=-4.494251082398648e-10, discriminator_loss=0.0009103154297918081\n",
            "step 147: generator_loss=-6.489404014153877e-10, discriminator_loss=0.0005350001156330109\n",
            "step 148: generator_loss=-1.1559787849169112e-10, discriminator_loss=0.0006248491699807346\n",
            "step 149: generator_loss=-5.373971267985667e-10, discriminator_loss=0.00046672276221215725\n",
            "step 150: generator_loss=-2.96802499244464e-10, discriminator_loss=0.000541206041816622\n",
            "step 151: generator_loss=-2.522929642978511e-10, discriminator_loss=0.0008519518305547535\n",
            "step 152: generator_loss=-4.179029122752809e-09, discriminator_loss=0.0005534651572816074\n",
            "step 153: generator_loss=-9.815472878926812e-10, discriminator_loss=0.0003540948673617095\n",
            "step 154: generator_loss=-2.1366980407222513e-10, discriminator_loss=0.0009634513407945633\n",
            "step 155: generator_loss=-1.989689246695292e-10, discriminator_loss=0.0005174889229238033\n",
            "step 156: generator_loss=-2.3818502725703183e-10, discriminator_loss=0.0005123795126564801\n",
            "step 157: generator_loss=-1.2506101709774953e-10, discriminator_loss=0.00041739706648513675\n",
            "step 158: generator_loss=-1.134660351786998e-10, discriminator_loss=0.0004995014751330018\n",
            "step 159: generator_loss=-5.158238280955629e-10, discriminator_loss=0.0012080601882189512\n",
            "step 160: generator_loss=-4.145361831575656e-10, discriminator_loss=0.0004553245671559125\n",
            "step 161: generator_loss=-9.205310125270927e-11, discriminator_loss=0.0010982718085870147\n",
            "step 162: generator_loss=-2.710082158685623e-10, discriminator_loss=0.0006678819190710783\n",
            "step 163: generator_loss=-4.100700057296791e-10, discriminator_loss=0.0005771117866970599\n",
            "step 164: generator_loss=-1.9004964268987123e-09, discriminator_loss=0.0004928697599098086\n",
            "step 165: generator_loss=-3.3838132296182266e-10, discriminator_loss=0.0005804227548651397\n",
            "step 166: generator_loss=-5.040321493510191e-10, discriminator_loss=0.0004278220876585692\n",
            "step 167: generator_loss=-1.2641536428770195e-10, discriminator_loss=0.0004908783012069762\n",
            "step 168: generator_loss=-2.7829842597082433e-11, discriminator_loss=0.00026282030739821494\n",
            "step 169: generator_loss=-4.7454543766756174e-11, discriminator_loss=0.0005847001448273659\n",
            "step 170: generator_loss=-4.364150707480974e-10, discriminator_loss=0.0005092063802294433\n",
            "step 171: generator_loss=-9.199264960901843e-11, discriminator_loss=0.0004079832579009235\n",
            "step 172: generator_loss=-3.4879793497921696e-10, discriminator_loss=0.000826643721666187\n",
            "step 173: generator_loss=-8.656204919521571e-11, discriminator_loss=0.0006319310632534325\n",
            "step 174: generator_loss=-7.866229889685883e-10, discriminator_loss=0.00069000746589154\n",
            "step 175: generator_loss=-8.24365853357989e-11, discriminator_loss=0.0003471766540315002\n",
            "step 176: generator_loss=-1.662754656184262e-10, discriminator_loss=0.0006627917755395174\n",
            "step 177: generator_loss=-2.4020352373810283e-10, discriminator_loss=0.0012585140066221356\n",
            "step 178: generator_loss=-7.292438319872474e-10, discriminator_loss=0.0004966372507624328\n",
            "step 179: generator_loss=-1.2417117334351246e-10, discriminator_loss=0.0003375482920091599\n",
            "step 180: generator_loss=-6.520843420787514e-09, discriminator_loss=0.0003686775453388691\n",
            "step 181: generator_loss=-5.474645625724861e-09, discriminator_loss=0.000260762230027467\n",
            "step 182: generator_loss=-2.023234496606463e-10, discriminator_loss=0.0005063128191977739\n",
            "step 183: generator_loss=-7.706954519015596e-10, discriminator_loss=0.00039478819235228\n",
            "step 184: generator_loss=-1.3351036942665928e-10, discriminator_loss=0.0002942736609838903\n",
            "step 185: generator_loss=-2.0671514500136823e-10, discriminator_loss=0.0006131317932158709\n",
            "step 186: generator_loss=-1.672910698857777e-10, discriminator_loss=0.0005708091775886714\n",
            "step 187: generator_loss=-4.4213788186198144e-10, discriminator_loss=0.0002745640813373029\n",
            "step 188: generator_loss=-2.1088043811179347e-10, discriminator_loss=0.0004305511829443276\n",
            "step 189: generator_loss=-2.6835586530715716e-10, discriminator_loss=0.0003284304984845221\n",
            "step 190: generator_loss=-5.1958118363337746e-11, discriminator_loss=0.0006310967146418989\n",
            "step 191: generator_loss=-2.119311837134319e-09, discriminator_loss=0.0007009349064901471\n",
            "step 192: generator_loss=-3.9960695863427986e-10, discriminator_loss=0.000484156102174893\n",
            "step 193: generator_loss=-1.608186223078789e-10, discriminator_loss=0.0008813830791041255\n",
            "step 194: generator_loss=-8.960875930164036e-10, discriminator_loss=0.00036860370892100036\n",
            "step 195: generator_loss=-2.3327331385991634e-11, discriminator_loss=0.000480756803881377\n",
            "step 196: generator_loss=-2.4772288664820508e-09, discriminator_loss=0.00026915015769191086\n",
            "step 197: generator_loss=-1.0853004606126149e-10, discriminator_loss=0.00039203412597998977\n",
            "step 198: generator_loss=-3.6409031345385756e-10, discriminator_loss=0.00032553094206377864\n",
            "step 199: generator_loss=-2.276596688943755e-10, discriminator_loss=0.0003268891014158726\n",
            "step 200: generator_loss=-7.234620680307557e-10, discriminator_loss=0.000508483441080898\n",
            "step 201: generator_loss=-1.7382620343120436e-10, discriminator_loss=0.000369072804460302\n",
            "step 202: generator_loss=-8.847923088639575e-11, discriminator_loss=0.00033800574601627886\n",
            "step 203: generator_loss=-8.104163451427837e-10, discriminator_loss=0.00038032582961022854\n",
            "step 204: generator_loss=-4.0676759183178035e-10, discriminator_loss=0.00022811141388956457\n",
            "step 205: generator_loss=-2.7081661357897246e-09, discriminator_loss=0.0006112919072620571\n",
            "step 206: generator_loss=-2.2550205258653477e-08, discriminator_loss=0.0003042609023395926\n",
            "step 207: generator_loss=-1.0730848154505424e-10, discriminator_loss=0.0003416673862375319\n",
            "step 208: generator_loss=-2.4460113934310357e-09, discriminator_loss=0.0002855314814951271\n",
            "step 209: generator_loss=-1.1122975457356077e-10, discriminator_loss=0.00025535403983667493\n",
            "step 210: generator_loss=-3.0778729565028584e-10, discriminator_loss=0.00040160512435249984\n",
            "step 211: generator_loss=-1.846616193290629e-10, discriminator_loss=0.00026563453138805926\n",
            "step 212: generator_loss=-4.8468247193511615e-09, discriminator_loss=0.0003445341426413506\n",
            "step 213: generator_loss=-3.4635497248025615e-10, discriminator_loss=0.00041806825902312994\n",
            "step 214: generator_loss=-6.518061090865501e-10, discriminator_loss=0.00023725858773104846\n",
            "step 215: generator_loss=-6.725108248062384e-10, discriminator_loss=0.0006724044214934111\n",
            "step 216: generator_loss=-2.1144445916387866e-10, discriminator_loss=0.00012216861068736762\n",
            "step 217: generator_loss=-1.549062766947884e-09, discriminator_loss=0.0003881363954860717\n",
            "step 218: generator_loss=-6.708397726207238e-11, discriminator_loss=0.00025045385700650513\n",
            "step 219: generator_loss=-4.48713677325685e-10, discriminator_loss=0.00025332707446068525\n",
            "step 220: generator_loss=-2.3156404571622602e-10, discriminator_loss=0.0002603199100121856\n",
            "step 221: generator_loss=-1.0454532378689763e-10, discriminator_loss=0.0002116734249284491\n",
            "step 222: generator_loss=-4.612721593577618e-10, discriminator_loss=0.0002648851368576288\n",
            "step 223: generator_loss=-1.1960533952137808e-10, discriminator_loss=0.00031662426772527397\n",
            "step 224: generator_loss=-1.1495358831492553e-10, discriminator_loss=0.0005212389514781535\n",
            "step 225: generator_loss=-1.8206804119902387e-10, discriminator_loss=0.00026736679137684405\n",
            "step 226: generator_loss=-1.5907222761235573e-10, discriminator_loss=0.0007206637528724968\n",
            "step 227: generator_loss=-1.7436213584076654e-10, discriminator_loss=0.0001683486916590482\n",
            "step 228: generator_loss=-3.398256953612844e-10, discriminator_loss=0.00041996422805823386\n",
            "step 229: generator_loss=-1.0600762628820704e-10, discriminator_loss=0.0003100262547377497\n",
            "step 230: generator_loss=-9.012999790947163e-10, discriminator_loss=0.0003075211716350168\n",
            "step 231: generator_loss=-6.9963115301163725e-09, discriminator_loss=0.00023853153106756508\n",
            "step 232: generator_loss=-3.765860193127857e-11, discriminator_loss=0.0004283237794879824\n",
            "step 233: generator_loss=-5.8960876181402e-09, discriminator_loss=0.0002420944656478241\n",
            "step 234: generator_loss=-6.302283139802967e-09, discriminator_loss=0.0004463676013983786\n",
            "step 235: generator_loss=-1.3290112066410842e-10, discriminator_loss=0.0003657541237771511\n",
            "step 236: generator_loss=-1.1003180311330851e-10, discriminator_loss=0.0003112738486379385\n",
            "step 237: generator_loss=-3.643249868456877e-10, discriminator_loss=0.00035044390824623406\n",
            "step 238: generator_loss=-7.311841132562336e-10, discriminator_loss=0.00036061136052012444\n",
            "step 239: generator_loss=-2.7523178180999253e-10, discriminator_loss=0.0003948296362068504\n",
            "step 240: generator_loss=-9.408170076330435e-11, discriminator_loss=0.00033209187677130103\n",
            "step 241: generator_loss=-9.43410127796085e-10, discriminator_loss=0.00024040453718043864\n",
            "step 242: generator_loss=-4.845543410958442e-10, discriminator_loss=0.00028506224043667316\n",
            "step 243: generator_loss=-2.950111543942313e-10, discriminator_loss=0.00038606379530392587\n",
            "step 244: generator_loss=-1.4120316027543822e-10, discriminator_loss=0.00019665401487145573\n",
            "step 245: generator_loss=-1.5359404026416001e-10, discriminator_loss=0.00028063173522241414\n",
            "step 246: generator_loss=-9.736516454195154e-11, discriminator_loss=0.00041750608943402767\n",
            "step 247: generator_loss=-1.469574184564948e-10, discriminator_loss=0.0003061690367758274\n",
            "step 248: generator_loss=-7.485075337321234e-10, discriminator_loss=0.00027785103884525597\n",
            "step 249: generator_loss=-1.5836895683740693e-10, discriminator_loss=0.0002810919831972569\n",
            "step 250: generator_loss=-3.8128576684837157e-11, discriminator_loss=0.00017917693185154349\n",
            "step 251: generator_loss=-1.293576579186606e-09, discriminator_loss=0.0003873526002280414\n",
            "step 252: generator_loss=-2.8984636912809947e-10, discriminator_loss=0.00018284347606822848\n",
            "step 253: generator_loss=-5.424927174146887e-10, discriminator_loss=0.0003582134668249637\n",
            "step 254: generator_loss=-5.4649104685999816e-11, discriminator_loss=0.00042859811219386756\n",
            "step 255: generator_loss=-1.298028351470748e-09, discriminator_loss=0.00028848741203546524\n",
            "step 256: generator_loss=-7.442916283295631e-10, discriminator_loss=0.00013493563164956868\n",
            "step 257: generator_loss=-3.558858208130289e-10, discriminator_loss=0.00031925871735438704\n",
            "step 258: generator_loss=-5.2797089616918313e-11, discriminator_loss=0.000244440627284348\n",
            "step 259: generator_loss=-2.3910617930056333e-10, discriminator_loss=0.0004766839847434312\n",
            "step 260: generator_loss=-2.2450027947762408e-10, discriminator_loss=0.00017118759569711983\n",
            "step 261: generator_loss=-1.3264485343444932e-10, discriminator_loss=0.00015946314670145512\n",
            "step 262: generator_loss=-3.8617034570087583e-10, discriminator_loss=0.00035976318758912385\n",
            "step 263: generator_loss=-4.512880624751858e-10, discriminator_loss=0.0002457770169712603\n",
            "step 264: generator_loss=-3.001902615373808e-10, discriminator_loss=0.00019886819063685834\n",
            "step 265: generator_loss=-2.1489685031461647e-10, discriminator_loss=0.00019054229778703302\n",
            "step 266: generator_loss=-1.2002797866728088e-08, discriminator_loss=0.00026973371859639883\n",
            "step 267: generator_loss=-4.103957618184495e-09, discriminator_loss=0.0003297313814982772\n",
            "step 268: generator_loss=-5.550149784205871e-10, discriminator_loss=0.00015748341684229672\n",
            "step 269: generator_loss=-5.519094070649544e-10, discriminator_loss=0.00028869457310065627\n",
            "step 270: generator_loss=-1.4177645168977904e-10, discriminator_loss=0.00024092082458082587\n",
            "step 271: generator_loss=-1.8479986985120433e-10, discriminator_loss=0.0003432552912272513\n",
            "step 272: generator_loss=-1.215661599163198e-10, discriminator_loss=0.0005643474287353456\n",
            "step 273: generator_loss=-1.072505417809566e-09, discriminator_loss=0.00014353748701978475\n",
            "step 274: generator_loss=-2.1612425737949081e-10, discriminator_loss=0.00019230053294450045\n",
            "step 275: generator_loss=-3.027285089274301e-10, discriminator_loss=0.00024118306464515626\n",
            "step 276: generator_loss=-2.381528307893177e-10, discriminator_loss=0.0003332928172312677\n",
            "step 277: generator_loss=-8.702830817108875e-11, discriminator_loss=0.0003100054746028036\n",
            "step 278: generator_loss=-1.402327698407646e-10, discriminator_loss=0.0004771172534674406\n",
            "step 279: generator_loss=-7.257178191721891e-10, discriminator_loss=0.00019494976731948555\n",
            "step 280: generator_loss=-3.348729349372803e-10, discriminator_loss=0.00016529555432498455\n",
            "step 281: generator_loss=-1.3833659218143168e-10, discriminator_loss=0.00033668457763269544\n",
            "step 282: generator_loss=-1.63297236843718e-10, discriminator_loss=0.0003447796043474227\n",
            "step 283: generator_loss=-2.2525448173382756e-09, discriminator_loss=0.00015017259283922613\n",
            "step 284: generator_loss=-4.001424747102078e-10, discriminator_loss=0.00025148954591713846\n",
            "step 285: generator_loss=-4.768652833719855e-11, discriminator_loss=0.0002146494953194633\n",
            "step 286: generator_loss=-5.638604028135319e-10, discriminator_loss=0.0001539221266284585\n",
            "step 287: generator_loss=-2.4850041469015594e-10, discriminator_loss=0.00026536406949162483\n",
            "step 288: generator_loss=-1.0518018400684781e-10, discriminator_loss=0.0002449320163577795\n",
            "step 289: generator_loss=-9.143809598377572e-10, discriminator_loss=0.0002253109560115263\n",
            "step 290: generator_loss=-3.114122293368382e-10, discriminator_loss=0.0002647705841809511\n",
            "step 291: generator_loss=-1.54111140515667e-10, discriminator_loss=0.0002771693980321288\n",
            "step 292: generator_loss=-2.93906357584639e-11, discriminator_loss=0.00014614987594541162\n",
            "step 293: generator_loss=-1.455689702112295e-08, discriminator_loss=0.00028412489336915314\n",
            "step 294: generator_loss=-3.4299085793776385e-10, discriminator_loss=0.000174960310687311\n",
            "step 295: generator_loss=-5.157848592673986e-10, discriminator_loss=0.00026983910356648266\n",
            "step 296: generator_loss=-5.827762716847928e-10, discriminator_loss=0.00041948113357648253\n",
            "step 297: generator_loss=-5.250033185966174e-10, discriminator_loss=0.0003232613380532712\n",
            "step 298: generator_loss=-4.937872333243831e-10, discriminator_loss=0.0002473587228450924\n",
            "step 299: generator_loss=-1.1631609009299382e-09, discriminator_loss=0.0001857811294030398\n",
            "step 300: generator_loss=-2.050677405662782e-10, discriminator_loss=0.00023645734472665936\n",
            "step 301: generator_loss=-2.2975017721638125e-10, discriminator_loss=0.00017846118134912103\n",
            "step 302: generator_loss=-1.729928283955573e-10, discriminator_loss=0.00023576793319080025\n",
            "step 303: generator_loss=-1.6603848851381997e-10, discriminator_loss=0.0002404198603471741\n",
            "step 304: generator_loss=-6.173926647701222e-11, discriminator_loss=0.00010784460027934983\n",
            "step 305: generator_loss=-9.777742504546438e-11, discriminator_loss=0.00022005521168466657\n",
            "step 306: generator_loss=-4.5296547762641026e-11, discriminator_loss=8.638068538857624e-05\n",
            "step 307: generator_loss=-1.834266905031967e-10, discriminator_loss=0.00022389221703633666\n",
            "step 308: generator_loss=-3.506198942293537e-10, discriminator_loss=0.0001683806476648897\n",
            "step 309: generator_loss=-6.557737020074228e-09, discriminator_loss=0.00016398417938034981\n",
            "step 310: generator_loss=-6.678735786636025e-09, discriminator_loss=0.0001310716470470652\n",
            "step 311: generator_loss=-7.486115893851064e-11, discriminator_loss=0.00021160542382858694\n",
            "step 312: generator_loss=-1.264276877632753e-10, discriminator_loss=0.00022059294860810041\n",
            "step 313: generator_loss=-5.008070069756343e-10, discriminator_loss=0.00019083208462689072\n",
            "step 314: generator_loss=-7.635969634378625e-11, discriminator_loss=0.00014624797040596604\n",
            "step 315: generator_loss=-8.46701667112093e-11, discriminator_loss=0.00024824481806717813\n",
            "step 316: generator_loss=-1.0907354186517892e-10, discriminator_loss=0.00021142381592653692\n",
            "step 317: generator_loss=-3.523322744669599e-10, discriminator_loss=0.00017865031259134412\n",
            "step 318: generator_loss=-8.686920627276606e-10, discriminator_loss=0.000400328979594633\n",
            "step 319: generator_loss=-1.895038570509655e-10, discriminator_loss=0.0002659090969245881\n",
            "step 320: generator_loss=-1.4499562661640653e-10, discriminator_loss=0.0003159209154546261\n",
            "step 321: generator_loss=-6.538827812541115e-11, discriminator_loss=0.0002509854093659669\n",
            "step 322: generator_loss=-1.1205487926435609e-10, discriminator_loss=0.00021095717966090888\n",
            "step 323: generator_loss=-1.0844003472954e-10, discriminator_loss=0.0003679589426610619\n",
            "step 324: generator_loss=-9.080088902990724e-10, discriminator_loss=0.00021475601533893496\n",
            "step 325: generator_loss=-2.531002907257829e-10, discriminator_loss=0.00024492357624694705\n",
            "step 326: generator_loss=-1.66136909784953e-10, discriminator_loss=9.583288192516193e-05\n",
            "step 327: generator_loss=-2.0345160278711916e-10, discriminator_loss=9.450611105421558e-05\n",
            "step 328: generator_loss=-1.5054682500625916e-10, discriminator_loss=0.00040021989843808115\n",
            "step 329: generator_loss=-2.1486450119123646e-10, discriminator_loss=0.0001388564269291237\n",
            "step 330: generator_loss=-5.886466314386496e-11, discriminator_loss=0.00012161753693362698\n",
            "step 331: generator_loss=-1.1447517933582674e-10, discriminator_loss=0.00018016759713646024\n",
            "step 332: generator_loss=-3.6550584781025464e-10, discriminator_loss=0.00010302528244210407\n",
            "step 333: generator_loss=-1.540708671754487e-10, discriminator_loss=0.00011344404629198834\n",
            "step 334: generator_loss=-1.0817667595031111e-10, discriminator_loss=0.00017442043463233858\n",
            "step 335: generator_loss=-3.7148303877465594e-10, discriminator_loss=0.00017348650726489723\n",
            "step 336: generator_loss=-1.658700260476209e-10, discriminator_loss=6.700417725369334e-05\n",
            "step 337: generator_loss=-4.782168550043764e-10, discriminator_loss=0.0005940551636740565\n",
            "step 338: generator_loss=-5.868657643182118e-11, discriminator_loss=0.0001709482166916132\n",
            "step 339: generator_loss=-3.584680607904289e-10, discriminator_loss=0.00016957111074589193\n",
            "step 340: generator_loss=-8.928817407660716e-11, discriminator_loss=0.00014885913697071373\n",
            "step 341: generator_loss=-7.814398433891867e-11, discriminator_loss=0.0001714170939521864\n",
            "step 342: generator_loss=-4.3245171332806365e-10, discriminator_loss=0.00014103415014687926\n",
            "step 343: generator_loss=-3.066011333707763e-10, discriminator_loss=0.0002666400105226785\n",
            "step 344: generator_loss=-3.363030687264512e-10, discriminator_loss=0.00022662871924694628\n",
            "step 345: generator_loss=-1.1554019963000428e-09, discriminator_loss=0.00015952260582707822\n",
            "step 346: generator_loss=-1.8363373044394393e-09, discriminator_loss=0.00018853180517908186\n",
            "step 347: generator_loss=-2.0887575002959125e-10, discriminator_loss=0.0001545346312923357\n",
            "step 348: generator_loss=-1.753075740129617e-10, discriminator_loss=0.00029082541004754603\n",
            "step 349: generator_loss=-2.991010217279211e-10, discriminator_loss=0.0005423789843916893\n",
            "step 350: generator_loss=-7.528552004032463e-09, discriminator_loss=0.00010978351201629266\n",
            "step 351: generator_loss=-7.652536382352082e-10, discriminator_loss=0.000117730516649317\n",
            "step 352: generator_loss=-9.759214963933616e-11, discriminator_loss=0.00012424866145011038\n",
            "step 353: generator_loss=-1.4786036284242243e-10, discriminator_loss=0.00023037476057652384\n",
            "step 354: generator_loss=-1.526095472215161e-09, discriminator_loss=0.00018883557640947402\n",
            "step 355: generator_loss=-2.08191575090666e-10, discriminator_loss=0.00033751330920495093\n",
            "step 356: generator_loss=-4.0005554424737966e-11, discriminator_loss=0.0001657732209423557\n",
            "step 357: generator_loss=-3.669730352928724e-10, discriminator_loss=7.287483458640054e-05\n",
            "step 358: generator_loss=-5.377120970706528e-10, discriminator_loss=0.0001347064389847219\n",
            "step 359: generator_loss=-1.2361575651986811e-10, discriminator_loss=0.00015504061593674123\n",
            "step 360: generator_loss=-1.984551412093083e-10, discriminator_loss=0.0002742766810115427\n",
            "step 361: generator_loss=-1.901318269492691e-10, discriminator_loss=0.00015669975255150348\n",
            "step 362: generator_loss=-6.022045639930695e-10, discriminator_loss=0.00011626656487351283\n",
            "step 363: generator_loss=-2.4450855229396495e-10, discriminator_loss=0.00021991734683979303\n",
            "step 364: generator_loss=-8.315875071884804e-11, discriminator_loss=9.671146108303219e-05\n",
            "step 365: generator_loss=-2.1814473838421833e-10, discriminator_loss=0.000262939662206918\n",
            "step 366: generator_loss=-1.242151242974998e-10, discriminator_loss=0.00013905364903621376\n",
            "step 367: generator_loss=-5.626609178577269e-10, discriminator_loss=0.00014405757247004658\n",
            "step 368: generator_loss=-2.61143218160953e-10, discriminator_loss=5.459029853227548e-05\n",
            "step 369: generator_loss=-1.0943716766131928e-10, discriminator_loss=7.95869855210185e-05\n",
            "step 370: generator_loss=-2.855092606779408e-09, discriminator_loss=0.000616842124145478\n",
            "step 371: generator_loss=-7.871897578226594e-11, discriminator_loss=7.323808677028865e-05\n",
            "step 372: generator_loss=-4.773852424477809e-09, discriminator_loss=0.00016448550741188228\n",
            "step 373: generator_loss=-4.679717030553476e-11, discriminator_loss=0.00017248716903850436\n",
            "step 374: generator_loss=-4.79099870887012e-10, discriminator_loss=0.00020478665828704834\n",
            "step 375: generator_loss=-5.347453035930982e-10, discriminator_loss=0.00012199161574244499\n",
            "step 376: generator_loss=-1.7167052501765312e-10, discriminator_loss=0.00015274023462552577\n",
            "step 377: generator_loss=-8.203678708573747e-11, discriminator_loss=0.00011198583524674177\n",
            "step 378: generator_loss=-9.509530662921151e-11, discriminator_loss=0.00023635593242943287\n",
            "step 379: generator_loss=-3.193643960397452e-10, discriminator_loss=0.00012463072198443115\n",
            "step 380: generator_loss=-5.9035349941893855e-09, discriminator_loss=8.059563697315753e-05\n",
            "step 381: generator_loss=-4.003222406345763e-11, discriminator_loss=8.865273412084207e-05\n",
            "step 382: generator_loss=-3.4965620676619125e-11, discriminator_loss=7.841395563445985e-05\n",
            "step 383: generator_loss=-7.686886543956106e-11, discriminator_loss=0.00031416991259902716\n",
            "step 384: generator_loss=-6.524851214884109e-10, discriminator_loss=8.782988879829645e-05\n",
            "step 385: generator_loss=-6.327912638326438e-10, discriminator_loss=0.00025940328487195075\n",
            "step 386: generator_loss=-1.3550310873355897e-10, discriminator_loss=0.00011820303916465491\n",
            "step 387: generator_loss=-2.6357651616848443e-09, discriminator_loss=0.00019241317932028323\n",
            "step 388: generator_loss=-8.062644996087442e-10, discriminator_loss=0.0001523991668364033\n",
            "step 389: generator_loss=-1.0478344858455557e-09, discriminator_loss=0.00020448872237466276\n",
            "step 390: generator_loss=-7.984588545895122e-10, discriminator_loss=0.00022898726456332952\n",
            "step 391: generator_loss=-2.1631572089120255e-09, discriminator_loss=0.0004291652294341475\n",
            "step 392: generator_loss=-2.411621458087154e-10, discriminator_loss=0.00011766692477976903\n",
            "step 393: generator_loss=-1.6130632940480893e-10, discriminator_loss=9.994995343731716e-05\n",
            "step 394: generator_loss=-8.125626838051403e-10, discriminator_loss=0.00013210138422437012\n",
            "step 395: generator_loss=-2.121506303964793e-10, discriminator_loss=0.0001840664481278509\n",
            "step 396: generator_loss=-1.91036630958763e-09, discriminator_loss=0.00020235504780430347\n",
            "step 397: generator_loss=-6.349838432839761e-10, discriminator_loss=0.00016207584121730179\n",
            "step 398: generator_loss=-1.1402573329988286e-10, discriminator_loss=0.0002750665880739689\n",
            "step 399: generator_loss=-9.390345168114322e-10, discriminator_loss=0.00011980785347986966\n",
            "step 400: generator_loss=-5.179853213022056e-10, discriminator_loss=0.00015467593038920313\n",
            "step 401: generator_loss=-2.752169603326138e-10, discriminator_loss=0.00013399760064203292\n",
            "step 402: generator_loss=-5.440517480970186e-11, discriminator_loss=0.0001244570448761806\n",
            "step 403: generator_loss=-4.853384916181369e-10, discriminator_loss=8.54146564961411e-05\n",
            "step 404: generator_loss=-1.3380287156028459e-10, discriminator_loss=0.00013227223826106638\n",
            "step 405: generator_loss=-1.289239132118425e-10, discriminator_loss=9.52368209254928e-05\n",
            "step 406: generator_loss=-7.835953413914964e-11, discriminator_loss=8.634558616904542e-05\n",
            "step 407: generator_loss=-1.6252338363997865e-10, discriminator_loss=0.0002072033821605146\n",
            "step 408: generator_loss=-1.1333191052287361e-09, discriminator_loss=8.026868454180658e-05\n",
            "step 409: generator_loss=-1.2603974808289564e-10, discriminator_loss=0.00012779475946445018\n",
            "step 410: generator_loss=-8.223825787023742e-11, discriminator_loss=7.127479329938069e-05\n",
            "step 411: generator_loss=-1.0669851287226084e-11, discriminator_loss=8.398353384109214e-05\n",
            "step 412: generator_loss=-2.751804784040246e-09, discriminator_loss=0.00020492107432801276\n",
            "step 413: generator_loss=-2.649462038650796e-10, discriminator_loss=0.00010335757542634383\n",
            "step 414: generator_loss=-1.2236403001963936e-09, discriminator_loss=0.0001499425561632961\n",
            "step 415: generator_loss=-1.9225593339555758e-10, discriminator_loss=6.099192250985652e-05\n",
            "step 416: generator_loss=-3.9564875681241674e-11, discriminator_loss=8.907169831218198e-05\n",
            "step 417: generator_loss=-1.0375122982964058e-10, discriminator_loss=0.00023087991576176137\n",
            "step 418: generator_loss=-2.887822758701475e-10, discriminator_loss=0.00015742788673378527\n",
            "step 419: generator_loss=-4.584334301060977e-10, discriminator_loss=8.593202801421285e-05\n",
            "step 420: generator_loss=-7.0016958897412e-10, discriminator_loss=0.0002239038294646889\n",
            "step 421: generator_loss=-1.5555738641648276e-10, discriminator_loss=0.00011603788152569905\n",
            "step 422: generator_loss=-3.2051067355709506e-10, discriminator_loss=0.00018465817265678197\n",
            "step 423: generator_loss=-5.68578406578979e-10, discriminator_loss=5.210531526245177e-05\n",
            "step 424: generator_loss=-8.913665916487901e-10, discriminator_loss=8.355036698048934e-05\n",
            "step 425: generator_loss=-2.344135552334592e-09, discriminator_loss=9.402153227711096e-05\n",
            "step 426: generator_loss=-6.037950139869963e-10, discriminator_loss=0.00018130870012100786\n",
            "step 427: generator_loss=-7.730947132467136e-11, discriminator_loss=0.00011546953464858234\n",
            "step 428: generator_loss=-4.6119469354621856e-10, discriminator_loss=7.096568879205734e-05\n",
            "step 429: generator_loss=-3.871312437286889e-10, discriminator_loss=0.00010662357817636803\n",
            "step 430: generator_loss=-9.323872229849428e-11, discriminator_loss=0.00010623253183439374\n",
            "step 431: generator_loss=-6.056774526363995e-11, discriminator_loss=0.0001752833486534655\n",
            "step 432: generator_loss=-2.416826960782714e-09, discriminator_loss=0.00015344223356805742\n",
            "step 433: generator_loss=-5.806068820168875e-11, discriminator_loss=0.00016139596118591726\n",
            "step 434: generator_loss=-2.8184016231946885e-10, discriminator_loss=5.460541069624014e-05\n",
            "step 435: generator_loss=-5.173364847621542e-09, discriminator_loss=7.01933095115237e-05\n",
            "step 436: generator_loss=-8.159171949184696e-11, discriminator_loss=0.00042868583113886416\n",
            "step 437: generator_loss=-5.411409098599052e-10, discriminator_loss=9.309261076850817e-05\n",
            "step 438: generator_loss=-5.434954708505302e-10, discriminator_loss=4.79626796732191e-05\n",
            "step 439: generator_loss=-3.4751383992670526e-09, discriminator_loss=0.00019873272685799748\n",
            "step 440: generator_loss=-1.7782583738856772e-10, discriminator_loss=0.00011520013504195958\n",
            "step 441: generator_loss=-4.73797390210251e-10, discriminator_loss=0.00011124661978101358\n",
            "step 442: generator_loss=-1.526259812978381e-10, discriminator_loss=0.00022946075478103012\n",
            "step 443: generator_loss=-1.2091766476984844e-09, discriminator_loss=7.904081576270983e-05\n",
            "step 444: generator_loss=-1.4868314912597214e-10, discriminator_loss=0.00010179713717661798\n",
            "step 445: generator_loss=-6.01362917795889e-11, discriminator_loss=7.395979628199711e-05\n",
            "step 446: generator_loss=-1.162528059928114e-10, discriminator_loss=0.0001427790120942518\n",
            "step 447: generator_loss=-3.75326214552274e-10, discriminator_loss=6.908712384756655e-05\n",
            "step 448: generator_loss=-1.428316354079584e-10, discriminator_loss=0.00019498966867104173\n",
            "step 449: generator_loss=-7.427002762794288e-11, discriminator_loss=0.00010276406101183966\n",
            "step 450: generator_loss=-1.4114527602249183e-10, discriminator_loss=7.415884465444833e-05\n",
            "step 451: generator_loss=-6.038967659272032e-10, discriminator_loss=0.0001870402629720047\n",
            "step 452: generator_loss=-2.581307390059351e-10, discriminator_loss=0.00012182543287053704\n",
            "step 453: generator_loss=-2.1770457658831788e-10, discriminator_loss=0.00013559259241446853\n",
            "step 454: generator_loss=-1.644007985301954e-10, discriminator_loss=8.174925460480154e-05\n",
            "step 455: generator_loss=-1.3684706146044334e-10, discriminator_loss=8.960772538557649e-05\n",
            "step 456: generator_loss=-4.359165806100407e-10, discriminator_loss=8.903378329705447e-05\n",
            "step 457: generator_loss=-2.2053299630897527e-08, discriminator_loss=0.00014272736734710634\n",
            "step 458: generator_loss=-4.546318432829821e-09, discriminator_loss=7.676465611439198e-05\n",
            "step 459: generator_loss=-6.671407870584289e-10, discriminator_loss=8.328715193783864e-05\n",
            "step 460: generator_loss=-3.756570332580367e-10, discriminator_loss=9.789408795768395e-05\n",
            "step 461: generator_loss=-8.110547788930944e-10, discriminator_loss=7.225420995382592e-05\n",
            "step 462: generator_loss=-1.045680070310695e-10, discriminator_loss=7.801506581017748e-05\n",
            "step 463: generator_loss=-1.1452765819042199e-10, discriminator_loss=7.322044984903187e-05\n",
            "step 464: generator_loss=-1.3127526843348392e-10, discriminator_loss=0.0001030759813147597\n",
            "step 465: generator_loss=-4.8460600116095875e-11, discriminator_loss=4.3161930079804733e-05\n",
            "step 466: generator_loss=-4.50898041126635e-10, discriminator_loss=5.2811275963904336e-05\n",
            "step 467: generator_loss=-1.229923662915411e-10, discriminator_loss=4.523469033301808e-05\n",
            "step 468: generator_loss=-2.4889970640096237e-10, discriminator_loss=7.893594010965899e-05\n",
            "step 469: generator_loss=-4.0795783418090537e-10, discriminator_loss=0.0002755420282483101\n",
            "step 470: generator_loss=-5.087312238138963e-10, discriminator_loss=0.00014952017227187753\n",
            "step 471: generator_loss=-1.538470739692599e-10, discriminator_loss=5.5917826102813706e-05\n",
            "step 472: generator_loss=-1.3596279657690502e-10, discriminator_loss=0.00012731844617519528\n",
            "step 473: generator_loss=-1.4446810414625588e-10, discriminator_loss=0.0001228310720762238\n",
            "step 474: generator_loss=-3.7508693373489166e-10, discriminator_loss=0.00015512558456975967\n",
            "step 475: generator_loss=-3.9326333856060103e-10, discriminator_loss=9.194774611387402e-05\n",
            "step 476: generator_loss=-5.013958692678955e-10, discriminator_loss=0.00014104341971687973\n",
            "step 477: generator_loss=-7.565293946854013e-10, discriminator_loss=0.00011268709931755438\n",
            "step 478: generator_loss=-3.7595054847017195e-10, discriminator_loss=5.0618145905900747e-05\n",
            "step 479: generator_loss=-4.324037239378242e-10, discriminator_loss=8.038556552492082e-05\n",
            "step 480: generator_loss=-1.1765743934688544e-10, discriminator_loss=8.234157576225698e-05\n",
            "step 481: generator_loss=-1.2588858844253537e-09, discriminator_loss=0.000136670729261823\n",
            "step 482: generator_loss=-3.9414208008459184e-11, discriminator_loss=0.00011838120553875342\n",
            "step 483: generator_loss=-1.704857782725e-10, discriminator_loss=5.8488403738010675e-05\n",
            "step 484: generator_loss=-2.7921109868600524e-10, discriminator_loss=0.00012093428813386708\n",
            "step 485: generator_loss=-6.113476391789163e-11, discriminator_loss=0.00014831295993644744\n",
            "step 486: generator_loss=-8.702876752586519e-10, discriminator_loss=6.045254849595949e-05\n",
            "step 487: generator_loss=-3.582977248228758e-10, discriminator_loss=9.490147203905508e-05\n",
            "step 488: generator_loss=-1.815285838313585e-10, discriminator_loss=0.00017216286505572498\n",
            "step 489: generator_loss=-6.734717228340514e-10, discriminator_loss=0.00014762232603970915\n",
            "step 490: generator_loss=-1.6241866185318088e-10, discriminator_loss=8.069420437095687e-05\n",
            "step 491: generator_loss=-2.132516940811513e-10, discriminator_loss=0.00010178530646953732\n",
            "step 492: generator_loss=-4.5214029853468674e-08, discriminator_loss=6.0398677305784076e-05\n",
            "step 493: generator_loss=-1.70561093026933e-10, discriminator_loss=8.660742605570704e-05\n",
            "step 494: generator_loss=-1.1833540813910304e-09, discriminator_loss=0.0003233025490771979\n",
            "step 495: generator_loss=-1.980113711885778e-10, discriminator_loss=4.5923192374175414e-05\n",
            "step 496: generator_loss=-4.20414192348062e-09, discriminator_loss=5.8111345424549654e-05\n",
            "step 497: generator_loss=-2.2894237894366398e-10, discriminator_loss=0.00011169352364959195\n",
            "step 498: generator_loss=-7.712930849557154e-10, discriminator_loss=0.00013153432519175112\n",
            "step 499: generator_loss=-2.2548994615956275e-10, discriminator_loss=0.0001545267878100276\n",
            "step 500: generator_loss=-5.723573837101981e-10, discriminator_loss=0.00014875650231260806\n",
            "step 501: generator_loss=-3.0000329998003394e-10, discriminator_loss=0.00011335314047755674\n",
            "step 502: generator_loss=-4.5581369234604097e-10, discriminator_loss=9.8373246146366e-05\n",
            "step 503: generator_loss=-9.785757620894842e-11, discriminator_loss=0.00012342767149675637\n",
            "step 504: generator_loss=-5.008576331455572e-10, discriminator_loss=8.988035551737994e-05\n",
            "step 505: generator_loss=-1.7155721288020231e-09, discriminator_loss=4.9953192501561716e-05\n",
            "step 506: generator_loss=-6.279319425539498e-11, discriminator_loss=0.000159678646014072\n",
            "step 507: generator_loss=-3.0354569552359933e-11, discriminator_loss=6.204345845617354e-05\n",
            "step 508: generator_loss=-8.616397872973636e-11, discriminator_loss=8.70836665853858e-05\n",
            "step 509: generator_loss=-1.652445402733349e-10, discriminator_loss=5.901881741010584e-05\n",
            "step 510: generator_loss=-3.971577233752299e-10, discriminator_loss=0.00012733903713524342\n",
            "step 511: generator_loss=-4.0330933037679983e-10, discriminator_loss=0.00010866567026823759\n",
            "step 512: generator_loss=-6.154505349798001e-09, discriminator_loss=7.719504355918616e-05\n",
            "step 513: generator_loss=-1.2982387387339145e-10, discriminator_loss=0.00012613885337486863\n",
            "step 514: generator_loss=-3.545546078953521e-10, discriminator_loss=6.147129170130938e-05\n",
            "step 515: generator_loss=-5.641191402894208e-10, discriminator_loss=5.5928947404026985e-05\n",
            "step 516: generator_loss=-1.1680675870984203e-10, discriminator_loss=3.9759852370480075e-05\n",
            "step 517: generator_loss=-1.7055354906148068e-09, discriminator_loss=0.00016687206516508013\n",
            "step 518: generator_loss=-7.195696816175712e-11, discriminator_loss=7.464225200237706e-05\n",
            "step 519: generator_loss=-1.1434116847786058e-10, discriminator_loss=0.0001213973737321794\n",
            "step 520: generator_loss=-1.024793513937361e-10, discriminator_loss=9.448703349335119e-05\n",
            "step 521: generator_loss=-2.277042304710264e-10, discriminator_loss=9.921618038788438e-05\n",
            "step 522: generator_loss=-8.348983171480029e-10, discriminator_loss=4.969456131220795e-05\n",
            "step 523: generator_loss=-1.2457529452447602e-10, discriminator_loss=0.00034285016590729356\n",
            "step 524: generator_loss=-1.762566204099869e-10, discriminator_loss=0.0002625295892357826\n",
            "step 525: generator_loss=-1.803815152801036e-10, discriminator_loss=7.709643978159875e-05\n",
            "step 526: generator_loss=-1.1973564362222078e-09, discriminator_loss=7.722037844359875e-05\n",
            "step 527: generator_loss=-2.569431889476448e-10, discriminator_loss=0.00012878388224635273\n",
            "step 528: generator_loss=-4.553115176553213e-11, discriminator_loss=7.599109812872484e-05\n",
            "step 529: generator_loss=-2.938284060505225e-10, discriminator_loss=6.659659266006202e-05\n",
            "step 530: generator_loss=-4.789730834175998e-10, discriminator_loss=5.279680772218853e-05\n",
            "step 531: generator_loss=-2.21695994895299e-09, discriminator_loss=0.0001805331266950816\n",
            "step 532: generator_loss=-8.33731750304878e-10, discriminator_loss=8.639237057650462e-05\n",
            "step 533: generator_loss=-1.3752827765500797e-09, discriminator_loss=4.351357711129822e-05\n",
            "step 534: generator_loss=-5.615443665618614e-10, discriminator_loss=6.283306720433757e-05\n",
            "step 535: generator_loss=-6.607018265825104e-10, discriminator_loss=4.0737369999988005e-05\n",
            "step 536: generator_loss=-2.630800299829872e-10, discriminator_loss=0.00011422725219745189\n",
            "step 537: generator_loss=-5.868439623135657e-10, discriminator_loss=8.42362642288208e-05\n",
            "step 538: generator_loss=-6.485738057726564e-10, discriminator_loss=7.281557918759063e-05\n",
            "step 539: generator_loss=-7.756146419568566e-11, discriminator_loss=5.3237370593706146e-05\n",
            "step 540: generator_loss=-6.330501400864108e-11, discriminator_loss=8.375176548724994e-05\n",
            "step 541: generator_loss=-8.029580472745934e-11, discriminator_loss=0.00013322052836883813\n",
            "step 542: generator_loss=-1.943265270920591e-10, discriminator_loss=5.1652041292982176e-05\n",
            "step 543: generator_loss=-2.0717479121135085e-10, discriminator_loss=7.607203588122502e-05\n",
            "step 544: generator_loss=-9.74446856538691e-10, discriminator_loss=9.033934475155547e-05\n",
            "step 545: generator_loss=-2.933437104335468e-10, discriminator_loss=5.7388650020584464e-05\n",
            "step 546: generator_loss=-2.527598963464328e-10, discriminator_loss=5.442024485091679e-05\n",
            "step 547: generator_loss=-1.6784287293347688e-09, discriminator_loss=5.0111069867853075e-05\n",
            "step 548: generator_loss=-2.0186192717375206e-09, discriminator_loss=0.0001801274629542604\n",
            "step 549: generator_loss=-1.2432162244113698e-10, discriminator_loss=5.577660340350121e-05\n",
            "step 550: generator_loss=-1.963622597855874e-10, discriminator_loss=3.596338865463622e-05\n",
            "step 551: generator_loss=-1.3575021662326492e-10, discriminator_loss=0.00012772691843565553\n",
            "step 552: generator_loss=-2.2225297158229296e-09, discriminator_loss=3.7344627344282344e-05\n",
            "step 553: generator_loss=-5.95150329019134e-09, discriminator_loss=6.769647006876767e-05\n",
            "step 554: generator_loss=-6.90681289938766e-10, discriminator_loss=3.593805740820244e-05\n",
            "step 555: generator_loss=-1.2987469433234367e-10, discriminator_loss=0.0002465617435518652\n",
            "step 556: generator_loss=-4.34144803440617e-10, discriminator_loss=3.8140249671414495e-05\n",
            "step 557: generator_loss=-1.1295522295284854e-09, discriminator_loss=4.125701525481418e-05\n",
            "step 558: generator_loss=-1.4677248305616786e-10, discriminator_loss=6.70721783535555e-05\n",
            "step 559: generator_loss=-4.2882741801975044e-10, discriminator_loss=6.354739161906764e-05\n",
            "step 560: generator_loss=-4.610113402137017e-10, discriminator_loss=5.988942939438857e-05\n",
            "step 561: generator_loss=-1.9798731543119175e-09, discriminator_loss=7.581797399325296e-05\n",
            "step 562: generator_loss=-2.385812103433693e-10, discriminator_loss=0.0001253373920917511\n",
            "step 563: generator_loss=-2.9086977271219894e-10, discriminator_loss=7.460807682946324e-05\n",
            "step 564: generator_loss=-9.30469590265659e-11, discriminator_loss=0.0002728003019001335\n",
            "step 565: generator_loss=-9.06207123230196e-11, discriminator_loss=8.818093192530796e-05\n",
            "step 566: generator_loss=-1.443264258105259e-10, discriminator_loss=4.673218063544482e-05\n",
            "step 567: generator_loss=-7.092341713921257e-10, discriminator_loss=6.725133425788954e-05\n",
            "step 568: generator_loss=-3.151181815486126e-10, discriminator_loss=6.304885755525902e-05\n",
            "step 569: generator_loss=-1.2465750653944951e-10, discriminator_loss=0.00015769073797855526\n",
            "step 570: generator_loss=-5.359713228791918e-10, discriminator_loss=0.000247946911258623\n",
            "step 571: generator_loss=-1.1586299697441405e-09, discriminator_loss=7.362519681919366e-05\n",
            "step 572: generator_loss=-9.690626079361664e-09, discriminator_loss=4.7693552915006876e-05\n",
            "step 573: generator_loss=-3.2997096721665287e-10, discriminator_loss=7.805111090419814e-05\n",
            "step 574: generator_loss=-2.50379106336851e-10, discriminator_loss=3.574771108105779e-05\n",
            "step 575: generator_loss=-4.54762449919599e-10, discriminator_loss=0.00014022689720150083\n",
            "step 576: generator_loss=-3.451311458846362e-10, discriminator_loss=7.627341256011277e-05\n",
            "step 577: generator_loss=-2.1429158447716645e-09, discriminator_loss=3.27968446072191e-05\n",
            "step 578: generator_loss=-3.214969401810208e-10, discriminator_loss=4.0837105188984424e-05\n",
            "step 579: generator_loss=-1.1341303590706175e-10, discriminator_loss=8.736595918890089e-05\n",
            "step 580: generator_loss=-6.243740940936604e-11, discriminator_loss=3.480008672340773e-05\n",
            "step 581: generator_loss=-3.3704619650798406e-10, discriminator_loss=3.4155702451244e-05\n",
            "step 582: generator_loss=-1.1328167570656689e-10, discriminator_loss=7.895539602031931e-05\n",
            "step 583: generator_loss=-3.3851593750355846e-10, discriminator_loss=5.943663927610032e-05\n",
            "step 584: generator_loss=-4.0056558070489245e-10, discriminator_loss=0.00012590341793838888\n",
            "step 585: generator_loss=-2.3328033948999405e-10, discriminator_loss=5.3287130867829546e-05\n",
            "step 586: generator_loss=-4.5674480864121847e-10, discriminator_loss=6.170588312670588e-05\n",
            "step 587: generator_loss=-1.6037757233355876e-10, discriminator_loss=8.474516653222963e-05\n",
            "step 588: generator_loss=-1.003296126733666e-10, discriminator_loss=7.638025999767706e-05\n",
            "step 589: generator_loss=-1.6330620189464184e-10, discriminator_loss=7.660952542209998e-05\n",
            "step 590: generator_loss=-1.7803367668989267e-09, discriminator_loss=5.111822611070238e-05\n",
            "step 591: generator_loss=-1.7501261551089442e-10, discriminator_loss=5.9283400332788005e-05\n",
            "step 592: generator_loss=-3.652528834940938e-10, discriminator_loss=5.662928015226498e-05\n",
            "step 593: generator_loss=-1.4946061055454152e-10, discriminator_loss=8.116383105516434e-05\n",
            "step 594: generator_loss=-4.1996317534653826e-10, discriminator_loss=7.322448800550774e-05\n",
            "step 595: generator_loss=-2.600114845652257e-10, discriminator_loss=0.00014701433246955276\n",
            "step 596: generator_loss=-9.486006424808124e-11, discriminator_loss=8.119478297885507e-05\n",
            "step 597: generator_loss=-2.7425295368033176e-09, discriminator_loss=7.731193181825802e-05\n",
            "step 598: generator_loss=-4.4981268709776145e-10, discriminator_loss=8.106877066893503e-05\n",
            "step 599: generator_loss=-7.329791218424475e-10, discriminator_loss=6.379840488079935e-05\n",
            "step 600: generator_loss=-2.054383885230493e-10, discriminator_loss=5.257127486402169e-05\n",
            "step 601: generator_loss=-2.1250388115845453e-09, discriminator_loss=5.294621951179579e-05\n",
            "step 602: generator_loss=-2.994629877406396e-09, discriminator_loss=3.8343569030985236e-05\n",
            "step 603: generator_loss=-2.529081666313715e-10, discriminator_loss=6.731163739459589e-05\n",
            "step 604: generator_loss=-3.7170450051249304e-10, discriminator_loss=6.15941607975401e-05\n",
            "step 605: generator_loss=-1.1861414628278055e-10, discriminator_loss=0.00010543726966716349\n",
            "step 606: generator_loss=-1.052197773354635e-10, discriminator_loss=0.00011250004899920896\n",
            "step 607: generator_loss=-3.612189436452695e-10, discriminator_loss=0.00011259416351094842\n",
            "step 608: generator_loss=-3.380743462955138e-10, discriminator_loss=6.129768735263497e-05\n",
            "step 609: generator_loss=-4.1556525581798454e-11, discriminator_loss=7.063737575663254e-05\n",
            "step 610: generator_loss=-2.104391660928684e-10, discriminator_loss=4.6089462557574734e-05\n",
            "step 611: generator_loss=-1.9071284829141888e-10, discriminator_loss=8.551793143851683e-05\n",
            "step 612: generator_loss=-1.3955883670924152e-10, discriminator_loss=9.537731239106506e-05\n",
            "step 613: generator_loss=-1.1485298267999156e-09, discriminator_loss=4.432603600434959e-05\n",
            "step 614: generator_loss=-1.996810494730994e-10, discriminator_loss=3.654839747468941e-05\n",
            "step 615: generator_loss=-7.755232567241421e-11, discriminator_loss=4.737664494314231e-05\n",
            "step 616: generator_loss=-3.4669431214773283e-10, discriminator_loss=3.0535386031260714e-05\n",
            "step 617: generator_loss=-1.5342593862044396e-10, discriminator_loss=3.817808465100825e-05\n",
            "step 618: generator_loss=-2.6072279751820915e-11, discriminator_loss=9.784918802324682e-05\n",
            "step 619: generator_loss=-3.1860097893243733e-10, discriminator_loss=3.384873707545921e-05\n",
            "step 620: generator_loss=-1.5246706674965083e-10, discriminator_loss=0.00010728440975071862\n",
            "step 621: generator_loss=-1.2513565184057995e-10, discriminator_loss=5.8374407672090456e-05\n",
            "step 622: generator_loss=-1.434990182236362e-10, discriminator_loss=3.165272937621921e-05\n",
            "step 623: generator_loss=-4.732098601856194e-10, discriminator_loss=0.0001333662075921893\n",
            "step 624: generator_loss=-2.822875821983928e-10, discriminator_loss=8.942579006543383e-05\n",
            "step 625: generator_loss=-1.995475035210248e-10, discriminator_loss=3.424577516852878e-05\n",
            "step 626: generator_loss=-2.6523433449554545e-10, discriminator_loss=3.267747524660081e-05\n",
            "step 627: generator_loss=-1.0097380709339632e-09, discriminator_loss=3.933698826585896e-05\n",
            "step 628: generator_loss=-7.951134195494092e-10, discriminator_loss=3.769678733078763e-05\n",
            "step 629: generator_loss=-1.360325463384271e-10, discriminator_loss=3.766443478525616e-05\n",
            "step 630: generator_loss=-3.6299968586561704e-10, discriminator_loss=6.73632966936566e-05\n",
            "step 631: generator_loss=-1.2047925157521178e-10, discriminator_loss=7.716401887591928e-05\n",
            "step 632: generator_loss=-3.737223586153249e-10, discriminator_loss=5.6398712331429124e-05\n",
            "step 633: generator_loss=-2.0002886846892665e-10, discriminator_loss=8.421300299232826e-05\n",
            "step 634: generator_loss=-1.7523542339414888e-10, discriminator_loss=7.890666165621951e-05\n",
            "step 635: generator_loss=-1.3870098403145903e-09, discriminator_loss=6.79175354889594e-05\n",
            "step 636: generator_loss=-1.9256352068452998e-09, discriminator_loss=4.490919309318997e-05\n",
            "step 637: generator_loss=-8.306625387533018e-10, discriminator_loss=7.56237204768695e-05\n",
            "step 638: generator_loss=-7.555788633650806e-11, discriminator_loss=4.482758231461048e-05\n",
            "step 639: generator_loss=-9.860617877777145e-11, discriminator_loss=8.142405567923561e-05\n",
            "step 640: generator_loss=-7.380603767037641e-11, discriminator_loss=3.1305753509514034e-05\n",
            "step 641: generator_loss=-7.797194001568641e-10, discriminator_loss=7.404253847198561e-05\n",
            "step 642: generator_loss=-5.519711354651236e-10, discriminator_loss=0.00010124244727194309\n",
            "step 643: generator_loss=-9.110377036103401e-11, discriminator_loss=6.07592701271642e-05\n",
            "step 644: generator_loss=-5.122596791196088e-10, discriminator_loss=4.572805482894182e-05\n",
            "step 645: generator_loss=-3.8253633594109715e-10, discriminator_loss=3.732462937477976e-05\n",
            "step 646: generator_loss=-4.405514009153677e-10, discriminator_loss=6.603579095099121e-05\n",
            "step 647: generator_loss=-1.21046497270072e-07, discriminator_loss=5.843140752403997e-05\n",
            "step 648: generator_loss=-4.911578921351634e-10, discriminator_loss=0.00010284373274771497\n",
            "step 649: generator_loss=-1.2144331373864503e-10, discriminator_loss=0.00011258207814535126\n",
            "step 650: generator_loss=-5.244963352524223e-10, discriminator_loss=0.00013969134306535125\n",
            "step 651: generator_loss=-1.4077727872319201e-09, discriminator_loss=6.525799835799262e-05\n",
            "step 652: generator_loss=-1.494760426545838e-10, discriminator_loss=2.7439116820460185e-05\n",
            "step 653: generator_loss=-2.1624049773016907e-10, discriminator_loss=6.0761478380300105e-05\n",
            "step 654: generator_loss=-1.528941417916485e-09, discriminator_loss=6.0676829889416695e-05\n",
            "step 655: generator_loss=-1.4658001479261884e-09, discriminator_loss=7.645645382581279e-05\n",
            "step 656: generator_loss=-2.3323573627997973e-10, discriminator_loss=2.5283799914177507e-05\n",
            "step 657: generator_loss=-1.5979282341760381e-09, discriminator_loss=9.071105159819126e-05\n",
            "step 658: generator_loss=-8.714384075458881e-11, discriminator_loss=0.00022280433040577918\n",
            "step 659: generator_loss=-4.102494788327249e-09, discriminator_loss=5.816512566525489e-05\n",
            "step 660: generator_loss=-2.08265560353027e-09, discriminator_loss=3.3312386221950874e-05\n",
            "step 661: generator_loss=-1.4439023587886624e-10, discriminator_loss=3.1837724236538634e-05\n",
            "step 662: generator_loss=-7.700910742425293e-11, discriminator_loss=0.00010785456834128127\n",
            "step 663: generator_loss=-1.4906162415506685e-10, discriminator_loss=5.249136302154511e-05\n",
            "step 664: generator_loss=-1.0411740913873757e-10, discriminator_loss=0.0002432698238408193\n",
            "step 665: generator_loss=-1.474182859118045e-10, discriminator_loss=7.001103222137317e-05\n",
            "step 666: generator_loss=-5.5665394516069e-10, discriminator_loss=2.4836652301019058e-05\n",
            "step 667: generator_loss=-8.742259138827535e-10, discriminator_loss=8.704727224539965e-05\n",
            "step 668: generator_loss=-6.664674367939938e-11, discriminator_loss=5.970242273178883e-05\n",
            "step 669: generator_loss=-6.487245185482493e-10, discriminator_loss=8.032433834159747e-05\n",
            "step 670: generator_loss=-4.2727953120103024e-11, discriminator_loss=5.2848754421574995e-05\n",
            "step 671: generator_loss=-1.248862124825223e-10, discriminator_loss=4.6047043724684045e-05\n",
            "step 672: generator_loss=-3.008014948235882e-10, discriminator_loss=5.807719935546629e-05\n",
            "step 673: generator_loss=-7.94129345615957e-11, discriminator_loss=0.00010681795538403094\n",
            "step 674: generator_loss=-1.3977752288951706e-10, discriminator_loss=6.155882874736562e-05\n",
            "step 675: generator_loss=-4.0579933857642914e-10, discriminator_loss=2.9102538974257186e-05\n",
            "step 676: generator_loss=-1.9641027693140245e-10, discriminator_loss=7.336078124353662e-05\n",
            "step 677: generator_loss=-6.761352033812784e-10, discriminator_loss=7.465806265827268e-05\n",
            "step 678: generator_loss=-4.938718323188596e-10, discriminator_loss=3.819399353233166e-05\n",
            "step 679: generator_loss=-2.159910028609602e-09, discriminator_loss=0.00010307082266081125\n",
            "step 680: generator_loss=-1.2561315876347123e-10, discriminator_loss=4.357024954515509e-05\n",
            "step 681: generator_loss=-2.321713654662716e-10, discriminator_loss=0.00011882299440912902\n",
            "step 682: generator_loss=-5.653631451885133e-10, discriminator_loss=6.069182563805953e-05\n",
            "step 683: generator_loss=-3.775095236413506e-10, discriminator_loss=2.5901386834448203e-05\n",
            "step 684: generator_loss=-1.7828583054324554e-08, discriminator_loss=7.905612437753007e-05\n",
            "step 685: generator_loss=-3.3530736520681614e-10, discriminator_loss=2.6062542019644752e-05\n",
            "step 686: generator_loss=-7.325809403546657e-11, discriminator_loss=5.863737533218227e-05\n",
            "step 687: generator_loss=-7.666154516750012e-11, discriminator_loss=4.601769978762604e-05\n",
            "step 688: generator_loss=-7.771333576656048e-10, discriminator_loss=5.7112512877210975e-05\n",
            "step 689: generator_loss=-1.9268582562848025e-10, discriminator_loss=2.6753619749797508e-05\n",
            "step 690: generator_loss=-3.276049986844498e-10, discriminator_loss=7.782828470226377e-05\n",
            "step 691: generator_loss=-1.6473941655270607e-10, discriminator_loss=3.162340362905525e-05\n",
            "step 692: generator_loss=-1.0473755196471757e-10, discriminator_loss=5.2115250582573935e-05\n",
            "step 693: generator_loss=-3.50813322835819e-10, discriminator_loss=7.748055213596672e-05\n",
            "step 694: generator_loss=-1.320227260848128e-10, discriminator_loss=3.881939483107999e-05\n",
            "step 695: generator_loss=-1.3015852284858909e-10, discriminator_loss=3.627320984378457e-05\n",
            "step 696: generator_loss=-1.3875374182958922e-09, discriminator_loss=4.883711881120689e-05\n",
            "step 697: generator_loss=-5.500525729340566e-11, discriminator_loss=6.096674042055383e-05\n",
            "step 698: generator_loss=-9.280554658097628e-10, discriminator_loss=8.834948675939813e-05\n",
            "step 699: generator_loss=-1.1853481529655596e-09, discriminator_loss=8.419646474067122e-05\n",
            "step 700: generator_loss=-2.0571533365654204e-10, discriminator_loss=9.286087879445404e-05\n",
            "step 701: generator_loss=-4.939451625496361e-10, discriminator_loss=5.8557452575769275e-05\n",
            "step 702: generator_loss=-1.821748529806655e-09, discriminator_loss=8.800072828307748e-05\n",
            "step 703: generator_loss=-4.4798759146758016e-10, discriminator_loss=3.8010140997357666e-05\n",
            "step 704: generator_loss=-6.69912791906313e-09, discriminator_loss=6.671619485132396e-05\n",
            "step 705: generator_loss=-2.474882243586052e-10, discriminator_loss=1.4546372767654248e-05\n",
            "step 706: generator_loss=-1.7227290427523911e-10, discriminator_loss=0.00010552672756602988\n",
            "step 707: generator_loss=-1.0307521502994632e-09, discriminator_loss=6.262880197027698e-05\n",
            "step 708: generator_loss=-2.5090425292972895e-09, discriminator_loss=3.101796028204262e-05\n",
            "step 709: generator_loss=-1.9276025220449355e-10, discriminator_loss=4.591485776472837e-05\n",
            "step 710: generator_loss=-6.433822918872067e-11, discriminator_loss=4.279321728972718e-05\n",
            "step 711: generator_loss=-1.1863609650220042e-08, discriminator_loss=3.820847632596269e-05\n",
            "step 712: generator_loss=-2.8453420175544863e-10, discriminator_loss=3.8687281630700454e-05\n",
            "step 713: generator_loss=-2.3030183315952968e-10, discriminator_loss=0.00018713314784690738\n",
            "step 714: generator_loss=-4.912253936950606e-10, discriminator_loss=4.519392678048462e-05\n",
            "step 715: generator_loss=-2.8752525360609127e-10, discriminator_loss=0.00019870520918630064\n",
            "step 716: generator_loss=-5.2389058369239905e-11, discriminator_loss=2.8931421184097417e-05\n",
            "step 717: generator_loss=-1.1329139709692626e-10, discriminator_loss=4.3239684600848705e-05\n",
            "step 718: generator_loss=-3.2110275549612766e-10, discriminator_loss=9.232416050508618e-05\n",
            "step 719: generator_loss=-1.08190331693514e-10, discriminator_loss=2.0485938875935972e-05\n",
            "step 720: generator_loss=-3.134065229559724e-10, discriminator_loss=1.2525339116109535e-05\n",
            "step 721: generator_loss=-1.677050442960848e-10, discriminator_loss=4.056879333802499e-05\n",
            "step 722: generator_loss=-1.441163438586912e-10, discriminator_loss=4.628933675121516e-05\n",
            "step 723: generator_loss=-4.946952292250728e-10, discriminator_loss=5.323849109117873e-05\n",
            "step 724: generator_loss=-2.2940231658719057e-10, discriminator_loss=3.2793461286928505e-05\n",
            "step 725: generator_loss=-8.893652481134495e-11, discriminator_loss=1.8275173715665005e-05\n",
            "step 726: generator_loss=-2.177469982100888e-09, discriminator_loss=5.015072019887157e-05\n",
            "step 727: generator_loss=-1.6075415998351161e-10, discriminator_loss=0.00011448811710579321\n",
            "step 728: generator_loss=-3.4305866480899283e-10, discriminator_loss=3.9323949749814346e-05\n",
            "step 729: generator_loss=-4.570061273856396e-10, discriminator_loss=3.2122614356921986e-05\n",
            "step 730: generator_loss=-1.1557790835503567e-10, discriminator_loss=4.578875450533815e-05\n",
            "step 731: generator_loss=-3.6815303583459524e-10, discriminator_loss=4.075252581969835e-05\n",
            "step 732: generator_loss=-2.6843083311689497e-09, discriminator_loss=5.420393790700473e-05\n",
            "step 733: generator_loss=-2.2479462735702782e-10, discriminator_loss=0.00011228164657950401\n",
            "step 734: generator_loss=-1.423185597149157e-10, discriminator_loss=0.00010774192196549848\n",
            "step 735: generator_loss=-1.7398020801806524e-08, discriminator_loss=3.243833270971663e-05\n",
            "step 736: generator_loss=-3.3184754943960115e-10, discriminator_loss=2.056766243185848e-05\n",
            "step 737: generator_loss=-3.731164821552113e-10, discriminator_loss=0.00010611503239488229\n",
            "step 738: generator_loss=-6.71584315936613e-11, discriminator_loss=8.345534297404811e-05\n",
            "step 739: generator_loss=-5.850552264874409e-10, discriminator_loss=3.3088785130530596e-05\n",
            "step 740: generator_loss=-2.6147795734177137e-11, discriminator_loss=5.214953125687316e-05\n",
            "step 741: generator_loss=-3.012410598746129e-10, discriminator_loss=2.2219730453798547e-05\n",
            "step 742: generator_loss=-1.118153347690054e-10, discriminator_loss=0.0001222794526256621\n",
            "step 743: generator_loss=-2.6428936816813575e-10, discriminator_loss=2.6586727472022176e-05\n",
            "step 744: generator_loss=-5.973422867455724e-10, discriminator_loss=4.4588668970391154e-05\n",
            "step 745: generator_loss=-4.1183619015061623e-11, discriminator_loss=6.46912885713391e-05\n",
            "step 746: generator_loss=-2.5698326799883375e-10, discriminator_loss=8.262162009486929e-05\n",
            "step 747: generator_loss=-2.4041629798077224e-10, discriminator_loss=3.8535210478585213e-05\n",
            "step 748: generator_loss=-3.1840108327685357e-10, discriminator_loss=1.6954132661339827e-05\n",
            "step 749: generator_loss=-6.623703807662196e-10, discriminator_loss=5.096337918075733e-05\n",
            "step 750: generator_loss=-8.862535705311814e-10, discriminator_loss=2.488310929038562e-05\n",
            "step 751: generator_loss=-2.5192492536518785e-10, discriminator_loss=3.2471118174726143e-05\n",
            "step 752: generator_loss=-1.6447725126322865e-10, discriminator_loss=5.494558354257606e-05\n",
            "step 753: generator_loss=-8.68946581356056e-10, discriminator_loss=2.9018146960879676e-05\n",
            "step 754: generator_loss=-5.71228453427608e-10, discriminator_loss=7.148989971028641e-05\n",
            "step 755: generator_loss=-6.831986087973974e-10, discriminator_loss=5.15980864292942e-05\n",
            "step 756: generator_loss=-2.4840951518001475e-10, discriminator_loss=8.223215263569728e-05\n",
            "step 757: generator_loss=-2.692849554453147e-10, discriminator_loss=7.099421782186255e-05\n",
            "step 758: generator_loss=-4.606278969365718e-10, discriminator_loss=3.547264714143239e-05\n",
            "step 759: generator_loss=-1.285582973409305e-09, discriminator_loss=3.8284200854832307e-05\n",
            "step 760: generator_loss=-1.2068734900338995e-09, discriminator_loss=6.39610952930525e-05\n",
            "step 761: generator_loss=-1.9580480292713531e-10, discriminator_loss=4.944040483678691e-05\n",
            "step 762: generator_loss=-1.640927282942073e-09, discriminator_loss=8.203304605558515e-05\n",
            "step 763: generator_loss=-6.075968617125227e-10, discriminator_loss=2.8110507628298365e-05\n",
            "step 764: generator_loss=-1.4281926752346408e-09, discriminator_loss=4.4509550207294524e-05\n",
            "step 765: generator_loss=-1.570139462891973e-09, discriminator_loss=2.4675915483385324e-05\n",
            "step 766: generator_loss=-1.0173101250288141e-09, discriminator_loss=9.384470467921346e-05\n",
            "step 767: generator_loss=-2.224285200469467e-10, discriminator_loss=4.552749669528566e-05\n",
            "step 768: generator_loss=-6.214009168337142e-11, discriminator_loss=5.541393693420105e-05\n",
            "step 769: generator_loss=-1.9100270254313045e-09, discriminator_loss=5.238169615040533e-05\n",
            "step 770: generator_loss=-3.236703793874085e-09, discriminator_loss=4.269300916348584e-05\n",
            "step 771: generator_loss=-6.211609560047293e-10, discriminator_loss=3.603101140470244e-05\n",
            "step 772: generator_loss=-7.597337342568622e-11, discriminator_loss=2.177861642849166e-05\n",
            "step 773: generator_loss=-1.728047704929736e-10, discriminator_loss=3.641533839982003e-05\n",
            "step 774: generator_loss=-2.34334829318783e-10, discriminator_loss=4.462154538487084e-05\n",
            "step 775: generator_loss=-8.391817796216117e-11, discriminator_loss=5.655126733472571e-05\n",
            "step 776: generator_loss=-1.883777578370882e-10, discriminator_loss=3.4552689612610266e-05\n",
            "step 777: generator_loss=-9.176374243802243e-11, discriminator_loss=4.7930549044394866e-05\n",
            "step 778: generator_loss=-1.01019148601722e-09, discriminator_loss=7.297166303033009e-05\n",
            "step 779: generator_loss=-6.80188544377458e-11, discriminator_loss=4.1150866309180856e-05\n",
            "step 780: generator_loss=-2.3887503086683637e-10, discriminator_loss=2.1992160327499732e-05\n",
            "step 781: generator_loss=-6.688871678761643e-11, discriminator_loss=8.682447514729574e-05\n",
            "step 782: generator_loss=-2.0067125738876257e-09, discriminator_loss=2.46131130552385e-05\n",
            "step 783: generator_loss=-4.1621150970172494e-11, discriminator_loss=3.788049434660934e-05\n",
            "step 784: generator_loss=-4.762902294785931e-10, discriminator_loss=0.00015002455620560795\n",
            "step 785: generator_loss=-6.138875519035025e-11, discriminator_loss=6.562771159224212e-05\n",
            "step 786: generator_loss=-2.730346226886837e-10, discriminator_loss=3.1747869797982275e-05\n",
            "step 787: generator_loss=-3.327970399258362e-10, discriminator_loss=3.5788754757959396e-05\n",
            "step 788: generator_loss=-5.717574746988419e-10, discriminator_loss=3.4761742426780984e-05\n",
            "step 789: generator_loss=-1.3644024798864507e-10, discriminator_loss=0.00011506961891427636\n",
            "step 790: generator_loss=-8.920801874978679e-10, discriminator_loss=3.888523860950954e-05\n",
            "step 791: generator_loss=-5.294572003045062e-10, discriminator_loss=1.941717346198857e-05\n",
            "step 792: generator_loss=-5.739689279415927e-11, discriminator_loss=3.9900980482343584e-05\n",
            "step 793: generator_loss=-1.5135792619247468e-10, discriminator_loss=5.445939677883871e-05\n",
            "step 794: generator_loss=-9.506135462133969e-11, discriminator_loss=3.088535231654532e-05\n",
            "step 795: generator_loss=-4.6254129415501666e-09, discriminator_loss=7.594597263960168e-05\n",
            "step 796: generator_loss=-5.089794807844328e-09, discriminator_loss=4.20885844505392e-05\n",
            "step 797: generator_loss=-8.025401176947611e-11, discriminator_loss=3.476517667877488e-05\n",
            "step 798: generator_loss=-4.71614691743838e-10, discriminator_loss=3.0491966754198074e-05\n",
            "step 799: generator_loss=-7.769088705700256e-10, discriminator_loss=3.7864348996663466e-05\n",
            "step 800: generator_loss=-2.995404480010677e-10, discriminator_loss=3.9292604924412444e-05\n",
            "step 801: generator_loss=-1.5152067101009692e-10, discriminator_loss=7.037800969555974e-05\n",
            "step 802: generator_loss=-1.7860504741840089e-10, discriminator_loss=3.511844261083752e-05\n",
            "step 803: generator_loss=-9.949900625638719e-11, discriminator_loss=2.754369234025944e-05\n",
            "step 804: generator_loss=-1.4335395093212355e-09, discriminator_loss=5.2002007578266785e-05\n",
            "step 805: generator_loss=-1.7219908832188935e-09, discriminator_loss=3.390672281966545e-05\n",
            "step 806: generator_loss=-1.3502311491109253e-09, discriminator_loss=2.7820709874504246e-05\n",
            "step 807: generator_loss=-6.352810499876682e-10, discriminator_loss=3.7296078517101705e-05\n",
            "step 808: generator_loss=-1.3192336112410885e-10, discriminator_loss=5.2338000386953354e-05\n",
            "step 809: generator_loss=-1.2659602532938408e-10, discriminator_loss=3.211269358871505e-05\n",
            "step 810: generator_loss=-4.391253471958123e-10, discriminator_loss=6.565484363818541e-05\n",
            "step 811: generator_loss=-2.0833443414858266e-08, discriminator_loss=4.44431061623618e-05\n",
            "step 812: generator_loss=-2.4364882333927085e-10, discriminator_loss=1.3885338375985157e-05\n",
            "step 813: generator_loss=-6.769751981217098e-10, discriminator_loss=2.4759952793829143e-05\n",
            "step 814: generator_loss=-2.5200755371379557e-10, discriminator_loss=4.677044853451662e-05\n",
            "step 815: generator_loss=-8.568017961785301e-10, discriminator_loss=0.00013934345042798668\n",
            "step 816: generator_loss=-2.0287618807124375e-10, discriminator_loss=3.632756124716252e-05\n",
            "step 817: generator_loss=-4.6123321828517305e-10, discriminator_loss=2.1850544726476073e-05\n",
            "step 818: generator_loss=-4.490489091679706e-10, discriminator_loss=3.6948404158465564e-05\n",
            "step 819: generator_loss=-6.086006698602375e-10, discriminator_loss=1.1747714779630769e-05\n",
            "step 820: generator_loss=-2.325846404360732e-09, discriminator_loss=0.00012596829037647694\n",
            "step 821: generator_loss=-3.235662293654684e-10, discriminator_loss=5.276910451357253e-05\n",
            "step 822: generator_loss=-4.696633082446056e-10, discriminator_loss=2.3571186829940416e-05\n",
            "step 823: generator_loss=-1.235193197723916e-10, discriminator_loss=9.652926382841542e-05\n",
            "step 824: generator_loss=-1.6048712359051365e-10, discriminator_loss=8.153456292347983e-05\n",
            "step 825: generator_loss=-2.1807295969011875e-09, discriminator_loss=3.745757931028493e-05\n",
            "step 826: generator_loss=-4.064918956991903e-10, discriminator_loss=4.063802771270275e-05\n",
            "step 827: generator_loss=-1.1535841726306728e-10, discriminator_loss=4.642835847334936e-05\n",
            "step 828: generator_loss=-2.0588125648757227e-10, discriminator_loss=6.28822817816399e-05\n",
            "step 829: generator_loss=-4.2935754951400895e-10, discriminator_loss=3.989649121649563e-05\n",
            "step 830: generator_loss=-2.6815111242584067e-10, discriminator_loss=4.361861647339538e-05\n",
            "step 831: generator_loss=-1.1982145831090918e-10, discriminator_loss=2.899169339798391e-05\n",
            "step 832: generator_loss=-1.844105146364683e-10, discriminator_loss=0.00018818926764652133\n",
            "step 833: generator_loss=-1.077153033435252e-09, discriminator_loss=2.3834068997530267e-05\n",
            "step 834: generator_loss=-9.392417954501298e-10, discriminator_loss=8.081156556727365e-05\n",
            "step 835: generator_loss=-9.444990622942129e-11, discriminator_loss=3.541836122167297e-05\n",
            "step 836: generator_loss=-7.328286866226108e-10, discriminator_loss=5.014957059756853e-05\n",
            "step 837: generator_loss=-1.0847397979851792e-10, discriminator_loss=2.741915886872448e-05\n",
            "step 838: generator_loss=-6.635438865032484e-10, discriminator_loss=2.717659663176164e-05\n",
            "step 839: generator_loss=-6.404218821920438e-10, discriminator_loss=4.818419984076172e-05\n",
            "step 840: generator_loss=-6.435244004343588e-10, discriminator_loss=1.3492808648152277e-05\n",
            "step 841: generator_loss=-4.4794572495732154e-09, discriminator_loss=5.0228118197992444e-05\n",
            "step 842: generator_loss=-1.597203896919197e-10, discriminator_loss=6.555330764967948e-05\n",
            "step 843: generator_loss=-3.512699020546961e-10, discriminator_loss=2.4241386199719273e-05\n",
            "step 844: generator_loss=-3.277686566605098e-09, discriminator_loss=3.830838613794185e-05\n",
            "step 845: generator_loss=-5.8829239257818244e-09, discriminator_loss=2.2294128939392976e-05\n",
            "step 846: generator_loss=-3.262673242687697e-09, discriminator_loss=4.768317739944905e-05\n",
            "step 847: generator_loss=-2.25931495734244e-09, discriminator_loss=2.5704035579110496e-05\n",
            "step 848: generator_loss=-6.445556866019331e-10, discriminator_loss=2.3789334591128863e-05\n",
            "step 849: generator_loss=-3.744633492175353e-09, discriminator_loss=2.4888237021514215e-05\n",
            "step 850: generator_loss=-7.412467306622261e-10, discriminator_loss=4.1687453631311655e-05\n",
            "step 851: generator_loss=-3.1738902617206577e-09, discriminator_loss=4.250443453202024e-05\n",
            "step 852: generator_loss=-5.835669170117797e-10, discriminator_loss=2.106280589941889e-05\n",
            "step 853: generator_loss=-1.5190290691968755e-10, discriminator_loss=2.8222606488270685e-05\n",
            "step 854: generator_loss=-7.0516206207571486e-09, discriminator_loss=5.516810415429063e-05\n",
            "step 855: generator_loss=-1.1499540208959047e-09, discriminator_loss=4.33723398600705e-05\n",
            "step 856: generator_loss=-1.9430969333544823e-10, discriminator_loss=5.0071790610672906e-05\n",
            "step 857: generator_loss=-2.9785821031858006e-10, discriminator_loss=2.3731701730866916e-05\n",
            "step 858: generator_loss=-2.0859365346126424e-09, discriminator_loss=2.726560524024535e-05\n",
            "step 859: generator_loss=-4.1523848248736783e-10, discriminator_loss=4.895808160654269e-05\n",
            "step 860: generator_loss=-8.78145167693134e-10, discriminator_loss=3.980363908340223e-05\n",
            "step 861: generator_loss=-9.178504484230743e-11, discriminator_loss=1.437326045561349e-05\n",
            "step 862: generator_loss=-7.820916136935807e-11, discriminator_loss=2.072406823572237e-05\n",
            "step 863: generator_loss=-4.137536091519678e-09, discriminator_loss=4.388693196233362e-05\n",
            "step 864: generator_loss=-3.4410481131175175e-09, discriminator_loss=1.4747087334399112e-05\n",
            "step 865: generator_loss=-5.99901739395392e-10, discriminator_loss=4.053721931995824e-05\n",
            "step 866: generator_loss=-1.1255096854512203e-10, discriminator_loss=2.2208007067092694e-05\n",
            "step 867: generator_loss=-2.4698219025509616e-09, discriminator_loss=4.246868775226176e-05\n",
            "step 868: generator_loss=-2.657166153774426e-10, discriminator_loss=2.7856427550432272e-05\n",
            "step 869: generator_loss=-2.2824353518302587e-10, discriminator_loss=7.285120955202729e-05\n",
            "step 870: generator_loss=-4.53377169140623e-10, discriminator_loss=3.254440889577381e-05\n",
            "step 871: generator_loss=-4.2691161716845727e-10, discriminator_loss=4.7519715735688806e-05\n",
            "step 872: generator_loss=-2.74326950044923e-10, discriminator_loss=4.537436325335875e-05\n",
            "step 873: generator_loss=-6.031967147990258e-10, discriminator_loss=6.437243428081274e-05\n",
            "step 874: generator_loss=-1.467129057131089e-10, discriminator_loss=4.5369066356215626e-05\n",
            "step 875: generator_loss=-9.41954070299289e-10, discriminator_loss=3.6202989576850086e-05\n",
            "step 876: generator_loss=-5.720415252596922e-10, discriminator_loss=5.7992685469798744e-05\n",
            "step 877: generator_loss=-1.4636024336933673e-10, discriminator_loss=2.8087028113077395e-05\n",
            "step 878: generator_loss=-2.929411158092421e-10, discriminator_loss=5.1715560402954e-05\n",
            "step 879: generator_loss=-2.6160279498199657e-10, discriminator_loss=1.2907361451652832e-05\n",
            "step 880: generator_loss=-5.371164624179414e-10, discriminator_loss=1.966945819731336e-05\n",
            "step 881: generator_loss=-4.617652094029978e-11, discriminator_loss=4.2728304833872244e-05\n",
            "step 882: generator_loss=-2.2774299113237362e-10, discriminator_loss=1.4915062820364255e-05\n",
            "step 883: generator_loss=-7.304084420622914e-11, discriminator_loss=5.083950964035466e-05\n",
            "step 884: generator_loss=-2.8218887226927336e-09, discriminator_loss=3.2833238947205245e-05\n",
            "step 885: generator_loss=-3.1762140140223494e-10, discriminator_loss=4.5381275413092226e-05\n",
            "step 886: generator_loss=-1.921466985521647e-09, discriminator_loss=1.2826750207750592e-05\n",
            "step 887: generator_loss=-2.2551836786899315e-10, discriminator_loss=3.1427840440301225e-05\n",
            "step 888: generator_loss=-1.1287756285227601e-09, discriminator_loss=2.076192686217837e-05\n",
            "step 889: generator_loss=-1.6234044664109604e-10, discriminator_loss=4.1555234929546714e-05\n",
            "step 890: generator_loss=-9.87943477026576e-11, discriminator_loss=1.7105612641898915e-05\n",
            "step 891: generator_loss=-8.098797188438311e-10, discriminator_loss=3.219423888367601e-05\n",
            "step 892: generator_loss=-2.3856847608527687e-09, discriminator_loss=3.253632894484326e-05\n",
            "step 893: generator_loss=-7.811394198142807e-09, discriminator_loss=5.9642345149768516e-05\n",
            "step 894: generator_loss=-2.773537510769586e-10, discriminator_loss=4.464766971068457e-05\n",
            "step 895: generator_loss=-2.262678933107054e-09, discriminator_loss=3.2177242246689275e-05\n",
            "step 896: generator_loss=-1.603870147803832e-09, discriminator_loss=2.8160766305518337e-05\n",
            "step 897: generator_loss=-3.6406083703255376e-10, discriminator_loss=2.8668737286352552e-05\n",
            "step 898: generator_loss=-2.1877137601489238e-10, discriminator_loss=1.7033151380019262e-05\n",
            "step 899: generator_loss=-2.680730637472095e-10, discriminator_loss=3.056304922210984e-05\n",
            "step 900: generator_loss=-8.63004528950384e-11, discriminator_loss=8.60025920701446e-06\n",
            "step 901: generator_loss=-4.317505020168255e-09, discriminator_loss=1.728415554680396e-05\n",
            "step 902: generator_loss=-5.510682188347715e-11, discriminator_loss=2.7012982172891498e-05\n",
            "step 903: generator_loss=-2.996462244997389e-10, discriminator_loss=3.6349232686916366e-05\n",
            "step 904: generator_loss=-4.413738263764344e-10, discriminator_loss=2.55517315963516e-05\n",
            "step 905: generator_loss=-8.186124694775643e-11, discriminator_loss=1.8777636796585284e-05\n",
            "step 906: generator_loss=-1.3804436760356253e-10, discriminator_loss=5.33095771970693e-05\n",
            "step 907: generator_loss=-7.171183785681379e-11, discriminator_loss=7.034056761767715e-05\n",
            "step 908: generator_loss=-3.984476637519663e-10, discriminator_loss=5.120526839164086e-05\n",
            "step 909: generator_loss=-9.1103048716068e-11, discriminator_loss=6.419536657631397e-05\n",
            "step 910: generator_loss=-1.2393982506964107e-09, discriminator_loss=4.62989519292023e-05\n",
            "step 911: generator_loss=-2.1113630288560614e-10, discriminator_loss=2.1867854229640216e-05\n",
            "step 912: generator_loss=-1.4060558273243373e-10, discriminator_loss=1.5258277926477604e-05\n",
            "step 913: generator_loss=-2.8029774057358736e-09, discriminator_loss=5.396773849497549e-05\n",
            "step 914: generator_loss=-6.275768793528869e-10, discriminator_loss=3.215129254385829e-05\n",
            "step 915: generator_loss=-3.6136799108632545e-10, discriminator_loss=1.7954533177544363e-05\n",
            "step 916: generator_loss=-8.304812393333805e-10, discriminator_loss=3.420414941501804e-05\n",
            "step 917: generator_loss=-2.899015194568477e-10, discriminator_loss=8.649418305139989e-06\n",
            "step 918: generator_loss=-3.0786644344971137e-09, discriminator_loss=6.111145194154233e-05\n",
            "step 919: generator_loss=-6.44716724451655e-10, discriminator_loss=2.4057906557573006e-05\n",
            "step 920: generator_loss=-9.135474321464443e-11, discriminator_loss=2.9466193154803477e-05\n",
            "step 921: generator_loss=-2.385308173202816e-09, discriminator_loss=4.205640289001167e-05\n",
            "step 922: generator_loss=-5.045704964956599e-10, discriminator_loss=2.6356470698374324e-05\n",
            "step 923: generator_loss=-5.208549147539543e-10, discriminator_loss=2.350395152461715e-05\n",
            "step 924: generator_loss=-4.75523509457787e-10, discriminator_loss=2.0199511709506623e-05\n",
            "step 925: generator_loss=-3.523935310223436e-10, discriminator_loss=3.08447124552913e-05\n",
            "step 926: generator_loss=-7.79961095709325e-11, discriminator_loss=2.3826793039916083e-05\n",
            "step 927: generator_loss=-4.504324135901072e-10, discriminator_loss=3.06311558233574e-05\n",
            "step 928: generator_loss=-3.869619902285848e-10, discriminator_loss=4.7191806515911594e-05\n",
            "step 929: generator_loss=-3.0207669254878056e-08, discriminator_loss=4.864713264396414e-05\n",
            "step 930: generator_loss=-4.035861644879901e-10, discriminator_loss=4.297798659536056e-05\n",
            "step 931: generator_loss=-1.1928917853509802e-09, discriminator_loss=1.6323216186719947e-05\n",
            "step 932: generator_loss=-6.282119824341237e-10, discriminator_loss=5.476314981933683e-05\n",
            "step 933: generator_loss=-7.96350274612223e-09, discriminator_loss=5.650864477502182e-05\n",
            "step 934: generator_loss=-2.9978508564454387e-10, discriminator_loss=3.9799870137358084e-05\n",
            "step 935: generator_loss=-5.23572574184783e-11, discriminator_loss=2.807813507388346e-05\n",
            "step 936: generator_loss=-9.448944959800087e-10, discriminator_loss=4.231354614603333e-05\n",
            "step 937: generator_loss=-2.538709686916718e-09, discriminator_loss=2.21677400986664e-05\n",
            "step 938: generator_loss=-6.74063374561662e-11, discriminator_loss=3.0895447707735e-05\n",
            "step 939: generator_loss=-2.8008181884864314e-10, discriminator_loss=4.190950858173892e-05\n",
            "step 940: generator_loss=-1.2725602516194812e-10, discriminator_loss=2.4709292119950987e-05\n",
            "step 941: generator_loss=-4.502056949462485e-09, discriminator_loss=4.526821794570424e-05\n",
            "step 942: generator_loss=-5.328929311709807e-11, discriminator_loss=2.006794420594815e-05\n",
            "step 943: generator_loss=-1.7579562805458693e-10, discriminator_loss=3.21090265060775e-05\n",
            "step 944: generator_loss=-1.8727798478668234e-10, discriminator_loss=4.025804082630202e-05\n",
            "step 945: generator_loss=-6.628845250489235e-10, discriminator_loss=2.6599378543323837e-05\n",
            "step 946: generator_loss=-8.612298652010963e-10, discriminator_loss=8.04172032076167e-06\n",
            "step 947: generator_loss=-1.0952053153268082e-10, discriminator_loss=2.9234619432827458e-05\n",
            "step 948: generator_loss=-2.831079259912883e-10, discriminator_loss=5.425382187240757e-05\n",
            "step 949: generator_loss=-1.0166448793924587e-09, discriminator_loss=2.0029247025377117e-05\n",
            "step 950: generator_loss=-3.6680936066346703e-10, discriminator_loss=5.402593524195254e-05\n",
            "step 951: generator_loss=-7.50786377512469e-11, discriminator_loss=1.882413744169753e-05\n",
            "step 952: generator_loss=-2.8110314076457144e-09, discriminator_loss=5.1710110710700974e-05\n",
            "step 953: generator_loss=-9.506292975025588e-11, discriminator_loss=2.7281665097689256e-05\n",
            "step 954: generator_loss=-5.855171347768362e-10, discriminator_loss=6.767779996152967e-05\n",
            "step 955: generator_loss=-3.3200098226160435e-09, discriminator_loss=2.336597208341118e-05\n",
            "step 956: generator_loss=-3.4836695750328772e-09, discriminator_loss=2.8713106075883843e-05\n",
            "step 957: generator_loss=-1.4333934039711949e-10, discriminator_loss=3.7803081795573235e-05\n",
            "step 958: generator_loss=-2.3150927008774858e-10, discriminator_loss=0.00015697994967922568\n",
            "step 959: generator_loss=-3.7917130546460953e-10, discriminator_loss=4.3148742406629026e-05\n",
            "step 960: generator_loss=-3.9811942631473585e-10, discriminator_loss=4.469659324968234e-05\n",
            "step 961: generator_loss=-1.087113732367584e-09, discriminator_loss=2.4258963094325736e-05\n",
            "step 962: generator_loss=-1.8111029342904317e-10, discriminator_loss=1.2285715456528123e-05\n",
            "step 963: generator_loss=-6.413438113916925e-10, discriminator_loss=1.569092637510039e-05\n",
            "step 964: generator_loss=-2.6970178867991024e-10, discriminator_loss=2.9620263376273215e-05\n",
            "step 965: generator_loss=-5.277265291425692e-10, discriminator_loss=3.787127570831217e-05\n",
            "step 966: generator_loss=-9.241581389041187e-10, discriminator_loss=3.511536124278791e-05\n",
            "step 967: generator_loss=-1.9618200397530927e-09, discriminator_loss=2.1949768779450096e-05\n",
            "step 968: generator_loss=-3.7935582453130223e-10, discriminator_loss=2.3154616428655572e-05\n",
            "step 969: generator_loss=-5.036903116817371e-10, discriminator_loss=2.952647082565818e-05\n",
            "step 970: generator_loss=-5.117005152932563e-10, discriminator_loss=1.7281079635722563e-05\n",
            "step 971: generator_loss=-2.507180851818447e-10, discriminator_loss=4.787871876033023e-05\n",
            "step 972: generator_loss=-1.4430925787678461e-08, discriminator_loss=4.359009108156897e-05\n",
            "step 973: generator_loss=-3.6603067798957056e-10, discriminator_loss=0.00013844853674527258\n",
            "step 974: generator_loss=-9.93044424468792e-10, discriminator_loss=2.4764171030255966e-05\n",
            "step 975: generator_loss=-2.0949887657994992e-10, discriminator_loss=6.137723539723083e-05\n",
            "step 976: generator_loss=-1.4106791290657839e-09, discriminator_loss=2.8640997697948478e-05\n",
            "step 977: generator_loss=-1.8702568660433627e-10, discriminator_loss=1.6871765183168463e-05\n",
            "step 978: generator_loss=-1.8156718351036716e-09, discriminator_loss=1.4170441318128724e-05\n",
            "step 979: generator_loss=-3.45912118393521e-11, discriminator_loss=3.905926860170439e-05\n",
            "step 980: generator_loss=-1.1170928765347199e-10, discriminator_loss=2.4857148673618212e-05\n",
            "step 981: generator_loss=-8.153369646102249e-11, discriminator_loss=3.202189691364765e-05\n",
            "step 982: generator_loss=-2.8188595901923463e-09, discriminator_loss=1.7201396985910833e-05\n",
            "step 983: generator_loss=-1.9930153083436153e-09, discriminator_loss=5.070983024779707e-05\n",
            "step 984: generator_loss=-3.7644387607116414e-10, discriminator_loss=4.697767144534737e-05\n",
            "step 985: generator_loss=-2.1340362810207125e-10, discriminator_loss=4.272904334357008e-05\n",
            "step 986: generator_loss=-9.949320256552596e-10, discriminator_loss=1.9439896277617663e-05\n",
            "step 987: generator_loss=-5.28482591022339e-10, discriminator_loss=7.000222831266001e-05\n",
            "step 988: generator_loss=-1.8555854075508194e-10, discriminator_loss=2.48113319685217e-05\n",
            "step 989: generator_loss=-8.328734368845403e-10, discriminator_loss=3.9150487282313406e-05\n",
            "step 990: generator_loss=-2.850209512850199e-10, discriminator_loss=3.7122892535990104e-05\n",
            "step 991: generator_loss=-1.7958903808512616e-10, discriminator_loss=8.176065421139356e-06\n",
            "step 992: generator_loss=-4.5123343950237427e-10, discriminator_loss=2.4005756131373346e-05\n",
            "step 993: generator_loss=-6.943699504269318e-10, discriminator_loss=2.3986882297322154e-05\n",
            "step 994: generator_loss=-1.410283695379988e-10, discriminator_loss=3.320329051348381e-05\n",
            "step 995: generator_loss=-1.1594210036491859e-09, discriminator_loss=3.2719632145017385e-05\n",
            "step 996: generator_loss=-8.822831909505169e-10, discriminator_loss=5.135687024448998e-05\n",
            "step 997: generator_loss=-3.3141267508085548e-09, discriminator_loss=3.5676112020155415e-05\n",
            "step 998: generator_loss=-1.1118782561325702e-09, discriminator_loss=2.2972972146817483e-05\n",
            "step 999: generator_loss=-1.1151773948725463e-09, discriminator_loss=2.9275610359036364e-05\n",
            "step 1000: generator_loss=-4.594760127929476e-10, discriminator_loss=5.789060014649294e-05\n",
            "step 1001: generator_loss=-1.772557378654227e-10, discriminator_loss=4.584187990985811e-05\n",
            "step 1002: generator_loss=-1.5166942701760888e-10, discriminator_loss=5.5112835980253294e-05\n",
            "step 1003: generator_loss=-3.621187794067282e-09, discriminator_loss=2.8941407435922883e-05\n",
            "step 1004: generator_loss=-1.0083216206435708e-10, discriminator_loss=2.3834934836486354e-05\n",
            "step 1005: generator_loss=-1.7322763223859283e-09, discriminator_loss=2.842054163920693e-05\n",
            "step 1006: generator_loss=-1.3479896088242072e-09, discriminator_loss=1.7644499166635796e-05\n",
            "step 1007: generator_loss=-1.6763582189049941e-10, discriminator_loss=3.051554085686803e-05\n",
            "step 1008: generator_loss=-5.624290477790339e-10, discriminator_loss=8.728574357519392e-06\n",
            "step 1009: generator_loss=-1.7088096493367289e-09, discriminator_loss=9.676287845650222e-06\n",
            "step 1010: generator_loss=-4.1334018874295e-08, discriminator_loss=1.337273442914011e-05\n",
            "step 1011: generator_loss=-7.899166876157437e-10, discriminator_loss=5.643291297019459e-05\n",
            "step 1012: generator_loss=-1.52913415263356e-09, discriminator_loss=9.282800419896375e-06\n",
            "step 1013: generator_loss=-1.1683489731240115e-08, discriminator_loss=3.936759821954183e-05\n",
            "step 1014: generator_loss=-2.556744815862544e-10, discriminator_loss=2.5098603146034293e-05\n",
            "step 1015: generator_loss=-5.889345677800861e-10, discriminator_loss=3.4364191378699616e-05\n",
            "step 1016: generator_loss=-9.889343788316296e-10, discriminator_loss=3.286708670202643e-05\n",
            "step 1017: generator_loss=-1.1396869004087762e-09, discriminator_loss=9.850095921137836e-06\n",
            "step 1018: generator_loss=-3.3035840729667143e-10, discriminator_loss=1.6273379515041597e-05\n",
            "step 1019: generator_loss=-1.6271960168179334e-10, discriminator_loss=3.549566099536605e-05\n",
            "step 1020: generator_loss=-1.0397311456245006e-08, discriminator_loss=2.7145695639774203e-05\n",
            "step 1021: generator_loss=-9.670937384242961e-10, discriminator_loss=2.897312879213132e-05\n",
            "step 1022: generator_loss=-5.0115667171724e-10, discriminator_loss=1.4194605682860129e-05\n",
            "step 1023: generator_loss=-1.024873297339468e-09, discriminator_loss=1.7123053112300113e-05\n",
            "step 1024: generator_loss=-5.604297026451377e-10, discriminator_loss=3.2850264688022435e-05\n",
            "step 1025: generator_loss=-3.8507255717412647e-10, discriminator_loss=3.461196683929302e-05\n",
            "step 1026: generator_loss=-1.1443577196956767e-09, discriminator_loss=3.139639011351392e-05\n",
            "step 1027: generator_loss=-5.620221510405088e-10, discriminator_loss=4.022464781883173e-05\n",
            "step 1028: generator_loss=-5.184161988580627e-10, discriminator_loss=2.7820011382573284e-05\n",
            "step 1029: generator_loss=-4.979086032363966e-10, discriminator_loss=3.3207434171345085e-05\n",
            "step 1030: generator_loss=-3.694451411462296e-10, discriminator_loss=2.326268258912023e-05\n",
            "step 1031: generator_loss=-1.0433468533577184e-09, discriminator_loss=5.690822581527755e-05\n",
            "step 1032: generator_loss=-5.531433089345228e-10, discriminator_loss=8.235322457039729e-05\n",
            "step 1033: generator_loss=-1.1155656259864699e-10, discriminator_loss=3.728023511939682e-05\n",
            "step 1034: generator_loss=-2.3303579510525196e-08, discriminator_loss=5.173894805921009e-06\n",
            "step 1035: generator_loss=-6.341528968611954e-10, discriminator_loss=2.973887967527844e-05\n",
            "step 1036: generator_loss=-4.5037560347793715e-09, discriminator_loss=1.265654918825021e-05\n",
            "step 1037: generator_loss=-1.2366174750866321e-09, discriminator_loss=7.747802010271698e-05\n",
            "step 1038: generator_loss=-2.3474491794850394e-10, discriminator_loss=4.6575300075346604e-05\n",
            "step 1039: generator_loss=-4.1233896852510554e-10, discriminator_loss=2.1384803403634578e-05\n",
            "step 1040: generator_loss=-1.8556282899151455e-10, discriminator_loss=9.537601727060974e-06\n",
            "step 1041: generator_loss=-1.1298610935739362e-09, discriminator_loss=2.012917866522912e-05\n",
            "step 1042: generator_loss=-9.912917153798162e-10, discriminator_loss=2.3220116418087855e-05\n",
            "step 1043: generator_loss=-5.422874371774355e-10, discriminator_loss=2.409039188933093e-05\n",
            "step 1044: generator_loss=-1.2184991904362619e-09, discriminator_loss=4.471595457289368e-05\n",
            "step 1045: generator_loss=-1.4624887412217902e-10, discriminator_loss=4.7823246859479696e-05\n",
            "step 1046: generator_loss=-1.7857137990517913e-10, discriminator_loss=2.2441534383688122e-05\n",
            "step 1047: generator_loss=-3.972671080987311e-09, discriminator_loss=7.8906086855568e-06\n",
            "step 1048: generator_loss=-9.789529187287371e-10, discriminator_loss=2.0995486920583062e-05\n",
            "step 1049: generator_loss=-2.587286773714226e-10, discriminator_loss=4.0033039113041013e-05\n",
            "step 1050: generator_loss=-1.4893550281946943e-10, discriminator_loss=1.981848072318826e-05\n",
            "step 1051: generator_loss=-7.742799179588644e-10, discriminator_loss=1.4702176486025564e-05\n",
            "step 1052: generator_loss=-4.0784839394625294e-10, discriminator_loss=2.3659522412344813e-05\n",
            "step 1053: generator_loss=-1.7214978331736575e-09, discriminator_loss=2.3122129277908243e-05\n",
            "step 1054: generator_loss=-3.2166497243579784e-10, discriminator_loss=3.4860026062233374e-05\n",
            "step 1055: generator_loss=-1.0436512765110706e-10, discriminator_loss=2.0466928617679514e-05\n",
            "step 1056: generator_loss=-1.491199386194353e-10, discriminator_loss=6.81451492710039e-05\n",
            "step 1057: generator_loss=-6.789876993984478e-10, discriminator_loss=1.183423137263162e-05\n",
            "step 1058: generator_loss=-4.815264187385537e-09, discriminator_loss=2.8779375497833826e-05\n",
            "step 1059: generator_loss=-1.9806915829700955e-10, discriminator_loss=4.7876274038571864e-06\n",
            "step 1060: generator_loss=-8.060525857889189e-11, discriminator_loss=3.297587318229489e-05\n",
            "step 1061: generator_loss=-4.757964022772398e-10, discriminator_loss=9.30961687117815e-06\n",
            "step 1062: generator_loss=-4.510442019878269e-10, discriminator_loss=5.353700908017345e-05\n",
            "step 1063: generator_loss=-2.125240955441754e-10, discriminator_loss=4.988385262549855e-05\n",
            "step 1064: generator_loss=-2.934604503845861e-10, discriminator_loss=3.4938406315632164e-05\n",
            "step 1065: generator_loss=-1.7196190027490843e-09, discriminator_loss=4.3718668166548014e-05\n",
            "step 1066: generator_loss=-3.8610542540951087e-10, discriminator_loss=1.630727456358727e-05\n",
            "step 1067: generator_loss=-2.90194313024017e-10, discriminator_loss=1.1597077900660224e-05\n",
            "step 1068: generator_loss=-2.5151186688887606e-10, discriminator_loss=1.767121830198448e-05\n",
            "step 1069: generator_loss=-3.354719280146412e-10, discriminator_loss=1.9015777070308104e-05\n",
            "step 1070: generator_loss=-1.4014135685247453e-10, discriminator_loss=1.2477527889132034e-05\n",
            "step 1071: generator_loss=-1.3265900600245573e-09, discriminator_loss=2.1361645849538036e-05\n",
            "step 1072: generator_loss=-4.282478816008961e-10, discriminator_loss=2.8709448088193312e-05\n",
            "step 1073: generator_loss=-1.0864089627915519e-09, discriminator_loss=1.3724581549467985e-05\n",
            "step 1074: generator_loss=-1.200690880054367e-09, discriminator_loss=9.493865945842117e-06\n",
            "step 1075: generator_loss=-1.0834698693784617e-09, discriminator_loss=2.6055869966512546e-05\n",
            "step 1076: generator_loss=-1.0814028839067902e-10, discriminator_loss=3.93237205571495e-05\n",
            "step 1077: generator_loss=-5.27187571375265e-10, discriminator_loss=1.2018233974231407e-05\n",
            "step 1078: generator_loss=-6.343671421493724e-11, discriminator_loss=1.789551788533572e-05\n",
            "step 1079: generator_loss=-7.764994203185438e-10, discriminator_loss=2.228716948593501e-05\n",
            "step 1080: generator_loss=-5.440915273879909e-09, discriminator_loss=2.3247665012604557e-05\n",
            "step 1081: generator_loss=-4.4913658903134035e-10, discriminator_loss=6.612727702304255e-06\n",
            "step 1082: generator_loss=-4.4533493559484327e-10, discriminator_loss=9.921914170263335e-06\n",
            "step 1083: generator_loss=-1.876165889314052e-09, discriminator_loss=2.0963025235687383e-05\n",
            "step 1084: generator_loss=-6.390136336742458e-11, discriminator_loss=3.877823837683536e-05\n",
            "step 1085: generator_loss=-6.580005984524462e-10, discriminator_loss=8.197655915864743e-06\n",
            "step 1086: generator_loss=-1.2532080928551181e-09, discriminator_loss=3.2573614589637145e-05\n",
            "step 1087: generator_loss=-7.515511130096186e-11, discriminator_loss=1.8793018170981668e-05\n",
            "step 1088: generator_loss=-3.004366533332359e-09, discriminator_loss=1.2680027793976478e-05\n",
            "step 1089: generator_loss=-2.0768825548245218e-10, discriminator_loss=1.6259516996797174e-05\n",
            "step 1090: generator_loss=-1.4990600427644551e-10, discriminator_loss=4.9479178414912894e-05\n",
            "step 1091: generator_loss=-2.0301382797072165e-10, discriminator_loss=3.171617572661489e-05\n",
            "step 1092: generator_loss=-1.8657388967113775e-09, discriminator_loss=1.1551343959581573e-05\n",
            "step 1093: generator_loss=-7.253770362147804e-10, discriminator_loss=3.935924178222194e-05\n",
            "step 1094: generator_loss=-3.1462227267908816e-10, discriminator_loss=2.1693802409572527e-05\n",
            "step 1095: generator_loss=-1.5616599680079446e-10, discriminator_loss=4.527718556346372e-05\n",
            "step 1096: generator_loss=-8.227287184858767e-10, discriminator_loss=2.6347206585342064e-05\n",
            "step 1097: generator_loss=-8.964021191992799e-11, discriminator_loss=1.9622864783741534e-05\n",
            "step 1098: generator_loss=-8.86807016708957e-11, discriminator_loss=3.1007988582132384e-05\n",
            "step 1099: generator_loss=-4.283267143745384e-11, discriminator_loss=0.00012052678357576951\n",
            "step 1100: generator_loss=-2.510546492917598e-10, discriminator_loss=1.6663292626617476e-05\n",
            "step 1101: generator_loss=-1.3162235190655736e-10, discriminator_loss=2.3613420125911944e-05\n",
            "step 1102: generator_loss=-1.4398136016779972e-08, discriminator_loss=1.1770821402024012e-05\n",
            "step 1103: generator_loss=-1.1467198024472935e-10, discriminator_loss=3.876763003063388e-05\n",
            "step 1104: generator_loss=-1.0602972944084854e-09, discriminator_loss=1.437009541405132e-05\n",
            "step 1105: generator_loss=-3.4776004298464613e-10, discriminator_loss=2.0258084987290204e-05\n",
            "step 1106: generator_loss=-1.0369465286430568e-09, discriminator_loss=3.4121931093977764e-05\n",
            "step 1107: generator_loss=-8.343373214536598e-11, discriminator_loss=1.2502644494816195e-05\n",
            "step 1108: generator_loss=-1.4391363101218246e-10, discriminator_loss=1.847887506301049e-05\n",
            "step 1109: generator_loss=-3.66559949060985e-10, discriminator_loss=1.35221125674434e-05\n",
            "step 1110: generator_loss=-4.4603143400934187e-10, discriminator_loss=1.6640145986457355e-05\n",
            "step 1111: generator_loss=-7.863358852944202e-10, discriminator_loss=2.374271753069479e-05\n",
            "step 1112: generator_loss=-7.027989301633397e-11, discriminator_loss=9.811955351324286e-06\n",
            "step 1113: generator_loss=-2.7349958409139674e-10, discriminator_loss=2.0195619072183035e-05\n",
            "step 1114: generator_loss=-5.8065725838662985e-11, discriminator_loss=2.0122373825870454e-05\n",
            "step 1115: generator_loss=-6.860236823058585e-10, discriminator_loss=1.6704141671652906e-05\n",
            "step 1116: generator_loss=-2.832512002726162e-10, discriminator_loss=3.9789436414139345e-05\n",
            "step 1117: generator_loss=-9.823700186650797e-11, discriminator_loss=2.2982514565228485e-05\n",
            "step 1118: generator_loss=-2.330999615551832e-09, discriminator_loss=1.1194390935997944e-05\n",
            "step 1119: generator_loss=-7.523960343647218e-10, discriminator_loss=1.8658009139471687e-05\n",
            "step 1120: generator_loss=-2.090537076782084e-09, discriminator_loss=2.120600220223423e-05\n",
            "step 1121: generator_loss=-1.1688404411014375e-10, discriminator_loss=6.435695831896737e-05\n",
            "step 1122: generator_loss=-5.6800779357768505e-11, discriminator_loss=2.155398942704778e-05\n",
            "step 1123: generator_loss=-5.819063286782722e-11, discriminator_loss=3.0640811019111425e-05\n",
            "step 1124: generator_loss=-1.3419193534147666e-10, discriminator_loss=3.220094367861748e-05\n",
            "step 1125: generator_loss=-1.193954379807849e-09, discriminator_loss=2.5653214834164828e-05\n",
            "step 1126: generator_loss=-3.126480740966997e-10, discriminator_loss=1.0597675100143533e-05\n",
            "step 1127: generator_loss=-2.322274594845908e-09, discriminator_loss=3.7101424823049456e-05\n",
            "step 1128: generator_loss=-2.5109114787369435e-10, discriminator_loss=5.583549864240922e-06\n",
            "step 1129: generator_loss=-3.7225394988738003e-10, discriminator_loss=3.4199536457890645e-05\n",
            "step 1130: generator_loss=-3.264510328726544e-10, discriminator_loss=4.552170503302477e-05\n",
            "step 1131: generator_loss=-4.360671546077555e-11, discriminator_loss=2.0768717149621807e-05\n",
            "step 1132: generator_loss=-2.10415840307121e-09, discriminator_loss=2.470772960805334e-05\n",
            "step 1133: generator_loss=-1.5329196800806244e-09, discriminator_loss=6.469163054134697e-05\n",
            "step 1134: generator_loss=-2.0044303994382062e-09, discriminator_loss=2.5203000404872e-05\n",
            "step 1135: generator_loss=-1.0123754612401115e-10, discriminator_loss=4.4339314626995474e-05\n",
            "step 1136: generator_loss=-3.106290780152676e-10, discriminator_loss=1.9229149984312244e-05\n",
            "step 1137: generator_loss=-1.2251505365767912e-09, discriminator_loss=3.434091922827065e-05\n",
            "step 1138: generator_loss=-6.295543947265614e-11, discriminator_loss=3.706045026774518e-05\n",
            "step 1139: generator_loss=-5.735002472917472e-10, discriminator_loss=2.1940995793556795e-05\n",
            "step 1140: generator_loss=-2.79707879080604e-09, discriminator_loss=2.957851938845124e-05\n",
            "step 1141: generator_loss=-2.274334193197447e-10, discriminator_loss=2.2958936824579723e-05\n",
            "step 1142: generator_loss=-1.2080965117178266e-09, discriminator_loss=1.8331140381633304e-05\n",
            "step 1143: generator_loss=-1.7100176830098235e-10, discriminator_loss=1.8162019841838628e-05\n",
            "step 1144: generator_loss=-1.1184244502748797e-10, discriminator_loss=1.3983782082505058e-05\n",
            "step 1145: generator_loss=-7.687201097894558e-09, discriminator_loss=2.118287557095755e-05\n",
            "step 1146: generator_loss=-4.096512573603661e-10, discriminator_loss=7.059496965666767e-06\n",
            "step 1147: generator_loss=-5.064971775325944e-10, discriminator_loss=2.1853720681974664e-05\n",
            "step 1148: generator_loss=-7.573576488173472e-11, discriminator_loss=2.4478364139213227e-05\n",
            "step 1149: generator_loss=-1.9096725589751173e-10, discriminator_loss=1.859846815932542e-05\n",
            "step 1150: generator_loss=-9.271335921212653e-10, discriminator_loss=1.8225526218884625e-05\n",
            "step 1151: generator_loss=-5.521509915951128e-10, discriminator_loss=2.032357588177547e-05\n",
            "step 1152: generator_loss=-4.1820298335437656e-09, discriminator_loss=1.751691524987109e-05\n",
            "step 1153: generator_loss=-1.1445791536779382e-10, discriminator_loss=9.69670418271562e-06\n",
            "step 1154: generator_loss=-4.1639747205834965e-10, discriminator_loss=2.1458923583850265e-05\n",
            "step 1155: generator_loss=-1.962652540488108e-10, discriminator_loss=3.58317956852261e-05\n",
            "step 1156: generator_loss=-8.634598591683584e-11, discriminator_loss=5.0012939027510583e-05\n",
            "step 1157: generator_loss=-5.968190525118544e-11, discriminator_loss=1.5786497897352092e-05\n",
            "step 1158: generator_loss=-3.563339068257676e-10, discriminator_loss=1.049587535817409e-05\n",
            "step 1159: generator_loss=-6.751490921885761e-09, discriminator_loss=2.4253582523670048e-05\n",
            "step 1160: generator_loss=-2.772303497877715e-10, discriminator_loss=1.6328365745721385e-05\n",
            "step 1161: generator_loss=-7.567193399671268e-11, discriminator_loss=5.521835555555299e-05\n",
            "step 1162: generator_loss=-1.3092071871056987e-09, discriminator_loss=2.4045482859946787e-05\n",
            "step 1163: generator_loss=-8.318410960050926e-10, discriminator_loss=1.9633027477539144e-05\n",
            "step 1164: generator_loss=-6.276882347222568e-10, discriminator_loss=2.4365619538002647e-05\n",
            "step 1165: generator_loss=-5.376942002754959e-09, discriminator_loss=8.222257747547701e-06\n",
            "step 1166: generator_loss=-1.4937543424409228e-09, discriminator_loss=8.26727682579076e-06\n",
            "step 1167: generator_loss=-4.0039133120117754e-10, discriminator_loss=2.9664770408999175e-05\n",
            "step 1168: generator_loss=-7.908482757557067e-10, discriminator_loss=6.972282790229656e-06\n",
            "step 1169: generator_loss=-9.203427603354797e-11, discriminator_loss=1.1610822184593417e-05\n",
            "step 1170: generator_loss=-2.5391977409583433e-10, discriminator_loss=5.1935297960881144e-05\n",
            "step 1171: generator_loss=-9.102923970161214e-10, discriminator_loss=1.0342154382669833e-05\n",
            "step 1172: generator_loss=-1.6444441641727536e-10, discriminator_loss=1.563614023325499e-05\n",
            "step 1173: generator_loss=-1.5909557005144848e-10, discriminator_loss=1.3197469343140256e-05\n",
            "step 1174: generator_loss=-4.588702473551365e-10, discriminator_loss=1.985585731745232e-05\n",
            "step 1175: generator_loss=-6.258621398913533e-10, discriminator_loss=2.5464934878982604e-05\n",
            "step 1176: generator_loss=-4.294096744850151e-10, discriminator_loss=1.6370660887332633e-05\n",
            "step 1177: generator_loss=-1.3885860516982262e-10, discriminator_loss=2.0200430299155414e-05\n",
            "step 1178: generator_loss=-3.198002140880618e-10, discriminator_loss=1.331023213424487e-05\n",
            "step 1179: generator_loss=-1.835405072370122e-08, discriminator_loss=1.6614440028206445e-05\n",
            "step 1180: generator_loss=-3.5256697561436567e-10, discriminator_loss=1.3820158528687898e-05\n",
            "step 1181: generator_loss=-1.4419284655176057e-09, discriminator_loss=2.3297507141251117e-05\n",
            "step 1182: generator_loss=-8.154700248397262e-10, discriminator_loss=1.8581802578410134e-05\n",
            "step 1183: generator_loss=-1.7570254973175992e-10, discriminator_loss=1.555172639200464e-05\n",
            "step 1184: generator_loss=-5.557276860912452e-10, discriminator_loss=2.7520753064891323e-05\n",
            "step 1185: generator_loss=-1.3648449037617638e-10, discriminator_loss=1.7222118913196027e-05\n",
            "step 1186: generator_loss=-8.652945027165515e-11, discriminator_loss=1.6606520148343407e-05\n",
            "step 1187: generator_loss=-9.27590781962806e-11, discriminator_loss=3.0588584195356816e-05\n",
            "step 1188: generator_loss=-3.9938066742628564e-10, discriminator_loss=1.4766529602638911e-05\n",
            "step 1189: generator_loss=-1.5161948085928856e-10, discriminator_loss=1.7643753380980343e-05\n",
            "step 1190: generator_loss=-1.6907388822318126e-09, discriminator_loss=1.085282929125242e-05\n",
            "step 1191: generator_loss=-1.747735289825414e-10, discriminator_loss=2.9777955205645412e-05\n",
            "step 1192: generator_loss=-3.3563540835501726e-10, discriminator_loss=3.0090808650129475e-05\n",
            "step 1193: generator_loss=-2.1288205920289016e-10, discriminator_loss=1.628076279303059e-05\n",
            "step 1194: generator_loss=-1.1207798022994098e-09, discriminator_loss=2.8881480830023065e-05\n",
            "step 1195: generator_loss=-2.6329097235766596e-10, discriminator_loss=2.3378517653327435e-05\n",
            "step 1196: generator_loss=-1.0161069208258766e-10, discriminator_loss=2.6312549380236305e-05\n",
            "step 1197: generator_loss=-2.9041999360934767e-10, discriminator_loss=1.4096898667048663e-05\n",
            "step 1198: generator_loss=-5.492243881910497e-10, discriminator_loss=4.690919740824029e-05\n",
            "step 1199: generator_loss=-1.4229933897880187e-09, discriminator_loss=6.430805569834774e-06\n",
            "step 1200: generator_loss=-8.919800453810467e-10, discriminator_loss=2.8619839213206433e-05\n",
            "step 1201: generator_loss=-2.2975174540640353e-10, discriminator_loss=8.425875421380624e-06\n",
            "step 1202: generator_loss=-1.9459192590609575e-10, discriminator_loss=9.542972293274943e-06\n",
            "step 1203: generator_loss=-5.156698956731987e-10, discriminator_loss=1.1966781130468007e-05\n",
            "step 1204: generator_loss=-5.250464507611241e-10, discriminator_loss=3.67528191418387e-05\n",
            "step 1205: generator_loss=-7.054994088928623e-11, discriminator_loss=9.860294085228816e-06\n",
            "step 1206: generator_loss=-4.781846585366623e-10, discriminator_loss=2.10196685657138e-05\n",
            "step 1207: generator_loss=-4.67193261854959e-09, discriminator_loss=2.844393929990474e-05\n",
            "step 1208: generator_loss=-1.6103320066296334e-10, discriminator_loss=1.857704046415165e-05\n",
            "step 1209: generator_loss=-2.471271798309971e-10, discriminator_loss=1.5909652574919164e-05\n",
            "step 1210: generator_loss=-1.355651146894843e-10, discriminator_loss=2.2113299564807676e-05\n",
            "step 1211: generator_loss=-2.281418165495097e-09, discriminator_loss=1.417170096829068e-05\n",
            "step 1212: generator_loss=-1.9525843442114166e-10, discriminator_loss=2.2760970750823617e-05\n",
            "step 1213: generator_loss=-5.77171366256124e-10, discriminator_loss=2.0479117665672675e-05\n",
            "step 1214: generator_loss=-8.29578572503209e-10, discriminator_loss=4.88339428557083e-05\n",
            "step 1215: generator_loss=-9.026238090292793e-10, discriminator_loss=1.3120280527800787e-05\n",
            "step 1216: generator_loss=-7.806371549179403e-09, discriminator_loss=1.5070140761963557e-05\n",
            "step 1217: generator_loss=-2.2552434919553832e-10, discriminator_loss=2.0656761989812367e-05\n",
            "step 1218: generator_loss=-1.7685055642147063e-09, discriminator_loss=2.1839494365849532e-05\n",
            "step 1219: generator_loss=-2.0350357510245942e-10, discriminator_loss=1.4993400327512063e-05\n",
            "step 1220: generator_loss=-2.506444218841608e-10, discriminator_loss=2.2643218471785076e-05\n",
            "step 1221: generator_loss=-7.400437485038935e-10, discriminator_loss=1.702394183666911e-05\n",
            "step 1222: generator_loss=-5.484063425598151e-09, discriminator_loss=1.3704000593861565e-05\n",
            "step 1223: generator_loss=-3.156243044699636e-10, discriminator_loss=5.706622232537484e-06\n",
            "step 1224: generator_loss=-1.095469048806308e-09, discriminator_loss=3.435714461375028e-05\n",
            "step 1225: generator_loss=-1.8182939598432313e-08, discriminator_loss=1.8711696611717343e-05\n",
            "step 1226: generator_loss=-1.1791384535442262e-10, discriminator_loss=5.499213875737041e-05\n",
            "step 1227: generator_loss=-6.024732102094532e-11, discriminator_loss=1.7698794181342237e-05\n",
            "step 1228: generator_loss=-1.3458947845101932e-10, discriminator_loss=1.1275968063273467e-05\n",
            "step 1229: generator_loss=-5.315174966824543e-10, discriminator_loss=1.5431243809871376e-05\n",
            "step 1230: generator_loss=-1.6711199091190565e-10, discriminator_loss=1.700202665233519e-05\n",
            "step 1231: generator_loss=-7.447758854084441e-09, discriminator_loss=6.268569904932519e-06\n",
            "step 1232: generator_loss=-1.1670741040248345e-09, discriminator_loss=2.296469574503135e-05\n",
            "step 1233: generator_loss=-2.6604765612781023e-10, discriminator_loss=3.181138163199648e-05\n",
            "step 1234: generator_loss=-3.0146392049346105e-09, discriminator_loss=8.139136298268568e-06\n",
            "step 1235: generator_loss=-1.0098620828458138e-09, discriminator_loss=2.0737445083796047e-05\n",
            "step 1236: generator_loss=-4.2788800280746386e-10, discriminator_loss=2.6884190447162837e-05\n",
            "step 1237: generator_loss=-2.823998812573336e-09, discriminator_loss=2.2661188268102705e-05\n",
            "step 1238: generator_loss=-2.3408752714004777e-09, discriminator_loss=2.0948653400409967e-05\n",
            "step 1239: generator_loss=-7.571478444212687e-10, discriminator_loss=1.1908094165846705e-05\n",
            "step 1240: generator_loss=-5.114714429765854e-09, discriminator_loss=3.088842277065851e-05\n",
            "step 1241: generator_loss=-2.2177575054183052e-10, discriminator_loss=5.4009979066904634e-05\n",
            "step 1242: generator_loss=-2.8646787719743827e-10, discriminator_loss=4.7875484597170725e-05\n",
            "step 1243: generator_loss=-3.588791763764476e-10, discriminator_loss=8.295713087136392e-06\n",
            "step 1244: generator_loss=-2.312400687598526e-10, discriminator_loss=1.6439566024928354e-05\n",
            "step 1245: generator_loss=-4.4570036550339864e-09, discriminator_loss=1.6302756193908863e-05\n",
            "step 1246: generator_loss=-1.1717562919955071e-08, discriminator_loss=8.531804633093998e-05\n",
            "step 1247: generator_loss=-5.415554671373002e-09, discriminator_loss=1.3847115951648448e-05\n",
            "step 1248: generator_loss=-9.643564835570828e-10, discriminator_loss=1.770194648997858e-05\n",
            "step 1249: generator_loss=-6.940821251077978e-10, discriminator_loss=1.3685369594895747e-05\n",
            "step 1250: generator_loss=-1.9012552643360436e-10, discriminator_loss=1.3888750800106209e-05\n",
            "step 1251: generator_loss=-4.763109698324719e-11, discriminator_loss=1.2916878404212184e-05\n",
            "step 1252: generator_loss=-1.0456510102230254e-09, discriminator_loss=2.8707623641821556e-05\n",
            "step 1253: generator_loss=-1.8273704771587518e-10, discriminator_loss=9.521996616967954e-06\n",
            "step 1254: generator_loss=-1.1876628847051762e-10, discriminator_loss=2.8574937459779903e-05\n",
            "step 1255: generator_loss=-5.007609882312636e-10, discriminator_loss=7.448653832398122e-06\n",
            "step 1256: generator_loss=-1.0613744605425524e-10, discriminator_loss=9.335455615655519e-06\n",
            "step 1257: generator_loss=-4.132151287805641e-10, discriminator_loss=3.8193149521248415e-05\n",
            "step 1258: generator_loss=-5.432591043685875e-10, discriminator_loss=4.890218860964524e-06\n",
            "step 1259: generator_loss=-8.792917505218156e-10, discriminator_loss=3.840838326141238e-05\n",
            "step 1260: generator_loss=-1.5493015204093297e-10, discriminator_loss=2.1673755327356048e-05\n",
            "step 1261: generator_loss=-1.2776963487226567e-08, discriminator_loss=9.914307156577706e-06\n",
            "step 1262: generator_loss=-1.1936203414553148e-10, discriminator_loss=2.3889810108812526e-05\n",
            "step 1263: generator_loss=-5.846340633830494e-10, discriminator_loss=1.4938147614884656e-05\n",
            "step 1264: generator_loss=-1.3150400213213231e-10, discriminator_loss=1.474578857596498e-05\n",
            "step 1265: generator_loss=-1.4839459439031089e-08, discriminator_loss=2.0773379219463095e-05\n",
            "step 1266: generator_loss=-5.047086637510745e-10, discriminator_loss=1.4003879186930135e-05\n",
            "step 1267: generator_loss=-6.909895988727044e-10, discriminator_loss=1.0562189345364459e-05\n",
            "step 1268: generator_loss=-1.9460244526925408e-09, discriminator_loss=2.016452890529763e-05\n",
            "step 1269: generator_loss=-3.8205119068379645e-09, discriminator_loss=3.064804332097992e-05\n",
            "step 1270: generator_loss=-2.9966590320285036e-10, discriminator_loss=1.191741739603458e-05\n",
            "step 1271: generator_loss=-3.037682816398046e-08, discriminator_loss=2.888090421038214e-05\n",
            "step 1272: generator_loss=-1.5197479941164715e-09, discriminator_loss=0.00010900481720454991\n",
            "step 1273: generator_loss=-1.3522957753586695e-10, discriminator_loss=3.2944681152002886e-05\n",
            "step 1274: generator_loss=-2.622147610154002e-09, discriminator_loss=1.5264737157849595e-05\n",
            "step 1275: generator_loss=-5.372326472574684e-10, discriminator_loss=1.5786677977303043e-05\n",
            "step 1276: generator_loss=-2.8159006237871154e-09, discriminator_loss=2.016988946706988e-05\n",
            "step 1277: generator_loss=-1.0196296584830122e-10, discriminator_loss=8.882802831067238e-06\n",
            "step 1278: generator_loss=-3.070715948183533e-08, discriminator_loss=7.2904786065919325e-06\n",
            "step 1279: generator_loss=-6.147347075824428e-10, discriminator_loss=1.6234063878073357e-05\n",
            "step 1280: generator_loss=-6.282397380097393e-10, discriminator_loss=1.2611589227162767e-05\n",
            "step 1281: generator_loss=-1.7015365505468338e-10, discriminator_loss=4.268130942364223e-05\n",
            "step 1282: generator_loss=-4.5338915954928893e-10, discriminator_loss=6.268271135922987e-06\n",
            "step 1283: generator_loss=-1.3591290315417837e-09, discriminator_loss=2.724841033341363e-05\n",
            "step 1284: generator_loss=-3.70729447141116e-10, discriminator_loss=1.5347419321187772e-05\n",
            "step 1285: generator_loss=-1.0253349280731072e-09, discriminator_loss=2.3142643840401433e-05\n",
            "step 1286: generator_loss=-1.983669062344262e-10, discriminator_loss=2.307023351022508e-05\n",
            "step 1287: generator_loss=-2.263763759779991e-10, discriminator_loss=7.34448485673056e-06\n",
            "step 1288: generator_loss=-5.632348476503068e-10, discriminator_loss=8.309863187605515e-05\n",
            "step 1289: generator_loss=-3.956142524685902e-09, discriminator_loss=2.150962063751649e-05\n",
            "step 1290: generator_loss=-8.501976900276986e-10, discriminator_loss=2.8690059480140917e-05\n",
            "step 1291: generator_loss=-6.808185126772059e-10, discriminator_loss=7.122774150047917e-06\n",
            "step 1292: generator_loss=-2.998089776440338e-09, discriminator_loss=2.9531700420193374e-05\n",
            "step 1293: generator_loss=-1.2485961153885228e-09, discriminator_loss=1.581284959684126e-05\n",
            "step 1294: generator_loss=-1.6461483287599776e-09, discriminator_loss=5.984962172078667e-06\n",
            "step 1295: generator_loss=-4.851019586027405e-10, discriminator_loss=1.0194733476964757e-05\n",
            "step 1296: generator_loss=-3.153781402698286e-11, discriminator_loss=5.481531843543053e-06\n",
            "step 1297: generator_loss=-2.815046529214271e-10, discriminator_loss=7.246738096000627e-05\n",
            "step 1298: generator_loss=-1.3727023684406703e-10, discriminator_loss=1.610543768038042e-05\n",
            "step 1299: generator_loss=-3.807832382740628e-10, discriminator_loss=4.396634176373482e-05\n",
            "step 1300: generator_loss=-3.253163294303363e-10, discriminator_loss=1.92539555428084e-05\n",
            "step 1301: generator_loss=-4.3580891673222766e-10, discriminator_loss=2.1328973161871545e-05\n",
            "step 1302: generator_loss=-7.414435038155531e-11, discriminator_loss=1.699600943538826e-05\n",
            "step 1303: generator_loss=-2.7227903959259336e-11, discriminator_loss=1.8007809558184817e-05\n",
            "step 1304: generator_loss=-4.3401704452605827e-10, discriminator_loss=6.355443019856466e-06\n",
            "step 1305: generator_loss=-7.500922105663221e-10, discriminator_loss=2.3187621991382912e-05\n",
            "step 1306: generator_loss=-9.405161094377945e-10, discriminator_loss=4.837328378926031e-05\n",
            "step 1307: generator_loss=-1.2620030021004425e-10, discriminator_loss=2.8075879527023062e-05\n",
            "step 1308: generator_loss=-1.7287364595386379e-10, discriminator_loss=3.85292514692992e-05\n",
            "step 1309: generator_loss=-9.973333964241604e-11, discriminator_loss=1.2698515092779417e-05\n",
            "step 1310: generator_loss=-4.007828291463511e-09, discriminator_loss=6.240562470338773e-06\n",
            "step 1311: generator_loss=-5.842771821917836e-10, discriminator_loss=1.0204807040281594e-05\n",
            "step 1312: generator_loss=-1.2912863833758337e-10, discriminator_loss=5.316707392921671e-05\n",
            "step 1313: generator_loss=-4.907021455835547e-10, discriminator_loss=3.551172267179936e-05\n",
            "step 1314: generator_loss=-1.1876408190225618e-10, discriminator_loss=1.5827441529836506e-05\n",
            "step 1315: generator_loss=-1.5118650775747255e-09, discriminator_loss=7.079814167809673e-06\n",
            "step 1316: generator_loss=-2.7094884669232044e-10, discriminator_loss=1.7262993424083106e-05\n",
            "step 1317: generator_loss=-1.8557102521299385e-09, discriminator_loss=2.0925253920722753e-05\n",
            "step 1318: generator_loss=-3.3107840913260134e-09, discriminator_loss=1.2505239283200353e-05\n",
            "step 1319: generator_loss=-4.517030915973663e-10, discriminator_loss=1.9546174371498637e-05\n",
            "step 1320: generator_loss=-2.292062928344052e-10, discriminator_loss=1.7793659935705364e-05\n",
            "step 1321: generator_loss=-1.9187568200962346e-10, discriminator_loss=1.0365570233261678e-05\n",
            "step 1322: generator_loss=-2.886278105407314e-09, discriminator_loss=5.98683072894346e-06\n",
            "step 1323: generator_loss=-4.373063022811152e-10, discriminator_loss=1.627254459890537e-05\n",
            "step 1324: generator_loss=-3.336695364453135e-10, discriminator_loss=7.271266440511681e-06\n",
            "step 1325: generator_loss=-1.4022794037060748e-09, discriminator_loss=7.174528946052305e-06\n",
            "step 1326: generator_loss=-2.63725458138353e-10, discriminator_loss=2.632852192618884e-05\n",
            "step 1327: generator_loss=-4.62221927399753e-10, discriminator_loss=2.1392661437857896e-05\n",
            "step 1328: generator_loss=-2.0435228509363412e-10, discriminator_loss=6.196450613060733e-06\n",
            "step 1329: generator_loss=-3.09581277280202e-10, discriminator_loss=2.1035501049482264e-05\n",
            "step 1330: generator_loss=-1.5090385607763324e-09, discriminator_loss=1.1678585906338412e-05\n",
            "step 1331: generator_loss=-4.976912770793263e-10, discriminator_loss=3.4996272006537765e-05\n",
            "step 1332: generator_loss=-1.0811639777896787e-10, discriminator_loss=1.0284053132636473e-05\n",
            "step 1333: generator_loss=-2.073137356228827e-10, discriminator_loss=2.071059680019971e-05\n",
            "step 1334: generator_loss=-5.593156604533078e-09, discriminator_loss=8.597270607424434e-06\n",
            "step 1335: generator_loss=-2.64664756777222e-09, discriminator_loss=2.1619067410938442e-05\n",
            "step 1336: generator_loss=-2.230403223224542e-10, discriminator_loss=7.131715392461047e-06\n",
            "step 1337: generator_loss=-8.727125966334626e-11, discriminator_loss=2.2960815840633586e-05\n",
            "step 1338: generator_loss=-8.55642612318519e-10, discriminator_loss=2.990078974107746e-05\n",
            "step 1339: generator_loss=-3.4798397496871303e-10, discriminator_loss=1.1701816220011096e-05\n",
            "step 1340: generator_loss=-1.2196196830238648e-10, discriminator_loss=8.272118429886177e-05\n",
            "step 1341: generator_loss=-2.0938417666371834e-10, discriminator_loss=1.2188785149191972e-05\n",
            "step 1342: generator_loss=-1.345231842586614e-10, discriminator_loss=1.3836111975251697e-05\n",
            "step 1343: generator_loss=-5.855664841902808e-10, discriminator_loss=2.8454030598368263e-06\n",
            "step 1344: generator_loss=-7.926093115173671e-10, discriminator_loss=3.885057139996206e-06\n",
            "step 1345: generator_loss=-1.9193275857531944e-09, discriminator_loss=1.3958172530692536e-05\n",
            "step 1346: generator_loss=-9.407222917312552e-11, discriminator_loss=2.6396231987746432e-05\n",
            "step 1347: generator_loss=-4.986957513608559e-10, discriminator_loss=5.246175078355009e-06\n",
            "step 1348: generator_loss=-1.8013575353581501e-10, discriminator_loss=6.847222266515018e-06\n",
            "step 1349: generator_loss=-1.783660164011991e-10, discriminator_loss=6.008198397466913e-06\n",
            "step 1350: generator_loss=-1.6058948615338409e-09, discriminator_loss=4.108012035430875e-06\n",
            "step 1351: generator_loss=-3.2317118425773117e-10, discriminator_loss=4.365710628917441e-05\n",
            "step 1352: generator_loss=-3.2329727783775297e-10, discriminator_loss=3.7264457205310464e-05\n",
            "step 1353: generator_loss=-6.218943138236455e-10, discriminator_loss=5.08460943819955e-05\n",
            "step 1354: generator_loss=-9.34438637578694e-10, discriminator_loss=1.0836376532097347e-05\n",
            "step 1355: generator_loss=-3.099923651106451e-10, discriminator_loss=1.0401406143500935e-05\n",
            "step 1356: generator_loss=-3.103063139775486e-09, discriminator_loss=1.6940066416282207e-05\n",
            "step 1357: generator_loss=-2.439151311484089e-11, discriminator_loss=2.5190633095917292e-05\n",
            "step 1358: generator_loss=-4.964357813719289e-10, discriminator_loss=9.840948223427404e-06\n",
            "step 1359: generator_loss=-1.0902531100143165e-09, discriminator_loss=6.734068847435992e-06\n",
            "step 1360: generator_loss=-5.547440284914273e-10, discriminator_loss=1.1229001756873913e-05\n",
            "step 1361: generator_loss=-1.2142710170692794e-09, discriminator_loss=1.1246588655922096e-05\n",
            "step 1362: generator_loss=-4.124936836547022e-09, discriminator_loss=4.288583568268223e-06\n",
            "step 1363: generator_loss=-5.593383534119312e-10, discriminator_loss=2.1826157535542734e-05\n",
            "step 1364: generator_loss=-1.7244179695286022e-10, discriminator_loss=1.3157346984371543e-05\n",
            "step 1365: generator_loss=-1.2772832791441147e-10, discriminator_loss=1.3277227481012233e-05\n",
            "step 1366: generator_loss=-1.3564036005497826e-10, discriminator_loss=2.1195230146986432e-05\n",
            "step 1367: generator_loss=-1.0295595487264109e-09, discriminator_loss=1.156006328528747e-05\n",
            "step 1368: generator_loss=-2.230083895327084e-10, discriminator_loss=6.697616754536284e-06\n",
            "step 1369: generator_loss=-1.2959928685774003e-09, discriminator_loss=1.3159935406292789e-05\n",
            "step 1370: generator_loss=-4.579064238896535e-09, discriminator_loss=1.8684453607420437e-05\n",
            "step 1371: generator_loss=-3.0841457165919905e-10, discriminator_loss=2.0308141756686382e-05\n",
            "step 1372: generator_loss=-7.033411630885666e-10, discriminator_loss=1.4177517186908517e-05\n",
            "step 1373: generator_loss=-2.847774793757196e-10, discriminator_loss=1.0688773727451917e-05\n",
            "step 1374: generator_loss=-1.41611078419146e-08, discriminator_loss=3.4485368814785033e-05\n",
            "step 1375: generator_loss=-4.1057532373933725e-10, discriminator_loss=1.0571733582764864e-05\n",
            "step 1376: generator_loss=-2.668636145397585e-10, discriminator_loss=1.2120981409680098e-05\n",
            "step 1377: generator_loss=-7.442915173072606e-10, discriminator_loss=1.4802984878770076e-05\n",
            "step 1378: generator_loss=-3.5242891938125354e-10, discriminator_loss=1.5576615624013357e-05\n",
            "step 1379: generator_loss=-4.361973560129684e-10, discriminator_loss=1.742962558637373e-05\n",
            "step 1380: generator_loss=-4.825081445503088e-10, discriminator_loss=1.6509318811586127e-05\n",
            "step 1381: generator_loss=-1.2626281131744577e-09, discriminator_loss=3.6504432500805706e-05\n",
            "step 1382: generator_loss=-1.1618404849311759e-10, discriminator_loss=1.3782429959974252e-05\n",
            "step 1383: generator_loss=-2.7434585159191727e-10, discriminator_loss=1.222613991558319e-05\n",
            "step 1384: generator_loss=-2.2377510955351454e-10, discriminator_loss=1.7271979231736623e-05\n",
            "step 1385: generator_loss=-1.0155830343361316e-10, discriminator_loss=2.2052778149372898e-05\n",
            "step 1386: generator_loss=-2.0141148748820115e-09, discriminator_loss=1.7481681425124407e-05\n",
            "step 1387: generator_loss=-6.356782322747279e-10, discriminator_loss=8.775888090895023e-06\n",
            "step 1388: generator_loss=-5.714351214436419e-10, discriminator_loss=6.112951723480364e-06\n",
            "step 1389: generator_loss=-7.823664494033267e-10, discriminator_loss=1.9171609892509878e-05\n",
            "step 1390: generator_loss=-4.70507677263754e-09, discriminator_loss=1.1603428902162705e-05\n",
            "step 1391: generator_loss=-1.1738143790296363e-10, discriminator_loss=1.9092096408712678e-05\n",
            "step 1392: generator_loss=-2.2825463741327212e-10, discriminator_loss=1.4908661796653178e-05\n",
            "step 1393: generator_loss=-2.2303826840985863e-10, discriminator_loss=8.101117600745056e-06\n",
            "step 1394: generator_loss=-1.197471011238349e-10, discriminator_loss=3.408631164347753e-05\n",
            "step 1395: generator_loss=-1.8024624848234083e-10, discriminator_loss=2.735401949394145e-06\n",
            "step 1396: generator_loss=-1.717335579298762e-10, discriminator_loss=2.6607232939568348e-05\n",
            "step 1397: generator_loss=-5.871490099673693e-11, discriminator_loss=1.8971135432366282e-05\n",
            "step 1398: generator_loss=-5.165202709989103e-10, discriminator_loss=7.377519978035707e-06\n",
            "step 1399: generator_loss=-1.2079875766346504e-08, discriminator_loss=1.4670878044853453e-05\n",
            "step 1400: generator_loss=-1.7982507150016147e-10, discriminator_loss=7.370732782874256e-05\n",
            "step 1401: generator_loss=-1.7052276257700782e-09, discriminator_loss=1.5712432286818512e-05\n",
            "step 1402: generator_loss=-9.780921628177452e-10, discriminator_loss=1.6655581930535845e-05\n",
            "step 1403: generator_loss=-8.659614691985951e-10, discriminator_loss=2.652111834322568e-05\n",
            "step 1404: generator_loss=-6.678045894048523e-10, discriminator_loss=4.3747888412326574e-05\n",
            "step 1405: generator_loss=-1.2561723883308673e-10, discriminator_loss=1.6712790966266766e-05\n",
            "step 1406: generator_loss=-5.083406473538332e-10, discriminator_loss=1.5525951312156394e-05\n",
            "step 1407: generator_loss=-7.7489648031559e-10, discriminator_loss=8.013580554688815e-06\n",
            "step 1408: generator_loss=-3.2238178793164707e-10, discriminator_loss=1.1696768524416257e-05\n",
            "step 1409: generator_loss=-1.5956246324222434e-09, discriminator_loss=2.0890905943815596e-05\n",
            "step 1410: generator_loss=-3.110440516262969e-10, discriminator_loss=9.944071280187927e-06\n",
            "step 1411: generator_loss=-4.223375427159226e-09, discriminator_loss=8.308035830850713e-06\n",
            "step 1412: generator_loss=-2.963911616138404e-10, discriminator_loss=1.2191128007543739e-05\n",
            "step 1413: generator_loss=-2.8092890236308676e-09, discriminator_loss=1.1681287105602678e-05\n",
            "step 1414: generator_loss=-1.452858056083528e-09, discriminator_loss=5.8079596783500165e-05\n",
            "step 1415: generator_loss=-3.2861327547983876e-10, discriminator_loss=4.4241442083148286e-06\n",
            "step 1416: generator_loss=-1.7759035908504472e-10, discriminator_loss=9.063231118489057e-06\n",
            "step 1417: generator_loss=-9.130279310376466e-10, discriminator_loss=1.1174930477864109e-05\n",
            "step 1418: generator_loss=-8.236429316355043e-09, discriminator_loss=9.723709808895364e-06\n",
            "step 1419: generator_loss=-1.0988741860895601e-10, discriminator_loss=1.7857864804682322e-05\n",
            "step 1420: generator_loss=-5.462129082367539e-10, discriminator_loss=2.582866363809444e-05\n",
            "step 1421: generator_loss=-1.0101944836193866e-09, discriminator_loss=6.117143129813485e-06\n",
            "step 1422: generator_loss=-2.451857883389863e-10, discriminator_loss=1.141533903137315e-05\n",
            "step 1423: generator_loss=-8.670608120375789e-10, discriminator_loss=1.760725353960879e-05\n",
            "step 1424: generator_loss=-6.882378000838685e-10, discriminator_loss=4.8539339331910014e-05\n",
            "step 1425: generator_loss=-2.3086205169775553e-10, discriminator_loss=6.991002010181546e-06\n",
            "step 1426: generator_loss=-7.370415389118534e-10, discriminator_loss=4.370116221252829e-05\n",
            "step 1427: generator_loss=-2.625691331026303e-10, discriminator_loss=1.917448389576748e-05\n",
            "step 1428: generator_loss=-1.6870976837779494e-10, discriminator_loss=7.980013833730482e-06\n",
            "step 1429: generator_loss=-1.1602661054155305e-09, discriminator_loss=2.9505547445296543e-06\n",
            "step 1430: generator_loss=-5.808201475332453e-09, discriminator_loss=1.812333175621461e-05\n",
            "step 1431: generator_loss=-2.570901269649539e-10, discriminator_loss=3.107382781308843e-06\n",
            "step 1432: generator_loss=-2.6821644905083986e-10, discriminator_loss=3.3330761652905494e-05\n",
            "step 1433: generator_loss=-8.156642028467331e-11, discriminator_loss=3.057894355151802e-05\n",
            "step 1434: generator_loss=-4.900726491285923e-09, discriminator_loss=5.335243713489035e-06\n",
            "step 1435: generator_loss=-3.985413776774749e-09, discriminator_loss=4.539025394478813e-05\n",
            "step 1436: generator_loss=-2.927928177687278e-10, discriminator_loss=9.990394573833328e-06\n",
            "step 1437: generator_loss=-1.3755316885522006e-09, discriminator_loss=3.514173295116052e-05\n",
            "step 1438: generator_loss=-1.6754837517396481e-09, discriminator_loss=1.1264944077993277e-05\n",
            "step 1439: generator_loss=-1.174594022046449e-08, discriminator_loss=2.6914829504676163e-05\n",
            "step 1440: generator_loss=-6.068198166175875e-10, discriminator_loss=1.908944614115171e-05\n",
            "step 1441: generator_loss=-2.4374849361130657e-10, discriminator_loss=1.2987338777747937e-05\n",
            "step 1442: generator_loss=-5.376616929453348e-09, discriminator_loss=1.4976933016441762e-05\n",
            "step 1443: generator_loss=-1.587690395821184e-10, discriminator_loss=1.5099970369192306e-05\n",
            "step 1444: generator_loss=-4.541374776234619e-10, discriminator_loss=9.19158810575027e-06\n",
            "step 1445: generator_loss=-6.739413194178923e-11, discriminator_loss=1.650255398999434e-05\n",
            "step 1446: generator_loss=-9.635376940764218e-10, discriminator_loss=1.0252860192849766e-05\n",
            "step 1447: generator_loss=-3.4896749379065284e-10, discriminator_loss=2.1746122001786716e-05\n",
            "step 1448: generator_loss=-1.627737250542438e-10, discriminator_loss=1.3321679034561384e-05\n",
            "step 1449: generator_loss=-1.3612867277856822e-08, discriminator_loss=2.2349842765834183e-05\n",
            "step 1450: generator_loss=-1.0085889901034761e-09, discriminator_loss=8.008226359379478e-06\n",
            "step 1451: generator_loss=-7.122449297014555e-09, discriminator_loss=1.542244353913702e-05\n",
            "step 1452: generator_loss=-2.494840167788226e-10, discriminator_loss=1.363393403153168e-05\n",
            "step 1453: generator_loss=-8.932123374272294e-10, discriminator_loss=1.1724242540367413e-05\n",
            "step 1454: generator_loss=-6.150027015427995e-11, discriminator_loss=1.9782799427048303e-05\n",
            "step 1455: generator_loss=-1.5745615922213574e-10, discriminator_loss=7.319655651372159e-06\n",
            "step 1456: generator_loss=-5.622621118694937e-11, discriminator_loss=1.3757316082774196e-05\n",
            "step 1457: generator_loss=-1.6320327311802885e-09, discriminator_loss=5.408751530922018e-05\n",
            "step 1458: generator_loss=-9.847087589776038e-10, discriminator_loss=5.134854745847406e-06\n",
            "step 1459: generator_loss=-1.0360577951118444e-09, discriminator_loss=5.2428425988182425e-05\n",
            "step 1460: generator_loss=-2.505722851431358e-10, discriminator_loss=9.812105417950079e-06\n",
            "step 1461: generator_loss=-1.3528782261129635e-10, discriminator_loss=1.5304456610465422e-05\n",
            "step 1462: generator_loss=-5.143709902455385e-10, discriminator_loss=1.334938315267209e-05\n",
            "step 1463: generator_loss=-4.717441992596605e-10, discriminator_loss=1.8674332750379108e-05\n",
            "step 1464: generator_loss=-2.1404725214502207e-10, discriminator_loss=1.4083516362006776e-05\n",
            "step 1465: generator_loss=-8.976963616902367e-11, discriminator_loss=7.478883617295651e-06\n",
            "step 1466: generator_loss=-4.440454670628924e-10, discriminator_loss=1.9126557162962854e-05\n",
            "step 1467: generator_loss=-4.18814760649866e-10, discriminator_loss=2.8509019102784805e-05\n",
            "step 1468: generator_loss=-2.0856751048459188e-10, discriminator_loss=4.133087259106105e-06\n",
            "step 1469: generator_loss=-9.012785656681288e-11, discriminator_loss=1.0748715794761665e-05\n",
            "step 1470: generator_loss=-1.5359371552392531e-09, discriminator_loss=5.6701351240917575e-06\n",
            "step 1471: generator_loss=-3.417565119789856e-10, discriminator_loss=6.1298010223254096e-06\n",
            "step 1472: generator_loss=-1.3885867455876166e-10, discriminator_loss=9.337352821603417e-06\n",
            "step 1473: generator_loss=-9.863183603187053e-10, discriminator_loss=2.546090036048554e-05\n",
            "step 1474: generator_loss=-4.972262046543108e-10, discriminator_loss=1.8417809769744053e-05\n",
            "step 1475: generator_loss=-4.783332618885083e-10, discriminator_loss=4.9750033213058487e-05\n",
            "step 1476: generator_loss=-1.607172173123672e-10, discriminator_loss=2.1041043510194868e-05\n",
            "step 1477: generator_loss=-7.285551051339212e-10, discriminator_loss=3.285527782281861e-05\n",
            "step 1478: generator_loss=-8.776255278064582e-10, discriminator_loss=9.982964002119843e-06\n",
            "step 1479: generator_loss=-3.246768826015156e-11, discriminator_loss=1.9950357454945333e-05\n",
            "step 1480: generator_loss=-1.1668109534124227e-10, discriminator_loss=1.0220001058769412e-05\n",
            "step 1481: generator_loss=-1.186749726267422e-10, discriminator_loss=1.0186935469391756e-05\n",
            "step 1482: generator_loss=-3.108189705613995e-09, discriminator_loss=6.2380490817304235e-06\n",
            "step 1483: generator_loss=-1.5552452659051141e-09, discriminator_loss=8.297484782815445e-06\n",
            "step 1484: generator_loss=-2.1052767862350663e-10, discriminator_loss=2.0370025595184416e-05\n",
            "step 1485: generator_loss=-3.412122251411631e-10, discriminator_loss=1.4455132259172387e-05\n",
            "step 1486: generator_loss=-4.8928545659521205e-09, discriminator_loss=2.325645436940249e-05\n",
            "step 1487: generator_loss=-1.918892544860995e-10, discriminator_loss=1.244652048626449e-05\n",
            "step 1488: generator_loss=-8.499785597582132e-11, discriminator_loss=5.663682713930029e-06\n",
            "step 1489: generator_loss=-3.444962093368531e-10, discriminator_loss=1.7958680473384447e-05\n",
            "step 1490: generator_loss=-1.8478554797418667e-10, discriminator_loss=1.0856336302822456e-05\n",
            "step 1491: generator_loss=-1.1033927937997845e-10, discriminator_loss=5.603616045846138e-06\n",
            "step 1492: generator_loss=-3.5160740985418215e-10, discriminator_loss=5.5343784879369196e-06\n",
            "step 1493: generator_loss=-1.8333760898325835e-10, discriminator_loss=2.5140378056676127e-05\n",
            "step 1494: generator_loss=-5.157099192132364e-10, discriminator_loss=8.377262929570861e-06\n",
            "step 1495: generator_loss=-2.679452659748449e-09, discriminator_loss=1.4094011021370534e-05\n",
            "step 1496: generator_loss=-4.719087898230612e-10, discriminator_loss=3.745381400221959e-05\n",
            "step 1497: generator_loss=-1.0393723381962872e-10, discriminator_loss=6.350323928927537e-06\n",
            "step 1498: generator_loss=-2.1776762337832878e-10, discriminator_loss=1.0441730410093442e-05\n",
            "step 1499: generator_loss=-1.2301663854241696e-10, discriminator_loss=1.5348954548244365e-05\n",
            "step 1500: generator_loss=-2.4977875323628496e-09, discriminator_loss=1.0608350748952944e-05\n",
            "step 1501: generator_loss=-2.733334669713372e-10, discriminator_loss=5.715321549359942e-06\n",
            "step 1502: generator_loss=-1.2776057989327683e-09, discriminator_loss=1.534415605419781e-05\n",
            "step 1503: generator_loss=-1.5309777057215257e-10, discriminator_loss=1.8169776012655348e-05\n",
            "step 1504: generator_loss=-1.5658246921290697e-10, discriminator_loss=1.5653697118978016e-05\n",
            "step 1505: generator_loss=-1.725673215435819e-10, discriminator_loss=2.118759039149154e-05\n",
            "step 1506: generator_loss=-9.410411117016793e-09, discriminator_loss=4.46848798674182e-06\n",
            "step 1507: generator_loss=-1.2473450050620727e-10, discriminator_loss=1.0974215001624543e-05\n",
            "step 1508: generator_loss=-1.505494062747914e-10, discriminator_loss=1.528682878415566e-05\n",
            "step 1509: generator_loss=-6.0915552602125445e-09, discriminator_loss=1.4918224223947618e-05\n",
            "step 1510: generator_loss=-8.027581932523731e-10, discriminator_loss=1.3222352208686061e-05\n",
            "step 1511: generator_loss=-4.224302019295578e-10, discriminator_loss=2.3644579414394684e-05\n",
            "step 1512: generator_loss=-2.4810159482413496e-10, discriminator_loss=3.0171431717462838e-06\n",
            "step 1513: generator_loss=-2.1032773300788676e-09, discriminator_loss=2.573929123173002e-05\n",
            "step 1514: generator_loss=-3.4948044458360528e-09, discriminator_loss=1.1416137567721307e-05\n",
            "step 1515: generator_loss=-7.253835576648271e-08, discriminator_loss=3.646657660283381e-06\n",
            "step 1516: generator_loss=-6.261871576818123e-10, discriminator_loss=1.4363329682964832e-05\n",
            "step 1517: generator_loss=-7.568834448079542e-10, discriminator_loss=1.846575651143212e-05\n",
            "step 1518: generator_loss=-6.960183818183197e-11, discriminator_loss=1.1095677109551616e-05\n",
            "step 1519: generator_loss=-1.5796917107735453e-09, discriminator_loss=1.6082260117400438e-05\n",
            "step 1520: generator_loss=-3.7701203270401606e-10, discriminator_loss=5.558615612244466e-06\n",
            "step 1521: generator_loss=-1.9538953788256208e-10, discriminator_loss=3.591368567867903e-06\n",
            "step 1522: generator_loss=-1.9323033451090765e-10, discriminator_loss=8.376120604225434e-06\n",
            "step 1523: generator_loss=-1.1507389485743147e-09, discriminator_loss=9.831049283093307e-06\n",
            "step 1524: generator_loss=-8.83191297873509e-09, discriminator_loss=1.1697037734847981e-05\n",
            "step 1525: generator_loss=-1.165543495051935e-10, discriminator_loss=7.108080808393424e-06\n",
            "step 1526: generator_loss=-1.1781819964085116e-08, discriminator_loss=1.8476666809874587e-05\n",
            "step 1527: generator_loss=-1.9290820330031266e-10, discriminator_loss=7.637670023541432e-06\n",
            "step 1528: generator_loss=-1.706747243535034e-10, discriminator_loss=8.695588803675491e-06\n",
            "step 1529: generator_loss=-6.818991482582248e-10, discriminator_loss=1.312706899625482e-05\n",
            "step 1530: generator_loss=-1.334587884649352e-09, discriminator_loss=1.872011853265576e-05\n",
            "step 1531: generator_loss=-3.981133200881004e-10, discriminator_loss=1.2611384590854868e-05\n",
            "step 1532: generator_loss=-8.805237650122422e-10, discriminator_loss=2.0096944354008883e-05\n",
            "step 1533: generator_loss=-4.0014769275842355e-10, discriminator_loss=3.1726816814625636e-05\n",
            "step 1534: generator_loss=-5.894483789958826e-10, discriminator_loss=1.4000058399687987e-05\n",
            "step 1535: generator_loss=-3.3908725827203057e-10, discriminator_loss=1.839153264882043e-05\n",
            "step 1536: generator_loss=-2.62481925084046e-09, discriminator_loss=2.2784664906794205e-05\n",
            "step 1537: generator_loss=-1.4311191121052502e-10, discriminator_loss=2.1307923816493712e-05\n",
            "step 1538: generator_loss=-2.8855595690657765e-10, discriminator_loss=8.008112672541756e-06\n",
            "step 1539: generator_loss=-1.1005978350908663e-09, discriminator_loss=1.2217326002428308e-05\n",
            "step 1540: generator_loss=-2.1042384501512856e-10, discriminator_loss=4.5889278226241e-06\n",
            "step 1541: generator_loss=-5.96722324330834e-11, discriminator_loss=1.5771362086525187e-05\n",
            "step 1542: generator_loss=-1.31432392747044e-10, discriminator_loss=7.626189926668303e-06\n",
            "step 1543: generator_loss=-3.668209513918441e-09, discriminator_loss=6.19096999798785e-06\n",
            "step 1544: generator_loss=-2.3036801632958515e-10, discriminator_loss=1.6660645997035317e-05\n",
            "step 1545: generator_loss=-1.8274219637515188e-10, discriminator_loss=4.694019935413962e-06\n",
            "step 1546: generator_loss=-4.4601577986469465e-10, discriminator_loss=1.8557147996034473e-05\n",
            "step 1547: generator_loss=-2.1970530950099487e-10, discriminator_loss=6.07346464676084e-06\n",
            "step 1548: generator_loss=-4.66466310022895e-10, discriminator_loss=5.133762442710577e-06\n",
            "step 1549: generator_loss=-9.380192178554125e-10, discriminator_loss=1.0684014341677539e-05\n",
            "step 1550: generator_loss=-2.2955362610765917e-10, discriminator_loss=2.831141864589881e-05\n",
            "step 1551: generator_loss=-1.9315143928722023e-10, discriminator_loss=6.622274668188766e-06\n",
            "step 1552: generator_loss=-5.16230225233727e-10, discriminator_loss=1.7367941836710088e-05\n",
            "step 1553: generator_loss=-4.900498895565875e-10, discriminator_loss=6.642060270678485e-06\n",
            "step 1554: generator_loss=-5.140403658288051e-10, discriminator_loss=1.049588627211051e-05\n",
            "step 1555: generator_loss=-2.4749726712514075e-09, discriminator_loss=1.445362522645155e-05\n",
            "step 1556: generator_loss=-1.3925931241498546e-10, discriminator_loss=1.933166458911728e-05\n",
            "step 1557: generator_loss=-3.959564343070099e-10, discriminator_loss=1.013241671898868e-05\n",
            "step 1558: generator_loss=-9.223741770369998e-10, discriminator_loss=1.0755928997241426e-05\n",
            "step 1559: generator_loss=-6.365696947341348e-08, discriminator_loss=1.7004522305796854e-05\n",
            "step 1560: generator_loss=-1.2165755070014939e-09, discriminator_loss=1.3668336578120943e-05\n",
            "step 1561: generator_loss=-2.1820445450515535e-09, discriminator_loss=9.196155588142574e-06\n",
            "step 1562: generator_loss=-2.3658919268143563e-09, discriminator_loss=1.656708263908513e-05\n",
            "step 1563: generator_loss=-5.1385475735576946e-11, discriminator_loss=7.097277375578415e-06\n",
            "step 1564: generator_loss=-6.173825339850225e-11, discriminator_loss=2.8151183869340457e-05\n",
            "step 1565: generator_loss=-4.11048795001534e-09, discriminator_loss=1.889839222712908e-05\n",
            "step 1566: generator_loss=-8.892686587103071e-11, discriminator_loss=4.8951260396279395e-06\n",
            "step 1567: generator_loss=-1.4997361685864519e-10, discriminator_loss=1.293721106776502e-05\n",
            "step 1568: generator_loss=-5.264618740952187e-10, discriminator_loss=2.938790748885367e-05\n",
            "step 1569: generator_loss=-6.218872639074391e-10, discriminator_loss=1.938024979608599e-05\n",
            "step 1570: generator_loss=-6.967330601348465e-10, discriminator_loss=7.448041287716478e-05\n",
            "step 1571: generator_loss=-1.1754794360108178e-10, discriminator_loss=6.1314112826948985e-06\n",
            "step 1572: generator_loss=-5.746938480655217e-10, discriminator_loss=6.2331628214451484e-06\n",
            "step 1573: generator_loss=-1.4109126089678625e-09, discriminator_loss=1.5446406905539334e-05\n",
            "step 1574: generator_loss=-2.931560549868095e-10, discriminator_loss=2.6155019440921023e-05\n",
            "step 1575: generator_loss=-1.7215943948212242e-10, discriminator_loss=2.6973630156135187e-05\n",
            "step 1576: generator_loss=-5.4104556390655034e-09, discriminator_loss=9.249653885490261e-06\n",
            "step 1577: generator_loss=-1.2836711693609004e-09, discriminator_loss=1.0871310223592445e-05\n",
            "step 1578: generator_loss=-2.4351449745552145e-09, discriminator_loss=2.1750352971139364e-05\n",
            "step 1579: generator_loss=-5.622990961740015e-10, discriminator_loss=7.410514626826625e-06\n",
            "step 1580: generator_loss=-5.568497885022339e-10, discriminator_loss=3.412698106330936e-06\n",
            "step 1581: generator_loss=-2.7502189414718714e-09, discriminator_loss=5.538658115256112e-06\n",
            "step 1582: generator_loss=-5.006553838171612e-09, discriminator_loss=1.0533134627621621e-05\n",
            "step 1583: generator_loss=-5.625809817999539e-10, discriminator_loss=8.040951797738671e-06\n",
            "step 1584: generator_loss=-4.546128362648005e-09, discriminator_loss=6.789021881559165e-06\n",
            "step 1585: generator_loss=-8.252058064650569e-11, discriminator_loss=2.3840306312195025e-05\n",
            "step 1586: generator_loss=-6.682892572662524e-10, discriminator_loss=8.973534932010807e-06\n",
            "step 1587: generator_loss=-2.557652423185175e-10, discriminator_loss=5.547837190533755e-06\n",
            "step 1588: generator_loss=-9.223124347590428e-11, discriminator_loss=1.2462557606340852e-05\n",
            "step 1589: generator_loss=-6.839172339567767e-09, discriminator_loss=1.0245574230793864e-05\n",
            "step 1590: generator_loss=-2.6395741148377283e-09, discriminator_loss=6.01210604145308e-06\n",
            "step 1591: generator_loss=-5.502771849297261e-11, discriminator_loss=6.0547258726728614e-06\n",
            "step 1592: generator_loss=-1.8212376051707224e-10, discriminator_loss=2.673606650205329e-05\n",
            "step 1593: generator_loss=-7.647324551385282e-09, discriminator_loss=7.1428262344852556e-06\n",
            "step 1594: generator_loss=-4.085155547173258e-10, discriminator_loss=1.8740414816420525e-05\n",
            "step 1595: generator_loss=-2.5015167715025655e-10, discriminator_loss=3.120962355751544e-05\n",
            "step 1596: generator_loss=-5.083851672971207e-10, discriminator_loss=2.456868242006749e-05\n",
            "step 1597: generator_loss=-2.652313924045302e-10, discriminator_loss=7.334558176808059e-06\n",
            "step 1598: generator_loss=-1.5030239275404256e-09, discriminator_loss=1.0796602509799413e-05\n",
            "step 1599: generator_loss=-2.7645982725310603e-10, discriminator_loss=2.4969398509711027e-05\n",
            "step 1600: generator_loss=-1.2116756487046132e-08, discriminator_loss=7.87083808972966e-06\n",
            "step 1601: generator_loss=-7.646333344268896e-09, discriminator_loss=2.9780680051771924e-05\n",
            "step 1602: generator_loss=-4.1286912777493967e-10, discriminator_loss=2.0149545889580622e-05\n",
            "step 1603: generator_loss=-7.877187235827421e-10, discriminator_loss=1.8159335013478994e-05\n",
            "step 1604: generator_loss=-1.0760969892942285e-09, discriminator_loss=3.2180239486478968e-06\n",
            "step 1605: generator_loss=-1.7833115539822586e-10, discriminator_loss=9.095655514101963e-06\n",
            "step 1606: generator_loss=-9.728809979847597e-10, discriminator_loss=2.3828151825000532e-05\n",
            "step 1607: generator_loss=-3.717612329090514e-10, discriminator_loss=1.1747132703021634e-05\n",
            "step 1608: generator_loss=-2.2559343282324562e-10, discriminator_loss=2.29131655942183e-05\n",
            "step 1609: generator_loss=-1.1938486310647534e-10, discriminator_loss=5.1912793423980474e-06\n",
            "step 1610: generator_loss=-3.2773453395584795e-10, discriminator_loss=1.2693550161202438e-05\n",
            "step 1611: generator_loss=-1.4056548147678427e-09, discriminator_loss=5.3933235903969035e-06\n",
            "step 1612: generator_loss=-2.7384444711842093e-10, discriminator_loss=2.8722986826323904e-05\n",
            "step 1613: generator_loss=-3.2103486535817183e-10, discriminator_loss=2.5288277356594335e-06\n",
            "step 1614: generator_loss=-1.4507349765935373e-09, discriminator_loss=1.7725311408867128e-05\n",
            "step 1615: generator_loss=-3.226430789204926e-10, discriminator_loss=1.0458451470185537e-05\n",
            "step 1616: generator_loss=-5.359194199527906e-10, discriminator_loss=1.6310032151523046e-05\n",
            "step 1617: generator_loss=-1.116409187318368e-09, discriminator_loss=2.164804573112633e-05\n",
            "step 1618: generator_loss=-2.1244112247131852e-08, discriminator_loss=7.2681809797359165e-06\n",
            "step 1619: generator_loss=-2.823398181917014e-09, discriminator_loss=8.196537237381563e-06\n",
            "step 1620: generator_loss=-4.16831791305583e-10, discriminator_loss=6.858712367829867e-06\n",
            "step 1621: generator_loss=-1.2851829600535325e-09, discriminator_loss=8.115460332192015e-06\n",
            "step 1622: generator_loss=-3.76453201944571e-10, discriminator_loss=1.6388263247790746e-05\n",
            "step 1623: generator_loss=-4.0698527881133373e-10, discriminator_loss=6.226270670595113e-06\n",
            "step 1624: generator_loss=-4.518334317804573e-10, discriminator_loss=7.385555363725871e-06\n",
            "step 1625: generator_loss=-8.563781905834844e-10, discriminator_loss=2.0573626898112707e-05\n",
            "step 1626: generator_loss=-2.06128580870768e-09, discriminator_loss=8.785244972386863e-06\n",
            "step 1627: generator_loss=-7.521616662842234e-10, discriminator_loss=1.1095669833594002e-05\n",
            "step 1628: generator_loss=-2.2984117387103709e-10, discriminator_loss=1.943481584021356e-05\n",
            "step 1629: generator_loss=-1.49582497499523e-08, discriminator_loss=2.2052638087188825e-05\n",
            "step 1630: generator_loss=-2.1087033508226938e-10, discriminator_loss=1.9313618395244703e-05\n",
            "step 1631: generator_loss=-2.2339102789814547e-10, discriminator_loss=5.909776155021973e-05\n",
            "step 1632: generator_loss=-4.028714251091969e-09, discriminator_loss=1.625606819288805e-05\n",
            "step 1633: generator_loss=-5.469588115758484e-10, discriminator_loss=1.69425766216591e-05\n",
            "step 1634: generator_loss=-1.029679189135102e-10, discriminator_loss=5.201971816859441e-06\n",
            "step 1635: generator_loss=-2.4609811966058714e-09, discriminator_loss=3.452025566730299e-06\n",
            "step 1636: generator_loss=-4.757658711440627e-10, discriminator_loss=1.4863023352518212e-05\n",
            "step 1637: generator_loss=-3.0611507773059543e-10, discriminator_loss=4.1679963942442555e-06\n",
            "step 1638: generator_loss=-6.533957402909962e-11, discriminator_loss=1.746863745211158e-05\n",
            "step 1639: generator_loss=-4.82684392455468e-10, discriminator_loss=1.1843257198052015e-05\n",
            "step 1640: generator_loss=-6.811050057287105e-10, discriminator_loss=4.366765551822027e-06\n",
            "step 1641: generator_loss=-6.165722377104998e-10, discriminator_loss=1.6109699572552927e-05\n",
            "step 1642: generator_loss=-3.6197658759284934e-10, discriminator_loss=1.8550150343799032e-05\n",
            "step 1643: generator_loss=-2.57447563267732e-10, discriminator_loss=8.859855370246805e-06\n",
            "step 1644: generator_loss=-1.3063655712741706e-10, discriminator_loss=1.3446616321743932e-05\n",
            "step 1645: generator_loss=-1.0705223513207685e-10, discriminator_loss=1.609205355634913e-05\n",
            "step 1646: generator_loss=-3.753782618076684e-09, discriminator_loss=7.171759534685407e-06\n",
            "step 1647: generator_loss=-1.0141374851002638e-08, discriminator_loss=1.8857022951124236e-05\n",
            "step 1648: generator_loss=-8.588975752843453e-09, discriminator_loss=1.6567542843404226e-05\n",
            "step 1649: generator_loss=-3.9211561775331916e-10, discriminator_loss=2.9298753361217678e-05\n",
            "step 1650: generator_loss=-1.4566379213931668e-09, discriminator_loss=7.490361895179376e-06\n",
            "step 1651: generator_loss=-2.1527933213860706e-08, discriminator_loss=8.127520231937524e-06\n",
            "step 1652: generator_loss=-3.969176098905791e-10, discriminator_loss=6.17127670921036e-06\n",
            "step 1653: generator_loss=-2.766723516955949e-10, discriminator_loss=1.7652630049269646e-05\n",
            "step 1654: generator_loss=-9.673618850403187e-11, discriminator_loss=7.294392162293661e-06\n",
            "step 1655: generator_loss=-2.4497032180548217e-10, discriminator_loss=6.708599812554894e-06\n",
            "step 1656: generator_loss=-1.0960812119042984e-10, discriminator_loss=7.808002919773571e-06\n",
            "step 1657: generator_loss=-4.5276071780619986e-10, discriminator_loss=8.729134606255684e-06\n",
            "step 1658: generator_loss=-2.44093367740561e-09, discriminator_loss=7.613740763190435e-06\n",
            "step 1659: generator_loss=-3.925518798908456e-10, discriminator_loss=8.603243259130977e-06\n",
            "step 1660: generator_loss=-1.1915721187527595e-10, discriminator_loss=6.094847321946872e-06\n",
            "step 1661: generator_loss=-5.592160068346175e-10, discriminator_loss=7.401279162877472e-06\n",
            "step 1662: generator_loss=-1.452366671372829e-09, discriminator_loss=3.7792488001286983e-06\n",
            "step 1663: generator_loss=-4.451179980158315e-10, discriminator_loss=2.7479094569571316e-05\n",
            "step 1664: generator_loss=-1.6934784130562264e-10, discriminator_loss=5.674143721989822e-06\n",
            "step 1665: generator_loss=-1.8732325413051143e-10, discriminator_loss=1.0790078704303596e-05\n",
            "step 1666: generator_loss=-1.5658539742613442e-10, discriminator_loss=1.556990719109308e-05\n",
            "step 1667: generator_loss=-3.6619171583929244e-10, discriminator_loss=4.562397953122854e-05\n",
            "step 1668: generator_loss=-6.287805831561855e-10, discriminator_loss=6.867671345389681e-06\n",
            "step 1669: generator_loss=-2.5705388928543016e-09, discriminator_loss=1.2246879123267718e-05\n",
            "step 1670: generator_loss=-8.523844963193028e-10, discriminator_loss=1.4779655430174898e-05\n",
            "step 1671: generator_loss=-8.684524765989465e-10, discriminator_loss=2.3530533326265868e-06\n",
            "step 1672: generator_loss=-1.1905736396755628e-09, discriminator_loss=6.610969649045728e-06\n",
            "step 1673: generator_loss=-9.677391110685107e-10, discriminator_loss=1.311665982939303e-05\n",
            "step 1674: generator_loss=-1.4109724499888898e-10, discriminator_loss=1.967812750081066e-05\n",
            "step 1675: generator_loss=-5.517545309530192e-10, discriminator_loss=5.4987672228890005e-06\n",
            "step 1676: generator_loss=-1.0070981382170885e-08, discriminator_loss=1.4914099665475078e-05\n",
            "step 1677: generator_loss=-2.124660447577753e-09, discriminator_loss=8.227003490901552e-06\n",
            "step 1678: generator_loss=-6.608933400542583e-10, discriminator_loss=2.045462497335393e-05\n",
            "step 1679: generator_loss=-6.085278947409734e-10, discriminator_loss=1.53000855789287e-05\n",
            "step 1680: generator_loss=-7.250479661102815e-10, discriminator_loss=1.470093320676824e-05\n",
            "step 1681: generator_loss=-5.078509279776711e-10, discriminator_loss=1.2136654731875751e-05\n",
            "step 1682: generator_loss=-1.0698854302493288e-10, discriminator_loss=4.6796635615464766e-06\n",
            "step 1683: generator_loss=-3.3585667580382506e-10, discriminator_loss=7.691281098232139e-06\n",
            "step 1684: generator_loss=-8.142410634626174e-10, discriminator_loss=3.20992803608533e-05\n",
            "step 1685: generator_loss=-7.676249635935051e-10, discriminator_loss=1.2392511052894406e-05\n",
            "step 1686: generator_loss=-1.7485107806081146e-10, discriminator_loss=2.7094823963125236e-05\n",
            "step 1687: generator_loss=-1.4903872580518396e-09, discriminator_loss=8.745484592509456e-06\n",
            "step 1688: generator_loss=-7.256777956321514e-10, discriminator_loss=1.1484660717542283e-05\n",
            "step 1689: generator_loss=-9.637883824353821e-10, discriminator_loss=6.840988135081716e-06\n",
            "step 1690: generator_loss=-2.4290119915448827e-10, discriminator_loss=9.536413926980458e-06\n",
            "step 1691: generator_loss=-3.001058568319337e-10, discriminator_loss=6.930656127224211e-06\n",
            "step 1692: generator_loss=-2.514508823381334e-09, discriminator_loss=3.6629969599744072e-06\n",
            "step 1693: generator_loss=-2.9628062225839358e-09, discriminator_loss=7.130262929422315e-06\n",
            "step 1694: generator_loss=-2.342672722477346e-10, discriminator_loss=6.775051588192582e-06\n",
            "step 1695: generator_loss=-1.1105392161425698e-09, discriminator_loss=2.648901045176899e-06\n",
            "step 1696: generator_loss=-5.315897722013574e-10, discriminator_loss=9.037876225193031e-06\n",
            "step 1697: generator_loss=-8.08951683417547e-10, discriminator_loss=7.67281926528085e-06\n",
            "step 1698: generator_loss=-6.784480199861775e-10, discriminator_loss=5.499522558238823e-06\n",
            "step 1699: generator_loss=-3.7144134990008126e-10, discriminator_loss=3.4343902370892465e-06\n",
            "step 1700: generator_loss=-6.597248858319915e-10, discriminator_loss=2.05847045435803e-05\n",
            "step 1701: generator_loss=-2.419958955446333e-10, discriminator_loss=6.2804092522128485e-06\n",
            "step 1702: generator_loss=-2.164787904490595e-09, discriminator_loss=6.340094842016697e-05\n",
            "step 1703: generator_loss=-3.298808448626289e-10, discriminator_loss=5.3392072913993616e-06\n",
            "step 1704: generator_loss=-2.1434184982460636e-10, discriminator_loss=9.223102097166702e-06\n",
            "step 1705: generator_loss=-3.201571230349032e-10, discriminator_loss=3.973246748500969e-06\n",
            "step 1706: generator_loss=-1.6349929743419978e-10, discriminator_loss=7.358712537097745e-06\n",
            "step 1707: generator_loss=-1.9254102756605107e-09, discriminator_loss=1.910179889819119e-05\n",
            "step 1708: generator_loss=-4.712344736645946e-09, discriminator_loss=3.288394509581849e-06\n",
            "step 1709: generator_loss=-6.650672235153365e-10, discriminator_loss=1.5047978195070755e-05\n",
            "step 1710: generator_loss=-1.1459062587704238e-09, discriminator_loss=1.0262581781717017e-05\n",
            "step 1711: generator_loss=-8.743510360176288e-10, discriminator_loss=2.0622350348276086e-05\n",
            "step 1712: generator_loss=-5.093572785774825e-11, discriminator_loss=1.0802603355841711e-05\n",
            "step 1713: generator_loss=-1.2579609576235384e-10, discriminator_loss=1.0339833352190908e-05\n",
            "step 1714: generator_loss=-1.1381033893087533e-09, discriminator_loss=1.5366171282948926e-05\n",
            "step 1715: generator_loss=-6.765346061143873e-10, discriminator_loss=2.141880031558685e-05\n",
            "step 1716: generator_loss=-8.052359334875803e-10, discriminator_loss=1.2489441360230558e-05\n",
            "step 1717: generator_loss=-1.2538822757868218e-10, discriminator_loss=2.7971641429758165e-06\n",
            "step 1718: generator_loss=-8.094434011951535e-10, discriminator_loss=4.147129857301479e-06\n",
            "step 1719: generator_loss=-2.748424543508321e-10, discriminator_loss=5.790357590740314e-06\n",
            "step 1720: generator_loss=-1.222706380588079e-10, discriminator_loss=6.4183727772615384e-06\n",
            "step 1721: generator_loss=-5.368716138320906e-09, discriminator_loss=4.568891654344043e-06\n",
            "step 1722: generator_loss=-1.944447797219695e-10, discriminator_loss=2.310227500856854e-05\n",
            "step 1723: generator_loss=-2.416821187622986e-10, discriminator_loss=1.2869235433754511e-05\n",
            "step 1724: generator_loss=-2.1495503987889464e-10, discriminator_loss=1.2885478099633474e-05\n",
            "step 1725: generator_loss=-1.2674585825322993e-09, discriminator_loss=7.779719453537837e-06\n",
            "step 1726: generator_loss=-1.7125409979001915e-09, discriminator_loss=1.1169449862791225e-05\n",
            "step 1727: generator_loss=-2.2580676217742734e-10, discriminator_loss=1.3356058843783103e-05\n",
            "step 1728: generator_loss=-1.0227195756939977e-09, discriminator_loss=4.415391231304966e-06\n",
            "step 1729: generator_loss=-7.764019649414422e-09, discriminator_loss=9.588995453668758e-06\n",
            "step 1730: generator_loss=-4.646794948826027e-09, discriminator_loss=1.441947551938938e-05\n",
            "step 1731: generator_loss=-5.112606449308998e-10, discriminator_loss=6.934618795639835e-06\n",
            "step 1732: generator_loss=-5.306379780023462e-10, discriminator_loss=1.1956364687648602e-05\n",
            "step 1733: generator_loss=-6.364667126668166e-10, discriminator_loss=4.94298319608788e-06\n",
            "step 1734: generator_loss=-6.786971540329034e-10, discriminator_loss=6.904720976308454e-06\n",
            "step 1735: generator_loss=-6.100219440696719e-09, discriminator_loss=5.046281785325846e-06\n",
            "step 1736: generator_loss=-3.0630159519873246e-10, discriminator_loss=6.9806233113922644e-06\n",
            "step 1737: generator_loss=-7.0513870298327674e-09, discriminator_loss=6.352892796712695e-06\n",
            "step 1738: generator_loss=-1.0871482880592254e-10, discriminator_loss=1.2172988135716878e-05\n",
            "step 1739: generator_loss=-5.977433548132183e-10, discriminator_loss=6.2028061620367225e-06\n",
            "step 1740: generator_loss=-1.75261150037187e-09, discriminator_loss=1.5732159226899967e-05\n",
            "step 1741: generator_loss=-2.573653790083341e-10, discriminator_loss=7.31063801140408e-06\n",
            "step 1742: generator_loss=-5.271846958976312e-09, discriminator_loss=1.0975122677336913e-05\n",
            "step 1743: generator_loss=-2.1501155023084806e-10, discriminator_loss=1.2238429007993545e-05\n",
            "step 1744: generator_loss=-8.115302319033901e-10, discriminator_loss=5.7962706705438904e-06\n",
            "step 1745: generator_loss=-1.4752712385046607e-09, discriminator_loss=5.3588213631883264e-05\n",
            "step 1746: generator_loss=-2.1583086429188825e-09, discriminator_loss=1.8121778339263983e-05\n",
            "step 1747: generator_loss=-1.4225652600341476e-10, discriminator_loss=8.317585525219329e-06\n",
            "step 1748: generator_loss=-2.405345089773192e-10, discriminator_loss=9.79753167484887e-06\n",
            "step 1749: generator_loss=-2.0441677517357704e-10, discriminator_loss=3.3343380891892593e-06\n",
            "step 1750: generator_loss=-8.434836717974292e-10, discriminator_loss=7.980873306223657e-06\n",
            "step 1751: generator_loss=-4.677949694276151e-10, discriminator_loss=5.708116805180907e-05\n",
            "step 1752: generator_loss=-7.038179761220675e-11, discriminator_loss=4.907392849418102e-06\n",
            "step 1753: generator_loss=-9.20824305694623e-10, discriminator_loss=7.998369255801663e-06\n",
            "step 1754: generator_loss=-9.80103886938366e-10, discriminator_loss=1.160043575509917e-05\n",
            "step 1755: generator_loss=-4.6190876124008184e-10, discriminator_loss=1.0143412509933114e-05\n",
            "step 1756: generator_loss=-5.052155360729671e-10, discriminator_loss=1.0482632205821574e-05\n",
            "step 1757: generator_loss=-6.877923230952376e-10, discriminator_loss=1.769210211932659e-05\n",
            "step 1758: generator_loss=-1.452456210859765e-10, discriminator_loss=1.300869644182967e-05\n",
            "step 1759: generator_loss=-4.7374797418342496e-09, discriminator_loss=5.6167441471188795e-06\n",
            "step 1760: generator_loss=-3.938340764619852e-10, discriminator_loss=3.822945018328028e-06\n",
            "step 1761: generator_loss=-8.776025739454241e-11, discriminator_loss=4.964285108144395e-05\n",
            "step 1762: generator_loss=-5.609607223178159e-10, discriminator_loss=9.890040018945001e-06\n",
            "step 1763: generator_loss=-1.3746456750673985e-10, discriminator_loss=7.844163519621361e-06\n",
            "step 1764: generator_loss=-9.241676313109792e-10, discriminator_loss=8.580320354667492e-06\n",
            "step 1765: generator_loss=-1.4725531904957734e-10, discriminator_loss=6.0939337345189415e-06\n",
            "step 1766: generator_loss=-1.3480142557753538e-09, discriminator_loss=1.3697020222025458e-05\n",
            "step 1767: generator_loss=-7.901942211674395e-08, discriminator_loss=9.71571535046678e-06\n",
            "step 1768: generator_loss=-1.2536534033102953e-09, discriminator_loss=1.4707908121636137e-05\n",
            "step 1769: generator_loss=-8.498733938822056e-10, discriminator_loss=2.8046795250702417e-06\n",
            "step 1770: generator_loss=-2.2386642539728996e-10, discriminator_loss=1.537615025881678e-05\n",
            "step 1771: generator_loss=-5.932374591566258e-10, discriminator_loss=1.501983297202969e-05\n",
            "step 1772: generator_loss=-1.5911488793207695e-10, discriminator_loss=9.387020327267237e-06\n",
            "step 1773: generator_loss=-7.159787346333601e-11, discriminator_loss=1.75714503711788e-05\n",
            "step 1774: generator_loss=-1.733669385828307e-08, discriminator_loss=7.939203896967229e-06\n",
            "step 1775: generator_loss=-7.215512076719222e-10, discriminator_loss=1.8392747733742e-05\n",
            "step 1776: generator_loss=-5.276758197059195e-11, discriminator_loss=1.5686984625062905e-05\n",
            "step 1777: generator_loss=-1.8117581046528386e-10, discriminator_loss=1.982142021006439e-05\n",
            "step 1778: generator_loss=-2.1250515236381773e-10, discriminator_loss=1.2041096852044575e-05\n",
            "step 1779: generator_loss=-1.6296128890758155e-09, discriminator_loss=1.2585581316670869e-05\n",
            "step 1780: generator_loss=-2.6414506137939497e-09, discriminator_loss=1.022347805701429e-05\n",
            "step 1781: generator_loss=-2.613187444211462e-10, discriminator_loss=5.936835805187002e-06\n",
            "step 1782: generator_loss=-1.6468046371009848e-10, discriminator_loss=1.2751003851008136e-05\n",
            "step 1783: generator_loss=-3.6441283324251117e-10, discriminator_loss=9.257816600438673e-06\n",
            "step 1784: generator_loss=-4.304824940959406e-09, discriminator_loss=7.113691026461311e-06\n",
            "step 1785: generator_loss=-3.41485839605582e-10, discriminator_loss=5.008014341001399e-06\n",
            "step 1786: generator_loss=-5.405916270184719e-10, discriminator_loss=1.1889687812072225e-05\n",
            "step 1787: generator_loss=-4.730908997885308e-10, discriminator_loss=4.175983576715225e-06\n",
            "step 1788: generator_loss=-1.775972563455852e-10, discriminator_loss=9.700009286461864e-06\n",
            "step 1789: generator_loss=-1.0624622293065045e-09, discriminator_loss=3.302441655250732e-06\n",
            "step 1790: generator_loss=-4.89925433555527e-10, discriminator_loss=5.252567007119069e-06\n",
            "step 1791: generator_loss=-2.992441572313709e-10, discriminator_loss=9.094033885048702e-06\n",
            "step 1792: generator_loss=-3.8054168149948e-10, discriminator_loss=3.822989128821064e-06\n",
            "step 1793: generator_loss=-2.5567087336142436e-10, discriminator_loss=3.9583337638759986e-06\n",
            "step 1794: generator_loss=-2.736614823639627e-10, discriminator_loss=6.794002274546074e-06\n",
            "step 1795: generator_loss=-4.0921055433074116e-10, discriminator_loss=3.4063687053276226e-06\n",
            "step 1796: generator_loss=-2.9780780064214696e-09, discriminator_loss=9.628198313293979e-06\n",
            "step 1797: generator_loss=-7.606943963622825e-10, discriminator_loss=5.2766634325962514e-05\n",
            "step 1798: generator_loss=-1.6470880215280204e-09, discriminator_loss=4.692598395195091e-06\n",
            "step 1799: generator_loss=-3.4668602211240795e-08, discriminator_loss=1.5579445971525274e-05\n",
            "step 1800: generator_loss=-3.3684004474565654e-09, discriminator_loss=5.609772415482439e-06\n",
            "step 1801: generator_loss=-1.3994802539052387e-10, discriminator_loss=8.714100658835378e-06\n",
            "step 1802: generator_loss=-9.046441373783409e-11, discriminator_loss=2.9824864213878755e-06\n",
            "step 1803: generator_loss=-7.96156585103347e-10, discriminator_loss=1.1649606676655822e-05\n",
            "step 1804: generator_loss=-1.071260302687449e-09, discriminator_loss=9.322896403318737e-06\n",
            "step 1805: generator_loss=-2.4276669563505493e-10, discriminator_loss=4.3095965338579845e-06\n",
            "step 1806: generator_loss=-3.3961825018913316e-10, discriminator_loss=2.634890734043438e-06\n",
            "step 1807: generator_loss=-2.700426826596214e-10, discriminator_loss=8.192937457351945e-06\n",
            "step 1808: generator_loss=-5.404269254327687e-10, discriminator_loss=5.112106464366661e-06\n",
            "step 1809: generator_loss=-5.259816471259171e-10, discriminator_loss=6.808956641179975e-06\n",
            "step 1810: generator_loss=-1.7123065187973907e-09, discriminator_loss=4.080913186044199e-06\n",
            "step 1811: generator_loss=-2.6616436832327395e-10, discriminator_loss=5.704109753423836e-06\n",
            "step 1812: generator_loss=-2.2506320362936094e-08, discriminator_loss=3.219413702026941e-05\n",
            "step 1813: generator_loss=-9.940430423238666e-11, discriminator_loss=6.65086054141284e-06\n",
            "step 1814: generator_loss=-4.748784698804798e-10, discriminator_loss=1.542270911158994e-05\n",
            "step 1815: generator_loss=-8.120549788159792e-10, discriminator_loss=1.3989372746436857e-05\n",
            "step 1816: generator_loss=-1.1326011656320745e-10, discriminator_loss=1.8956530766445212e-05\n",
            "step 1817: generator_loss=-2.320728331728361e-11, discriminator_loss=7.97825850895606e-06\n",
            "step 1818: generator_loss=-4.895435168350559e-10, discriminator_loss=6.341977041302016e-06\n",
            "step 1819: generator_loss=-1.1832766710906384e-10, discriminator_loss=8.485573744110297e-06\n",
            "step 1820: generator_loss=-6.222752868545456e-10, discriminator_loss=2.8721233320538886e-06\n",
            "step 1821: generator_loss=-1.2669507110096845e-10, discriminator_loss=1.84335822268622e-05\n",
            "step 1822: generator_loss=-1.4377840584778312e-10, discriminator_loss=1.1522858585522044e-05\n",
            "step 1823: generator_loss=-3.868657061367742e-10, discriminator_loss=4.859649925492704e-05\n",
            "step 1824: generator_loss=-2.1285900819734138e-10, discriminator_loss=8.656297723064199e-06\n",
            "step 1825: generator_loss=-3.5461156233651536e-10, discriminator_loss=1.7678705262369476e-05\n",
            "step 1826: generator_loss=-5.868102115336171e-10, discriminator_loss=1.16911987788626e-05\n",
            "step 1827: generator_loss=-1.5532469754830913e-10, discriminator_loss=2.4240618586190976e-05\n",
            "step 1828: generator_loss=-1.3612024007958468e-10, discriminator_loss=1.0595760613796301e-05\n",
            "step 1829: generator_loss=-2.9768758569304055e-09, discriminator_loss=5.18521710546338e-06\n",
            "step 1830: generator_loss=-1.7672363572529548e-09, discriminator_loss=7.4984786806453485e-06\n",
            "step 1831: generator_loss=-3.5024116940007843e-10, discriminator_loss=3.584942896850407e-05\n",
            "step 1832: generator_loss=-1.0314757936669139e-09, discriminator_loss=1.0966304216708522e-05\n",
            "step 1833: generator_loss=-4.6487813598616867e-10, discriminator_loss=1.683217124082148e-05\n",
            "step 1834: generator_loss=-3.0026917063885605e-10, discriminator_loss=4.0723134588915855e-06\n",
            "step 1835: generator_loss=-2.5096275058089645e-10, discriminator_loss=1.3537542145058978e-05\n",
            "step 1836: generator_loss=-6.075517866577229e-10, discriminator_loss=3.501553146634251e-05\n",
            "step 1837: generator_loss=-4.953075727343048e-09, discriminator_loss=1.3769790712103713e-05\n",
            "step 1838: generator_loss=-7.459848738733399e-09, discriminator_loss=4.514601187111111e-06\n",
            "step 1839: generator_loss=-9.278984802740808e-10, discriminator_loss=7.25391146261245e-06\n",
            "step 1840: generator_loss=-9.474199202941236e-11, discriminator_loss=1.3389187188295182e-05\n",
            "step 1841: generator_loss=-8.156537667503017e-10, discriminator_loss=3.514738637022674e-06\n",
            "step 1842: generator_loss=-3.8550321268537857e-10, discriminator_loss=1.4948939679015893e-05\n",
            "step 1843: generator_loss=-1.6960677307054084e-10, discriminator_loss=3.7997124309185892e-06\n",
            "step 1844: generator_loss=-8.573933923949895e-11, discriminator_loss=3.532088840074721e-06\n",
            "step 1845: generator_loss=-5.964705118710611e-11, discriminator_loss=3.5661696529132314e-06\n",
            "step 1846: generator_loss=-1.494215307040747e-10, discriminator_loss=1.077058186638169e-05\n",
            "step 1847: generator_loss=-5.794729696084744e-10, discriminator_loss=5.897752544115065e-06\n",
            "step 1848: generator_loss=-4.096315286972185e-09, discriminator_loss=4.5025608415016904e-06\n",
            "step 1849: generator_loss=-2.513123043001997e-10, discriminator_loss=1.2322578186285682e-05\n",
            "step 1850: generator_loss=-1.0474306977314995e-09, discriminator_loss=7.536339126090752e-06\n",
            "step 1851: generator_loss=-6.901501592437853e-10, discriminator_loss=1.1437748071330134e-05\n",
            "step 1852: generator_loss=-2.75321432319231e-10, discriminator_loss=1.4994945559010375e-05\n",
            "step 1853: generator_loss=-3.34752048303244e-09, discriminator_loss=2.3683448944211705e-06\n",
            "step 1854: generator_loss=-9.203760670262184e-11, discriminator_loss=8.748659638513345e-06\n",
            "step 1855: generator_loss=-8.053538280705652e-09, discriminator_loss=6.162670160847483e-06\n",
            "step 1856: generator_loss=-1.1225705087714033e-10, discriminator_loss=4.41932297690073e-06\n",
            "step 1857: generator_loss=-8.188881239767909e-10, discriminator_loss=1.5959294614731334e-05\n",
            "step 1858: generator_loss=-1.184937037379541e-09, discriminator_loss=1.900782808661461e-05\n",
            "step 1859: generator_loss=-1.5965322397448745e-09, discriminator_loss=1.928602387124556e-06\n",
            "step 1860: generator_loss=-2.299679890960249e-10, discriminator_loss=1.0611305697239004e-05\n",
            "step 1861: generator_loss=-1.8439078042220558e-10, discriminator_loss=9.352023880637717e-06\n",
            "step 1862: generator_loss=-1.6946538394790878e-08, discriminator_loss=6.509944341814844e-06\n",
            "step 1863: generator_loss=-6.579700784214992e-09, discriminator_loss=5.934987257205648e-06\n",
            "step 1864: generator_loss=-3.312183860515461e-10, discriminator_loss=3.6222108974470757e-06\n",
            "step 1865: generator_loss=-1.7660622964044137e-09, discriminator_loss=4.519113645073958e-06\n",
            "step 1866: generator_loss=-1.5636679451258573e-10, discriminator_loss=1.9765388969972264e-06\n",
            "step 1867: generator_loss=-1.3886694572029512e-10, discriminator_loss=2.836234671121929e-05\n",
            "step 1868: generator_loss=-2.838854151754333e-10, discriminator_loss=5.370369308366207e-06\n",
            "step 1869: generator_loss=-4.226970995446777e-10, discriminator_loss=1.1061971235903911e-05\n",
            "step 1870: generator_loss=-3.0368318970630526e-10, discriminator_loss=8.151057954819407e-06\n",
            "step 1871: generator_loss=-5.3041318004432014e-09, discriminator_loss=5.363589480111841e-06\n",
            "step 1872: generator_loss=-2.240570645684059e-10, discriminator_loss=1.2193107977509499e-05\n",
            "step 1873: generator_loss=-7.106387700517303e-10, discriminator_loss=1.1367636943759862e-05\n",
            "step 1874: generator_loss=-5.990595797200626e-10, discriminator_loss=1.5346045984188095e-05\n",
            "step 1875: generator_loss=-1.2199410370783426e-09, discriminator_loss=6.625100922974525e-06\n",
            "step 1876: generator_loss=-1.18436621621143e-10, discriminator_loss=4.616780643118545e-06\n",
            "step 1877: generator_loss=-9.870306794113048e-10, discriminator_loss=6.06459525442915e-06\n",
            "step 1878: generator_loss=-2.2150231648865315e-10, discriminator_loss=1.605591387487948e-05\n",
            "step 1879: generator_loss=-5.089668131397218e-10, discriminator_loss=5.921318916080054e-06\n",
            "step 1880: generator_loss=-3.611345888998585e-09, discriminator_loss=2.1961255697533488e-05\n",
            "step 1881: generator_loss=-2.1216808865354153e-10, discriminator_loss=6.061809926904971e-06\n",
            "step 1882: generator_loss=-1.0585416987396457e-09, discriminator_loss=4.516840817814227e-06\n",
            "step 1883: generator_loss=-2.298532891797933e-10, discriminator_loss=1.6001295080059208e-05\n",
            "step 1884: generator_loss=-5.243480094563324e-10, discriminator_loss=5.995328592689475e-06\n",
            "step 1885: generator_loss=-2.961603462470208e-10, discriminator_loss=6.94519894750556e-06\n",
            "step 1886: generator_loss=-1.0621168389235436e-09, discriminator_loss=4.60666160506662e-06\n",
            "step 1887: generator_loss=-4.1925546367949096e-10, discriminator_loss=8.462533514830284e-06\n",
            "step 1888: generator_loss=-1.1276055089659565e-10, discriminator_loss=6.582624337170273e-06\n",
            "step 1889: generator_loss=-1.6808303360260624e-10, discriminator_loss=7.566300155303907e-06\n",
            "step 1890: generator_loss=-1.400929788841765e-10, discriminator_loss=1.372031147184316e-05\n",
            "step 1891: generator_loss=-2.440009305715307e-10, discriminator_loss=3.0501548735628603e-06\n",
            "step 1892: generator_loss=-2.681281308092309e-10, discriminator_loss=1.7242045942111872e-05\n",
            "step 1893: generator_loss=-1.3506652740691294e-10, discriminator_loss=1.171819258161122e-05\n",
            "step 1894: generator_loss=-1.6796798674167945e-10, discriminator_loss=6.923974979144987e-06\n",
            "step 1895: generator_loss=-4.0201919571103417e-10, discriminator_loss=1.4437263416766655e-05\n",
            "step 1896: generator_loss=-4.4557674216960663e-10, discriminator_loss=1.2049927136104088e-05\n",
            "step 1897: generator_loss=-6.220479686902536e-11, discriminator_loss=9.38143057283014e-06\n",
            "step 1898: generator_loss=-1.0063994082543104e-08, discriminator_loss=3.6035826269653626e-06\n",
            "step 1899: generator_loss=-8.5828688600742e-10, discriminator_loss=6.379963451763615e-06\n",
            "step 1900: generator_loss=-4.328082781057674e-09, discriminator_loss=2.4097980713122524e-06\n",
            "step 1901: generator_loss=-2.7405477193154226e-11, discriminator_loss=7.593771442770958e-06\n",
            "step 1902: generator_loss=-5.747137835077076e-11, discriminator_loss=1.71176598087186e-05\n",
            "step 1903: generator_loss=-3.5861441594065013e-10, discriminator_loss=1.1719493159034755e-05\n",
            "step 1904: generator_loss=-7.307383032006953e-10, discriminator_loss=1.1092964996350929e-05\n",
            "step 1905: generator_loss=-1.285032219522364e-10, discriminator_loss=7.205716883618152e-06\n",
            "step 1906: generator_loss=-2.3598634157906417e-10, discriminator_loss=4.720263859780971e-06\n",
            "step 1907: generator_loss=-8.510838700459544e-10, discriminator_loss=6.865862360427855e-06\n",
            "step 1908: generator_loss=-3.6743447173748223e-10, discriminator_loss=1.7219654182554223e-06\n",
            "step 1909: generator_loss=-1.0266746480747102e-10, discriminator_loss=1.0241241398034617e-05\n",
            "step 1910: generator_loss=-1.6402915137270213e-10, discriminator_loss=6.428066262742504e-05\n",
            "step 1911: generator_loss=-3.1061861416326053e-10, discriminator_loss=1.008799699775409e-05\n",
            "step 1912: generator_loss=-2.9665203626905168e-09, discriminator_loss=3.778889549721498e-06\n",
            "step 1913: generator_loss=-4.131666397899636e-10, discriminator_loss=7.1714566729497164e-06\n",
            "step 1914: generator_loss=-1.180473274686733e-09, discriminator_loss=6.760395081073511e-06\n",
            "step 1915: generator_loss=-1.5613502157840742e-10, discriminator_loss=4.931051535095321e-06\n",
            "step 1916: generator_loss=-1.1792261611631716e-09, discriminator_loss=3.4926586067740573e-06\n",
            "step 1917: generator_loss=-5.787702539450379e-10, discriminator_loss=6.488874532806221e-06\n",
            "step 1918: generator_loss=-4.187565405544547e-09, discriminator_loss=7.206272584880935e-06\n",
            "step 1919: generator_loss=-2.5557617133742383e-10, discriminator_loss=3.4789054552675225e-06\n",
            "step 1920: generator_loss=-1.4095796752044976e-10, discriminator_loss=4.503424406721024e-06\n",
            "step 1921: generator_loss=-5.840518624289359e-10, discriminator_loss=1.6066767784650438e-05\n",
            "step 1922: generator_loss=-2.621107775269138e-10, discriminator_loss=4.028302555525443e-06\n",
            "step 1923: generator_loss=-1.1541877870113737e-10, discriminator_loss=2.6777144739753567e-05\n",
            "step 1924: generator_loss=-3.1995348592772643e-09, discriminator_loss=4.707035259343684e-06\n",
            "step 1925: generator_loss=-5.253622537004787e-10, discriminator_loss=5.618998329737224e-06\n",
            "step 1926: generator_loss=-2.185599062842769e-10, discriminator_loss=1.2900532965431921e-05\n",
            "step 1927: generator_loss=-1.6174470096608218e-10, discriminator_loss=6.15717453911202e-06\n",
            "step 1928: generator_loss=-2.8532326501462535e-10, discriminator_loss=9.715708984003868e-06\n",
            "step 1929: generator_loss=-1.8701948323318618e-10, discriminator_loss=5.496634912560694e-06\n",
            "step 1930: generator_loss=-1.5381084184085125e-09, discriminator_loss=1.718518433335703e-05\n",
            "step 1931: generator_loss=-1.538240312903838e-09, discriminator_loss=1.1135123713756911e-05\n",
            "step 1932: generator_loss=-7.635330145916441e-10, discriminator_loss=1.2703515494649764e-05\n",
            "step 1933: generator_loss=-2.9884811292291147e-10, discriminator_loss=1.4052293408894911e-05\n",
            "step 1934: generator_loss=-5.305230699192975e-10, discriminator_loss=4.86824546896969e-06\n",
            "step 1935: generator_loss=-1.4962396877038486e-09, discriminator_loss=9.56143321673153e-06\n",
            "step 1936: generator_loss=-1.0897609481475001e-09, discriminator_loss=2.296153070346918e-06\n",
            "step 1937: generator_loss=-8.341912716147704e-10, discriminator_loss=6.327456958388211e-06\n",
            "step 1938: generator_loss=-2.6106056205676964e-10, discriminator_loss=9.336253242508974e-06\n",
            "step 1939: generator_loss=-7.298085746842986e-11, discriminator_loss=7.55238943384029e-06\n",
            "step 1940: generator_loss=-1.3035159618368652e-09, discriminator_loss=3.834804829239147e-06\n",
            "step 1941: generator_loss=-1.518100922748289e-10, discriminator_loss=2.6492291453905636e-06\n",
            "step 1942: generator_loss=-2.2508064856374688e-10, discriminator_loss=9.456640327698551e-06\n",
            "step 1943: generator_loss=-5.337288833118237e-09, discriminator_loss=2.8751667286996963e-06\n",
            "step 1944: generator_loss=-3.233926737511439e-10, discriminator_loss=6.243145890039159e-06\n",
            "step 1945: generator_loss=-1.7333368074190503e-10, discriminator_loss=1.0037998436018825e-05\n",
            "step 1946: generator_loss=-1.4103856971203754e-09, discriminator_loss=3.3004582746798405e-06\n",
            "step 1947: generator_loss=-1.3139935806094627e-09, discriminator_loss=6.36996264802292e-06\n",
            "step 1948: generator_loss=-6.678108066537902e-10, discriminator_loss=4.1256844269810244e-05\n",
            "step 1949: generator_loss=-1.0589291665752398e-09, discriminator_loss=6.480657248175703e-06\n",
            "step 1950: generator_loss=-9.088491070841087e-10, discriminator_loss=6.3224451878340915e-06\n",
            "step 1951: generator_loss=-1.4934247172249115e-09, discriminator_loss=5.379783033276908e-06\n",
            "step 1952: generator_loss=-8.547898500133044e-10, discriminator_loss=9.146785487246234e-06\n",
            "step 1953: generator_loss=-1.1898199092641448e-09, discriminator_loss=2.3704296836513095e-05\n",
            "step 1954: generator_loss=-5.203378283802351e-10, discriminator_loss=5.563678314501885e-06\n",
            "step 1955: generator_loss=-3.4042980240345244e-11, discriminator_loss=1.2880665053671692e-05\n",
            "step 1956: generator_loss=-2.6080293480390537e-10, discriminator_loss=5.422226877271896e-06\n",
            "step 1957: generator_loss=-1.6347077858025472e-10, discriminator_loss=2.880586862374912e-06\n",
            "step 1958: generator_loss=-9.971064252045636e-11, discriminator_loss=6.108343768573832e-06\n",
            "step 1959: generator_loss=-6.560685883449935e-10, discriminator_loss=4.719743628811557e-06\n",
            "step 1960: generator_loss=-3.873407816712415e-09, discriminator_loss=1.4493199159915093e-05\n",
            "step 1961: generator_loss=-1.1762356366684656e-10, discriminator_loss=4.451629592949757e-06\n",
            "step 1962: generator_loss=-7.636656640386263e-09, discriminator_loss=1.2220109056215733e-05\n",
            "step 1963: generator_loss=-3.2871627642094836e-10, discriminator_loss=7.399625246762298e-06\n",
            "step 1964: generator_loss=-2.0417478818757218e-09, discriminator_loss=1.6511725334567018e-05\n",
            "step 1965: generator_loss=-5.500827016113874e-10, discriminator_loss=1.3889775800635107e-05\n",
            "step 1966: generator_loss=-1.4773446355142994e-10, discriminator_loss=4.754932888317853e-05\n",
            "step 1967: generator_loss=-7.753027664314516e-10, discriminator_loss=7.735672625130974e-06\n",
            "step 1968: generator_loss=-4.826782862288326e-10, discriminator_loss=5.994096227368573e-06\n",
            "step 1969: generator_loss=-1.2651337755187342e-09, discriminator_loss=1.1161221664224286e-05\n",
            "step 1970: generator_loss=-4.316146107186114e-09, discriminator_loss=4.253696715750266e-06\n",
            "step 1971: generator_loss=-3.156002570392502e-09, discriminator_loss=1.7694097778075957e-06\n",
            "step 1972: generator_loss=-6.69389266239051e-11, discriminator_loss=2.549403461671318e-06\n",
            "step 1973: generator_loss=-1.414721811920927e-10, discriminator_loss=1.3528174349630717e-06\n",
            "step 1974: generator_loss=-1.8121554035133158e-08, discriminator_loss=8.23355821921723e-06\n",
            "step 1975: generator_loss=-6.332200319647541e-10, discriminator_loss=8.009626981220208e-06\n",
            "step 1976: generator_loss=-2.7245303235723384e-10, discriminator_loss=1.5435454770340584e-05\n",
            "step 1977: generator_loss=-2.2948669631261964e-09, discriminator_loss=8.787174920144025e-06\n",
            "step 1978: generator_loss=-1.0861782306914591e-10, discriminator_loss=3.8726284401491284e-06\n",
            "step 1979: generator_loss=-6.87534362775466e-10, discriminator_loss=3.4134695852117147e-06\n",
            "step 1980: generator_loss=-8.734981071789605e-10, discriminator_loss=5.746122042182833e-06\n",
            "step 1981: generator_loss=-8.028876175014688e-11, discriminator_loss=5.858886652276851e-06\n",
            "step 1982: generator_loss=-5.129079938548387e-10, discriminator_loss=4.777361027663574e-06\n",
            "step 1983: generator_loss=-9.343827100938285e-11, discriminator_loss=2.2560026991413906e-05\n",
            "step 1984: generator_loss=-1.3166850942880615e-10, discriminator_loss=6.0247380133660045e-06\n",
            "step 1985: generator_loss=-6.068789915048001e-10, discriminator_loss=1.1984411685261875e-05\n",
            "step 1986: generator_loss=-3.009778815066255e-10, discriminator_loss=5.281511676002992e-06\n",
            "step 1987: generator_loss=-1.1153213907988402e-09, discriminator_loss=9.850586138782091e-06\n",
            "step 1988: generator_loss=-2.1617896361902922e-10, discriminator_loss=3.4743404739856487e-06\n",
            "step 1989: generator_loss=-2.1551432860533737e-10, discriminator_loss=1.0697513062041253e-05\n",
            "step 1990: generator_loss=-8.441635723777097e-10, discriminator_loss=7.723319868091494e-06\n",
            "step 1991: generator_loss=-1.6471748964796973e-10, discriminator_loss=1.2615337254828773e-05\n",
            "step 1992: generator_loss=-5.18169285257386e-10, discriminator_loss=4.873720627074363e-06\n",
            "step 1993: generator_loss=-2.8946081642722277e-10, discriminator_loss=3.087956429226324e-05\n",
            "step 1994: generator_loss=-2.796358145040756e-10, discriminator_loss=5.406986474554287e-06\n",
            "step 1995: generator_loss=-4.647351836695179e-09, discriminator_loss=4.6608562115579844e-05\n",
            "step 1996: generator_loss=-9.242383247620722e-11, discriminator_loss=5.236303331912495e-05\n",
            "step 1997: generator_loss=-4.281862420185689e-09, discriminator_loss=3.930876846425235e-05\n",
            "step 1998: generator_loss=-5.875282482747934e-10, discriminator_loss=1.7008607755997218e-05\n",
            "step 1999: generator_loss=-1.3848376889669112e-09, discriminator_loss=5.665900516760303e-06\n",
            "step 2000: generator_loss=-2.4400403919599967e-10, discriminator_loss=3.889766503561987e-06\n",
            "step 2001: generator_loss=-1.0664926580750134e-10, discriminator_loss=1.4299690519692376e-05\n",
            "step 2002: generator_loss=-6.735632052112805e-10, discriminator_loss=9.754847269505262e-06\n",
            "step 2003: generator_loss=-5.31177768436919e-09, discriminator_loss=2.2364447431755252e-06\n",
            "step 2004: generator_loss=-1.7024563703227358e-10, discriminator_loss=6.8271469899627846e-06\n",
            "step 2005: generator_loss=-6.440746824765142e-10, discriminator_loss=3.2360001114284387e-06\n",
            "step 2006: generator_loss=-2.8132163265581767e-10, discriminator_loss=4.71836028737016e-06\n",
            "step 2007: generator_loss=-5.499426469768309e-10, discriminator_loss=9.043116733664647e-06\n",
            "step 2008: generator_loss=-2.5457333463485554e-10, discriminator_loss=5.383126335800625e-06\n",
            "step 2009: generator_loss=-2.1158796936759927e-10, discriminator_loss=9.077141839952674e-06\n",
            "step 2010: generator_loss=-4.779669715571089e-11, discriminator_loss=9.715384294395335e-06\n",
            "step 2011: generator_loss=-3.782845703348414e-10, discriminator_loss=9.055888767761644e-06\n",
            "step 2012: generator_loss=-5.401220581902066e-10, discriminator_loss=8.723493010620587e-06\n",
            "step 2013: generator_loss=-1.603680660489104e-10, discriminator_loss=6.471366305049742e-06\n",
            "step 2014: generator_loss=-1.3405199172922266e-10, discriminator_loss=4.5136207518226e-06\n",
            "step 2015: generator_loss=-3.0947674978243356e-10, discriminator_loss=6.1535565691883676e-06\n",
            "step 2016: generator_loss=-8.754266644928066e-09, discriminator_loss=7.297202955669491e-06\n",
            "step 2017: generator_loss=-2.9314720095818814e-10, discriminator_loss=3.6423609799385304e-06\n",
            "step 2018: generator_loss=-8.479374979941667e-10, discriminator_loss=4.566861207422335e-06\n",
            "step 2019: generator_loss=-1.2354663958547007e-09, discriminator_loss=1.2716478522634134e-05\n",
            "step 2020: generator_loss=-3.8573393368324105e-09, discriminator_loss=2.567203182479716e-06\n",
            "step 2021: generator_loss=-1.2154727224711337e-09, discriminator_loss=1.4960402040742338e-05\n",
            "step 2022: generator_loss=-4.131503139603865e-09, discriminator_loss=9.25164385989774e-06\n",
            "step 2023: generator_loss=-6.703512744898887e-10, discriminator_loss=4.9655313887342345e-06\n",
            "step 2024: generator_loss=-1.1258957655080337e-10, discriminator_loss=6.515687346109189e-06\n",
            "step 2025: generator_loss=-1.1903796837131608e-09, discriminator_loss=8.476701623294502e-06\n",
            "step 2026: generator_loss=-2.3662541370761403e-10, discriminator_loss=3.1816421142139006e-06\n",
            "step 2027: generator_loss=-2.2453078285522565e-10, discriminator_loss=1.5185916709015146e-05\n",
            "step 2028: generator_loss=-2.442465119045778e-10, discriminator_loss=1.5366165371233365e-06\n",
            "step 2029: generator_loss=-2.921222985730054e-10, discriminator_loss=1.8794190737025929e-06\n",
            "step 2030: generator_loss=-6.48626174992728e-09, discriminator_loss=4.949142294208286e-06\n",
            "step 2031: generator_loss=-1.5195532332423767e-10, discriminator_loss=2.3875891201896593e-06\n",
            "step 2032: generator_loss=-3.2052485110511952e-09, discriminator_loss=6.393027888407232e-06\n",
            "step 2033: generator_loss=-9.879533857670708e-10, discriminator_loss=4.067244844918605e-06\n",
            "step 2034: generator_loss=-1.7691148546106206e-10, discriminator_loss=9.634015441406518e-06\n",
            "step 2035: generator_loss=-9.729295147309358e-11, discriminator_loss=9.171659257845022e-06\n",
            "step 2036: generator_loss=-1.3956307221008046e-09, discriminator_loss=4.9639493227005005e-06\n",
            "step 2037: generator_loss=-2.71607653035133e-10, discriminator_loss=3.4063712064380525e-06\n",
            "step 2038: generator_loss=-3.775206813827481e-10, discriminator_loss=4.685951353167184e-06\n",
            "step 2039: generator_loss=-3.297283002190454e-10, discriminator_loss=9.695670996734407e-06\n",
            "step 2040: generator_loss=-8.7762019873594e-10, discriminator_loss=4.26625183536089e-06\n",
            "step 2041: generator_loss=-2.044584945792849e-09, discriminator_loss=1.4227824067347683e-05\n",
            "step 2042: generator_loss=-2.589462810842491e-10, discriminator_loss=3.030559582839487e-06\n",
            "step 2043: generator_loss=-1.795294191087038e-10, discriminator_loss=9.894209142657928e-06\n",
            "step 2044: generator_loss=-5.311251438655518e-10, discriminator_loss=5.19621562489192e-06\n",
            "step 2045: generator_loss=-2.193263626271147e-10, discriminator_loss=2.1806069980812026e-06\n",
            "step 2046: generator_loss=-8.223799974338419e-10, discriminator_loss=1.7293043129029684e-05\n",
            "step 2047: generator_loss=-1.1396806415264749e-10, discriminator_loss=1.4588294106943067e-05\n",
            "step 2048: generator_loss=-4.1018644036938667e-10, discriminator_loss=4.353155873104697e-06\n",
            "step 2049: generator_loss=-1.9180113053351988e-10, discriminator_loss=5.973040515527828e-06\n",
            "step 2050: generator_loss=-1.7888757142259237e-10, discriminator_loss=5.7208062571589835e-06\n",
            "step 2051: generator_loss=-1.017235254363591e-10, discriminator_loss=1.4984639165049884e-05\n",
            "step 2052: generator_loss=-1.4492641808860895e-10, discriminator_loss=2.440787648083642e-05\n",
            "step 2053: generator_loss=-2.844149915581795e-10, discriminator_loss=6.563584975083359e-06\n",
            "step 2054: generator_loss=-7.297385473670204e-10, discriminator_loss=7.458158506779e-06\n",
            "step 2055: generator_loss=-4.921591134632308e-09, discriminator_loss=6.401176960935118e-06\n",
            "step 2056: generator_loss=-1.7795914741824959e-10, discriminator_loss=9.591712114342954e-06\n",
            "step 2057: generator_loss=-3.6926015578586657e-09, discriminator_loss=2.3496136236644816e-06\n",
            "step 2058: generator_loss=-4.943121467704259e-10, discriminator_loss=7.485555670427857e-06\n",
            "step 2059: generator_loss=-1.7608299263116578e-09, discriminator_loss=2.643080051711877e-06\n",
            "step 2060: generator_loss=-3.5313516555390834e-09, discriminator_loss=6.032177225279156e-06\n",
            "step 2061: generator_loss=-1.4490900146491015e-10, discriminator_loss=5.493789558386197e-06\n",
            "step 2062: generator_loss=-3.1696753555188195e-10, discriminator_loss=8.031483048398513e-06\n",
            "step 2063: generator_loss=-3.5067590498094603e-10, discriminator_loss=1.1036995601898525e-05\n",
            "step 2064: generator_loss=-2.8068708468609316e-10, discriminator_loss=4.255701696820324e-06\n",
            "step 2065: generator_loss=-3.799107695101611e-10, discriminator_loss=1.3659051774084219e-06\n",
            "step 2066: generator_loss=-1.6272275749074083e-09, discriminator_loss=1.1402022209949791e-05\n",
            "step 2067: generator_loss=-9.64619606413919e-10, discriminator_loss=2.4230969302152516e-06\n",
            "step 2068: generator_loss=-6.168343613666138e-10, discriminator_loss=2.894764293159824e-06\n",
            "step 2069: generator_loss=-2.463589332535321e-10, discriminator_loss=6.546793429151876e-06\n",
            "step 2070: generator_loss=-4.808896614250102e-10, discriminator_loss=5.638041784550296e-06\n",
            "step 2071: generator_loss=-2.0560846081263406e-10, discriminator_loss=5.277055606711656e-06\n",
            "step 2072: generator_loss=-2.0612504758599215e-10, discriminator_loss=2.3368595520878443e-06\n",
            "step 2073: generator_loss=-4.546606979793921e-10, discriminator_loss=4.601162800099701e-06\n",
            "step 2074: generator_loss=-1.9713149168598676e-10, discriminator_loss=1.1381202966731507e-05\n",
            "step 2075: generator_loss=-1.5827214538965961e-10, discriminator_loss=2.8572649171110243e-06\n",
            "step 2076: generator_loss=-5.185625262527083e-10, discriminator_loss=6.3244956436392386e-06\n",
            "step 2077: generator_loss=-1.909524538490359e-09, discriminator_loss=8.325790986418724e-06\n",
            "step 2078: generator_loss=-5.183873774683434e-09, discriminator_loss=7.0489577410626225e-06\n",
            "step 2079: generator_loss=-2.1411628026157814e-10, discriminator_loss=2.5095812361541903e-06\n",
            "step 2080: generator_loss=-5.0018794439665726e-08, discriminator_loss=6.11020004726015e-06\n",
            "step 2081: generator_loss=-8.638574577890523e-11, discriminator_loss=3.872611159749795e-06\n",
            "step 2082: generator_loss=-1.37054256832414e-10, discriminator_loss=4.851482572121313e-06\n",
            "step 2083: generator_loss=-4.744713066884287e-09, discriminator_loss=5.258941655483795e-06\n",
            "step 2084: generator_loss=-1.1639319508205404e-09, discriminator_loss=7.331868346227566e-06\n",
            "step 2085: generator_loss=-7.116088274194965e-10, discriminator_loss=6.949113867449341e-06\n",
            "step 2086: generator_loss=-2.1629460444927417e-09, discriminator_loss=4.993624315829948e-06\n",
            "step 2087: generator_loss=-2.509313867804508e-10, discriminator_loss=4.258887202013284e-06\n",
            "step 2088: generator_loss=-1.3412920774058534e-09, discriminator_loss=8.570935278839897e-06\n",
            "step 2089: generator_loss=-2.031069978869482e-09, discriminator_loss=9.859867532213684e-06\n",
            "step 2090: generator_loss=-2.096689627473225e-10, discriminator_loss=9.109295206144452e-06\n",
            "step 2091: generator_loss=-5.274448655612218e-10, discriminator_loss=8.570024874643423e-06\n",
            "step 2092: generator_loss=-3.1657314547572923e-09, discriminator_loss=8.576563232054468e-06\n",
            "step 2093: generator_loss=-1.4505664724939749e-10, discriminator_loss=1.3612179827759974e-05\n",
            "step 2094: generator_loss=-1.7447487898891723e-10, discriminator_loss=4.718139280157629e-06\n",
            "step 2095: generator_loss=-3.377390034309258e-10, discriminator_loss=1.4122261745797005e-05\n",
            "step 2096: generator_loss=-3.7494607418864234e-10, discriminator_loss=7.669427759537939e-06\n",
            "step 2097: generator_loss=-1.7166811028257456e-10, discriminator_loss=3.4648123801162e-06\n",
            "step 2098: generator_loss=-2.477905880482467e-09, discriminator_loss=2.7467511245049536e-05\n",
            "step 2099: generator_loss=-2.0378615461780214e-10, discriminator_loss=2.5482927412667777e-06\n",
            "step 2100: generator_loss=-1.7904198956752992e-10, discriminator_loss=9.858535122475587e-06\n",
            "step 2101: generator_loss=-2.355589057145835e-10, discriminator_loss=2.701326138776494e-06\n",
            "step 2102: generator_loss=-2.50463233486542e-10, discriminator_loss=2.865810074581532e-06\n",
            "step 2103: generator_loss=-2.883028260569631e-10, discriminator_loss=6.404737177945208e-06\n",
            "step 2104: generator_loss=-1.635297175450745e-10, discriminator_loss=1.2412765499902889e-05\n",
            "step 2105: generator_loss=-5.334729880068778e-10, discriminator_loss=1.452224842068972e-05\n",
            "step 2106: generator_loss=-1.8097302545427851e-09, discriminator_loss=4.02245314035099e-06\n",
            "step 2107: generator_loss=-7.877406504874784e-10, discriminator_loss=7.783172804920468e-06\n",
            "step 2108: generator_loss=-4.0317243987786355e-10, discriminator_loss=6.652365755144274e-06\n",
            "step 2109: generator_loss=-1.6843108596731327e-07, discriminator_loss=3.939895123039605e-06\n",
            "step 2110: generator_loss=-3.102905932195199e-09, discriminator_loss=3.91094454244012e-06\n",
            "step 2111: generator_loss=-1.1695253654409044e-09, discriminator_loss=5.228823283687234e-06\n",
            "step 2112: generator_loss=-1.7222642756387074e-10, discriminator_loss=9.140600013779476e-06\n",
            "step 2113: generator_loss=-6.276951181050094e-11, discriminator_loss=5.632156899082474e-06\n",
            "step 2114: generator_loss=-1.686606687645309e-10, discriminator_loss=7.747205927444156e-06\n",
            "step 2115: generator_loss=-1.4678953885738366e-10, discriminator_loss=5.1033462113991845e-06\n",
            "step 2116: generator_loss=-5.023417237737249e-10, discriminator_loss=8.710718248039484e-06\n",
            "step 2117: generator_loss=-3.182588637073991e-10, discriminator_loss=3.754345925699454e-06\n",
            "step 2118: generator_loss=-6.895500836989754e-10, discriminator_loss=4.850189725402743e-06\n",
            "step 2119: generator_loss=-6.865016888291109e-10, discriminator_loss=6.604346708627418e-06\n",
            "step 2120: generator_loss=-1.140568528512631e-09, discriminator_loss=9.54300685407361e-06\n",
            "step 2121: generator_loss=-1.7258108830908725e-10, discriminator_loss=1.2826843885704875e-05\n",
            "step 2122: generator_loss=-7.320777317687543e-10, discriminator_loss=3.636742576418328e-06\n",
            "step 2123: generator_loss=-1.8709096494262667e-09, discriminator_loss=5.744525424233871e-06\n",
            "step 2124: generator_loss=-2.0917421128530123e-09, discriminator_loss=7.124431249394547e-06\n",
            "step 2125: generator_loss=-1.9062008915771145e-10, discriminator_loss=1.2580879229062703e-05\n",
            "step 2126: generator_loss=-6.043365807784085e-09, discriminator_loss=8.937257007346489e-06\n",
            "step 2127: generator_loss=-1.8787120747987274e-09, discriminator_loss=2.6635732865543105e-05\n",
            "step 2128: generator_loss=-1.488384970826928e-10, discriminator_loss=9.796594895306043e-06\n",
            "step 2129: generator_loss=-2.550149535984758e-10, discriminator_loss=1.2189186236355454e-05\n",
            "step 2130: generator_loss=-4.194243841126877e-10, discriminator_loss=6.121581918705488e-06\n",
            "step 2131: generator_loss=-2.622734252000214e-10, discriminator_loss=1.521755280009529e-06\n",
            "step 2132: generator_loss=-2.5782127544005107e-09, discriminator_loss=3.3977510156546487e-06\n",
            "step 2133: generator_loss=-3.704222484302022e-10, discriminator_loss=4.5425617827277165e-06\n",
            "step 2134: generator_loss=-5.134006286766635e-08, discriminator_loss=7.288459073606646e-06\n",
            "step 2135: generator_loss=-3.5311828128214984e-08, discriminator_loss=6.014326572767459e-06\n",
            "step 2136: generator_loss=-5.228339094998091e-09, discriminator_loss=4.7216717575793155e-06\n",
            "step 2137: generator_loss=-3.273566973049924e-10, discriminator_loss=4.034573521494167e-06\n",
            "step 2138: generator_loss=-5.463847707609659e-10, discriminator_loss=3.0094261092017405e-06\n",
            "step 2139: generator_loss=-1.5606664849343588e-09, discriminator_loss=5.994655566610163e-06\n",
            "step 2140: generator_loss=-2.3185485475973877e-10, discriminator_loss=6.280863544816384e-06\n",
            "step 2141: generator_loss=-2.545330890502129e-10, discriminator_loss=2.1617925085593015e-06\n",
            "step 2142: generator_loss=-6.445327604964746e-11, discriminator_loss=1.2673809578700457e-05\n",
            "step 2143: generator_loss=-5.6729980713043915e-09, discriminator_loss=3.493494205031311e-06\n",
            "step 2144: generator_loss=-1.0492591240307547e-09, discriminator_loss=4.810527570953127e-06\n",
            "step 2145: generator_loss=-1.766351620524631e-09, discriminator_loss=4.7548037400702015e-06\n",
            "step 2146: generator_loss=-4.462819003236973e-10, discriminator_loss=1.4358304269990185e-06\n",
            "step 2147: generator_loss=-1.8552467895283087e-10, discriminator_loss=2.1178657334530726e-05\n",
            "step 2148: generator_loss=-7.280681613153206e-11, discriminator_loss=1.157606857304927e-05\n",
            "step 2149: generator_loss=-2.9770044762678083e-10, discriminator_loss=1.543955659144558e-05\n",
            "step 2150: generator_loss=-2.423596323630761e-10, discriminator_loss=1.124875507230172e-05\n",
            "step 2151: generator_loss=-3.709645479688106e-09, discriminator_loss=7.877649295551237e-06\n",
            "step 2152: generator_loss=-1.2362090517914481e-10, discriminator_loss=1.5522815601798357e-06\n",
            "step 2153: generator_loss=-1.745474736969399e-10, discriminator_loss=4.498952876019757e-06\n",
            "step 2154: generator_loss=-5.663427365965035e-11, discriminator_loss=3.946800006815465e-06\n",
            "step 2155: generator_loss=-2.4325477743225576e-10, discriminator_loss=2.2686479042022256e-06\n",
            "step 2156: generator_loss=-8.331603740252547e-10, discriminator_loss=5.724109541915823e-06\n",
            "step 2157: generator_loss=-1.449785069773668e-09, discriminator_loss=1.6308938938891515e-05\n",
            "step 2158: generator_loss=-1.0413492290695103e-09, discriminator_loss=3.882753662765026e-05\n",
            "step 2159: generator_loss=-1.0020145602140929e-08, discriminator_loss=5.237343884800794e-06\n",
            "step 2160: generator_loss=-3.6020584293083857e-09, discriminator_loss=1.8906050172518007e-05\n",
            "step 2161: generator_loss=-6.351204562271562e-10, discriminator_loss=2.1136304440005915e-06\n",
            "step 2162: generator_loss=-4.184960156194961e-10, discriminator_loss=8.1494636106072e-06\n",
            "step 2163: generator_loss=-1.050257769641405e-09, discriminator_loss=9.061998753168155e-06\n",
            "step 2164: generator_loss=-1.293216755904325e-09, discriminator_loss=1.0021741218224633e-05\n",
            "step 2165: generator_loss=-2.8164182097611956e-10, discriminator_loss=3.754764111363329e-05\n",
            "step 2166: generator_loss=-6.239656347162281e-09, discriminator_loss=5.06887090523378e-06\n",
            "step 2167: generator_loss=-3.5349090321545873e-10, discriminator_loss=7.832306437194347e-06\n",
            "step 2168: generator_loss=-2.335594218028092e-10, discriminator_loss=8.169341526809148e-06\n",
            "step 2169: generator_loss=-4.01379568470972e-10, discriminator_loss=5.901517852180405e-06\n",
            "step 2170: generator_loss=-2.2159547086175735e-08, discriminator_loss=4.853285190620227e-06\n",
            "step 2171: generator_loss=-2.5838502448749523e-09, discriminator_loss=5.536607659450965e-06\n",
            "step 2172: generator_loss=-7.016954794991648e-10, discriminator_loss=2.3643262920813868e-06\n",
            "step 2173: generator_loss=-1.3266373555254063e-09, discriminator_loss=2.9984482807776658e-06\n",
            "step 2174: generator_loss=-5.705143024670178e-10, discriminator_loss=4.159536274528364e-06\n",
            "step 2175: generator_loss=-4.003253284423636e-11, discriminator_loss=1.9741751202673186e-06\n",
            "step 2176: generator_loss=-5.069105690758136e-10, discriminator_loss=1.1569031812541652e-05\n",
            "step 2177: generator_loss=-2.2807116195622257e-09, discriminator_loss=1.2335866813373286e-05\n",
            "step 2178: generator_loss=-2.5600069286646487e-10, discriminator_loss=6.548910732817603e-06\n",
            "step 2179: generator_loss=-2.2520256492963853e-10, discriminator_loss=2.453692786730244e-06\n",
            "step 2180: generator_loss=-1.0895365720742234e-09, discriminator_loss=4.04189040636993e-06\n",
            "step 2181: generator_loss=-3.654594682434009e-10, discriminator_loss=4.213573447486851e-06\n",
            "step 2182: generator_loss=-3.2266023186622306e-10, discriminator_loss=1.649519049351511e-06\n",
            "step 2183: generator_loss=-2.018140932147361e-10, discriminator_loss=2.126103572663851e-05\n",
            "step 2184: generator_loss=-2.1958199702964976e-09, discriminator_loss=3.238286126361345e-06\n",
            "step 2185: generator_loss=-2.529658704730764e-09, discriminator_loss=3.156411366944667e-06\n",
            "step 2186: generator_loss=-9.376244225478558e-10, discriminator_loss=2.1907360860495828e-05\n",
            "step 2187: generator_loss=-1.8754766628603647e-09, discriminator_loss=2.972642960230587e-06\n",
            "step 2188: generator_loss=-7.199634638466179e-11, discriminator_loss=5.621772743324982e-06\n",
            "step 2189: generator_loss=-1.9305623766285862e-09, discriminator_loss=5.354479526431533e-06\n",
            "step 2190: generator_loss=-7.340359986507394e-10, discriminator_loss=3.6150543110125e-06\n",
            "step 2191: generator_loss=-4.4913162078330515e-10, discriminator_loss=2.9652392186108045e-06\n",
            "step 2192: generator_loss=-2.709377722176498e-10, discriminator_loss=7.773677680233959e-06\n",
            "step 2193: generator_loss=-9.47996348088509e-10, discriminator_loss=2.201927600253839e-06\n",
            "step 2194: generator_loss=-1.0313418175034172e-10, discriminator_loss=8.685740795044694e-06\n",
            "step 2195: generator_loss=-3.1030356062444753e-10, discriminator_loss=4.754132987727644e-06\n",
            "step 2196: generator_loss=-2.76780515173769e-10, discriminator_loss=5.596861228696071e-06\n",
            "step 2197: generator_loss=-2.1527840621260452e-10, discriminator_loss=5.512263214768609e-06\n",
            "step 2198: generator_loss=-9.426298630543783e-11, discriminator_loss=3.1299525744543644e-06\n",
            "step 2199: generator_loss=-7.862872020147904e-10, discriminator_loss=5.040129053668352e-06\n",
            "step 2200: generator_loss=-1.4967035943946883e-10, discriminator_loss=3.35351137437101e-06\n",
            "step 2201: generator_loss=-9.851736093580143e-11, discriminator_loss=3.0397500268009026e-06\n",
            "step 2202: generator_loss=-2.2102245034183454e-10, discriminator_loss=7.137089596653823e-06\n",
            "step 2203: generator_loss=-1.1840593394651933e-08, discriminator_loss=5.789158876723377e-06\n",
            "step 2204: generator_loss=-1.8659261635800561e-10, discriminator_loss=5.0841249503719155e-06\n",
            "step 2205: generator_loss=-2.7964863758001e-09, discriminator_loss=4.473565695661819e-06\n",
            "step 2206: generator_loss=-3.1134284039779914e-10, discriminator_loss=2.8114620818087133e-06\n",
            "step 2207: generator_loss=-2.8876858682025386e-09, discriminator_loss=2.5250619728467427e-06\n",
            "step 2208: generator_loss=-6.482701042642702e-09, discriminator_loss=2.9425589218590176e-06\n",
            "step 2209: generator_loss=-5.398405056311617e-10, discriminator_loss=5.6050685088848695e-06\n",
            "step 2210: generator_loss=-2.099632412377872e-10, discriminator_loss=1.8885274357671733e-06\n",
            "step 2211: generator_loss=-6.683786302197348e-10, discriminator_loss=5.047097602073336e-06\n",
            "step 2212: generator_loss=-5.374792833023889e-10, discriminator_loss=2.14475790016877e-06\n",
            "step 2213: generator_loss=-8.115667859964759e-11, discriminator_loss=4.1120301830233075e-06\n",
            "step 2214: generator_loss=-2.4601218839848116e-09, discriminator_loss=1.0629696589603554e-05\n",
            "step 2215: generator_loss=-3.8720998629671044e-10, discriminator_loss=1.2909951692563482e-05\n",
            "step 2216: generator_loss=-2.0571107484101958e-08, discriminator_loss=9.493874131294433e-06\n",
            "step 2217: generator_loss=-6.073971325903926e-10, discriminator_loss=3.076399707424571e-06\n",
            "step 2218: generator_loss=-2.472248794571641e-10, discriminator_loss=6.122430022514891e-06\n",
            "step 2219: generator_loss=-3.959601535541424e-10, discriminator_loss=1.2723641702905297e-05\n",
            "step 2220: generator_loss=-1.5601904213013995e-09, discriminator_loss=1.7649375649853027e-06\n",
            "step 2221: generator_loss=-1.263700699638548e-09, discriminator_loss=2.1964433472021483e-06\n",
            "step 2222: generator_loss=-5.537339475836234e-10, discriminator_loss=4.313044428272406e-06\n",
            "step 2223: generator_loss=-5.644364975410099e-10, discriminator_loss=9.446162039239425e-06\n",
            "step 2224: generator_loss=-9.517765742206308e-11, discriminator_loss=6.251988907024497e-06\n",
            "step 2225: generator_loss=-2.440899149469544e-10, discriminator_loss=6.528901394631248e-06\n",
            "step 2226: generator_loss=-3.7127965146765973e-09, discriminator_loss=3.606379095799639e-06\n",
            "step 2227: generator_loss=-3.3759903206309616e-10, discriminator_loss=1.0178058801102452e-05\n",
            "step 2228: generator_loss=-2.3445989594250705e-10, discriminator_loss=6.623724402743392e-06\n",
            "step 2229: generator_loss=-1.0853334203586584e-10, discriminator_loss=1.9149520085193217e-05\n",
            "step 2230: generator_loss=-3.21750820431177e-10, discriminator_loss=6.302269866864663e-06\n",
            "step 2231: generator_loss=-3.967405959315329e-09, discriminator_loss=2.690156634344021e-06\n",
            "step 2232: generator_loss=-6.635835214652275e-10, discriminator_loss=3.240826572437072e-06\n",
            "step 2233: generator_loss=-2.443606983426605e-10, discriminator_loss=1.3637390111398418e-05\n",
            "step 2234: generator_loss=-5.289494398041938e-10, discriminator_loss=2.80578683486965e-06\n",
            "step 2235: generator_loss=-4.766187444715797e-10, discriminator_loss=4.539992005447857e-06\n",
            "step 2236: generator_loss=-1.0354476165375104e-09, discriminator_loss=5.18298065799172e-06\n",
            "step 2237: generator_loss=-4.073520964986699e-10, discriminator_loss=3.5178961752535542e-06\n",
            "step 2238: generator_loss=-2.1256482685139133e-10, discriminator_loss=7.744019058009144e-06\n",
            "step 2239: generator_loss=-6.116859241345196e-10, discriminator_loss=1.7529569049656857e-06\n",
            "step 2240: generator_loss=-5.275823666828217e-10, discriminator_loss=4.556145540846046e-06\n",
            "step 2241: generator_loss=-3.188302122314468e-10, discriminator_loss=4.462817742023617e-06\n",
            "step 2242: generator_loss=-3.9388905470616464e-09, discriminator_loss=7.93460276327096e-06\n",
            "step 2243: generator_loss=-3.761608732832933e-11, discriminator_loss=8.0498411989538e-06\n",
            "step 2244: generator_loss=-1.5052850632635284e-10, discriminator_loss=1.932235818458139e-06\n",
            "step 2245: generator_loss=-6.817253428437198e-10, discriminator_loss=1.0208344065176789e-05\n",
            "step 2246: generator_loss=-1.5941106767947133e-10, discriminator_loss=8.961493222159334e-06\n",
            "step 2247: generator_loss=-2.4837960577173135e-09, discriminator_loss=6.768268121959409e-06\n",
            "step 2248: generator_loss=-4.734043712595337e-10, discriminator_loss=5.644039447361138e-06\n",
            "step 2249: generator_loss=-2.0375691411889107e-10, discriminator_loss=2.896708565458539e-06\n",
            "step 2250: generator_loss=-9.34941360442032e-11, discriminator_loss=6.774212579330197e-06\n",
            "step 2251: generator_loss=-1.5161263355878418e-09, discriminator_loss=4.529505076789064e-06\n",
            "step 2252: generator_loss=-3.7958231002832576e-10, discriminator_loss=1.0407083209429402e-05\n",
            "step 2253: generator_loss=-4.065016379062314e-10, discriminator_loss=7.910663953225594e-06\n",
            "step 2254: generator_loss=-6.803973495728144e-10, discriminator_loss=2.7030905584979337e-06\n",
            "step 2255: generator_loss=-5.686665582871342e-10, discriminator_loss=3.0396993224712787e-06\n",
            "step 2256: generator_loss=-3.911399204525878e-09, discriminator_loss=1.2549589882837608e-06\n",
            "step 2257: generator_loss=-1.433979601728197e-10, discriminator_loss=2.622786723804893e-06\n",
            "step 2258: generator_loss=-9.909120746165456e-11, discriminator_loss=4.8772021727927495e-06\n",
            "step 2259: generator_loss=-4.93018126324074e-10, discriminator_loss=2.9487946449080482e-06\n",
            "step 2260: generator_loss=-2.6306556932809144e-10, discriminator_loss=4.064793756697327e-06\n",
            "step 2261: generator_loss=-2.2070703598053854e-10, discriminator_loss=2.1200260107434588e-06\n",
            "step 2262: generator_loss=-4.318252422308433e-10, discriminator_loss=2.1372793526097666e-06\n",
            "step 2263: generator_loss=-1.5756471127836846e-10, discriminator_loss=3.3846281439764425e-06\n",
            "step 2264: generator_loss=-5.2611111023281865e-09, discriminator_loss=1.0684865628718399e-05\n",
            "step 2265: generator_loss=-2.8312466260338454e-10, discriminator_loss=1.4707315131090581e-05\n",
            "step 2266: generator_loss=-5.738918229525325e-10, discriminator_loss=1.0443553946970496e-05\n",
            "step 2267: generator_loss=-4.3354764223124675e-10, discriminator_loss=4.820846243092092e-06\n",
            "step 2268: generator_loss=-1.1547250933219289e-09, discriminator_loss=1.3026175111008342e-05\n",
            "step 2269: generator_loss=-2.152968497926011e-10, discriminator_loss=2.355501010242733e-06\n",
            "step 2270: generator_loss=-2.738504145671783e-10, discriminator_loss=3.5562427456170553e-06\n",
            "step 2271: generator_loss=-1.846386044057624e-09, discriminator_loss=2.6377854283055058e-06\n",
            "step 2272: generator_loss=-9.418317237219753e-10, discriminator_loss=6.887566996738315e-06\n",
            "step 2273: generator_loss=-2.1770709679458378e-08, discriminator_loss=2.740353238550597e-06\n",
            "step 2274: generator_loss=-2.7027369231547027e-10, discriminator_loss=6.75684941597865e-06\n",
            "step 2275: generator_loss=-1.1370162589230404e-09, discriminator_loss=2.385283005423844e-05\n",
            "step 2276: generator_loss=-5.969461591703862e-10, discriminator_loss=6.001918336551171e-06\n",
            "step 2277: generator_loss=-1.2821852468647421e-09, discriminator_loss=9.41390226216754e-06\n",
            "step 2278: generator_loss=-2.3775031943173985e-10, discriminator_loss=9.048674655787181e-06\n",
            "step 2279: generator_loss=-4.239940620820448e-10, discriminator_loss=7.1772801675251685e-06\n",
            "step 2280: generator_loss=-1.2673505578320032e-09, discriminator_loss=4.027635895909043e-06\n",
            "step 2281: generator_loss=-2.2622079209888568e-10, discriminator_loss=2.1671005470125237e-06\n",
            "step 2282: generator_loss=-1.8394279432953908e-09, discriminator_loss=2.2859483124193503e-06\n",
            "step 2283: generator_loss=-6.700523469405084e-10, discriminator_loss=7.24348728908808e-06\n",
            "step 2284: generator_loss=-3.2883751277523743e-10, discriminator_loss=4.553752205538331e-06\n",
            "step 2285: generator_loss=-3.629893330359124e-10, discriminator_loss=1.111502388084773e-05\n",
            "step 2286: generator_loss=-1.375859287611192e-10, discriminator_loss=1.615488508832641e-05\n",
            "step 2287: generator_loss=-6.0047422589804e-10, discriminator_loss=2.7870228223036975e-06\n",
            "step 2288: generator_loss=-6.588778134197781e-11, discriminator_loss=1.7488378944108263e-05\n",
            "step 2289: generator_loss=-7.209686736509013e-10, discriminator_loss=4.347727553977165e-06\n",
            "step 2290: generator_loss=-3.96530641655346e-10, discriminator_loss=2.104230134136742e-06\n",
            "step 2291: generator_loss=-2.117706010551501e-10, discriminator_loss=4.994426944904262e-06\n",
            "step 2292: generator_loss=-1.2823012096596642e-10, discriminator_loss=3.0655928640044294e-06\n",
            "step 2293: generator_loss=-3.8225161924643203e-10, discriminator_loss=5.7128554544760846e-06\n",
            "step 2294: generator_loss=-2.2962123868985884e-10, discriminator_loss=7.803988410159945e-06\n",
            "step 2295: generator_loss=-4.2568798486186665e-10, discriminator_loss=3.4823210626200307e-06\n",
            "step 2296: generator_loss=-1.0108051062829304e-09, discriminator_loss=1.0229593499389011e-05\n",
            "step 2297: generator_loss=-3.1592388705092844e-09, discriminator_loss=2.654958507264382e-06\n",
            "step 2298: generator_loss=-1.1297396351750422e-09, discriminator_loss=4.906693902739789e-06\n",
            "step 2299: generator_loss=-3.5364172701335406e-10, discriminator_loss=1.1426032870076597e-05\n",
            "step 2300: generator_loss=-1.1404167887807404e-10, discriminator_loss=2.7271496492176084e-06\n",
            "step 2301: generator_loss=-1.3019476163833588e-08, discriminator_loss=8.603847163612954e-06\n",
            "step 2302: generator_loss=-7.23257620460771e-10, discriminator_loss=3.378648898433312e-06\n",
            "step 2303: generator_loss=-2.0808879619416132e-10, discriminator_loss=1.2633940059458837e-05\n",
            "step 2304: generator_loss=-2.9407495882871615e-10, discriminator_loss=9.406436220160685e-06\n",
            "step 2305: generator_loss=-2.2257020670934935e-09, discriminator_loss=8.305732080771122e-06\n",
            "step 2306: generator_loss=-1.1557483858837259e-08, discriminator_loss=2.718615860430873e-06\n",
            "step 2307: generator_loss=-4.2900932806233527e-10, discriminator_loss=2.972172524096095e-06\n",
            "step 2308: generator_loss=-5.127265834126149e-10, discriminator_loss=4.504107891989406e-06\n",
            "step 2309: generator_loss=-4.240590101289854e-10, discriminator_loss=6.451903573179152e-06\n",
            "step 2310: generator_loss=-5.63455726521056e-10, discriminator_loss=9.150076039077248e-06\n",
            "step 2311: generator_loss=-2.0236312625598885e-10, discriminator_loss=9.155367479252163e-06\n",
            "step 2312: generator_loss=-1.91466065224688e-10, discriminator_loss=2.935591282948735e-06\n",
            "step 2313: generator_loss=-1.444615538304106e-10, discriminator_loss=8.382018677366432e-06\n",
            "step 2314: generator_loss=-5.63363300454256e-10, discriminator_loss=7.957160050864331e-06\n",
            "step 2315: generator_loss=-1.4563263095457302e-10, discriminator_loss=7.615040431119269e-06\n",
            "step 2316: generator_loss=-1.5673060071996758e-10, discriminator_loss=5.4914457905397285e-06\n",
            "step 2317: generator_loss=-3.1686833157351657e-09, discriminator_loss=5.459140083985403e-06\n",
            "step 2318: generator_loss=-1.1286366286000771e-10, discriminator_loss=6.582810328836786e-06\n",
            "step 2319: generator_loss=-3.270140158662116e-09, discriminator_loss=8.600519322499167e-06\n",
            "step 2320: generator_loss=-2.315199837399362e-10, discriminator_loss=4.4812240957980976e-06\n",
            "step 2321: generator_loss=-3.6533851499598313e-09, discriminator_loss=8.675728167872876e-06\n",
            "step 2322: generator_loss=-2.1981665376813453e-09, discriminator_loss=7.497647402487928e-06\n",
            "step 2323: generator_loss=-3.9983993893599745e-10, discriminator_loss=8.768624866206665e-06\n",
            "step 2324: generator_loss=-2.451504999001486e-09, discriminator_loss=4.622352207661606e-06\n",
            "step 2325: generator_loss=-3.534563752793929e-10, discriminator_loss=1.7801748981582932e-05\n",
            "step 2326: generator_loss=-1.8851855632107117e-09, discriminator_loss=1.0626782568579074e-05\n",
            "step 2327: generator_loss=-1.1843800939992377e-10, discriminator_loss=4.165766767982859e-06\n",
            "step 2328: generator_loss=-6.250008288688491e-10, discriminator_loss=3.7513161714741727e-06\n",
            "step 2329: generator_loss=-1.076069511274369e-10, discriminator_loss=8.100563718471676e-06\n",
            "step 2330: generator_loss=-2.6173210265767466e-09, discriminator_loss=3.408274278626777e-05\n",
            "step 2331: generator_loss=-1.5636341110791818e-09, discriminator_loss=1.0705090971896425e-05\n",
            "step 2332: generator_loss=-1.938980531690504e-09, discriminator_loss=3.5500345347827533e-06\n",
            "step 2333: generator_loss=-5.851893969399669e-10, discriminator_loss=1.5603935025865212e-05\n",
            "step 2334: generator_loss=-7.174008054278147e-10, discriminator_loss=8.491676453559194e-06\n",
            "step 2335: generator_loss=-4.815843834826694e-10, discriminator_loss=5.869500455446541e-06\n",
            "step 2336: generator_loss=-8.430628417599451e-10, discriminator_loss=5.11109010403743e-06\n",
            "step 2337: generator_loss=-3.3129565757406e-10, discriminator_loss=2.6981497285305522e-06\n",
            "step 2338: generator_loss=-6.647398187453746e-10, discriminator_loss=1.3282042345963418e-05\n",
            "step 2339: generator_loss=-3.4578845342636555e-10, discriminator_loss=3.97025132770068e-06\n",
            "step 2340: generator_loss=-2.2810303645925956e-10, discriminator_loss=2.834739461832214e-06\n",
            "step 2341: generator_loss=-3.4655029956809358e-09, discriminator_loss=4.855909082834842e-06\n",
            "step 2342: generator_loss=-6.804050101116843e-10, discriminator_loss=5.021172000851948e-06\n",
            "step 2343: generator_loss=-4.737514824881828e-10, discriminator_loss=4.229048954584869e-06\n",
            "step 2344: generator_loss=-6.790867868033956e-10, discriminator_loss=4.22827997681452e-06\n",
            "step 2345: generator_loss=-3.7676781139417415e-10, discriminator_loss=4.865918526775204e-06\n",
            "step 2346: generator_loss=-1.043310771109418e-09, discriminator_loss=1.737246748234611e-05\n",
            "step 2347: generator_loss=-1.5738854663993607e-09, discriminator_loss=6.772192136850208e-06\n",
            "step 2348: generator_loss=-4.771200656783492e-10, discriminator_loss=5.598746156465495e-06\n",
            "step 2349: generator_loss=-2.259888498556961e-09, discriminator_loss=3.745503136087791e-06\n",
            "step 2350: generator_loss=-2.1041419273615247e-08, discriminator_loss=8.39474978420185e-06\n",
            "step 2351: generator_loss=-4.149673660247544e-11, discriminator_loss=3.955370630137622e-06\n",
            "step 2352: generator_loss=-4.01133404270837e-10, discriminator_loss=2.5846845801424934e-06\n",
            "step 2353: generator_loss=-2.75510336766871e-10, discriminator_loss=3.712261332111666e-06\n",
            "step 2354: generator_loss=-5.102037681226079e-10, discriminator_loss=1.044048804033082e-05\n",
            "step 2355: generator_loss=-1.3878715954263043e-09, discriminator_loss=5.440640961751342e-06\n",
            "step 2356: generator_loss=-4.480338322565558e-10, discriminator_loss=1.4056615327717736e-05\n",
            "step 2357: generator_loss=-5.894426058361546e-10, discriminator_loss=1.1822961596408277e-06\n",
            "step 2358: generator_loss=-8.917243610184755e-10, discriminator_loss=1.4452612958848476e-05\n",
            "step 2359: generator_loss=-5.8939537694868704e-09, discriminator_loss=4.865402843279298e-06\n",
            "step 2360: generator_loss=-3.7133335295536085e-10, discriminator_loss=3.114335413556546e-06\n",
            "step 2361: generator_loss=-3.8138037172785744e-10, discriminator_loss=6.432513600884704e-06\n",
            "step 2362: generator_loss=-5.899881139193042e-10, discriminator_loss=1.5010768038337119e-05\n",
            "step 2363: generator_loss=-1.330678484068315e-10, discriminator_loss=1.4329131772683468e-05\n",
            "step 2364: generator_loss=-6.8291576837964385e-09, discriminator_loss=6.1957612160767894e-06\n",
            "step 2365: generator_loss=-2.0468962635966648e-10, discriminator_loss=1.0252691026835237e-05\n",
            "step 2366: generator_loss=-1.9597037881347035e-10, discriminator_loss=1.4585798453481402e-06\n",
            "step 2367: generator_loss=-1.0312526388389642e-09, discriminator_loss=9.074656190932728e-06\n",
            "step 2368: generator_loss=-4.206120174377048e-10, discriminator_loss=1.7542168279760517e-05\n",
            "step 2369: generator_loss=-3.155884442662682e-10, discriminator_loss=4.6207296691136435e-06\n",
            "step 2370: generator_loss=-1.0038742059848005e-09, discriminator_loss=8.53862366057001e-06\n",
            "step 2371: generator_loss=-2.1381328707548164e-08, discriminator_loss=2.05444348466699e-06\n",
            "step 2372: generator_loss=-2.3658705550211323e-10, discriminator_loss=1.7930015019373968e-05\n",
            "step 2373: generator_loss=-7.752908315339369e-10, discriminator_loss=6.447934538300615e-06\n",
            "step 2374: generator_loss=-5.84677417592161e-10, discriminator_loss=4.184829322184669e-06\n",
            "step 2375: generator_loss=-6.874117941535474e-10, discriminator_loss=2.3063003027345985e-06\n",
            "step 2376: generator_loss=-1.2271552662923568e-09, discriminator_loss=5.2692307690449525e-06\n",
            "step 2377: generator_loss=-3.231873657583151e-10, discriminator_loss=7.73559349909192e-06\n",
            "step 2378: generator_loss=-8.301314635694723e-10, discriminator_loss=1.491381112828094e-06\n",
            "step 2379: generator_loss=-1.9472456980196284e-10, discriminator_loss=3.798900706897257e-06\n",
            "step 2380: generator_loss=-1.5879281889397134e-08, discriminator_loss=9.261915693059564e-06\n",
            "step 2381: generator_loss=-8.004863438770826e-09, discriminator_loss=2.7777280138252536e-06\n",
            "step 2382: generator_loss=-4.0386186062058016e-10, discriminator_loss=2.678710870895884e-06\n",
            "step 2383: generator_loss=-5.974769567984595e-10, discriminator_loss=3.420535222176113e-06\n",
            "step 2384: generator_loss=-6.558452669835901e-10, discriminator_loss=1.0905095223279204e-05\n",
            "step 2385: generator_loss=-4.6541315246173554e-10, discriminator_loss=6.634971668972867e-06\n",
            "step 2386: generator_loss=-3.7063658808733635e-09, discriminator_loss=7.653584361833055e-06\n",
            "step 2387: generator_loss=-1.4590168184724917e-08, discriminator_loss=8.084212822723202e-06\n",
            "step 2388: generator_loss=-1.9124749006671493e-10, discriminator_loss=6.74878538120538e-06\n",
            "step 2389: generator_loss=-8.532951234485608e-09, discriminator_loss=5.2354616855154745e-06\n",
            "step 2390: generator_loss=-2.0179742321602134e-09, discriminator_loss=5.075772605778184e-06\n",
            "step 2391: generator_loss=-1.677800121058226e-09, discriminator_loss=3.150331394863315e-06\n",
            "step 2392: generator_loss=-2.476729932254784e-10, discriminator_loss=3.909600764018251e-06\n",
            "step 2393: generator_loss=-5.864819740963867e-09, discriminator_loss=3.0176058771758107e-06\n",
            "step 2394: generator_loss=-2.7390767431967333e-10, discriminator_loss=3.4964596125064418e-06\n",
            "step 2395: generator_loss=-1.4798470004961928e-08, discriminator_loss=3.1915474210109096e-06\n",
            "step 2396: generator_loss=-3.006006998873545e-09, discriminator_loss=4.540412192000076e-06\n",
            "step 2397: generator_loss=-4.965285405056363e-10, discriminator_loss=8.359484127140604e-06\n",
            "step 2398: generator_loss=-8.115148553144991e-10, discriminator_loss=4.226717464916874e-06\n",
            "step 2399: generator_loss=-5.0721975231038385e-11, discriminator_loss=1.9364242689334787e-06\n",
            "step 2400: generator_loss=-2.314549663040566e-09, discriminator_loss=6.763081728422549e-06\n",
            "step 2401: generator_loss=-2.45097497852953e-10, discriminator_loss=2.4514636152161984e-06\n",
            "step 2402: generator_loss=-2.335264204234022e-10, discriminator_loss=2.425326556476648e-06\n",
            "step 2403: generator_loss=-4.017645660603364e-10, discriminator_loss=4.4766861719836015e-06\n",
            "step 2404: generator_loss=-3.4982688967843956e-10, discriminator_loss=3.4200927530037006e-06\n",
            "step 2405: generator_loss=-1.3395912157321277e-10, discriminator_loss=6.048019258741988e-06\n",
            "step 2406: generator_loss=-8.067248535859051e-10, discriminator_loss=4.431589331943542e-06\n",
            "step 2407: generator_loss=-5.560493177014791e-10, discriminator_loss=6.152492460387293e-06\n",
            "step 2408: generator_loss=-4.069957426633408e-10, discriminator_loss=3.677329232232296e-06\n",
            "step 2409: generator_loss=-1.293073703667602e-10, discriminator_loss=3.020435087819351e-06\n",
            "step 2410: generator_loss=-7.088865050519644e-10, discriminator_loss=2.9874538540752837e-06\n",
            "step 2411: generator_loss=-4.487122673424437e-09, discriminator_loss=2.3593433979840484e-06\n",
            "step 2412: generator_loss=-5.288681714787913e-10, discriminator_loss=7.784767149132676e-06\n",
            "step 2413: generator_loss=-7.81662012894202e-10, discriminator_loss=1.7362203834636603e-06\n",
            "step 2414: generator_loss=-2.794663944705178e-10, discriminator_loss=4.880687356489943e-06\n",
            "step 2415: generator_loss=-2.067218618506672e-10, discriminator_loss=2.3179889012681087e-06\n",
            "step 2416: generator_loss=-9.722077309870514e-11, discriminator_loss=3.963181825383799e-06\n",
            "step 2417: generator_loss=-1.6170080552324606e-10, discriminator_loss=1.4976172906244756e-06\n",
            "step 2418: generator_loss=-1.5924947471823714e-10, discriminator_loss=4.474989054870093e-06\n",
            "step 2419: generator_loss=-5.951942272375277e-10, discriminator_loss=3.5161408504791325e-06\n",
            "step 2420: generator_loss=-1.8118216649209984e-10, discriminator_loss=2.5539816306263674e-06\n",
            "step 2421: generator_loss=-2.336573157180055e-10, discriminator_loss=1.421906563336961e-05\n",
            "step 2422: generator_loss=-3.9057762579730593e-10, discriminator_loss=1.7953310589291505e-06\n",
            "step 2423: generator_loss=-1.0826951779563387e-08, discriminator_loss=4.17560113419313e-06\n",
            "step 2424: generator_loss=-4.759934668641108e-10, discriminator_loss=6.655364359176019e-06\n",
            "step 2425: generator_loss=-5.436928685043085e-10, discriminator_loss=2.429409505566582e-06\n",
            "step 2426: generator_loss=-6.309714417618295e-10, discriminator_loss=2.0396869331307244e-06\n",
            "step 2427: generator_loss=-2.090337347659954e-10, discriminator_loss=1.5760793758090585e-05\n",
            "step 2428: generator_loss=-8.957500297057663e-10, discriminator_loss=9.082184078579303e-06\n",
            "step 2429: generator_loss=-1.6685657022730283e-10, discriminator_loss=4.5952888285683e-06\n",
            "step 2430: generator_loss=-5.343219200426574e-10, discriminator_loss=7.128479865059489e-06\n",
            "step 2431: generator_loss=-1.1291741153218737e-10, discriminator_loss=5.6643152674951125e-06\n",
            "step 2432: generator_loss=-3.311168839115197e-10, discriminator_loss=2.3438003609044245e-06\n",
            "step 2433: generator_loss=-3.234337242474794e-08, discriminator_loss=4.475245987123344e-06\n",
            "step 2434: generator_loss=-1.175917807572091e-09, discriminator_loss=8.78775153978495e-06\n",
            "step 2435: generator_loss=-8.586553690292931e-11, discriminator_loss=3.076571601923206e-06\n",
            "step 2436: generator_loss=-6.10764994135593e-10, discriminator_loss=3.095168040090357e-06\n",
            "step 2437: generator_loss=-2.5029920358576874e-09, discriminator_loss=2.871361175493803e-06\n",
            "step 2438: generator_loss=-1.5096914829371144e-09, discriminator_loss=4.471834472496994e-06\n",
            "step 2439: generator_loss=-2.976038526725233e-09, discriminator_loss=9.14336214918876e-06\n",
            "step 2440: generator_loss=-1.486134826311769e-10, discriminator_loss=3.792425331994309e-06\n",
            "step 2441: generator_loss=-1.1164571489530317e-09, discriminator_loss=3.7142647215659963e-06\n",
            "step 2442: generator_loss=-2.959864853213645e-10, discriminator_loss=1.048233298206469e-05\n",
            "step 2443: generator_loss=-7.843473093238629e-10, discriminator_loss=6.036794275132706e-06\n",
            "step 2444: generator_loss=-1.8098042509073764e-10, discriminator_loss=5.735987997468328e-06\n",
            "step 2445: generator_loss=-1.1680659772750346e-09, discriminator_loss=5.842118298460264e-06\n",
            "step 2446: generator_loss=-1.23121846051788e-10, discriminator_loss=2.5394240310561145e-06\n",
            "step 2447: generator_loss=-1.4497877565133876e-08, discriminator_loss=5.182515906199114e-06\n",
            "step 2448: generator_loss=-2.021592004908257e-09, discriminator_loss=5.047194918006426e-06\n",
            "step 2449: generator_loss=-3.877584919820265e-10, discriminator_loss=7.630199434061069e-06\n",
            "step 2450: generator_loss=-2.6603472758068847e-09, discriminator_loss=1.7331374692730606e-05\n",
            "step 2451: generator_loss=-6.44878039857133e-10, discriminator_loss=6.785981440771138e-06\n",
            "step 2452: generator_loss=-6.282460107698284e-10, discriminator_loss=1.2050397799612256e-06\n",
            "step 2453: generator_loss=-1.9054866018386463e-10, discriminator_loss=6.483467586804181e-06\n",
            "step 2454: generator_loss=-1.4932514946774944e-10, discriminator_loss=2.4515129553037696e-06\n",
            "step 2455: generator_loss=-6.344712533135066e-10, discriminator_loss=2.8887041025882354e-06\n",
            "step 2456: generator_loss=-1.0950992335168053e-09, discriminator_loss=2.9729576453974005e-06\n",
            "step 2457: generator_loss=-1.0805004668767992e-09, discriminator_loss=3.884907528117765e-06\n",
            "step 2458: generator_loss=-8.165509379765012e-10, discriminator_loss=2.962578037113417e-06\n",
            "step 2459: generator_loss=-2.439749513527545e-10, discriminator_loss=2.912066520366352e-06\n",
            "step 2460: generator_loss=-1.1121665810520653e-09, discriminator_loss=4.846596766583389e-06\n",
            "step 2461: generator_loss=-2.3604602716886802e-09, discriminator_loss=2.6759121283248533e-06\n",
            "step 2462: generator_loss=-3.457657771210876e-10, discriminator_loss=4.233858817315195e-06\n",
            "step 2463: generator_loss=-3.638925272220206e-10, discriminator_loss=4.64480763184838e-06\n",
            "step 2464: generator_loss=-1.1874357053187623e-09, discriminator_loss=8.519518814864568e-06\n",
            "step 2465: generator_loss=-7.504559196291893e-10, discriminator_loss=2.978484417326399e-06\n",
            "step 2466: generator_loss=-5.654537393873227e-10, discriminator_loss=5.491001502377912e-06\n",
            "step 2467: generator_loss=-9.346143858834921e-10, discriminator_loss=6.182498509588186e-06\n",
            "step 2468: generator_loss=-7.224663089999694e-10, discriminator_loss=7.839523277652916e-06\n",
            "step 2469: generator_loss=-4.011666554504245e-09, discriminator_loss=8.894552593119442e-06\n",
            "step 2470: generator_loss=-6.811926578365046e-10, discriminator_loss=2.279730779264355e-06\n",
            "step 2471: generator_loss=-2.097795964717264e-10, discriminator_loss=3.821379777946277e-06\n",
            "step 2472: generator_loss=-9.237487996749394e-10, discriminator_loss=2.1128255411895225e-06\n",
            "step 2473: generator_loss=-4.2467906968823854e-10, discriminator_loss=2.144900008715922e-06\n",
            "step 2474: generator_loss=-3.904939704924004e-10, discriminator_loss=7.0287028393067885e-06\n",
            "step 2475: generator_loss=-1.2277477923205993e-09, discriminator_loss=3.94011840398889e-06\n",
            "step 2476: generator_loss=-1.396550652899009e-10, discriminator_loss=6.358472546708072e-06\n",
            "step 2477: generator_loss=-2.8023919296238375e-10, discriminator_loss=3.5221976304455893e-06\n",
            "step 2478: generator_loss=-3.033313045186503e-10, discriminator_loss=2.3828820303606335e-06\n",
            "step 2479: generator_loss=-6.003595953707475e-10, discriminator_loss=5.593794412561692e-06\n",
            "step 2480: generator_loss=-3.4113806224311816e-10, discriminator_loss=3.6709068353957264e-06\n",
            "step 2481: generator_loss=-2.713611779725511e-09, discriminator_loss=3.840048520942219e-06\n",
            "step 2482: generator_loss=-6.329236579283304e-10, discriminator_loss=7.559937785117654e-06\n",
            "step 2483: generator_loss=-5.567037941744957e-10, discriminator_loss=4.159118361712899e-06\n",
            "step 2484: generator_loss=-6.607433489236314e-10, discriminator_loss=8.454538146906998e-06\n",
            "step 2485: generator_loss=-1.3920717911730662e-09, discriminator_loss=3.594361260184087e-06\n",
            "step 2486: generator_loss=-3.8426994919404933e-10, discriminator_loss=2.9344814720388968e-06\n",
            "step 2487: generator_loss=-7.886357122899312e-10, discriminator_loss=8.219164556066971e-06\n",
            "step 2488: generator_loss=-5.195027741322633e-10, discriminator_loss=3.7208715184533503e-06\n",
            "step 2489: generator_loss=-1.3477721716448343e-10, discriminator_loss=3.1055624276632443e-06\n",
            "step 2490: generator_loss=-3.464821762833026e-10, discriminator_loss=4.803817773790797e-06\n",
            "step 2491: generator_loss=-2.506910790067707e-10, discriminator_loss=5.634313311020378e-06\n",
            "step 2492: generator_loss=-1.988731956892309e-10, discriminator_loss=1.1918170457647648e-05\n",
            "step 2493: generator_loss=-6.341260849751507e-10, discriminator_loss=3.950870905100601e-06\n",
            "step 2494: generator_loss=-5.152747672987346e-10, discriminator_loss=1.4971667951613199e-05\n",
            "step 2495: generator_loss=-1.7221135628631146e-10, discriminator_loss=1.53319924720563e-05\n",
            "step 2496: generator_loss=-2.435828205804569e-10, discriminator_loss=1.5385970755232847e-06\n",
            "step 2497: generator_loss=-2.200371440608251e-09, discriminator_loss=3.172888682456687e-06\n",
            "step 2498: generator_loss=-5.370308642227428e-10, discriminator_loss=2.771179879346164e-06\n",
            "step 2499: generator_loss=-7.098695936624821e-11, discriminator_loss=2.301342419741559e-06\n",
            "step 2500: generator_loss=-3.3001018584499775e-10, discriminator_loss=7.589905180793721e-06\n",
            "step 2501: generator_loss=-5.992962237577615e-10, discriminator_loss=3.0001162940607173e-06\n",
            "step 2502: generator_loss=-2.226098611002314e-10, discriminator_loss=3.6390188142831903e-06\n",
            "step 2503: generator_loss=-1.3791688902031751e-09, discriminator_loss=9.967086953110993e-06\n",
            "step 2504: generator_loss=-2.196005599586215e-10, discriminator_loss=5.969986887066625e-06\n",
            "step 2505: generator_loss=-7.993883888168796e-10, discriminator_loss=5.159190095582744e-06\n",
            "step 2506: generator_loss=-5.070572850485178e-10, discriminator_loss=4.784758402820444e-07\n",
            "step 2507: generator_loss=-8.645580917843176e-10, discriminator_loss=4.544545390672283e-06\n",
            "step 2508: generator_loss=-1.4599361719547232e-09, discriminator_loss=1.6950865528997383e-06\n",
            "step 2509: generator_loss=-4.547686227596159e-09, discriminator_loss=9.365284313389566e-06\n",
            "step 2510: generator_loss=-6.170870481270185e-10, discriminator_loss=7.883222679083701e-06\n",
            "step 2511: generator_loss=-6.149362130614122e-10, discriminator_loss=1.456084760320664e-06\n",
            "step 2512: generator_loss=-1.173114244634732e-10, discriminator_loss=3.175807432853617e-05\n",
            "step 2513: generator_loss=-8.472017531957476e-10, discriminator_loss=8.507052370987367e-06\n",
            "step 2514: generator_loss=-1.271006078162884e-10, discriminator_loss=7.731620826234575e-06\n",
            "step 2515: generator_loss=-4.641824258300176e-09, discriminator_loss=3.6095398172619753e-06\n",
            "step 2516: generator_loss=-2.554952249766984e-09, discriminator_loss=2.1470179490279406e-05\n",
            "step 2517: generator_loss=-2.506215235342779e-10, discriminator_loss=6.360060524457367e-06\n",
            "step 2518: generator_loss=-1.8902154841349272e-10, discriminator_loss=2.697435093068634e-06\n",
            "step 2519: generator_loss=-3.613502830290827e-10, discriminator_loss=1.537583375466056e-05\n",
            "step 2520: generator_loss=-2.0300242042914363e-10, discriminator_loss=2.170354036934441e-06\n",
            "step 2521: generator_loss=-3.857772434834317e-10, discriminator_loss=3.103681592619978e-06\n",
            "step 2522: generator_loss=-3.709100249160713e-10, discriminator_loss=3.2739926609792747e-06\n",
            "step 2523: generator_loss=-9.506354592403454e-10, discriminator_loss=1.7576589925738517e-06\n",
            "step 2524: generator_loss=-3.365998313409335e-10, discriminator_loss=9.246676199836656e-06\n",
            "step 2525: generator_loss=-1.193259713261341e-09, discriminator_loss=4.119894583709538e-05\n",
            "step 2526: generator_loss=-2.3921878367083593e-10, discriminator_loss=9.297041287936736e-06\n",
            "step 2527: generator_loss=-9.85513626261536e-09, discriminator_loss=7.643935532541946e-06\n",
            "step 2528: generator_loss=-4.267181330508407e-10, discriminator_loss=6.758386007277295e-06\n",
            "step 2529: generator_loss=-5.468565600352804e-10, discriminator_loss=1.2464158317015972e-05\n",
            "step 2530: generator_loss=-3.6963757055197277e-10, discriminator_loss=7.249087957461597e-06\n",
            "step 2531: generator_loss=-6.431307930654384e-09, discriminator_loss=1.5074372640810907e-05\n",
            "step 2532: generator_loss=-2.2185467352109356e-10, discriminator_loss=7.029287189652678e-06\n",
            "step 2533: generator_loss=-2.5079585075360455e-09, discriminator_loss=4.311476459406549e-06\n",
            "step 2534: generator_loss=-5.225966770439072e-09, discriminator_loss=2.809056013575173e-06\n",
            "step 2535: generator_loss=-7.08441589836184e-08, discriminator_loss=1.0520364412514027e-05\n",
            "step 2536: generator_loss=-2.3715465702345284e-10, discriminator_loss=3.3602302664803574e-06\n",
            "step 2537: generator_loss=-6.675159314184498e-10, discriminator_loss=7.384003765764646e-06\n",
            "step 2538: generator_loss=-4.3364370427845245e-10, discriminator_loss=7.692005965509452e-06\n",
            "step 2539: generator_loss=-6.970828914099059e-10, discriminator_loss=9.209971722157206e-06\n",
            "step 2540: generator_loss=-1.55348045538517e-09, discriminator_loss=1.4546320699082571e-06\n",
            "step 2541: generator_loss=-1.1033847169272804e-09, discriminator_loss=1.0611335710564163e-05\n",
            "step 2542: generator_loss=-9.94652471497659e-10, discriminator_loss=4.652953066397458e-06\n",
            "step 2543: generator_loss=-2.69128297425425e-09, discriminator_loss=8.628891009720974e-06\n",
            "step 2544: generator_loss=-1.0990186538606395e-08, discriminator_loss=7.100505285961844e-07\n",
            "step 2545: generator_loss=-1.1401109223374561e-10, discriminator_loss=2.423407067908556e-06\n",
            "step 2546: generator_loss=-3.0834281794511753e-09, discriminator_loss=1.2926747331221122e-05\n",
            "step 2547: generator_loss=-2.1041623998740988e-10, discriminator_loss=1.6144706478371518e-06\n",
            "step 2548: generator_loss=-3.690483682539103e-11, discriminator_loss=1.3837678807249176e-06\n",
            "step 2549: generator_loss=-2.875959748127599e-10, discriminator_loss=9.623779078538064e-06\n",
            "step 2550: generator_loss=-3.066136788909546e-10, discriminator_loss=6.0011784626112785e-06\n",
            "step 2551: generator_loss=-8.400283135756581e-09, discriminator_loss=2.555304490670096e-06\n",
            "step 2552: generator_loss=-7.853306338567734e-10, discriminator_loss=4.339244242146378e-06\n",
            "step 2553: generator_loss=-1.4938819070664522e-09, discriminator_loss=3.1905235573503887e-06\n",
            "step 2554: generator_loss=-1.5162643363098027e-10, discriminator_loss=3.913305135938572e-06\n",
            "step 2555: generator_loss=-1.8995435779878278e-10, discriminator_loss=3.037917849724181e-05\n",
            "step 2556: generator_loss=-3.6958742732906558e-09, discriminator_loss=1.4715364159201272e-05\n",
            "step 2557: generator_loss=-2.7629868171175076e-08, discriminator_loss=2.8260815270186868e-06\n",
            "step 2558: generator_loss=-7.982604577350116e-10, discriminator_loss=1.3213993042882066e-05\n",
            "step 2559: generator_loss=-3.804417336716881e-10, discriminator_loss=2.6212142074655276e-06\n",
            "step 2560: generator_loss=-1.1641701491704737e-10, discriminator_loss=1.0486486644367687e-05\n",
            "step 2561: generator_loss=-6.546146957830956e-10, discriminator_loss=1.8750039316728362e-06\n",
            "step 2562: generator_loss=-1.4100287604179584e-09, discriminator_loss=2.6645509478839813e-06\n",
            "step 2563: generator_loss=-1.9804062834083425e-09, discriminator_loss=5.611514552583685e-06\n",
            "step 2564: generator_loss=-6.387470413704577e-11, discriminator_loss=1.0037446372734848e-05\n",
            "step 2565: generator_loss=-7.014667069427105e-09, discriminator_loss=3.8935681914153975e-06\n",
            "step 2566: generator_loss=-4.113566709484928e-10, discriminator_loss=1.4693017647005036e-06\n",
            "step 2567: generator_loss=-1.0834907970824759e-10, discriminator_loss=4.4173316382511985e-06\n",
            "step 2568: generator_loss=-6.357439019666344e-10, discriminator_loss=5.500284260051558e-06\n",
            "step 2569: generator_loss=-5.275260783754732e-10, discriminator_loss=2.6024110411526635e-05\n",
            "step 2570: generator_loss=-5.96174387634818e-10, discriminator_loss=1.1619202268775553e-05\n",
            "step 2571: generator_loss=-3.152768934810979e-09, discriminator_loss=2.269295009682537e-06\n",
            "step 2572: generator_loss=-2.744006410981825e-10, discriminator_loss=3.130703817078029e-06\n",
            "step 2573: generator_loss=-3.907150436521789e-10, discriminator_loss=5.70244446862489e-06\n",
            "step 2574: generator_loss=-2.9607549745236383e-10, discriminator_loss=1.6493364682901301e-06\n",
            "step 2575: generator_loss=-5.309939155040411e-10, discriminator_loss=5.036992206441937e-06\n",
            "step 2576: generator_loss=-6.582561717927149e-10, discriminator_loss=8.500323019688949e-06\n",
            "step 2577: generator_loss=-7.942222990386938e-10, discriminator_loss=2.1676401956938207e-05\n",
            "step 2578: generator_loss=-1.5900941674473756e-10, discriminator_loss=3.163946757922531e-06\n",
            "step 2579: generator_loss=-5.584885331977318e-10, discriminator_loss=3.2234297577815596e-06\n",
            "step 2580: generator_loss=-1.9182860855337935e-10, discriminator_loss=7.427688160532853e-06\n",
            "step 2581: generator_loss=-1.766510548950606e-10, discriminator_loss=2.6590334528009407e-05\n",
            "step 2582: generator_loss=-1.1687529832826726e-09, discriminator_loss=2.4617681901872857e-06\n",
            "step 2583: generator_loss=-3.9273878593704126e-10, discriminator_loss=3.0528240131388884e-06\n",
            "step 2584: generator_loss=-1.1553572543121504e-09, discriminator_loss=2.833936150636873e-06\n",
            "step 2585: generator_loss=-9.921112820165945e-10, discriminator_loss=3.843249487545108e-06\n",
            "step 2586: generator_loss=-3.301898476859577e-10, discriminator_loss=2.746194695646409e-06\n",
            "step 2587: generator_loss=-5.692974980320287e-10, discriminator_loss=8.120574420900084e-06\n",
            "step 2588: generator_loss=-4.116369189954838e-10, discriminator_loss=2.3758918814564822e-06\n",
            "step 2589: generator_loss=-1.1051168868903005e-09, discriminator_loss=2.0065394892299082e-06\n",
            "step 2590: generator_loss=-1.325780596417303e-10, discriminator_loss=1.4802415080339415e-06\n",
            "step 2591: generator_loss=-2.1176574382941737e-10, discriminator_loss=5.78045501242741e-06\n",
            "step 2592: generator_loss=-2.4270649379154463e-10, discriminator_loss=3.196425041096518e-06\n",
            "step 2593: generator_loss=-4.0306871729178795e-10, discriminator_loss=2.6221330244879937e-06\n",
            "step 2594: generator_loss=-4.9923894879233544e-11, discriminator_loss=2.731940867306548e-06\n",
            "step 2595: generator_loss=-4.6199349901243636e-11, discriminator_loss=3.123840087937424e-06\n",
            "step 2596: generator_loss=-2.8046151512306494e-10, discriminator_loss=7.636194823135156e-06\n",
            "step 2597: generator_loss=-6.013797237969243e-10, discriminator_loss=2.439913032503682e-06\n",
            "step 2598: generator_loss=-8.186153421796405e-10, discriminator_loss=7.2204857133328915e-06\n",
            "step 2599: generator_loss=-1.3809189347568918e-09, discriminator_loss=1.4285866427599103e-06\n",
            "step 2600: generator_loss=-2.3345098076887894e-10, discriminator_loss=1.8087961279888987e-06\n",
            "step 2601: generator_loss=-3.7282371634361766e-10, discriminator_loss=1.0164269951928873e-05\n",
            "step 2602: generator_loss=-1.6501237876109798e-10, discriminator_loss=2.5210713374690386e-06\n",
            "step 2603: generator_loss=-3.421428140804039e-10, discriminator_loss=2.632447831274476e-06\n",
            "step 2604: generator_loss=-5.67126179351618e-10, discriminator_loss=2.8271658720768755e-06\n",
            "step 2605: generator_loss=-5.825467330744516e-10, discriminator_loss=1.9649239675345598e-06\n",
            "step 2606: generator_loss=-1.8328190076744022e-09, discriminator_loss=1.2705599147011526e-05\n",
            "step 2607: generator_loss=-3.958557787120398e-11, discriminator_loss=1.913184860313777e-06\n",
            "step 2608: generator_loss=-4.279284149255602e-10, discriminator_loss=1.5290905821530032e-06\n",
            "step 2609: generator_loss=-2.013742506079552e-09, discriminator_loss=5.673151463270187e-06\n",
            "step 2610: generator_loss=-1.968332025148456e-10, discriminator_loss=7.742472007521428e-06\n",
            "step 2611: generator_loss=-1.104677238572549e-09, discriminator_loss=2.15800332625804e-06\n",
            "step 2612: generator_loss=-4.847757750781057e-10, discriminator_loss=1.192968284158269e-06\n",
            "step 2613: generator_loss=-4.0866193762312264e-10, discriminator_loss=3.581141072572791e-06\n",
            "step 2614: generator_loss=-2.6826918464450955e-10, discriminator_loss=5.3490207392314915e-06\n",
            "step 2615: generator_loss=-6.7320509167245746e-09, discriminator_loss=1.3949349522590637e-05\n",
            "step 2616: generator_loss=-1.2631946599839239e-09, discriminator_loss=2.558477262937231e-06\n",
            "step 2617: generator_loss=-2.0731708016974437e-10, discriminator_loss=7.0468913691001944e-06\n",
            "step 2618: generator_loss=-1.6137892133727405e-09, discriminator_loss=2.980671297336812e-06\n",
            "step 2619: generator_loss=-3.816454652305623e-10, discriminator_loss=2.430456561341998e-06\n",
            "step 2620: generator_loss=-2.0008956991279803e-10, discriminator_loss=7.752226338197943e-06\n",
            "step 2621: generator_loss=-5.806243263961619e-10, discriminator_loss=1.2800864169548731e-05\n",
            "step 2622: generator_loss=-1.819618589138372e-08, discriminator_loss=3.6910059861838818e-06\n",
            "step 2623: generator_loss=-8.245021332342617e-10, discriminator_loss=2.7514065550349187e-06\n",
            "step 2624: generator_loss=-1.9239931869918792e-10, discriminator_loss=6.402783128578449e-06\n",
            "step 2625: generator_loss=-2.8559938858307987e-09, discriminator_loss=7.85422798799118e-06\n",
            "step 2626: generator_loss=-2.4654978059146515e-10, discriminator_loss=1.3033910363446921e-05\n",
            "step 2627: generator_loss=-8.958845221229694e-09, discriminator_loss=1.7918434878083644e-06\n",
            "step 2628: generator_loss=-2.2177292891001343e-08, discriminator_loss=3.4492372833483387e-06\n",
            "step 2629: generator_loss=-3.439779849845337e-10, discriminator_loss=3.4276383757969597e-06\n",
            "step 2630: generator_loss=-1.6431540850181392e-10, discriminator_loss=2.4842966013238765e-06\n",
            "step 2631: generator_loss=-3.1417754509099893e-10, discriminator_loss=6.915747690072749e-06\n",
            "step 2632: generator_loss=-2.4372320828192073e-10, discriminator_loss=4.253783117746934e-06\n",
            "step 2633: generator_loss=-6.70189070905991e-10, discriminator_loss=1.861934151747846e-06\n",
            "step 2634: generator_loss=-1.1049138270990966e-09, discriminator_loss=1.7340380509267561e-06\n",
            "step 2635: generator_loss=-2.5041449469576094e-10, discriminator_loss=2.7563974072108977e-06\n",
            "step 2636: generator_loss=-4.471900627578407e-10, discriminator_loss=3.7671350128221093e-06\n",
            "step 2637: generator_loss=-4.755677518453183e-10, discriminator_loss=1.5420764611917548e-05\n",
            "step 2638: generator_loss=-1.3636777818071266e-10, discriminator_loss=4.9852014853968285e-06\n",
            "step 2639: generator_loss=-1.3490278893968366e-09, discriminator_loss=2.827765229085344e-06\n",
            "step 2640: generator_loss=-8.272315055180002e-10, discriminator_loss=2.273735390190268e-06\n",
            "step 2641: generator_loss=-2.904394225122786e-10, discriminator_loss=1.2321401072767912e-06\n",
            "step 2642: generator_loss=-6.713836153693364e-10, discriminator_loss=6.50265292279073e-06\n",
            "step 2643: generator_loss=-1.0004787220907474e-08, discriminator_loss=5.231090653978754e-06\n",
            "step 2644: generator_loss=-1.1108594599740229e-10, discriminator_loss=5.600120857707225e-06\n",
            "step 2645: generator_loss=-2.8460367396121455e-09, discriminator_loss=1.1385296602384187e-05\n",
            "step 2646: generator_loss=-3.2690428142245764e-10, discriminator_loss=4.174029982095817e-06\n",
            "step 2647: generator_loss=-4.4733825532716764e-09, discriminator_loss=2.4103521809593076e-06\n",
            "step 2648: generator_loss=-6.261450247180278e-10, discriminator_loss=1.5100312111826497e-06\n",
            "step 2649: generator_loss=-9.72136482424446e-10, discriminator_loss=2.7833052627102006e-06\n",
            "step 2650: generator_loss=-4.1314562881922257e-10, discriminator_loss=5.640454219246749e-07\n",
            "step 2651: generator_loss=-3.5293937217240057e-10, discriminator_loss=3.623105158112594e-06\n",
            "step 2652: generator_loss=-1.555787720874946e-09, discriminator_loss=6.0323641264403705e-06\n",
            "step 2653: generator_loss=-6.563453947006082e-11, discriminator_loss=4.093038114660885e-06\n",
            "step 2654: generator_loss=-6.305567179509808e-11, discriminator_loss=6.805451903346693e-06\n",
            "step 2655: generator_loss=-1.4085365096505598e-09, discriminator_loss=1.4748393368790857e-06\n",
            "step 2656: generator_loss=-2.24193608122647e-10, discriminator_loss=4.473969966056757e-06\n",
            "step 2657: generator_loss=-4.5192302677854457e-10, discriminator_loss=1.928921847138554e-06\n",
            "step 2658: generator_loss=-1.9454420296938224e-09, discriminator_loss=1.4176900549500715e-05\n",
            "step 2659: generator_loss=-2.250431663242125e-08, discriminator_loss=8.295011184600298e-07\n",
            "step 2660: generator_loss=-3.026653372373289e-10, discriminator_loss=2.8124245545768645e-06\n",
            "step 2661: generator_loss=-7.210617103403649e-10, discriminator_loss=2.4105795091600157e-05\n",
            "step 2662: generator_loss=-1.8716435346011195e-10, discriminator_loss=2.9406101020867936e-06\n",
            "step 2663: generator_loss=-1.8854591221639794e-09, discriminator_loss=1.894734964480449e-06\n",
            "step 2664: generator_loss=-1.093475621161133e-08, discriminator_loss=2.327859419892775e-06\n",
            "step 2665: generator_loss=-3.663379599672112e-10, discriminator_loss=6.4653950175852515e-06\n",
            "step 2666: generator_loss=-1.7266637009072383e-09, discriminator_loss=1.4010934137331787e-06\n",
            "step 2667: generator_loss=-9.14459619139052e-11, discriminator_loss=3.530344883984071e-06\n",
            "step 2668: generator_loss=-2.300963863888228e-09, discriminator_loss=1.5751600130897714e-06\n",
            "step 2669: generator_loss=-1.1839873526042766e-09, discriminator_loss=1.2520215477707097e-06\n",
            "step 2670: generator_loss=-1.6907474309491022e-09, discriminator_loss=3.100150252066669e-06\n",
            "step 2671: generator_loss=-4.785049023681154e-10, discriminator_loss=4.471649390325183e-06\n",
            "step 2672: generator_loss=-2.951138222684335e-10, discriminator_loss=2.1813204966747435e-06\n",
            "step 2673: generator_loss=-8.537308082701145e-10, discriminator_loss=3.7548729778791312e-06\n",
            "step 2674: generator_loss=-4.896943406329513e-10, discriminator_loss=6.652905540249776e-06\n",
            "step 2675: generator_loss=-2.0964392444255964e-09, discriminator_loss=4.55054578196723e-06\n",
            "step 2676: generator_loss=-3.426449679544419e-10, discriminator_loss=8.247895493695978e-06\n",
            "step 2677: generator_loss=-8.344772095547626e-10, discriminator_loss=5.51914308744017e-06\n",
            "step 2678: generator_loss=-5.573257966240419e-10, discriminator_loss=5.715237875847379e-06\n",
            "step 2679: generator_loss=-1.6681417358554995e-10, discriminator_loss=3.960594767704606e-06\n",
            "step 2680: generator_loss=-4.614039372796697e-09, discriminator_loss=6.714503342664102e-06\n",
            "step 2681: generator_loss=-1.3165730727848768e-09, discriminator_loss=5.369248810893623e-06\n",
            "step 2682: generator_loss=-1.8623033670728262e-10, discriminator_loss=3.6109609027334955e-06\n",
            "step 2683: generator_loss=-1.1699015090016474e-09, discriminator_loss=8.280377187475096e-06\n",
            "step 2684: generator_loss=-1.0061782657055929e-10, discriminator_loss=3.522402721500839e-06\n",
            "step 2685: generator_loss=-3.9277109342705785e-10, discriminator_loss=3.439407464611577e-06\n",
            "step 2686: generator_loss=-2.5853252871854693e-10, discriminator_loss=1.1026331776520237e-05\n",
            "step 2687: generator_loss=-2.7663580315362424e-09, discriminator_loss=5.328599286258395e-07\n",
            "step 2688: generator_loss=-9.531857247946363e-11, discriminator_loss=7.274936706380686e-06\n",
            "step 2689: generator_loss=-6.104768357495516e-10, discriminator_loss=7.133728558983421e-07\n",
            "step 2690: generator_loss=-2.338738980256494e-09, discriminator_loss=3.111870000793715e-06\n",
            "step 2691: generator_loss=-6.00967497987881e-10, discriminator_loss=6.57437385598314e-06\n",
            "step 2692: generator_loss=-2.5166990713643145e-10, discriminator_loss=2.6951852305501234e-06\n",
            "step 2693: generator_loss=-4.847457435452895e-10, discriminator_loss=8.094898475974333e-06\n",
            "step 2694: generator_loss=-7.654167299975256e-10, discriminator_loss=7.076258953020442e-06\n",
            "step 2695: generator_loss=-4.2734421557000246e-10, discriminator_loss=2.4158584892575163e-06\n",
            "step 2696: generator_loss=-6.17583317819026e-09, discriminator_loss=7.229844868561486e-06\n",
            "step 2697: generator_loss=-5.72609112903244e-11, discriminator_loss=2.2953067855269182e-06\n",
            "step 2698: generator_loss=-6.798808044328197e-11, discriminator_loss=2.3248690013133455e-06\n",
            "step 2699: generator_loss=-1.4979895102129603e-09, discriminator_loss=3.1657270938012516e-06\n",
            "step 2700: generator_loss=-2.523578013224892e-09, discriminator_loss=7.447793905157596e-06\n",
            "step 2701: generator_loss=-1.2416497829903506e-09, discriminator_loss=2.6267594876117073e-05\n",
            "step 2702: generator_loss=-4.245707785344166e-09, discriminator_loss=5.585404323937837e-06\n",
            "step 2703: generator_loss=-2.8184529710095774e-10, discriminator_loss=1.6482933915540343e-06\n",
            "step 2704: generator_loss=-1.941357907764285e-10, discriminator_loss=4.383211035019485e-06\n",
            "step 2705: generator_loss=-3.387605196358834e-10, discriminator_loss=1.277952833333984e-06\n",
            "step 2706: generator_loss=-6.703270716279519e-10, discriminator_loss=4.552025075099664e-06\n",
            "step 2707: generator_loss=-1.6743209485525767e-08, discriminator_loss=2.788165602396475e-06\n",
            "step 2708: generator_loss=-2.6937310715346996e-10, discriminator_loss=5.299041276884964e-06\n",
            "step 2709: generator_loss=-3.8125874679550975e-10, discriminator_loss=4.949893991579302e-06\n",
            "step 2710: generator_loss=-5.605520492224514e-10, discriminator_loss=1.5441186178577482e-06\n",
            "step 2711: generator_loss=-2.5606350373408304e-10, discriminator_loss=1.8485088730813004e-06\n",
            "step 2712: generator_loss=-4.495828154205128e-10, discriminator_loss=3.3439607705076924e-06\n",
            "step 2713: generator_loss=-4.5646486590555924e-10, discriminator_loss=1.99009650714288e-06\n",
            "step 2714: generator_loss=-3.268130766009847e-10, discriminator_loss=1.1254822993578273e-06\n",
            "step 2715: generator_loss=-5.262633662184157e-10, discriminator_loss=3.1656347800890217e-06\n",
            "step 2716: generator_loss=-2.4674318144235485e-10, discriminator_loss=3.382081331437803e-06\n",
            "step 2717: generator_loss=-6.703081978365333e-10, discriminator_loss=3.2745358566899085e-06\n",
            "step 2718: generator_loss=-1.170809005301976e-09, discriminator_loss=1.7453234022468678e-06\n",
            "step 2719: generator_loss=-7.567485527104623e-10, discriminator_loss=8.453627742710523e-06\n",
            "step 2720: generator_loss=-1.5276682696629962e-10, discriminator_loss=3.4457452784408815e-06\n",
            "step 2721: generator_loss=-1.6230135291284142e-10, discriminator_loss=3.6576718684955267e-06\n",
            "step 2722: generator_loss=-8.250790051178569e-10, discriminator_loss=2.666003183549037e-06\n",
            "step 2723: generator_loss=-1.7092856019473857e-09, discriminator_loss=7.805597306287382e-06\n",
            "step 2724: generator_loss=-1.6804491131949817e-09, discriminator_loss=3.203147343810997e-06\n",
            "step 2725: generator_loss=-5.597095009690634e-10, discriminator_loss=2.8648198622249765e-06\n",
            "step 2726: generator_loss=-8.35180147262804e-10, discriminator_loss=2.2676471417071298e-05\n",
            "step 2727: generator_loss=-8.441876087061928e-10, discriminator_loss=3.12790348289127e-06\n",
            "step 2728: generator_loss=-4.966588251775761e-10, discriminator_loss=2.6152751161134802e-05\n",
            "step 2729: generator_loss=-3.66358193781835e-10, discriminator_loss=2.490148517608759e-06\n",
            "step 2730: generator_loss=-1.0931228144883676e-09, discriminator_loss=2.1796181499667e-06\n",
            "step 2731: generator_loss=-1.0521397642015984e-10, discriminator_loss=6.929750270501245e-06\n",
            "step 2732: generator_loss=-2.745109140001034e-10, discriminator_loss=2.6952309326588875e-06\n",
            "step 2733: generator_loss=-1.9643359161491958e-10, discriminator_loss=5.088196303404402e-06\n",
            "step 2734: generator_loss=-1.0361103086609091e-09, discriminator_loss=5.732179488404654e-06\n",
            "step 2735: generator_loss=-2.0456486504727422e-10, discriminator_loss=1.3918513559474377e-06\n",
            "step 2736: generator_loss=-9.235930908957357e-10, discriminator_loss=1.345660894003231e-05\n",
            "step 2737: generator_loss=-3.0652709259726407e-09, discriminator_loss=9.358103852719069e-06\n",
            "step 2738: generator_loss=-4.325411140371216e-10, discriminator_loss=7.0360283643822186e-06\n",
            "step 2739: generator_loss=-2.961622613817383e-10, discriminator_loss=1.9961325961048715e-06\n",
            "step 2740: generator_loss=-4.722972013482263e-10, discriminator_loss=6.21520393906394e-06\n",
            "step 2741: generator_loss=-5.3862126564441226e-11, discriminator_loss=4.055765657540178e-06\n",
            "step 2742: generator_loss=-6.667326690745767e-10, discriminator_loss=3.1535410016658716e-06\n",
            "step 2743: generator_loss=-2.599655601898121e-09, discriminator_loss=5.741813765780535e-06\n",
            "step 2744: generator_loss=-9.057765093523074e-10, discriminator_loss=2.3210657218442066e-06\n",
            "step 2745: generator_loss=-7.172379357101022e-10, discriminator_loss=3.0592677831009496e-06\n",
            "step 2746: generator_loss=-8.758371250472408e-10, discriminator_loss=7.612384706590092e-06\n",
            "step 2747: generator_loss=-3.72412962690305e-08, discriminator_loss=4.465156507649226e-06\n",
            "step 2748: generator_loss=-1.4651335700222035e-10, discriminator_loss=3.342369382153265e-06\n",
            "step 2749: generator_loss=-1.1684648804077824e-09, discriminator_loss=3.4587080790515756e-06\n",
            "step 2750: generator_loss=-3.859937924843848e-10, discriminator_loss=2.6343682293372694e-06\n",
            "step 2751: generator_loss=-7.154712378110162e-10, discriminator_loss=3.151282044200343e-06\n",
            "step 2752: generator_loss=-2.434709656107259e-10, discriminator_loss=3.579611302484409e-06\n",
            "step 2753: generator_loss=-4.1800701788829997e-10, discriminator_loss=1.4387564988282975e-06\n",
            "step 2754: generator_loss=-1.99897709496355e-10, discriminator_loss=1.0156439884667634e-06\n",
            "step 2755: generator_loss=-1.8178721028494493e-10, discriminator_loss=3.982326234108768e-06\n",
            "step 2756: generator_loss=-2.0440138470689817e-09, discriminator_loss=1.9048879948968533e-06\n",
            "step 2757: generator_loss=-5.828212357172902e-10, discriminator_loss=5.3870471674599685e-06\n",
            "step 2758: generator_loss=-1.690020207112397e-10, discriminator_loss=2.6852194423554465e-06\n",
            "step 2759: generator_loss=-5.202580033447646e-10, discriminator_loss=1.4022087952980655e-06\n",
            "step 2760: generator_loss=-7.191875983636464e-10, discriminator_loss=6.150822173367487e-06\n",
            "step 2761: generator_loss=-1.5259697949687734e-09, discriminator_loss=3.364275926287519e-06\n",
            "step 2762: generator_loss=-3.12569775617888e-10, discriminator_loss=6.5037538661272265e-06\n",
            "step 2763: generator_loss=-5.607748154723424e-10, discriminator_loss=2.1387197648436995e-06\n",
            "step 2764: generator_loss=-6.437851640672676e-11, discriminator_loss=1.6921942460612627e-06\n",
            "step 2765: generator_loss=-1.4978531748255364e-09, discriminator_loss=1.6632795450277627e-05\n",
            "step 2766: generator_loss=-2.3523546999193456e-10, discriminator_loss=6.218629550858168e-06\n",
            "step 2767: generator_loss=-2.8862487400083126e-10, discriminator_loss=7.697688602092967e-07\n",
            "step 2768: generator_loss=-1.2586037767547964e-10, discriminator_loss=1.4783953474761802e-06\n",
            "step 2769: generator_loss=-7.37504723957727e-10, discriminator_loss=1.4241235476220027e-05\n",
            "step 2770: generator_loss=-3.2619515422105394e-10, discriminator_loss=4.389960395201342e-06\n",
            "step 2771: generator_loss=-1.792571646674901e-10, discriminator_loss=7.1517665674036834e-06\n",
            "step 2772: generator_loss=-1.5396230956810086e-09, discriminator_loss=5.873963345948141e-06\n",
            "step 2773: generator_loss=-1.0033753738980522e-07, discriminator_loss=1.740479888212576e-06\n",
            "step 2774: generator_loss=-8.518894478726224e-10, discriminator_loss=1.3278194046506542e-06\n",
            "step 2775: generator_loss=-1.2580767538850068e-09, discriminator_loss=4.307471499487292e-06\n",
            "step 2776: generator_loss=-1.2726720788336365e-09, discriminator_loss=3.712447551151854e-06\n",
            "step 2777: generator_loss=-1.2854886044522118e-09, discriminator_loss=1.541483015898848e-06\n",
            "step 2778: generator_loss=-2.013446520621187e-09, discriminator_loss=7.2449142862751614e-06\n",
            "step 2779: generator_loss=-7.997935091985653e-10, discriminator_loss=1.3433206731860992e-05\n",
            "step 2780: generator_loss=-9.82963932472103e-10, discriminator_loss=1.517308078291535e-06\n",
            "step 2781: generator_loss=-2.0279038170922803e-10, discriminator_loss=2.8929721338499803e-06\n",
            "step 2782: generator_loss=-8.388576944184933e-09, discriminator_loss=3.3201806672877865e-06\n",
            "step 2783: generator_loss=-5.598870256307009e-10, discriminator_loss=7.383372576441616e-06\n",
            "step 2784: generator_loss=-2.7922014700365594e-10, discriminator_loss=1.9952431102865376e-06\n",
            "step 2785: generator_loss=-1.6848918094058973e-10, discriminator_loss=1.3005316759517882e-05\n",
            "step 2786: generator_loss=-3.0119318150667596e-10, discriminator_loss=5.240085101831937e-06\n",
            "step 2787: generator_loss=-1.3222171135751637e-09, discriminator_loss=4.467604412639048e-06\n",
            "step 2788: generator_loss=-4.3749492917299904e-10, discriminator_loss=1.177315425593406e-06\n",
            "step 2789: generator_loss=-1.7547682751306581e-10, discriminator_loss=4.5873534872953314e-06\n",
            "step 2790: generator_loss=-8.571065523987897e-10, discriminator_loss=2.7932253487961134e-06\n",
            "step 2791: generator_loss=-1.9288014241336526e-10, discriminator_loss=1.2826359352402505e-06\n",
            "step 2792: generator_loss=-8.42295178049568e-10, discriminator_loss=5.23895278092823e-06\n",
            "step 2793: generator_loss=-2.515449515350099e-10, discriminator_loss=3.2323234790965216e-06\n",
            "step 2794: generator_loss=-1.0149930895764214e-10, discriminator_loss=1.5111348830032512e-06\n",
            "step 2795: generator_loss=-4.453660995551445e-09, discriminator_loss=1.975044369828538e-06\n",
            "step 2796: generator_loss=-2.2526311371784402e-10, discriminator_loss=3.84419945476111e-06\n",
            "step 2797: generator_loss=-5.072401387806735e-10, discriminator_loss=1.883315007944475e-06\n",
            "step 2798: generator_loss=-1.3978513901946599e-09, discriminator_loss=3.2608240871923044e-06\n",
            "step 2799: generator_loss=-4.796180119726046e-10, discriminator_loss=7.243582786031766e-06\n",
            "step 2800: generator_loss=-4.430890099271778e-10, discriminator_loss=4.59398552266066e-06\n",
            "step 2801: generator_loss=-1.8872517437706904e-10, discriminator_loss=5.975889507681131e-06\n",
            "step 2802: generator_loss=-6.791680551287982e-10, discriminator_loss=1.0576781050986028e-06\n",
            "step 2803: generator_loss=-7.675627911041261e-10, discriminator_loss=1.4027152701601153e-06\n",
            "step 2804: generator_loss=-3.2649632997205913e-10, discriminator_loss=2.525690433685668e-06\n",
            "step 2805: generator_loss=-1.8956622382937383e-10, discriminator_loss=1.2627057230929495e-06\n",
            "step 2806: generator_loss=-1.5765262706413097e-10, discriminator_loss=6.209433195181191e-06\n",
            "step 2807: generator_loss=-1.344632849509253e-09, discriminator_loss=3.0682249416713603e-06\n",
            "step 2808: generator_loss=-1.2768298918164334e-10, discriminator_loss=4.4489652282209136e-06\n",
            "step 2809: generator_loss=-2.34819941269393e-10, discriminator_loss=4.366503617347917e-06\n",
            "step 2810: generator_loss=-3.4678202531779334e-09, discriminator_loss=1.3940280041424558e-06\n",
            "step 2811: generator_loss=-2.524223052802199e-09, discriminator_loss=8.61371518112719e-06\n",
            "step 2812: generator_loss=-4.570037681617123e-09, discriminator_loss=1.1830136372736888e-06\n",
            "step 2813: generator_loss=-7.120621869916022e-10, discriminator_loss=5.10928930452792e-06\n",
            "step 2814: generator_loss=-4.072183479308933e-09, discriminator_loss=2.2581099983653985e-05\n",
            "step 2815: generator_loss=-6.28784663225801e-11, discriminator_loss=2.1288651623763144e-06\n",
            "step 2816: generator_loss=-9.289859992378524e-10, discriminator_loss=1.957201448021806e-06\n",
            "step 2817: generator_loss=-1.0339923361968317e-09, discriminator_loss=1.521235049040115e-06\n",
            "step 2818: generator_loss=-1.1370928643117395e-09, discriminator_loss=3.0965111363912e-06\n",
            "step 2819: generator_loss=-5.741591646568622e-09, discriminator_loss=3.552249381755246e-06\n",
            "step 2820: generator_loss=-1.3320424763207939e-09, discriminator_loss=1.367305458188639e-06\n",
            "step 2821: generator_loss=-5.612829090395621e-10, discriminator_loss=3.2080995424621506e-06\n",
            "step 2822: generator_loss=-1.4855091601262416e-09, discriminator_loss=2.748688302744995e-06\n",
            "step 2823: generator_loss=-2.2220167372744015e-10, discriminator_loss=2.908419219238567e-06\n",
            "step 2824: generator_loss=-1.001863259020297e-09, discriminator_loss=7.537631745435647e-07\n",
            "step 2825: generator_loss=-1.956722839313585e-10, discriminator_loss=4.647147306968691e-06\n",
            "step 2826: generator_loss=-3.197734299575927e-10, discriminator_loss=1.4241466487874277e-05\n",
            "step 2827: generator_loss=-4.4714276725699165e-10, discriminator_loss=4.149236701778136e-06\n",
            "step 2828: generator_loss=-2.691902534213142e-10, discriminator_loss=1.2749886082019657e-05\n",
            "step 2829: generator_loss=-1.517157843800021e-09, discriminator_loss=3.4885588320321403e-06\n",
            "step 2830: generator_loss=-3.794407010815348e-10, discriminator_loss=2.3546158445242327e-06\n",
            "step 2831: generator_loss=-8.802154005671525e-10, discriminator_loss=3.5197226679883897e-06\n",
            "step 2832: generator_loss=-1.8769212573044314e-10, discriminator_loss=3.3756546145014e-06\n",
            "step 2833: generator_loss=-2.3966475470871274e-09, discriminator_loss=3.1291019695345312e-06\n",
            "step 2834: generator_loss=-3.143072024869298e-09, discriminator_loss=1.3188531511332258e-06\n",
            "step 2835: generator_loss=-2.160967405018255e-09, discriminator_loss=1.6154659761014045e-06\n",
            "step 2836: generator_loss=-5.587736939816068e-10, discriminator_loss=2.3788904854882276e-06\n",
            "step 2837: generator_loss=-1.5752925630607706e-09, discriminator_loss=2.7943954137299443e-06\n",
            "step 2838: generator_loss=-5.942628611421696e-10, discriminator_loss=3.011659373441944e-06\n",
            "step 2839: generator_loss=-2.357869899327625e-09, discriminator_loss=9.752575351740234e-06\n",
            "step 2840: generator_loss=-3.6913036516317277e-10, discriminator_loss=6.521415798488306e-06\n",
            "step 2841: generator_loss=-5.208000697365378e-09, discriminator_loss=2.2933693344384665e-06\n",
            "step 2842: generator_loss=-9.814581369838038e-10, discriminator_loss=7.943179298308678e-06\n",
            "step 2843: generator_loss=-2.7220392606608357e-10, discriminator_loss=2.4595699414931005e-06\n",
            "step 2844: generator_loss=-1.534929822133435e-10, discriminator_loss=5.872004749107873e-07\n",
            "step 2845: generator_loss=-1.369665075801052e-10, discriminator_loss=3.6966014249628643e-06\n",
            "step 2846: generator_loss=-4.4390141562544727e-10, discriminator_loss=2.5198114599334076e-06\n",
            "step 2847: generator_loss=-2.4062292158788523e-09, discriminator_loss=1.727285052766092e-05\n",
            "step 2848: generator_loss=-3.450147390005043e-10, discriminator_loss=1.5780065041326452e-06\n",
            "step 2849: generator_loss=-1.3429940493026038e-09, discriminator_loss=4.831095338886371e-06\n",
            "step 2850: generator_loss=-2.6443518663654686e-07, discriminator_loss=1.1586183973122388e-05\n",
            "step 2851: generator_loss=-2.3987174468942385e-09, discriminator_loss=3.3216304018424125e-06\n",
            "step 2852: generator_loss=-9.122405941752731e-09, discriminator_loss=1.2154038131484413e-06\n",
            "step 2853: generator_loss=-1.9635022496800048e-09, discriminator_loss=7.698892545704439e-07\n",
            "step 2854: generator_loss=-6.995171109025478e-10, discriminator_loss=1.4025994460098445e-05\n",
            "step 2855: generator_loss=-9.246527432615892e-10, discriminator_loss=5.1842416723957285e-06\n",
            "step 2856: generator_loss=-1.2486438549785817e-08, discriminator_loss=1.1545700999704422e-06\n",
            "step 2857: generator_loss=-5.326026286667229e-10, discriminator_loss=8.403451829508413e-06\n",
            "step 2858: generator_loss=-2.2261062437856083e-10, discriminator_loss=7.89144542068243e-06\n",
            "step 2859: generator_loss=-6.409584418776149e-09, discriminator_loss=3.284654894741834e-06\n",
            "step 2860: generator_loss=-8.345310220647661e-09, discriminator_loss=4.2102842598978896e-06\n",
            "step 2861: generator_loss=-3.163223682989269e-09, discriminator_loss=9.109296115639154e-06\n",
            "step 2862: generator_loss=-5.017057880252196e-09, discriminator_loss=7.308216254386934e-07\n",
            "step 2863: generator_loss=-8.814406426971289e-10, discriminator_loss=1.4240688869904261e-05\n",
            "step 2864: generator_loss=-1.1274996214449828e-10, discriminator_loss=7.393568921543192e-06\n",
            "step 2865: generator_loss=-2.2145598688183554e-09, discriminator_loss=1.534886791887402e-06\n",
            "step 2866: generator_loss=-3.5573760603924143e-10, discriminator_loss=3.8968123590166215e-06\n",
            "step 2867: generator_loss=-3.733737763411682e-10, discriminator_loss=7.437308795488207e-07\n",
            "step 2868: generator_loss=-7.269015250832567e-11, discriminator_loss=6.655643119302113e-06\n",
            "step 2869: generator_loss=-8.018440772472601e-11, discriminator_loss=1.3962533103040187e-06\n",
            "step 2870: generator_loss=-2.64361155188908e-09, discriminator_loss=1.8041578186966944e-06\n",
            "step 2871: generator_loss=-1.527969972769938e-10, discriminator_loss=7.3721748776733875e-06\n",
            "step 2872: generator_loss=-2.366230544836867e-10, discriminator_loss=6.079721515561687e-06\n",
            "step 2873: generator_loss=-2.4228880013410503e-10, discriminator_loss=6.227425274119014e-06\n",
            "step 2874: generator_loss=-1.9129353656666126e-09, discriminator_loss=1.981340346901561e-06\n",
            "step 2875: generator_loss=-1.078907518881067e-09, discriminator_loss=5.720612989534857e-06\n",
            "step 2876: generator_loss=-2.433367118914731e-10, discriminator_loss=2.500894197510206e-06\n",
            "step 2877: generator_loss=-3.6619401955206854e-10, discriminator_loss=1.282347398046113e-06\n",
            "step 2878: generator_loss=-5.432879923716882e-09, discriminator_loss=2.776272822302417e-06\n",
            "step 2879: generator_loss=-1.2477965327661877e-09, discriminator_loss=3.846956587949535e-06\n",
            "step 2880: generator_loss=-7.66883001546148e-09, discriminator_loss=1.8985344922839431e-06\n",
            "step 2881: generator_loss=-2.5232416156484305e-10, discriminator_loss=1.4271069630922284e-05\n",
            "step 2882: generator_loss=-6.862631019011189e-10, discriminator_loss=2.455678213664214e-06\n",
            "step 2883: generator_loss=-4.358567284867831e-09, discriminator_loss=5.728772521251813e-06\n",
            "step 2884: generator_loss=-2.595128001381397e-10, discriminator_loss=3.3142239317385247e-06\n",
            "step 2885: generator_loss=-1.2484404621204703e-09, discriminator_loss=8.732160381441645e-07\n",
            "step 2886: generator_loss=-5.716974671443609e-10, discriminator_loss=9.030036380863748e-06\n",
            "step 2887: generator_loss=-3.1554309165571226e-10, discriminator_loss=3.1771455724083353e-06\n",
            "step 2888: generator_loss=-2.5035326589595286e-10, discriminator_loss=1.427844722456939e-06\n",
            "step 2889: generator_loss=-1.1230709695553287e-09, discriminator_loss=2.588288680271944e-06\n",
            "step 2890: generator_loss=-6.759826726154827e-11, discriminator_loss=4.222169991408009e-06\n",
            "step 2891: generator_loss=-3.8825179182744307e-10, discriminator_loss=1.8217799606645713e-06\n",
            "step 2892: generator_loss=-1.558417617175678e-09, discriminator_loss=4.2449823922652286e-06\n",
            "step 2893: generator_loss=-1.688566619861831e-09, discriminator_loss=3.535868700055289e-06\n",
            "step 2894: generator_loss=-2.556773681661184e-10, discriminator_loss=7.0153455453692e-06\n",
            "step 2895: generator_loss=-4.1684503071515167e-10, discriminator_loss=4.310110853111837e-06\n",
            "step 2896: generator_loss=-1.3638229434675964e-10, discriminator_loss=1.1958734376094071e-06\n",
            "step 2897: generator_loss=-9.63682289523149e-09, discriminator_loss=2.3654285996599356e-06\n",
            "step 2898: generator_loss=-2.2992717063630153e-08, discriminator_loss=8.195939926736173e-07\n",
            "step 2899: generator_loss=-3.6663908020706515e-10, discriminator_loss=5.999410404911032e-06\n",
            "step 2900: generator_loss=-4.668387898476567e-10, discriminator_loss=4.2796086745511275e-06\n",
            "step 2901: generator_loss=-1.3573322465987303e-09, discriminator_loss=4.8286538003594615e-06\n",
            "step 2902: generator_loss=-1.328343268713894e-10, discriminator_loss=2.8518134058685973e-06\n",
            "step 2903: generator_loss=-4.619430948871184e-10, discriminator_loss=1.594443915564625e-06\n",
            "step 2904: generator_loss=-6.80783485140779e-11, discriminator_loss=2.3703189526713686e-06\n",
            "step 2905: generator_loss=-1.2001999394328777e-09, discriminator_loss=2.1247814174785162e-07\n",
            "step 2906: generator_loss=-6.680667824499054e-11, discriminator_loss=6.945087534404593e-06\n",
            "step 2907: generator_loss=-6.654644058023962e-10, discriminator_loss=1.6451839428555104e-06\n",
            "step 2908: generator_loss=-2.9253435229747993e-09, discriminator_loss=1.4197030395735055e-06\n",
            "step 2909: generator_loss=-3.679044846549573e-10, discriminator_loss=5.689346380677307e-06\n",
            "step 2910: generator_loss=-1.3237663742948769e-10, discriminator_loss=3.0118160339043243e-06\n",
            "step 2911: generator_loss=-7.505443488931007e-10, discriminator_loss=2.0199620394123485e-06\n",
            "step 2912: generator_loss=-2.285176214922302e-10, discriminator_loss=1.3905049627283006e-06\n",
            "step 2913: generator_loss=-2.13568762674754e-09, discriminator_loss=5.794666321889963e-06\n",
            "step 2914: generator_loss=-5.686070725374748e-09, discriminator_loss=2.1111432943143882e-05\n",
            "step 2915: generator_loss=-2.5614607324087046e-08, discriminator_loss=3.1540030249743722e-06\n",
            "step 2916: generator_loss=-1.3240947227544098e-10, discriminator_loss=7.050349267956335e-06\n",
            "step 2917: generator_loss=-6.816801290110419e-11, discriminator_loss=1.7869201656139921e-06\n",
            "step 2918: generator_loss=-3.5283602706215333e-09, discriminator_loss=1.5198141909422702e-06\n",
            "step 2919: generator_loss=-3.450056684783931e-09, discriminator_loss=2.4803173801046796e-05\n",
            "step 2920: generator_loss=-6.772201688320933e-10, discriminator_loss=1.552811409055721e-05\n",
            "step 2921: generator_loss=-6.213413117350797e-10, discriminator_loss=4.5031652007310186e-06\n",
            "step 2922: generator_loss=-3.252324409785956e-09, discriminator_loss=3.1438248697668314e-06\n",
            "step 2923: generator_loss=-1.3863066250507927e-08, discriminator_loss=4.630516741599422e-06\n",
            "step 2924: generator_loss=-2.99872016107372e-10, discriminator_loss=6.488947292382363e-06\n",
            "step 2925: generator_loss=-1.8413398583660978e-10, discriminator_loss=2.21141067413555e-06\n",
            "step 2926: generator_loss=-3.928993130841718e-09, discriminator_loss=5.168831194168888e-06\n",
            "step 2927: generator_loss=-5.497221344796799e-09, discriminator_loss=6.578278316737851e-06\n",
            "step 2928: generator_loss=-1.914177427675412e-10, discriminator_loss=2.900635081459768e-06\n",
            "step 2929: generator_loss=-2.3678436988916474e-09, discriminator_loss=6.646963583989418e-07\n",
            "step 2930: generator_loss=-4.840455591903492e-09, discriminator_loss=1.5046420003272942e-06\n",
            "step 2931: generator_loss=-3.9377096028303527e-10, discriminator_loss=2.381989133937168e-06\n",
            "step 2932: generator_loss=-5.913936007573284e-10, discriminator_loss=1.8369629515291308e-06\n",
            "step 2933: generator_loss=-8.121553207729448e-09, discriminator_loss=4.005553819297347e-06\n",
            "step 2934: generator_loss=-1.6275992775760528e-09, discriminator_loss=7.0810406214150134e-06\n",
            "step 2935: generator_loss=-5.28166954616438e-10, discriminator_loss=3.66787685379677e-06\n",
            "step 2936: generator_loss=-5.130724733959369e-10, discriminator_loss=2.242043819933315e-06\n",
            "step 2937: generator_loss=-1.7858636791601157e-10, discriminator_loss=2.4579796900070505e-06\n",
            "step 2938: generator_loss=-6.7918177748538255e-09, discriminator_loss=2.0496472643571906e-05\n",
            "step 2939: generator_loss=-1.585479247889765e-10, discriminator_loss=1.9476190118439263e-06\n",
            "step 2940: generator_loss=-2.6559077159760136e-10, discriminator_loss=2.8337412913970184e-06\n",
            "step 2941: generator_loss=-1.6908616728983361e-09, discriminator_loss=3.2389993975812104e-06\n",
            "step 2942: generator_loss=-1.9113451099617151e-10, discriminator_loss=3.1010856673674425e-06\n",
            "step 2943: generator_loss=-4.6239487239141397e-10, discriminator_loss=1.9697363313753158e-05\n",
            "step 2944: generator_loss=-4.66601068893624e-09, discriminator_loss=4.293865458748769e-06\n",
            "step 2945: generator_loss=-7.547912989069872e-11, discriminator_loss=6.232874511624686e-06\n",
            "step 2946: generator_loss=-5.043258033410325e-10, discriminator_loss=1.8062639810523251e-06\n",
            "step 2947: generator_loss=-2.136190557777695e-09, discriminator_loss=1.2565941460707108e-06\n",
            "step 2948: generator_loss=-1.6814560854783167e-10, discriminator_loss=5.7110414672933985e-06\n",
            "step 2949: generator_loss=-1.0308423004090628e-09, discriminator_loss=1.7390360653735115e-06\n",
            "step 2950: generator_loss=-2.0508921227957444e-09, discriminator_loss=5.017123385187006e-06\n",
            "step 2951: generator_loss=-2.090974615676089e-10, discriminator_loss=1.3723918073083041e-06\n",
            "step 2952: generator_loss=-1.666650983889184e-10, discriminator_loss=1.0139477808479569e-06\n",
            "step 2953: generator_loss=-1.0450139642514955e-09, discriminator_loss=2.310628588020336e-06\n",
            "step 2954: generator_loss=-8.367968540312631e-10, discriminator_loss=4.7419442239515774e-07\n",
            "step 2955: generator_loss=-1.0052756405087848e-09, discriminator_loss=1.7395594795743818e-06\n",
            "step 2956: generator_loss=-1.6982747652605212e-08, discriminator_loss=4.959502803103533e-06\n",
            "step 2957: generator_loss=-7.790204037405601e-09, discriminator_loss=2.1693479084206047e-06\n",
            "step 2958: generator_loss=-2.1450929921229545e-09, discriminator_loss=3.966151325585088e-06\n",
            "step 2959: generator_loss=-3.3283037437215057e-10, discriminator_loss=5.608902938547544e-06\n",
            "step 2960: generator_loss=-3.958594341213484e-09, discriminator_loss=1.8124163716493058e-06\n",
            "step 2961: generator_loss=-1.177964570331369e-08, discriminator_loss=1.0972034033329692e-05\n",
            "step 2962: generator_loss=-1.686974449022216e-10, discriminator_loss=6.3375973695656285e-06\n",
            "step 2963: generator_loss=-4.6115808394198154e-10, discriminator_loss=1.8069691805067123e-06\n",
            "step 2964: generator_loss=-1.6631417354417977e-09, discriminator_loss=3.24788925354369e-06\n",
            "step 2965: generator_loss=-1.6632171195851697e-09, discriminator_loss=2.0856298306171084e-06\n",
            "step 2966: generator_loss=-2.3336491072889487e-10, discriminator_loss=1.1639729109447217e-06\n",
            "step 2967: generator_loss=-3.1441307335455804e-09, discriminator_loss=1.6790950212453026e-06\n",
            "step 2968: generator_loss=-4.1386249982622303e-10, discriminator_loss=5.239335678197676e-06\n",
            "step 2969: generator_loss=-2.1576117281707496e-10, discriminator_loss=1.6293486169161042e-06\n",
            "step 2970: generator_loss=-3.01533709112789e-09, discriminator_loss=3.2674925023457035e-06\n",
            "step 2971: generator_loss=-4.6370507433834973e-10, discriminator_loss=1.4856690313536092e-06\n",
            "step 2972: generator_loss=-9.308882553682452e-10, discriminator_loss=2.5808064947341336e-06\n",
            "step 2973: generator_loss=-9.915814835892434e-10, discriminator_loss=1.1521749001985881e-05\n",
            "step 2974: generator_loss=-2.200015281061951e-09, discriminator_loss=2.7518090064404532e-06\n",
            "step 2975: generator_loss=-5.300160865751025e-10, discriminator_loss=8.521769814251456e-07\n",
            "step 2976: generator_loss=-1.0053897714357163e-09, discriminator_loss=3.5732577998714987e-06\n",
            "step 2977: generator_loss=-1.092813506353707e-09, discriminator_loss=6.414147719624452e-07\n",
            "step 2978: generator_loss=-5.1824002866851515e-09, discriminator_loss=1.3803612546325894e-06\n",
            "step 2979: generator_loss=-3.61587804142971e-09, discriminator_loss=1.871917902462883e-06\n",
            "step 2980: generator_loss=-7.739164864517534e-11, discriminator_loss=1.0256444511469454e-06\n",
            "step 2981: generator_loss=-1.8765944354015573e-10, discriminator_loss=2.642688741616439e-06\n",
            "step 2982: generator_loss=-6.980187539085136e-10, discriminator_loss=2.105285830111825e-06\n",
            "step 2983: generator_loss=-1.5522797491840379e-09, discriminator_loss=4.166852704656776e-06\n",
            "step 2984: generator_loss=-7.038108429391343e-10, discriminator_loss=5.176405920792604e-06\n",
            "step 2985: generator_loss=-1.8159938830475397e-10, discriminator_loss=2.045528617600212e-06\n",
            "step 2986: generator_loss=-2.41495889952148e-09, discriminator_loss=4.797158453584416e-06\n",
            "step 2987: generator_loss=-1.1384602149888678e-09, discriminator_loss=1.8189804222856765e-06\n",
            "step 2988: generator_loss=-6.972906696489645e-09, discriminator_loss=1.3354873544813017e-06\n",
            "step 2989: generator_loss=-2.0727375371620838e-10, discriminator_loss=1.8291012793270056e-06\n",
            "step 2990: generator_loss=-1.287923379056366e-10, discriminator_loss=8.542285286239348e-06\n",
            "step 2991: generator_loss=-6.099906690870682e-10, discriminator_loss=4.8148999667319e-06\n",
            "step 2992: generator_loss=-8.74609606960064e-10, discriminator_loss=1.0222038326901384e-05\n",
            "step 2993: generator_loss=-1.8017813629978008e-10, discriminator_loss=1.3246924481791211e-06\n",
            "step 2994: generator_loss=-1.0758782753583773e-10, discriminator_loss=3.7242182315821992e-06\n",
            "step 2995: generator_loss=-1.4192166331028488e-09, discriminator_loss=7.522426130890381e-07\n",
            "step 2996: generator_loss=-2.151079980805548e-09, discriminator_loss=2.8072577151760925e-06\n",
            "step 2997: generator_loss=-4.0125922029510264e-10, discriminator_loss=7.515794777646079e-07\n",
            "step 2998: generator_loss=-3.5305197654267317e-10, discriminator_loss=3.50424579664832e-06\n",
            "step 2999: generator_loss=-1.0664928662418305e-10, discriminator_loss=2.6552079361863434e-06\n",
            "step 3000: generator_loss=-6.154541876135511e-10, discriminator_loss=2.9783579975628527e-06\n",
            "step 3001: generator_loss=-1.2005494376410297e-09, discriminator_loss=3.077736209888826e-06\n",
            "step 3002: generator_loss=-5.364671901153528e-11, discriminator_loss=2.9558484584413236e-06\n",
            "step 3003: generator_loss=-1.5612259263164674e-09, discriminator_loss=1.7930009335032082e-06\n",
            "step 3004: generator_loss=-2.9124699874039095e-10, discriminator_loss=3.1322297218139283e-06\n",
            "step 3005: generator_loss=-1.2663996240558362e-10, discriminator_loss=1.2704734899671166e-06\n",
            "step 3006: generator_loss=-8.839765586188264e-10, discriminator_loss=8.145422725647222e-06\n",
            "step 3007: generator_loss=-2.137718890793394e-09, discriminator_loss=2.72788156507886e-06\n",
            "step 3008: generator_loss=-3.244780444333628e-09, discriminator_loss=1.699170525171212e-06\n",
            "step 3009: generator_loss=-3.495039258005761e-10, discriminator_loss=6.231273800949566e-06\n",
            "step 3010: generator_loss=-2.552734246208388e-09, discriminator_loss=1.1668649904095219e-06\n",
            "step 3011: generator_loss=-3.6597611607902536e-09, discriminator_loss=1.4640847894042963e-06\n",
            "step 3012: generator_loss=-1.956946826808803e-09, discriminator_loss=2.9878724490117747e-06\n",
            "step 3013: generator_loss=-6.119053597153368e-10, discriminator_loss=1.424559741280973e-06\n",
            "step 3014: generator_loss=-1.4956225147244595e-10, discriminator_loss=3.841115358227398e-06\n",
            "step 3015: generator_loss=-4.809074471978647e-09, discriminator_loss=5.36110110260779e-06\n",
            "step 3016: generator_loss=-1.62706917383737e-10, discriminator_loss=2.020452711803955e-06\n",
            "step 3017: generator_loss=-2.3389751246938317e-10, discriminator_loss=3.147331881336868e-06\n",
            "step 3018: generator_loss=-1.8600753159958572e-09, discriminator_loss=1.3614854879051563e-06\n",
            "step 3019: generator_loss=-9.833466263486912e-10, discriminator_loss=6.260425379878143e-06\n",
            "step 3020: generator_loss=-2.3568991203148926e-10, discriminator_loss=1.8771891063806834e-06\n",
            "step 3021: generator_loss=-8.282131647163737e-10, discriminator_loss=4.545745468931273e-06\n",
            "step 3022: generator_loss=-2.429993095631744e-09, discriminator_loss=2.530812707846053e-06\n",
            "step 3023: generator_loss=-3.1585389859145607e-10, discriminator_loss=1.7597568557903287e-06\n",
            "step 3024: generator_loss=-9.51337231214211e-10, discriminator_loss=2.614303411974106e-06\n",
            "step 3025: generator_loss=-1.320041604913058e-07, discriminator_loss=1.8894875211117323e-06\n",
            "step 3026: generator_loss=-1.7433465782090707e-09, discriminator_loss=2.196961304434808e-06\n",
            "step 3027: generator_loss=-4.4937542575951284e-10, discriminator_loss=1.44983073369076e-06\n",
            "step 3028: generator_loss=-5.668283620252623e-10, discriminator_loss=3.4434906410751864e-06\n",
            "step 3029: generator_loss=-1.4879524279365341e-08, discriminator_loss=4.7274234020733275e-06\n",
            "step 3030: generator_loss=-1.1817689049564706e-08, discriminator_loss=4.274014372640522e-06\n",
            "step 3031: generator_loss=-1.02230535148351e-09, discriminator_loss=7.316291885217652e-06\n",
            "step 3032: generator_loss=-8.590411715303503e-10, discriminator_loss=1.1015092695743078e-06\n",
            "step 3033: generator_loss=-3.1247834875181013e-10, discriminator_loss=2.0643281004595337e-06\n",
            "step 3034: generator_loss=-7.377076172154773e-10, discriminator_loss=3.2494126571691595e-06\n",
            "step 3035: generator_loss=-3.329531095275229e-10, discriminator_loss=1.6833141671668272e-06\n",
            "step 3036: generator_loss=-9.062453565356066e-10, discriminator_loss=6.709065473842202e-06\n",
            "step 3037: generator_loss=-1.0645221509841818e-10, discriminator_loss=1.722747583698947e-06\n",
            "step 3038: generator_loss=-5.408756775793222e-10, discriminator_loss=1.5490145415242296e-06\n",
            "step 3039: generator_loss=-5.265198832482554e-10, discriminator_loss=1.8556200302555226e-05\n",
            "step 3040: generator_loss=-8.442373189421204e-11, discriminator_loss=1.6463526435472886e-06\n",
            "step 3041: generator_loss=-2.6045978707145423e-09, discriminator_loss=5.749315732828109e-06\n",
            "step 3042: generator_loss=-4.930103547629017e-10, discriminator_loss=9.712346127344063e-07\n",
            "step 3043: generator_loss=-6.766713300798699e-10, discriminator_loss=1.7430226080250577e-06\n",
            "step 3044: generator_loss=-5.538283165407165e-10, discriminator_loss=1.7399470380041748e-06\n",
            "step 3045: generator_loss=-6.57877641252469e-11, discriminator_loss=4.867791176366154e-06\n",
            "step 3046: generator_loss=-1.7068388924457167e-09, discriminator_loss=3.8969810702838e-06\n",
            "step 3047: generator_loss=-6.352194881209527e-10, discriminator_loss=2.5654142064013286e-06\n",
            "step 3048: generator_loss=-2.4404489540330587e-09, discriminator_loss=2.6411203180032317e-06\n",
            "step 3049: generator_loss=-6.275467367977683e-10, discriminator_loss=5.2338755267555825e-06\n",
            "step 3050: generator_loss=-1.8209302121707793e-10, discriminator_loss=6.841509048172156e-07\n",
            "step 3051: generator_loss=-3.93526722319848e-09, discriminator_loss=4.306862592784455e-06\n",
            "step 3052: generator_loss=-2.498961926278298e-09, discriminator_loss=2.6800003070093226e-06\n",
            "step 3053: generator_loss=-1.7843881927603888e-09, discriminator_loss=8.783051157479349e-07\n",
            "step 3054: generator_loss=-9.241384324454316e-10, discriminator_loss=1.9733772660401883e-06\n",
            "step 3055: generator_loss=-5.156151061669334e-10, discriminator_loss=2.2618969524046406e-06\n",
            "step 3056: generator_loss=-2.017086719874328e-09, discriminator_loss=3.7919844544376247e-06\n",
            "step 3057: generator_loss=-6.233176197412149e-10, discriminator_loss=1.6711506987121538e-06\n",
            "step 3058: generator_loss=-4.731512959210704e-10, discriminator_loss=1.6052390492404811e-06\n",
            "step 3059: generator_loss=-9.225234465226606e-10, discriminator_loss=9.961396472135675e-07\n",
            "step 3060: generator_loss=-5.179548789868704e-09, discriminator_loss=7.011486559349578e-06\n",
            "step 3061: generator_loss=-8.565995690545947e-10, discriminator_loss=3.667729288281407e-06\n",
            "step 3062: generator_loss=-1.990781428595767e-10, discriminator_loss=5.981067943139351e-07\n",
            "step 3063: generator_loss=-3.01757330234409e-09, discriminator_loss=1.6611419368928182e-06\n",
            "step 3064: generator_loss=-2.2383210562804123e-10, discriminator_loss=3.036492671526503e-06\n",
            "step 3065: generator_loss=-2.392605669143677e-09, discriminator_loss=1.8112215229848516e-06\n",
            "step 3066: generator_loss=-3.6196717845271564e-10, discriminator_loss=7.728384048277803e-07\n",
            "step 3067: generator_loss=-5.703485239649808e-09, discriminator_loss=5.3055750868225005e-06\n",
            "step 3068: generator_loss=-6.212161896002044e-10, discriminator_loss=2.286800281581236e-06\n",
            "step 3069: generator_loss=-4.1389433547145416e-11, discriminator_loss=8.626374778941681e-07\n",
            "step 3070: generator_loss=-4.3706127605958045e-10, discriminator_loss=2.6364377845311537e-06\n",
            "step 3071: generator_loss=-1.6568013627704659e-09, discriminator_loss=6.1631662902073e-06\n",
            "step 3072: generator_loss=-1.5904617900464046e-10, discriminator_loss=1.503219664300559e-06\n",
            "step 3073: generator_loss=-4.708343714909802e-10, discriminator_loss=7.906742780505738e-07\n",
            "step 3074: generator_loss=-1.7017944831110299e-09, discriminator_loss=1.2950208656548057e-05\n",
            "step 3075: generator_loss=-2.0053325666680166e-09, discriminator_loss=9.649677394918399e-07\n",
            "step 3076: generator_loss=-1.1123173493388094e-09, discriminator_loss=9.939470146491658e-06\n",
            "step 3077: generator_loss=-4.4250514363852744e-09, discriminator_loss=1.2055810657329857e-05\n",
            "step 3078: generator_loss=-3.3082961370389796e-10, discriminator_loss=2.190043687733123e-06\n",
            "step 3079: generator_loss=-6.410867392503405e-10, discriminator_loss=2.149244437532616e-06\n",
            "step 3080: generator_loss=-6.382532696802556e-11, discriminator_loss=2.2357180569088086e-06\n",
            "step 3081: generator_loss=-1.6074069852933803e-09, discriminator_loss=2.184505319746677e-06\n",
            "step 3082: generator_loss=-7.615230113167115e-10, discriminator_loss=1.9146209524478763e-06\n",
            "step 3083: generator_loss=-5.651011214524715e-09, discriminator_loss=2.72536522061273e-06\n",
            "step 3084: generator_loss=-8.198328238506747e-09, discriminator_loss=7.184458468145749e-07\n",
            "step 3085: generator_loss=-6.31318886057386e-10, discriminator_loss=1.1854252761622774e-06\n",
            "step 3086: generator_loss=-7.343540442406038e-09, discriminator_loss=1.6267123328361777e-06\n",
            "step 3087: generator_loss=-3.0260216554722774e-10, discriminator_loss=3.323784085296211e-06\n",
            "step 3088: generator_loss=-1.6981843709018563e-10, discriminator_loss=3.6092783375352155e-06\n",
            "step 3089: generator_loss=-2.6472890546358485e-09, discriminator_loss=3.107333668594947e-06\n",
            "step 3090: generator_loss=-6.644863548288527e-10, discriminator_loss=3.84352233595564e-06\n",
            "step 3091: generator_loss=-1.2458904741219357e-10, discriminator_loss=1.1666628552120528e-06\n",
            "step 3092: generator_loss=-6.288845000312904e-10, discriminator_loss=1.5202421081994544e-06\n",
            "step 3093: generator_loss=-8.092660763736603e-09, discriminator_loss=3.234482392144855e-06\n",
            "step 3094: generator_loss=-4.378124529580418e-09, discriminator_loss=4.342819465819048e-06\n",
            "step 3095: generator_loss=-9.252867916309526e-11, discriminator_loss=1.4410876246984117e-05\n",
            "step 3096: generator_loss=-2.919079422625259e-10, discriminator_loss=3.019261839654064e-06\n",
            "step 3097: generator_loss=-1.0556141516460116e-09, discriminator_loss=4.056242232763907e-06\n",
            "step 3098: generator_loss=-1.808443839124152e-09, discriminator_loss=1.412549636370386e-06\n",
            "step 3099: generator_loss=-5.47820885876682e-11, discriminator_loss=1.2916412970298552e-06\n",
            "step 3100: generator_loss=-8.312537463917025e-11, discriminator_loss=5.1629176596179605e-06\n",
            "step 3101: generator_loss=-3.1267033406834344e-10, discriminator_loss=1.479431034567824e-06\n",
            "step 3102: generator_loss=-7.661531409297595e-10, discriminator_loss=2.8581041533470852e-06\n",
            "step 3103: generator_loss=-6.39240083089021e-09, discriminator_loss=2.2428778265748406e-06\n",
            "step 3104: generator_loss=-3.1858499172088273e-10, discriminator_loss=3.827628916042158e-06\n",
            "step 3105: generator_loss=-3.308674001445411e-09, discriminator_loss=4.3422915041446686e-07\n",
            "step 3106: generator_loss=-1.445868091920488e-09, discriminator_loss=2.856873834389262e-06\n",
            "step 3107: generator_loss=-1.3969844725458813e-10, discriminator_loss=2.0324589513620595e-06\n",
            "step 3108: generator_loss=-2.494527640006794e-10, discriminator_loss=6.969699484216108e-07\n",
            "step 3109: generator_loss=-2.9684019686726515e-09, discriminator_loss=1.6671654066158226e-06\n",
            "step 3110: generator_loss=-3.2177011055622984e-10, discriminator_loss=3.5229747936682543e-06\n",
            "step 3111: generator_loss=-8.218641878166011e-10, discriminator_loss=3.268233967901324e-06\n",
            "step 3112: generator_loss=-3.5925786789903214e-09, discriminator_loss=1.131205863202922e-05\n",
            "step 3113: generator_loss=-6.303799149343092e-10, discriminator_loss=6.221229796210537e-06\n",
            "step 3114: generator_loss=-1.4736639686319108e-10, discriminator_loss=8.555634849471971e-06\n",
            "step 3115: generator_loss=-2.5068901621239092e-08, discriminator_loss=2.193532054661773e-06\n",
            "step 3116: generator_loss=-3.0892972624485537e-09, discriminator_loss=2.0410238903423306e-06\n",
            "step 3117: generator_loss=-2.6393669472213332e-09, discriminator_loss=3.5865132304024883e-06\n",
            "step 3118: generator_loss=-4.0229819475712247e-10, discriminator_loss=3.0504211281368043e-06\n",
            "step 3119: generator_loss=-1.9870443068725763e-09, discriminator_loss=4.7785592869331595e-06\n",
            "step 3120: generator_loss=-1.2753362810258295e-08, discriminator_loss=2.588725180885376e-07\n",
            "step 3121: generator_loss=-1.3177553492838e-10, discriminator_loss=2.4804076019790955e-06\n",
            "step 3122: generator_loss=-6.446414513305854e-10, discriminator_loss=1.8145750573239638e-06\n",
            "step 3123: generator_loss=-2.5587778562652375e-09, discriminator_loss=2.40629833569983e-06\n",
            "step 3124: generator_loss=-3.6372502232318027e-10, discriminator_loss=1.943941896342949e-07\n",
            "step 3125: generator_loss=-3.1947852696667667e-10, discriminator_loss=1.3011655255468213e-06\n",
            "step 3126: generator_loss=-1.350156653145973e-10, discriminator_loss=2.5105862277996494e-06\n",
            "step 3127: generator_loss=-1.7745974134619757e-10, discriminator_loss=1.9254985090810806e-06\n",
            "step 3128: generator_loss=-6.971401234068253e-10, discriminator_loss=4.485299541556742e-06\n",
            "step 3129: generator_loss=-6.215273851140068e-10, discriminator_loss=4.524485120782629e-06\n",
            "step 3130: generator_loss=-8.806930185123463e-10, discriminator_loss=9.398166298524302e-07\n",
            "step 3131: generator_loss=-9.507832021693474e-11, discriminator_loss=2.8095021207263926e-06\n",
            "step 3132: generator_loss=-2.2882301609072897e-10, discriminator_loss=8.665068094160233e-07\n",
            "step 3133: generator_loss=-3.5072428294924407e-10, discriminator_loss=2.894085582738626e-06\n",
            "step 3134: generator_loss=-1.3546963550936653e-09, discriminator_loss=2.4316664166690316e-06\n",
            "step 3135: generator_loss=-1.2508694524626662e-08, discriminator_loss=1.1771376193792094e-06\n",
            "step 3136: generator_loss=-4.011041498941381e-10, discriminator_loss=1.5339464880526066e-05\n",
            "step 3137: generator_loss=-2.028182510827037e-09, discriminator_loss=5.305977538228035e-06\n",
            "step 3138: generator_loss=-6.837040711360487e-09, discriminator_loss=1.1612544767558575e-05\n",
            "step 3139: generator_loss=-6.252213746726909e-10, discriminator_loss=1.6907303006519214e-06\n",
            "step 3140: generator_loss=-1.1886640560732076e-09, discriminator_loss=6.823150670243194e-06\n",
            "step 3141: generator_loss=-2.115173591832331e-10, discriminator_loss=1.2704952496278565e-05\n",
            "step 3142: generator_loss=-3.962402073121041e-10, discriminator_loss=1.9117508145427564e-06\n",
            "step 3143: generator_loss=-3.955890129359041e-11, discriminator_loss=2.4716825919313123e-06\n",
            "step 3144: generator_loss=-1.1534040389449274e-09, discriminator_loss=8.995791063171055e-07\n",
            "step 3145: generator_loss=-8.135954132626466e-09, discriminator_loss=2.2219298898562556e-06\n",
            "step 3146: generator_loss=-1.610594158041323e-10, discriminator_loss=3.2810009997774614e-07\n",
            "step 3147: generator_loss=-6.11022066276945e-10, discriminator_loss=1.5186338941930444e-06\n",
            "step 3148: generator_loss=-6.176621436537744e-10, discriminator_loss=2.943051185866352e-06\n",
            "step 3149: generator_loss=-5.007922410094068e-10, discriminator_loss=1.0517931059439434e-06\n",
            "step 3150: generator_loss=-2.2952041656143507e-10, discriminator_loss=7.942227284729597e-07\n",
            "step 3151: generator_loss=-2.476046034871615e-10, discriminator_loss=2.361947736062575e-06\n",
            "step 3152: generator_loss=-7.467015894491169e-10, discriminator_loss=2.5175177142955363e-06\n",
            "step 3153: generator_loss=-6.318910727998173e-09, discriminator_loss=2.929151150965481e-06\n",
            "step 3154: generator_loss=-5.28414378919706e-09, discriminator_loss=2.276474333484657e-06\n",
            "step 3155: generator_loss=-2.2989710135590258e-09, discriminator_loss=1.62168748829572e-06\n",
            "step 3156: generator_loss=-4.136768705365057e-10, discriminator_loss=1.0849038289961754e-06\n",
            "step 3157: generator_loss=-6.9064705066068655e-09, discriminator_loss=2.8576071144925663e-06\n",
            "step 3158: generator_loss=-1.0003525785506895e-09, discriminator_loss=2.4750684133323375e-06\n",
            "step 3159: generator_loss=-3.038463347593279e-08, discriminator_loss=9.444845545658609e-07\n",
            "step 3160: generator_loss=-2.5487723043227106e-09, discriminator_loss=2.9359182462940225e-06\n",
            "step 3161: generator_loss=-4.083462012971495e-09, discriminator_loss=1.2437971008694149e-06\n",
            "step 3162: generator_loss=-3.0622748781183873e-09, discriminator_loss=2.138066975021502e-06\n",
            "step 3163: generator_loss=-1.0172124254026471e-09, discriminator_loss=3.2039913548942422e-06\n",
            "step 3164: generator_loss=-9.387419730444435e-10, discriminator_loss=2.915333652708796e-06\n",
            "step 3165: generator_loss=-2.1942367367522309e-10, discriminator_loss=2.8105105229769833e-06\n",
            "step 3166: generator_loss=-2.676515675759106e-10, discriminator_loss=4.16424381910474e-06\n",
            "step 3167: generator_loss=-3.7836489497067305e-09, discriminator_loss=1.1575302778510377e-06\n",
            "step 3168: generator_loss=-2.7300450788914077e-10, discriminator_loss=2.0983054582757177e-06\n",
            "step 3169: generator_loss=-2.1372145719844582e-10, discriminator_loss=1.5355656159954378e-06\n",
            "step 3170: generator_loss=-5.901222843718301e-10, discriminator_loss=5.284828603180358e-06\n",
            "step 3171: generator_loss=-1.0962437624328913e-09, discriminator_loss=2.8373203804221703e-06\n",
            "step 3172: generator_loss=-1.11800416147112e-10, discriminator_loss=1.7228837805305375e-06\n",
            "step 3173: generator_loss=-1.6464799523774332e-09, discriminator_loss=4.005410119134467e-06\n",
            "step 3174: generator_loss=-6.311607486653159e-11, discriminator_loss=3.028195578735904e-06\n",
            "step 3175: generator_loss=-2.1225822488535329e-10, discriminator_loss=2.806237034747028e-06\n",
            "step 3176: generator_loss=-4.555433363861994e-09, discriminator_loss=6.5595640990068205e-06\n",
            "step 3177: generator_loss=-8.668309958714815e-10, discriminator_loss=1.7992155108004226e-06\n",
            "step 3178: generator_loss=-2.547093091997965e-10, discriminator_loss=4.271457328286488e-06\n",
            "step 3179: generator_loss=-7.957565162364233e-10, discriminator_loss=4.754540441354038e-06\n",
            "step 3180: generator_loss=-1.214043449104807e-10, discriminator_loss=3.5879927509085974e-06\n",
            "step 3181: generator_loss=-1.1770117103182542e-09, discriminator_loss=6.844955350970849e-06\n",
            "step 3182: generator_loss=-3.7664188434760604e-10, discriminator_loss=1.932704662976903e-06\n",
            "step 3183: generator_loss=-1.1906271524253498e-09, discriminator_loss=1.728137021927978e-06\n",
            "step 3184: generator_loss=-1.726786907907396e-10, discriminator_loss=1.1801276968981256e-06\n",
            "step 3185: generator_loss=-3.735227238621519e-09, discriminator_loss=1.5777393400639994e-06\n",
            "step 3186: generator_loss=-2.3600849052840545e-10, discriminator_loss=1.301952579524368e-06\n",
            "step 3187: generator_loss=-1.0731848743006367e-09, discriminator_loss=1.8742157408269122e-06\n",
            "step 3188: generator_loss=-2.4193919090365057e-10, discriminator_loss=6.28530415269779e-07\n",
            "step 3189: generator_loss=-3.898267486590612e-09, discriminator_loss=2.0708455394924385e-06\n",
            "step 3190: generator_loss=-3.066673803786557e-09, discriminator_loss=1.3960124078948866e-06\n",
            "step 3191: generator_loss=-7.466862683713771e-10, discriminator_loss=1.6401121456510737e-06\n",
            "step 3192: generator_loss=-2.1404078509590363e-10, discriminator_loss=2.0154773210379062e-06\n",
            "step 3193: generator_loss=-1.5934251695881585e-09, discriminator_loss=1.3976937225379515e-06\n",
            "step 3194: generator_loss=-9.058624406144133e-10, discriminator_loss=5.041336521571793e-07\n",
            "step 3195: generator_loss=-5.818452386563422e-10, discriminator_loss=1.28529552512191e-06\n",
            "step 3196: generator_loss=-4.778636930602431e-10, discriminator_loss=2.1993039354128996e-06\n",
            "step 3197: generator_loss=-1.4604048526045688e-10, discriminator_loss=8.431265996478032e-07\n",
            "step 3198: generator_loss=-2.4137405407742563e-09, discriminator_loss=1.5799674883965054e-06\n",
            "step 3199: generator_loss=-5.073185205262121e-10, discriminator_loss=5.489502541422553e-07\n",
            "step 3200: generator_loss=-5.010318826492721e-10, discriminator_loss=4.678951881942339e-06\n",
            "step 3201: generator_loss=-5.120803781011318e-10, discriminator_loss=5.855766858076095e-07\n",
            "step 3202: generator_loss=-4.408279297152262e-11, discriminator_loss=3.001509867317509e-06\n",
            "step 3203: generator_loss=-2.7433766369711066e-10, discriminator_loss=2.0402260361152003e-06\n",
            "step 3204: generator_loss=-8.533278250677512e-11, discriminator_loss=8.231645551859401e-06\n",
            "step 3205: generator_loss=-3.156662153891432e-10, discriminator_loss=8.772032060733181e-07\n",
            "step 3206: generator_loss=-3.348490651422509e-10, discriminator_loss=1.2857666433774284e-06\n",
            "step 3207: generator_loss=-1.0029600483463241e-09, discriminator_loss=1.719798660815286e-06\n",
            "step 3208: generator_loss=-3.812174534378876e-11, discriminator_loss=1.2437322993719135e-06\n",
            "step 3209: generator_loss=-5.501405997421216e-10, discriminator_loss=1.9258991414972115e-06\n",
            "step 3210: generator_loss=-1.4792836400268072e-10, discriminator_loss=1.4972180224503973e-06\n",
            "step 3211: generator_loss=-4.849542989404654e-10, discriminator_loss=1.1919969438167755e-06\n",
            "step 3212: generator_loss=-1.0067164879501433e-09, discriminator_loss=1.10659157144255e-05\n",
            "step 3213: generator_loss=-6.422862242061456e-09, discriminator_loss=4.8419151426060125e-06\n",
            "step 3214: generator_loss=-2.9516997179790394e-10, discriminator_loss=2.871083779609762e-06\n",
            "step 3215: generator_loss=-1.3404435339481324e-09, discriminator_loss=1.3723685015065712e-06\n",
            "step 3216: generator_loss=-3.2723386222954787e-09, discriminator_loss=4.895168785878923e-06\n",
            "step 3217: generator_loss=-8.60044835349072e-09, discriminator_loss=1.243398855876876e-06\n",
            "step 3218: generator_loss=-3.428535677585387e-09, discriminator_loss=2.9358619713093503e-07\n",
            "step 3219: generator_loss=-1.487700851399154e-09, discriminator_loss=2.285736854901188e-06\n",
            "step 3220: generator_loss=-2.9973179493936186e-10, discriminator_loss=1.5739603895781329e-06\n",
            "step 3221: generator_loss=-1.5002018516341309e-09, discriminator_loss=4.85554892293294e-07\n",
            "step 3222: generator_loss=-1.0235579495088132e-08, discriminator_loss=2.3534805677627446e-06\n",
            "step 3223: generator_loss=-6.72362387987846e-10, discriminator_loss=2.6516969228396192e-05\n",
            "step 3224: generator_loss=-2.9171692839113916e-10, discriminator_loss=4.4281500777287874e-06\n",
            "step 3225: generator_loss=-1.906977908916474e-10, discriminator_loss=1.96214364223124e-06\n",
            "step 3226: generator_loss=-1.0289687990550078e-09, discriminator_loss=8.122204349092499e-07\n",
            "step 3227: generator_loss=-2.501519547060127e-10, discriminator_loss=3.2879029276955407e-06\n",
            "step 3228: generator_loss=-2.435592560967592e-10, discriminator_loss=1.419591740159376e-06\n",
            "step 3229: generator_loss=-2.097023388270003e-10, discriminator_loss=1.2424291071511107e-06\n",
            "step 3230: generator_loss=-1.1753920059476286e-09, discriminator_loss=4.675229320127983e-06\n",
            "step 3231: generator_loss=-5.595440777383942e-10, discriminator_loss=3.474863433439168e-06\n",
            "step 3232: generator_loss=-1.0037417119690417e-08, discriminator_loss=1.3949651474831626e-05\n",
            "step 3233: generator_loss=-3.9340147806044e-10, discriminator_loss=7.474272933905013e-06\n",
            "step 3234: generator_loss=-2.3061019760461932e-10, discriminator_loss=6.576533905899851e-06\n",
            "step 3235: generator_loss=-3.2484959167078387e-09, discriminator_loss=2.8208326057210797e-06\n",
            "step 3236: generator_loss=-2.475393778844648e-10, discriminator_loss=3.1814388421480544e-06\n",
            "step 3237: generator_loss=-4.455737112607494e-09, discriminator_loss=5.586217866948573e-06\n",
            "step 3238: generator_loss=-1.5805933228918434e-09, discriminator_loss=2.6991692720912397e-06\n",
            "step 3239: generator_loss=-6.350374670560655e-10, discriminator_loss=1.0031541933130939e-05\n",
            "step 3240: generator_loss=-1.2966873130793033e-09, discriminator_loss=8.803116315903026e-07\n",
            "step 3241: generator_loss=-7.957586811713213e-10, discriminator_loss=3.08157018480415e-06\n",
            "step 3242: generator_loss=-1.8823803626943914e-10, discriminator_loss=1.1071507515225676e-06\n",
            "step 3243: generator_loss=-7.807332003118006e-10, discriminator_loss=3.5210957776143914e-06\n",
            "step 3244: generator_loss=-9.586107463377402e-10, discriminator_loss=2.970154355352861e-06\n",
            "step 3245: generator_loss=-3.4156516504069145e-10, discriminator_loss=7.583206524941488e-07\n",
            "step 3246: generator_loss=-5.404680869514067e-11, discriminator_loss=3.860860942950239e-06\n",
            "step 3247: generator_loss=-1.960352769003748e-09, discriminator_loss=1.1068421372328885e-05\n",
            "step 3248: generator_loss=-2.4183426372559325e-09, discriminator_loss=2.8294957701291423e-06\n",
            "step 3249: generator_loss=-2.4249308117063606e-10, discriminator_loss=3.6209842164680595e-06\n",
            "step 3250: generator_loss=-3.7374983663518435e-10, discriminator_loss=3.0616438380093314e-06\n",
            "step 3251: generator_loss=-8.270812368316172e-10, discriminator_loss=2.448630766593851e-06\n",
            "step 3252: generator_loss=-1.1105287522905627e-10, discriminator_loss=3.171338903484866e-06\n",
            "step 3253: generator_loss=-1.967479512643422e-10, discriminator_loss=1.6497341448484804e-06\n",
            "step 3254: generator_loss=-1.0610760048379575e-09, discriminator_loss=2.926876049968996e-06\n",
            "step 3255: generator_loss=-2.11353290424654e-09, discriminator_loss=1.047885007210425e-06\n",
            "step 3256: generator_loss=-4.053359592415262e-10, discriminator_loss=1.0494258049220662e-06\n",
            "step 3257: generator_loss=-8.003123164179726e-10, discriminator_loss=5.305858394422103e-06\n",
            "step 3258: generator_loss=-5.324228835590361e-10, discriminator_loss=3.3818091651482973e-06\n",
            "step 3259: generator_loss=-1.136176042138004e-09, discriminator_loss=1.4179147001414094e-05\n",
            "step 3260: generator_loss=-8.838488829709945e-10, discriminator_loss=2.5524088869133266e-06\n",
            "step 3261: generator_loss=-2.0940252309920027e-10, discriminator_loss=1.951198100869078e-06\n",
            "step 3262: generator_loss=-6.929755658191539e-10, discriminator_loss=1.2695855957645108e-06\n",
            "step 3263: generator_loss=-7.555473580111993e-09, discriminator_loss=3.1863883123151027e-06\n",
            "step 3264: generator_loss=-3.0226207647920944e-10, discriminator_loss=3.668881845442229e-06\n",
            "step 3265: generator_loss=-3.5046776591940443e-10, discriminator_loss=1.0256156883770018e-06\n",
            "step 3266: generator_loss=-2.9593127948146503e-10, discriminator_loss=1.8544851627666503e-06\n",
            "step 3267: generator_loss=-6.709647060176849e-09, discriminator_loss=1.0579825584500213e-06\n",
            "step 3268: generator_loss=-2.6173777034621537e-10, discriminator_loss=2.163037891023123e-07\n",
            "step 3269: generator_loss=-1.410870975604439e-09, discriminator_loss=9.559629461364239e-07\n",
            "step 3270: generator_loss=-1.8127474521456577e-10, discriminator_loss=1.9253470782132354e-06\n",
            "step 3271: generator_loss=-1.3276723054289619e-09, discriminator_loss=1.5890017266428913e-06\n",
            "step 3272: generator_loss=-5.075860287639955e-10, discriminator_loss=1.8818384432961466e-06\n",
            "step 3273: generator_loss=-1.2366169199751198e-10, discriminator_loss=5.958301244390896e-06\n",
            "step 3274: generator_loss=-1.4400072245734918e-09, discriminator_loss=2.7416333523433423e-06\n",
            "step 3275: generator_loss=-1.6127220392458952e-10, discriminator_loss=2.8662582280958304e-06\n",
            "step 3276: generator_loss=-1.2978587093925853e-09, discriminator_loss=3.7035038076282945e-06\n",
            "step 3277: generator_loss=-6.428821364146131e-10, discriminator_loss=1.2579513395394315e-06\n",
            "step 3278: generator_loss=-4.984764823134924e-10, discriminator_loss=6.516711437143385e-06\n",
            "step 3279: generator_loss=-9.749299145767054e-10, discriminator_loss=3.5857387956639286e-06\n",
            "step 3280: generator_loss=-1.8692872250092307e-10, discriminator_loss=8.063500445132377e-07\n",
            "step 3281: generator_loss=-1.8772077226003603e-09, discriminator_loss=2.661617600097088e-06\n",
            "step 3282: generator_loss=-2.594478243356235e-10, discriminator_loss=1.4516477904180647e-06\n",
            "step 3283: generator_loss=-2.363416129469442e-10, discriminator_loss=1.9880062609445304e-06\n",
            "step 3284: generator_loss=-3.4399227910597574e-10, discriminator_loss=1.2971310070497566e-06\n",
            "step 3285: generator_loss=-8.499284831486875e-09, discriminator_loss=2.0642335130105494e-06\n",
            "step 3286: generator_loss=-3.480489452201141e-09, discriminator_loss=2.491804025339661e-06\n",
            "step 3287: generator_loss=-8.24816659417138e-10, discriminator_loss=2.8624867809412535e-06\n",
            "step 3288: generator_loss=-3.427365058428222e-10, discriminator_loss=5.0179928621219005e-06\n",
            "step 3289: generator_loss=-1.7200603164013728e-09, discriminator_loss=1.473040697419492e-06\n",
            "step 3290: generator_loss=-1.4130602243866974e-10, discriminator_loss=9.901054909278173e-07\n",
            "step 3291: generator_loss=-4.833736189091553e-10, discriminator_loss=4.247990091243992e-06\n",
            "step 3292: generator_loss=-1.2295016116325996e-09, discriminator_loss=1.4210492054189672e-06\n",
            "step 3293: generator_loss=-1.3620211625209322e-09, discriminator_loss=5.748162266172585e-07\n",
            "step 3294: generator_loss=-3.2606642386134865e-10, discriminator_loss=3.1346526156994514e-06\n",
            "step 3295: generator_loss=-9.491206431899712e-11, discriminator_loss=1.678075591371453e-06\n",
            "step 3296: generator_loss=-8.758072045367271e-10, discriminator_loss=4.377133336674888e-06\n",
            "step 3297: generator_loss=-4.2196748317735455e-09, discriminator_loss=1.1597535376495216e-05\n",
            "step 3298: generator_loss=-2.0227503005898484e-10, discriminator_loss=3.0382905151782325e-06\n",
            "step 3299: generator_loss=-3.384776070536333e-10, discriminator_loss=9.530816100777884e-07\n",
            "step 3300: generator_loss=-7.926533873714448e-10, discriminator_loss=2.5267368073400576e-06\n",
            "step 3301: generator_loss=-7.491736120357473e-10, discriminator_loss=2.7789344585471554e-06\n",
            "step 3302: generator_loss=-2.765384365943646e-09, discriminator_loss=1.8698937083172495e-06\n",
            "step 3303: generator_loss=-2.3035715557284675e-09, discriminator_loss=2.1872706383874174e-06\n",
            "step 3304: generator_loss=-1.3390362429976932e-10, discriminator_loss=1.4934108776287758e-06\n",
            "step 3305: generator_loss=-2.7338450947489434e-10, discriminator_loss=2.024783270826447e-06\n",
            "step 3306: generator_loss=-6.952496356404936e-10, discriminator_loss=1.3731903436564608e-06\n",
            "step 3307: generator_loss=-4.240862772064702e-09, discriminator_loss=3.0836559972158284e-07\n",
            "step 3308: generator_loss=-3.479590504618102e-10, discriminator_loss=9.268483154301066e-07\n",
            "step 3309: generator_loss=-1.8991515027266814e-09, discriminator_loss=2.7714709176507313e-06\n",
            "step 3310: generator_loss=-3.358606726067137e-10, discriminator_loss=2.7815824523713673e-06\n",
            "step 3311: generator_loss=-2.6014994602974184e-09, discriminator_loss=1.0572576911727083e-06\n",
            "step 3312: generator_loss=-9.667328049189905e-10, discriminator_loss=3.924334578186972e-06\n",
            "step 3313: generator_loss=-2.8623645675907028e-09, discriminator_loss=7.202785354820662e-07\n",
            "step 3314: generator_loss=-4.495510630420085e-09, discriminator_loss=1.1506499504321255e-05\n",
            "step 3315: generator_loss=-9.079668683575903e-10, discriminator_loss=2.4609987576695858e-06\n",
            "step 3316: generator_loss=-1.4527405944875227e-09, discriminator_loss=1.7101702951549669e-06\n",
            "step 3317: generator_loss=-8.547758056920429e-10, discriminator_loss=4.868869041274593e-07\n",
            "step 3318: generator_loss=-2.8062068224699033e-09, discriminator_loss=4.425846327649197e-06\n",
            "step 3319: generator_loss=-2.1711772379973127e-09, discriminator_loss=7.112961384336813e-07\n",
            "step 3320: generator_loss=-5.351132870146103e-10, discriminator_loss=2.3629343104403233e-06\n",
            "step 3321: generator_loss=-3.162042017113009e-10, discriminator_loss=4.901991815131623e-06\n",
            "step 3322: generator_loss=-1.4855319196982464e-09, discriminator_loss=1.0995731827279087e-06\n",
            "step 3323: generator_loss=-5.22692786830703e-08, discriminator_loss=7.383472620858811e-06\n",
            "step 3324: generator_loss=-5.050727613920003e-10, discriminator_loss=1.5381302773675998e-06\n",
            "step 3325: generator_loss=-9.48061185113147e-10, discriminator_loss=6.451858212130901e-07\n",
            "step 3326: generator_loss=-1.1289193191377223e-10, discriminator_loss=1.3520224229068845e-06\n",
            "step 3327: generator_loss=-4.722029434134356e-10, discriminator_loss=9.563882485963404e-07\n",
            "step 3328: generator_loss=-3.695708739037684e-10, discriminator_loss=1.199236521642888e-06\n",
            "step 3329: generator_loss=-5.501849531519554e-10, discriminator_loss=1.9995200091216248e-06\n",
            "step 3330: generator_loss=-4.214119719847531e-09, discriminator_loss=1.2616303592949407e-06\n",
            "step 3331: generator_loss=-2.225827744339881e-09, discriminator_loss=2.673343487913371e-06\n",
            "step 3332: generator_loss=-2.0057455696331772e-10, discriminator_loss=1.5673076632083394e-06\n",
            "step 3333: generator_loss=-1.1625332918541176e-09, discriminator_loss=1.1033474720534286e-06\n",
            "step 3334: generator_loss=-1.4116728896951258e-09, discriminator_loss=2.6839129532163497e-06\n",
            "step 3335: generator_loss=-2.3433925910865128e-09, discriminator_loss=7.242123842843284e-07\n",
            "step 3336: generator_loss=-2.690876133026876e-10, discriminator_loss=3.7090867408551276e-06\n",
            "step 3337: generator_loss=-2.930519160670997e-10, discriminator_loss=4.690757123171352e-06\n",
            "step 3338: generator_loss=-7.024398840371759e-10, discriminator_loss=1.5398391042253934e-06\n",
            "step 3339: generator_loss=-2.353868211457666e-10, discriminator_loss=3.913503405783558e-06\n",
            "step 3340: generator_loss=-1.8412597002637199e-09, discriminator_loss=1.4302229828899726e-05\n",
            "step 3341: generator_loss=-3.4570214746398875e-11, discriminator_loss=4.101600552530726e-06\n",
            "step 3342: generator_loss=-2.6842976730279133e-09, discriminator_loss=1.9358792542334413e-06\n",
            "step 3343: generator_loss=-5.184901397115027e-10, discriminator_loss=1.6464820873807184e-05\n",
            "step 3344: generator_loss=-7.150043668247008e-09, discriminator_loss=3.4550441796454834e-06\n",
            "step 3345: generator_loss=-5.762526011920954e-10, discriminator_loss=8.828446880215779e-06\n",
            "step 3346: generator_loss=-6.637016491950476e-10, discriminator_loss=3.245926052386494e-07\n",
            "step 3347: generator_loss=-1.101301688732903e-10, discriminator_loss=1.8856621863960754e-06\n",
            "step 3348: generator_loss=-4.26817559073811e-09, discriminator_loss=1.316999032496824e-06\n",
            "step 3349: generator_loss=-1.5766098149239127e-10, discriminator_loss=2.3333814169745892e-06\n",
            "step 3350: generator_loss=-6.918962625057645e-10, discriminator_loss=4.419547622092068e-06\n",
            "step 3351: generator_loss=-2.018017530858174e-09, discriminator_loss=6.847769213891297e-07\n",
            "step 3352: generator_loss=-8.398468726023012e-11, discriminator_loss=7.673418167541968e-07\n",
            "step 3353: generator_loss=-2.1908283520666316e-10, discriminator_loss=5.545666226680623e-06\n",
            "step 3354: generator_loss=-5.685730011806278e-11, discriminator_loss=1.623162575015158e-06\n",
            "step 3355: generator_loss=-3.4878839816343543e-09, discriminator_loss=3.5478460631566122e-06\n",
            "step 3356: generator_loss=-1.7431187604444176e-09, discriminator_loss=8.492091865264229e-07\n",
            "step 3357: generator_loss=-8.909466497897256e-10, discriminator_loss=1.2911752946820343e-06\n",
            "step 3358: generator_loss=-1.5490071447743503e-09, discriminator_loss=1.6352636293959222e-06\n",
            "step 3359: generator_loss=-2.847387325921602e-10, discriminator_loss=2.475995188433444e-06\n",
            "step 3360: generator_loss=-1.5555809418366096e-10, discriminator_loss=7.44400495023001e-07\n",
            "step 3361: generator_loss=-1.309569230834029e-09, discriminator_loss=1.1562725603653234e-06\n",
            "step 3362: generator_loss=-5.13658449108334e-10, discriminator_loss=1.9234009869251167e-06\n",
            "step 3363: generator_loss=-2.7228805321577454e-10, discriminator_loss=1.972683548956411e-06\n",
            "step 3364: generator_loss=-1.8849755090144527e-10, discriminator_loss=5.785869916508091e-07\n",
            "step 3365: generator_loss=-1.395335791354313e-10, discriminator_loss=3.7026634345238563e-06\n",
            "step 3366: generator_loss=-1.106439384557234e-09, discriminator_loss=1.2206127166791703e-06\n",
            "step 3367: generator_loss=-7.493335951735958e-10, discriminator_loss=6.075995315768523e-07\n",
            "step 3368: generator_loss=-2.101353757666402e-08, discriminator_loss=1.4135426908978843e-06\n",
            "step 3369: generator_loss=-3.944688486967607e-08, discriminator_loss=2.9643651942024007e-06\n",
            "step 3370: generator_loss=-1.7851942146762667e-08, discriminator_loss=1.1634942893579137e-06\n",
            "step 3371: generator_loss=-1.916657277334366e-09, discriminator_loss=9.182593885270762e-07\n",
            "step 3372: generator_loss=-4.613940618458656e-10, discriminator_loss=2.3814184260118054e-06\n",
            "step 3373: generator_loss=-4.114756313455814e-10, discriminator_loss=8.074163815763313e-06\n",
            "step 3374: generator_loss=-3.11353609561138e-08, discriminator_loss=1.341438178315002e-06\n",
            "step 3375: generator_loss=-5.027757099540509e-10, discriminator_loss=2.5843974071904086e-06\n",
            "step 3376: generator_loss=-1.554660733482649e-09, discriminator_loss=3.941197064705193e-06\n",
            "step 3377: generator_loss=-3.2802630056671944e-10, discriminator_loss=6.098438916524174e-06\n",
            "step 3378: generator_loss=-2.1665569338580326e-10, discriminator_loss=3.6041365092387423e-06\n",
            "step 3379: generator_loss=-3.7722014400998205e-10, discriminator_loss=2.2869144231663086e-06\n",
            "step 3380: generator_loss=-7.656708600478623e-10, discriminator_loss=5.620328010991216e-06\n",
            "step 3381: generator_loss=-1.0296495212003265e-08, discriminator_loss=1.075061618394102e-06\n",
            "step 3382: generator_loss=-1.415144251781797e-10, discriminator_loss=7.997185207386792e-07\n",
            "step 3383: generator_loss=-5.04488628649824e-09, discriminator_loss=2.4915793801483233e-06\n",
            "step 3384: generator_loss=-5.422183257941526e-10, discriminator_loss=3.7621002775267698e-06\n",
            "step 3385: generator_loss=-5.763379218315379e-10, discriminator_loss=2.2590913886233466e-06\n",
            "step 3386: generator_loss=-5.703498562326104e-09, discriminator_loss=7.868918032727379e-07\n",
            "step 3387: generator_loss=-6.93213708657936e-10, discriminator_loss=6.588285259567783e-07\n",
            "step 3388: generator_loss=-1.485969680636856e-10, discriminator_loss=5.804139163956279e-06\n",
            "step 3389: generator_loss=-1.2281370365130329e-10, discriminator_loss=6.09406356488762e-07\n",
            "step 3390: generator_loss=-1.6867045538049297e-09, discriminator_loss=1.7628273781156167e-05\n",
            "step 3391: generator_loss=-1.8836157078538918e-09, discriminator_loss=4.066326255269814e-06\n",
            "step 3392: generator_loss=-1.1678875644349773e-09, discriminator_loss=9.834777756623225e-07\n",
            "step 3393: generator_loss=-1.3368082196762998e-09, discriminator_loss=7.655681656615343e-06\n",
            "step 3394: generator_loss=-3.286859950879517e-10, discriminator_loss=3.4399229775772255e-07\n",
            "step 3395: generator_loss=-1.1346199535466894e-09, discriminator_loss=4.058597369294148e-06\n",
            "step 3396: generator_loss=-4.3446718445139254e-10, discriminator_loss=6.594781893909385e-07\n",
            "step 3397: generator_loss=-1.390890780328391e-08, discriminator_loss=3.7751897252746858e-06\n",
            "step 3398: generator_loss=-9.535792294679268e-11, discriminator_loss=1.0938706509477925e-06\n",
            "step 3399: generator_loss=-2.9369506826526504e-10, discriminator_loss=7.791455232109001e-07\n",
            "step 3400: generator_loss=-2.0291082702961205e-10, discriminator_loss=1.3060609944659518e-06\n",
            "step 3401: generator_loss=-6.004800212622285e-08, discriminator_loss=7.223165425784828e-07\n",
            "step 3402: generator_loss=-1.3857248681858891e-09, discriminator_loss=5.877181138203014e-06\n",
            "step 3403: generator_loss=-3.8499967103255983e-10, discriminator_loss=5.09899882672471e-06\n",
            "step 3404: generator_loss=-2.486637007415027e-10, discriminator_loss=6.2290596360981e-06\n",
            "step 3405: generator_loss=-7.346950825493082e-10, discriminator_loss=8.94225422598538e-07\n",
            "step 3406: generator_loss=-3.508344947888986e-09, discriminator_loss=1.777959141691099e-06\n",
            "step 3407: generator_loss=-8.597092815421092e-09, discriminator_loss=6.647045211138902e-06\n",
            "step 3408: generator_loss=-1.2953865757836525e-09, discriminator_loss=1.6655401395837544e-06\n",
            "step 3409: generator_loss=-5.221926224763251e-10, discriminator_loss=2.2676649678032845e-06\n",
            "step 3410: generator_loss=-5.094657473669884e-10, discriminator_loss=1.4416000340133905e-06\n",
            "step 3411: generator_loss=-2.6724593649163353e-09, discriminator_loss=1.1234983503527474e-06\n",
            "step 3412: generator_loss=-3.507357182463977e-10, discriminator_loss=4.845896000915673e-06\n",
            "step 3413: generator_loss=-6.904424254550179e-10, discriminator_loss=2.476961526554078e-06\n",
            "step 3414: generator_loss=-5.656570767342828e-10, discriminator_loss=3.182517502864357e-06\n",
            "step 3415: generator_loss=-1.0988759902019751e-09, discriminator_loss=1.4988759176048916e-06\n",
            "step 3416: generator_loss=-1.8042119187544614e-10, discriminator_loss=2.1357348032324808e-06\n",
            "step 3417: generator_loss=-3.894823907835132e-10, discriminator_loss=6.307607804956206e-07\n",
            "step 3418: generator_loss=-3.879289667274577e-10, discriminator_loss=2.1924925022176467e-06\n",
            "step 3419: generator_loss=-4.495721017683252e-10, discriminator_loss=1.6587736126894015e-06\n",
            "step 3420: generator_loss=-4.994857652484974e-11, discriminator_loss=3.0272151434473926e-06\n",
            "step 3421: generator_loss=-4.0724937311331644e-10, discriminator_loss=1.568932361806219e-06\n",
            "step 3422: generator_loss=-9.229750297379269e-10, discriminator_loss=6.8014492171641905e-06\n",
            "step 3423: generator_loss=-3.167063555853389e-10, discriminator_loss=1.6113721130750491e-06\n",
            "step 3424: generator_loss=-7.7642170470682e-10, discriminator_loss=4.149798314756481e-06\n",
            "step 3425: generator_loss=-1.748406197599195e-09, discriminator_loss=1.767094090610044e-06\n",
            "step 3426: generator_loss=-1.3625786610127477e-10, discriminator_loss=1.077223146239703e-06\n",
            "step 3427: generator_loss=-4.192577840456124e-09, discriminator_loss=2.7472635792946676e-06\n",
            "step 3428: generator_loss=-1.5228138194878227e-10, discriminator_loss=2.6727245767688146e-06\n",
            "step 3429: generator_loss=-5.335561437114222e-10, discriminator_loss=1.9474364307825454e-06\n",
            "step 3430: generator_loss=-2.3367510149086e-09, discriminator_loss=1.6749286260164808e-06\n",
            "step 3431: generator_loss=-6.752066683546332e-10, discriminator_loss=1.8904532907981775e-06\n",
            "step 3432: generator_loss=-6.7680433479822e-10, discriminator_loss=2.4772671167738736e-06\n",
            "step 3433: generator_loss=-2.9358867337236916e-08, discriminator_loss=1.7197221495734993e-06\n",
            "step 3434: generator_loss=-5.524469770534779e-10, discriminator_loss=1.472506141908525e-06\n",
            "step 3435: generator_loss=-6.245768346957448e-10, discriminator_loss=1.8467879954187083e-06\n",
            "step 3436: generator_loss=-2.027059770037809e-10, discriminator_loss=1.016874989545613e-06\n",
            "step 3437: generator_loss=-2.529584042232358e-10, discriminator_loss=2.7212427085032687e-06\n",
            "step 3438: generator_loss=-3.363838374514927e-10, discriminator_loss=1.1798944115071208e-06\n",
            "step 3439: generator_loss=-2.514483898874431e-10, discriminator_loss=1.733097178657772e-06\n",
            "step 3440: generator_loss=-5.733833408072542e-10, discriminator_loss=1.3863987078366335e-06\n",
            "step 3441: generator_loss=-1.713778285949985e-10, discriminator_loss=1.0229144891127362e-06\n",
            "step 3442: generator_loss=-3.3651357256303527e-09, discriminator_loss=3.92489801015472e-06\n",
            "step 3443: generator_loss=-8.168986598278138e-10, discriminator_loss=9.403370881955198e-07\n",
            "step 3444: generator_loss=-7.011505820386787e-10, discriminator_loss=1.0552039384492673e-06\n",
            "step 3445: generator_loss=-9.048700455593917e-09, discriminator_loss=2.6817358502739808e-06\n",
            "step 3446: generator_loss=-6.788946627089842e-10, discriminator_loss=3.473225888228626e-06\n",
            "step 3447: generator_loss=-3.378322899205699e-10, discriminator_loss=1.506628450442804e-06\n",
            "step 3448: generator_loss=-1.191851173309999e-09, discriminator_loss=2.3277104901353596e-06\n",
            "step 3449: generator_loss=-1.9282582641722e-08, discriminator_loss=4.346612513472792e-06\n",
            "step 3450: generator_loss=-1.3095503348381499e-08, discriminator_loss=5.666670404025353e-07\n",
            "step 3451: generator_loss=-3.1658728416594784e-10, discriminator_loss=1.9368308130651712e-06\n",
            "step 3452: generator_loss=-2.5349553012254944e-10, discriminator_loss=2.1536163785640383e-06\n",
            "step 3453: generator_loss=-2.9911428889306535e-09, discriminator_loss=4.285276418158901e-07\n",
            "step 3454: generator_loss=-3.948904758743765e-09, discriminator_loss=3.223178055122844e-06\n",
            "step 3455: generator_loss=-7.618227160222091e-10, discriminator_loss=2.950420139313792e-06\n",
            "step 3456: generator_loss=-5.852593965016695e-10, discriminator_loss=1.033660737448372e-06\n",
            "step 3457: generator_loss=-7.261551915327402e-10, discriminator_loss=1.0533415206737118e-06\n",
            "step 3458: generator_loss=-2.5140187709382644e-09, discriminator_loss=2.44256671066978e-06\n",
            "step 3459: generator_loss=-8.783332283712753e-09, discriminator_loss=3.5719122024602257e-06\n",
            "step 3460: generator_loss=-6.220931547673558e-10, discriminator_loss=1.2575553682836471e-06\n",
            "step 3461: generator_loss=-2.5829323124781922e-09, discriminator_loss=5.308592108121957e-07\n",
            "step 3462: generator_loss=-1.951883654705e-10, discriminator_loss=2.9614313916681567e-06\n",
            "step 3463: generator_loss=-3.233866285867748e-09, discriminator_loss=2.894664930863655e-06\n",
            "step 3464: generator_loss=-2.6580687650934465e-10, discriminator_loss=3.1079100608621957e-06\n",
            "step 3465: generator_loss=-6.799659724165963e-10, discriminator_loss=1.1914092965525924e-06\n",
            "step 3466: generator_loss=-4.371338291342397e-10, discriminator_loss=5.151040113560157e-06\n",
            "step 3467: generator_loss=-1.3077484872781042e-08, discriminator_loss=9.63993329605728e-07\n",
            "step 3468: generator_loss=-2.972081469820864e-10, discriminator_loss=1.2894829524157103e-06\n",
            "step 3469: generator_loss=-2.5147917082080085e-10, discriminator_loss=1.5831396922294516e-06\n",
            "step 3470: generator_loss=-1.9007484475253023e-10, discriminator_loss=5.499995836544258e-07\n",
            "step 3471: generator_loss=-2.0827850555349414e-10, discriminator_loss=1.970683342733537e-06\n",
            "step 3472: generator_loss=-9.056665972728695e-10, discriminator_loss=9.58294776864932e-07\n",
            "step 3473: generator_loss=-1.9617854563058756e-10, discriminator_loss=2.297016408192576e-06\n",
            "step 3474: generator_loss=-1.6666427959943775e-10, discriminator_loss=1.32391858187475e-06\n",
            "step 3475: generator_loss=-1.636973334662173e-10, discriminator_loss=1.7528227544971742e-06\n",
            "step 3476: generator_loss=-3.583021657149743e-10, discriminator_loss=1.9097615222563036e-06\n",
            "step 3477: generator_loss=-4.475843307094607e-10, discriminator_loss=5.154712653165916e-06\n",
            "step 3478: generator_loss=-2.6993944857167662e-09, discriminator_loss=3.0064322800171794e-06\n",
            "step 3479: generator_loss=-4.432333944315303e-10, discriminator_loss=9.678185506345471e-07\n",
            "step 3480: generator_loss=-6.082117032235601e-09, discriminator_loss=9.902073543344159e-07\n",
            "step 3481: generator_loss=-2.781749830482738e-10, discriminator_loss=1.2477124755605473e-06\n",
            "step 3482: generator_loss=-4.775810302781736e-10, discriminator_loss=1.4685898577226908e-06\n",
            "step 3483: generator_loss=-8.344624435885351e-10, discriminator_loss=4.678628556575859e-06\n",
            "step 3484: generator_loss=-4.838457412503772e-10, discriminator_loss=2.2277662026226608e-07\n",
            "step 3485: generator_loss=-6.839536159652937e-10, discriminator_loss=5.343154043657705e-06\n",
            "step 3486: generator_loss=-6.782167050189969e-10, discriminator_loss=3.7272181998559972e-06\n",
            "step 3487: generator_loss=-9.23536747077236e-10, discriminator_loss=1.0919292208200204e-06\n",
            "step 3488: generator_loss=-6.29712060273846e-10, discriminator_loss=1.9723800050996942e-06\n",
            "step 3489: generator_loss=-6.609777170041298e-10, discriminator_loss=7.396848104690434e-06\n",
            "step 3490: generator_loss=-1.2794472148414116e-09, discriminator_loss=3.144176162095391e-06\n",
            "step 3491: generator_loss=-2.1664112725972018e-09, discriminator_loss=3.03400838674861e-06\n",
            "step 3492: generator_loss=-4.3012388095675647e-10, discriminator_loss=1.2753862392855808e-06\n",
            "step 3493: generator_loss=-1.277627559304051e-09, discriminator_loss=1.9019013279830688e-06\n",
            "step 3494: generator_loss=-1.3644982921334758e-09, discriminator_loss=2.1584032765531447e-06\n",
            "step 3495: generator_loss=-1.5956694854324383e-09, discriminator_loss=3.982325324614067e-06\n",
            "step 3496: generator_loss=-1.351620204648185e-10, discriminator_loss=8.848846277942357e-07\n",
            "step 3497: generator_loss=-3.155239958196887e-10, discriminator_loss=7.990082053765946e-07\n",
            "step 3498: generator_loss=-1.1827490986604516e-08, discriminator_loss=1.723090576888353e-06\n",
            "step 3499: generator_loss=-3.803870107788043e-09, discriminator_loss=2.9199647997302236e-06\n",
            "step 3500: generator_loss=-3.0014912777431846e-09, discriminator_loss=2.6663967673812294e-06\n",
            "step 3501: generator_loss=-1.070928790092296e-09, discriminator_loss=6.948361601644137e-07\n",
            "step 3502: generator_loss=-1.258935178327647e-09, discriminator_loss=1.0399190841781092e-06\n",
            "step 3503: generator_loss=-6.441862598904891e-10, discriminator_loss=2.2131478090159362e-06\n",
            "step 3504: generator_loss=-7.150403602551592e-10, discriminator_loss=8.36493370570679e-07\n",
            "step 3505: generator_loss=-7.306703853071639e-11, discriminator_loss=1.530672761873575e-06\n",
            "step 3506: generator_loss=-2.5291052585529883e-10, discriminator_loss=4.648491540137911e-06\n",
            "step 3507: generator_loss=-3.807230086749769e-09, discriminator_loss=6.039269464963581e-06\n",
            "step 3508: generator_loss=-1.5707972422784877e-10, discriminator_loss=1.6849635358084925e-06\n",
            "step 3509: generator_loss=-4.0037098081313616e-09, discriminator_loss=9.807137075767969e-07\n",
            "step 3510: generator_loss=-3.1779701092915502e-09, discriminator_loss=1.383191488457669e-06\n",
            "step 3511: generator_loss=-1.642541103130668e-09, discriminator_loss=1.344659494861844e-06\n",
            "step 3512: generator_loss=-1.6235228716965366e-09, discriminator_loss=2.9289394660736434e-06\n",
            "step 3513: generator_loss=-1.3388403719005737e-09, discriminator_loss=1.2075264521627105e-06\n",
            "step 3514: generator_loss=-2.589121417262419e-10, discriminator_loss=9.563374305798789e-07\n",
            "step 3515: generator_loss=-5.36805266904139e-09, discriminator_loss=1.8781275912260753e-06\n",
            "step 3516: generator_loss=-1.5613041415285522e-10, discriminator_loss=3.4666838928387733e-06\n",
            "step 3517: generator_loss=-2.1031454355835422e-10, discriminator_loss=1.3271427405925351e-06\n",
            "step 3518: generator_loss=-7.038786775659389e-10, discriminator_loss=1.0050271157524548e-06\n",
            "step 3519: generator_loss=-6.9690626602891825e-09, discriminator_loss=2.226040123787243e-06\n",
            "step 3520: generator_loss=-1.0074926448666588e-09, discriminator_loss=7.01941871739109e-07\n",
            "step 3521: generator_loss=-1.63099900252206e-09, discriminator_loss=1.0500879398023244e-05\n",
            "step 3522: generator_loss=-1.0036994568807245e-09, discriminator_loss=2.6449836241226876e-06\n",
            "step 3523: generator_loss=-3.1195976912812284e-09, discriminator_loss=1.4173140243656235e-06\n",
            "step 3524: generator_loss=-9.425925318051753e-11, discriminator_loss=1.2858048421549029e-06\n",
            "step 3525: generator_loss=-2.809490695643291e-10, discriminator_loss=1.5925814977890695e-06\n",
            "step 3526: generator_loss=-2.554244993291377e-08, discriminator_loss=8.876197625795612e-07\n",
            "step 3527: generator_loss=-2.0878400397439378e-10, discriminator_loss=1.1061223631259054e-05\n",
            "step 3528: generator_loss=-1.0569480846100987e-09, discriminator_loss=3.0980913834355306e-06\n",
            "step 3529: generator_loss=-3.0721494792551596e-10, discriminator_loss=3.8037846934457775e-06\n",
            "step 3530: generator_loss=-1.1429587831734977e-10, discriminator_loss=1.1888683957295143e-06\n",
            "step 3531: generator_loss=-1.2613510236292313e-08, discriminator_loss=1.3682905546374968e-06\n",
            "step 3532: generator_loss=-3.7124114893316573e-09, discriminator_loss=1.277544015465537e-06\n",
            "step 3533: generator_loss=-4.285300725381802e-10, discriminator_loss=2.3299230633710977e-06\n",
            "step 3534: generator_loss=-2.5372489886876792e-08, discriminator_loss=2.9944371817691717e-06\n",
            "step 3535: generator_loss=-6.001894120588602e-11, discriminator_loss=9.526358439870819e-07\n",
            "step 3536: generator_loss=-1.4031362738364805e-08, discriminator_loss=1.2094802741557942e-06\n",
            "step 3537: generator_loss=-1.0702037478438342e-08, discriminator_loss=1.404044724040432e-06\n",
            "step 3538: generator_loss=-1.0134046934950902e-09, discriminator_loss=1.6570184016018175e-06\n",
            "step 3539: generator_loss=-6.270871044655735e-10, discriminator_loss=9.176056892101769e-07\n",
            "step 3540: generator_loss=-3.787024027701591e-09, discriminator_loss=1.8803311832016334e-06\n",
            "step 3541: generator_loss=-2.1455759391386664e-09, discriminator_loss=1.2884983107142034e-06\n",
            "step 3542: generator_loss=-2.206613225474996e-10, discriminator_loss=1.9487281406327384e-06\n",
            "step 3543: generator_loss=-3.5573660683851926e-10, discriminator_loss=3.0872072329657385e-06\n",
            "step 3544: generator_loss=-1.4362380729160407e-10, discriminator_loss=1.5853263448661892e-06\n",
            "step 3545: generator_loss=-8.885826519033913e-10, discriminator_loss=1.6051991451604408e-06\n",
            "step 3546: generator_loss=-7.115544820024411e-10, discriminator_loss=1.2886113154308987e-06\n",
            "step 3547: generator_loss=-4.219355698165117e-10, discriminator_loss=1.268934511244879e-06\n",
            "step 3548: generator_loss=-1.4892995725546143e-09, discriminator_loss=1.157432961917948e-06\n",
            "step 3549: generator_loss=-1.6325812923767558e-10, discriminator_loss=5.038370545662474e-06\n",
            "step 3550: generator_loss=-8.508829196784973e-10, discriminator_loss=4.813009581994265e-07\n",
            "step 3551: generator_loss=-3.9691427922150524e-10, discriminator_loss=2.9503055998247874e-07\n",
            "step 3552: generator_loss=-5.399243274695209e-10, discriminator_loss=2.454616833347245e-06\n",
            "step 3553: generator_loss=-2.6442451006580825e-10, discriminator_loss=5.152219728188356e-06\n",
            "step 3554: generator_loss=-4.3063688726086014e-10, discriminator_loss=3.7854251786484383e-06\n",
            "step 3555: generator_loss=-6.350375780783679e-10, discriminator_loss=1.1713715366568067e-06\n",
            "step 3556: generator_loss=-1.531104132368455e-10, discriminator_loss=2.5646334051998565e-06\n",
            "step 3557: generator_loss=-2.5928978408806813e-10, discriminator_loss=5.302471890900051e-06\n",
            "step 3558: generator_loss=-8.457392008942577e-10, discriminator_loss=3.4372947084193584e-06\n",
            "step 3559: generator_loss=-1.2506642388387945e-09, discriminator_loss=8.842303600431478e-07\n",
            "step 3560: generator_loss=-1.6349387399472448e-09, discriminator_loss=2.774036147457082e-06\n",
            "step 3561: generator_loss=-4.2474371242384734e-10, discriminator_loss=5.867202617082512e-07\n",
            "step 3562: generator_loss=-3.4399177950561466e-10, discriminator_loss=1.3152144902051077e-06\n",
            "step 3563: generator_loss=-1.4102932155424242e-09, discriminator_loss=4.993090897187358e-06\n",
            "step 3564: generator_loss=-3.712849194759116e-10, discriminator_loss=1.0658418432285544e-06\n",
            "step 3565: generator_loss=-1.2860051912255699e-09, discriminator_loss=3.825544808933046e-06\n",
            "step 3566: generator_loss=-3.001814907754863e-10, discriminator_loss=6.055062158338842e-07\n",
            "step 3567: generator_loss=-9.697258551710775e-10, discriminator_loss=4.115723641007207e-06\n",
            "step 3568: generator_loss=-1.2007135286040693e-09, discriminator_loss=1.4817400142419501e-06\n",
            "step 3569: generator_loss=-2.8413305042107595e-09, discriminator_loss=1.7305893607044709e-06\n",
            "step 3570: generator_loss=-3.8550025394101795e-09, discriminator_loss=3.3950370834645582e-06\n",
            "step 3571: generator_loss=-4.5314141328134383e-10, discriminator_loss=5.8130644902121276e-06\n",
            "step 3572: generator_loss=-1.433091700864253e-10, discriminator_loss=2.7259811758995056e-06\n",
            "step 3573: generator_loss=-3.573208118279325e-10, discriminator_loss=1.5823620742594358e-06\n",
            "step 3574: generator_loss=-1.1658455534302448e-08, discriminator_loss=5.049917945143534e-06\n",
            "step 3575: generator_loss=-1.3470312643093507e-09, discriminator_loss=1.911974777613068e-06\n",
            "step 3576: generator_loss=-4.6701753575462135e-09, discriminator_loss=2.8170809400762664e-06\n",
            "step 3577: generator_loss=-5.076897791056467e-10, discriminator_loss=1.1108401167803095e-06\n",
            "step 3578: generator_loss=-2.0522060495409278e-08, discriminator_loss=7.27624978935637e-07\n",
            "step 3579: generator_loss=-5.589818830031845e-09, discriminator_loss=2.4953180854936363e-06\n",
            "step 3580: generator_loss=-1.4268136672157539e-10, discriminator_loss=7.405067776744545e-07\n",
            "step 3581: generator_loss=-7.560538861639543e-10, discriminator_loss=1.2747098026011372e-06\n",
            "step 3582: generator_loss=-4.1117664828504985e-10, discriminator_loss=1.6529871800230467e-06\n",
            "step 3583: generator_loss=-9.499422082281939e-11, discriminator_loss=2.0873126231890637e-06\n",
            "step 3584: generator_loss=-6.037330635422222e-10, discriminator_loss=1.0452217793499585e-06\n",
            "step 3585: generator_loss=-2.029677537151997e-10, discriminator_loss=1.7881432086142013e-06\n",
            "step 3586: generator_loss=-1.3498926421107171e-08, discriminator_loss=1.0690305316529702e-06\n",
            "step 3587: generator_loss=-2.236162144342302e-09, discriminator_loss=1.0297507060386124e-06\n",
            "step 3588: generator_loss=-7.159652315458231e-10, discriminator_loss=2.0455895537452307e-06\n",
            "step 3589: generator_loss=-8.155610076165942e-10, discriminator_loss=3.000665628860588e-06\n",
            "step 3590: generator_loss=-3.991614261344978e-10, discriminator_loss=3.0582982617488597e-06\n",
            "step 3591: generator_loss=-1.5346179882413935e-09, discriminator_loss=4.464031064799201e-07\n",
            "step 3592: generator_loss=-5.513982048732657e-10, discriminator_loss=1.7268512237933464e-06\n",
            "step 3593: generator_loss=-2.7937593904958646e-10, discriminator_loss=3.2634663966746302e-06\n",
            "step 3594: generator_loss=-4.741356196547031e-10, discriminator_loss=2.7686367047863314e-06\n",
            "step 3595: generator_loss=-1.4377431689638343e-08, discriminator_loss=4.368163899926003e-06\n",
            "step 3596: generator_loss=-9.320333393958435e-10, discriminator_loss=1.7531207276988425e-06\n",
            "step 3597: generator_loss=-4.912202866691473e-10, discriminator_loss=1.6654515775371692e-06\n",
            "step 3598: generator_loss=-1.942612293248658e-09, discriminator_loss=4.592500772560015e-06\n",
            "step 3599: generator_loss=-2.2089526041657592e-10, discriminator_loss=2.23505435315019e-06\n",
            "step 3600: generator_loss=-1.9834982545319235e-09, discriminator_loss=7.258294090206618e-07\n",
            "step 3601: generator_loss=-3.1250770859969634e-09, discriminator_loss=2.861565633338614e-07\n",
            "step 3602: generator_loss=-2.3351331979171164e-10, discriminator_loss=2.6062507458846085e-06\n",
            "step 3603: generator_loss=-3.0439817333416386e-10, discriminator_loss=2.335883664272842e-06\n",
            "step 3604: generator_loss=-2.954593791848481e-10, discriminator_loss=1.9829517441394273e-06\n",
            "step 3605: generator_loss=-1.8005022472955545e-10, discriminator_loss=3.493823896860704e-06\n",
            "step 3606: generator_loss=-3.255611058516905e-10, discriminator_loss=5.17883017892018e-06\n",
            "step 3607: generator_loss=-1.7302095867144374e-10, discriminator_loss=1.8085474948748015e-06\n",
            "step 3608: generator_loss=-8.317941002644602e-09, discriminator_loss=1.5669139656893094e-06\n",
            "step 3609: generator_loss=-2.8084445879983377e-10, discriminator_loss=7.827248964531464e-07\n",
            "step 3610: generator_loss=-7.990159645032691e-10, discriminator_loss=1.72783802554477e-06\n",
            "step 3611: generator_loss=-6.213943803956568e-10, discriminator_loss=7.95759774518956e-07\n",
            "step 3612: generator_loss=-5.14271299156821e-11, discriminator_loss=9.932786042554653e-07\n",
            "step 3613: generator_loss=-9.175589177345955e-10, discriminator_loss=2.2007859570294386e-06\n",
            "step 3614: generator_loss=-4.331246028499436e-09, discriminator_loss=2.0299785319366492e-06\n",
            "step 3615: generator_loss=-1.2183092312767485e-09, discriminator_loss=1.5108652178241755e-06\n",
            "step 3616: generator_loss=-5.856221063638145e-10, discriminator_loss=6.332946895781788e-07\n",
            "step 3617: generator_loss=-5.996773910776909e-11, discriminator_loss=8.54714380693622e-06\n",
            "step 3618: generator_loss=-1.5298213895675872e-07, discriminator_loss=1.6408047258664737e-06\n",
            "step 3619: generator_loss=-5.484581677706046e-10, discriminator_loss=3.047716177206894e-07\n",
            "step 3620: generator_loss=-5.373967937316593e-10, discriminator_loss=1.907742671392043e-06\n",
            "step 3621: generator_loss=-1.7570388477494703e-09, discriminator_loss=4.098014869668987e-06\n",
            "step 3622: generator_loss=-2.569369716987069e-10, discriminator_loss=6.954450668672507e-07\n",
            "step 3623: generator_loss=-2.8485322434157467e-10, discriminator_loss=1.8369047438682173e-06\n",
            "step 3624: generator_loss=-1.2009936378731823e-09, discriminator_loss=5.416854946815874e-07\n",
            "step 3625: generator_loss=-5.579682826883925e-10, discriminator_loss=1.2981449799553957e-06\n",
            "step 3626: generator_loss=-1.0291913987714452e-08, discriminator_loss=2.8071383439964848e-06\n",
            "step 3627: generator_loss=-8.267164175457253e-10, discriminator_loss=9.391948196935118e-07\n",
            "step 3628: generator_loss=-1.099351498723422e-09, discriminator_loss=1.969607637875015e-06\n",
            "step 3629: generator_loss=-6.43467334970893e-10, discriminator_loss=1.9699448330356972e-06\n",
            "step 3630: generator_loss=-3.45701550719113e-10, discriminator_loss=5.010392101212346e-07\n",
            "step 3631: generator_loss=-2.2648640740641213e-09, discriminator_loss=9.20342245080974e-07\n",
            "step 3632: generator_loss=-2.735736970294056e-09, discriminator_loss=7.640664421160182e-07\n",
            "step 3633: generator_loss=-1.4332494913116278e-10, discriminator_loss=4.460692252905574e-06\n",
            "step 3634: generator_loss=-5.307184136604803e-10, discriminator_loss=9.750617664394667e-07\n",
            "step 3635: generator_loss=-6.323338519464983e-10, discriminator_loss=1.1771331855925382e-06\n",
            "step 3636: generator_loss=-1.456290643631064e-09, discriminator_loss=1.1996912689937744e-06\n",
            "step 3637: generator_loss=-1.5905592398723911e-09, discriminator_loss=1.9690050976350904e-06\n",
            "step 3638: generator_loss=-1.0740848210843978e-09, discriminator_loss=2.3441334633389488e-06\n",
            "step 3639: generator_loss=-3.233296408389208e-10, discriminator_loss=1.936058197316015e-06\n",
            "step 3640: generator_loss=-2.1226494173465227e-10, discriminator_loss=5.960460839560255e-06\n",
            "step 3641: generator_loss=-2.934857246117417e-09, discriminator_loss=4.7293346483456844e-07\n",
            "step 3642: generator_loss=-4.777961359891947e-10, discriminator_loss=7.954149623401463e-07\n",
            "step 3643: generator_loss=-1.810007976832395e-10, discriminator_loss=2.3648592559766257e-06\n",
            "step 3644: generator_loss=-4.921932861279288e-10, discriminator_loss=6.029667360962776e-07\n",
            "step 3645: generator_loss=-2.588029790473456e-09, discriminator_loss=9.315662282460835e-06\n",
            "step 3646: generator_loss=-7.393433421043483e-09, discriminator_loss=3.8135956401674775e-06\n",
            "step 3647: generator_loss=-2.417259725717713e-10, discriminator_loss=1.2059334721925552e-06\n",
            "step 3648: generator_loss=-1.0309857856327653e-08, discriminator_loss=5.964896445220802e-06\n",
            "step 3649: generator_loss=-2.679508281921983e-10, discriminator_loss=1.210426148645638e-06\n",
            "step 3650: generator_loss=-2.3281132577324115e-10, discriminator_loss=6.002996997267473e-07\n",
            "step 3651: generator_loss=-3.977506934926822e-10, discriminator_loss=1.1903467793672462e-06\n",
            "step 3652: generator_loss=-1.193201870641758e-09, discriminator_loss=1.5379602018583682e-06\n",
            "step 3653: generator_loss=-5.926797941313566e-10, discriminator_loss=1.3941137240180979e-06\n",
            "step 3654: generator_loss=-9.64902291400449e-09, discriminator_loss=1.688651423137344e-06\n",
            "step 3655: generator_loss=-2.324127001962495e-10, discriminator_loss=3.5324103464517975e-06\n",
            "step 3656: generator_loss=-3.856429398041428e-09, discriminator_loss=1.958995881068404e-06\n",
            "step 3657: generator_loss=-1.982725927884843e-10, discriminator_loss=1.8064879441226367e-06\n",
            "step 3658: generator_loss=-2.968793544333437e-10, discriminator_loss=1.079266667147749e-06\n",
            "step 3659: generator_loss=-4.4485201633470695e-10, discriminator_loss=1.1801216714957263e-06\n",
            "step 3660: generator_loss=-9.69972990816359e-10, discriminator_loss=3.454189254625817e-06\n",
            "step 3661: generator_loss=-1.2067442600738332e-09, discriminator_loss=1.4276027968662675e-06\n",
            "step 3662: generator_loss=-8.037654430914642e-10, discriminator_loss=1.0108193464475335e-06\n",
            "step 3663: generator_loss=-5.425129678826579e-09, discriminator_loss=1.0799514029713464e-06\n",
            "step 3664: generator_loss=-1.0243814685395591e-09, discriminator_loss=1.7284813793594367e-06\n",
            "step 3665: generator_loss=-3.3251651432308904e-10, discriminator_loss=4.523603820416611e-06\n",
            "step 3666: generator_loss=-2.771802787293609e-09, discriminator_loss=9.52606399096112e-07\n",
            "step 3667: generator_loss=-2.4978379364881675e-09, discriminator_loss=2.294034857186489e-06\n",
            "step 3668: generator_loss=-7.673721658107979e-10, discriminator_loss=2.5525278033455834e-06\n",
            "step 3669: generator_loss=-1.5586407720036277e-09, discriminator_loss=1.4386981774805463e-06\n",
            "step 3670: generator_loss=-3.7030924993075587e-09, discriminator_loss=4.131198238610523e-06\n",
            "step 3671: generator_loss=-2.6872242209208252e-09, discriminator_loss=2.00326758204028e-06\n",
            "step 3672: generator_loss=-2.695291212440054e-10, discriminator_loss=6.531128065034864e-07\n",
            "step 3673: generator_loss=-2.665161147330508e-10, discriminator_loss=2.740025593084283e-06\n",
            "step 3674: generator_loss=-9.620618746097875e-10, discriminator_loss=5.484550456458237e-06\n",
            "step 3675: generator_loss=-1.1266117205810389e-10, discriminator_loss=5.592851834990142e-07\n",
            "step 3676: generator_loss=-8.811824603327523e-10, discriminator_loss=1.1993759017059347e-06\n",
            "step 3677: generator_loss=-2.1236603586771707e-09, discriminator_loss=4.04219281335827e-06\n",
            "step 3678: generator_loss=-5.158016791462217e-10, discriminator_loss=1.8301124100617017e-06\n",
            "step 3679: generator_loss=-4.740242331990885e-08, discriminator_loss=1.6488245364598697e-06\n",
            "step 3680: generator_loss=-8.847234056474917e-11, discriminator_loss=5.541272116715845e-07\n",
            "step 3681: generator_loss=-1.6137018388207025e-09, discriminator_loss=9.60959027906938e-08\n",
            "step 3682: generator_loss=-1.0211054224384952e-09, discriminator_loss=1.1828166179839172e-06\n",
            "step 3683: generator_loss=-2.3492487954968055e-09, discriminator_loss=2.3513211999670602e-06\n",
            "step 3684: generator_loss=-3.1071273332017313e-10, discriminator_loss=1.3256777720016544e-06\n",
            "step 3685: generator_loss=-7.822271164137362e-10, discriminator_loss=2.8153194762126077e-06\n",
            "step 3686: generator_loss=-1.489995488102025e-10, discriminator_loss=2.130872189809452e-06\n",
            "step 3687: generator_loss=-9.634314457329651e-10, discriminator_loss=3.074452024520724e-06\n",
            "step 3688: generator_loss=-3.1206040529419e-10, discriminator_loss=2.4201501673815073e-06\n",
            "step 3689: generator_loss=-2.2165917101801824e-08, discriminator_loss=1.8759889144348563e-06\n",
            "step 3690: generator_loss=-9.934171263381586e-10, discriminator_loss=4.004697018444858e-07\n",
            "step 3691: generator_loss=-1.2924714631878942e-09, discriminator_loss=3.990552158938954e-06\n",
            "step 3692: generator_loss=-4.3361619850301736e-10, discriminator_loss=6.257395170905511e-07\n",
            "step 3693: generator_loss=-1.672515126394103e-09, discriminator_loss=5.246089358479367e-07\n",
            "step 3694: generator_loss=-3.103841073048841e-10, discriminator_loss=1.1152304750794428e-06\n",
            "step 3695: generator_loss=-6.52728315841955e-10, discriminator_loss=5.795368451799732e-07\n",
            "step 3696: generator_loss=-9.612511897572062e-10, discriminator_loss=2.689807843125891e-06\n",
            "step 3697: generator_loss=-1.762063273069714e-10, discriminator_loss=1.3156228533262038e-06\n",
            "step 3698: generator_loss=-6.624332749005646e-10, discriminator_loss=1.6696377542757546e-06\n",
            "step 3699: generator_loss=-2.4698132428113695e-10, discriminator_loss=3.1106307574191305e-07\n",
            "step 3700: generator_loss=-7.03235858434681e-10, discriminator_loss=2.7276453238300746e-06\n",
            "step 3701: generator_loss=-5.929723378983454e-10, discriminator_loss=2.061918621620862e-06\n",
            "step 3702: generator_loss=-5.178008244399734e-09, discriminator_loss=2.703921154534328e-06\n",
            "step 3703: generator_loss=-5.486133769494472e-10, discriminator_loss=7.708745783929771e-07\n",
            "step 3704: generator_loss=-1.4654910618361328e-09, discriminator_loss=3.281057843196322e-06\n",
            "step 3705: generator_loss=-1.0949335882415312e-09, discriminator_loss=5.758813017564535e-07\n",
            "step 3706: generator_loss=-5.95073323950146e-10, discriminator_loss=1.163385149993701e-06\n",
            "step 3707: generator_loss=-1.4485020127796844e-10, discriminator_loss=5.511310973815853e-06\n",
            "step 3708: generator_loss=-1.2589761455572557e-09, discriminator_loss=8.835053449729457e-06\n",
            "step 3709: generator_loss=-3.667627090919723e-09, discriminator_loss=2.5366175577801187e-06\n",
            "step 3710: generator_loss=-5.237204003805118e-10, discriminator_loss=8.554722512599255e-07\n",
            "step 3711: generator_loss=-2.3236332302722928e-10, discriminator_loss=6.589427243852697e-07\n",
            "step 3712: generator_loss=-4.4886946937161554e-10, discriminator_loss=9.316224804933881e-07\n",
            "step 3713: generator_loss=-1.640086955134734e-10, discriminator_loss=4.868513201472524e-07\n",
            "step 3714: generator_loss=-1.0629912228221627e-10, discriminator_loss=1.667676087890868e-06\n",
            "step 3715: generator_loss=-1.7713450151113364e-10, discriminator_loss=2.778361249511363e-06\n",
            "step 3716: generator_loss=-3.317849883721635e-10, discriminator_loss=3.2551491813137545e-07\n",
            "step 3717: generator_loss=-6.518898754137581e-09, discriminator_loss=1.631930899748113e-06\n",
            "step 3718: generator_loss=-2.0354287699753115e-10, discriminator_loss=2.4639289222250227e-06\n",
            "step 3719: generator_loss=-8.963511877180252e-11, discriminator_loss=1.006913748824445e-06\n",
            "step 3720: generator_loss=-8.28042256983963e-09, discriminator_loss=2.6116565550182713e-06\n",
            "step 3721: generator_loss=-6.537884122970183e-10, discriminator_loss=1.9706258171936497e-06\n",
            "step 3722: generator_loss=-7.537753754505161e-10, discriminator_loss=9.558435749568162e-07\n",
            "step 3723: generator_loss=-2.3341778510044264e-10, discriminator_loss=1.2714580179817858e-06\n",
            "step 3724: generator_loss=-7.367891297072049e-10, discriminator_loss=7.25671725376742e-06\n",
            "step 3725: generator_loss=-1.0758681723288532e-09, discriminator_loss=7.200396225925942e-07\n",
            "step 3726: generator_loss=-1.409190653056669e-09, discriminator_loss=9.55746827457915e-07\n",
            "step 3727: generator_loss=-2.531760079360623e-10, discriminator_loss=1.9538554170139832e-06\n",
            "step 3728: generator_loss=-4.631624528350642e-10, discriminator_loss=8.71373231348116e-07\n",
            "step 3729: generator_loss=-8.00613186857646e-10, discriminator_loss=1.296963432650955e-06\n",
            "step 3730: generator_loss=-6.69060640223762e-10, discriminator_loss=5.513726136996411e-06\n",
            "step 3731: generator_loss=-1.360891954682586e-09, discriminator_loss=6.178919988997222e-07\n",
            "step 3732: generator_loss=-1.3794723696669564e-10, discriminator_loss=1.00355237009353e-06\n",
            "step 3733: generator_loss=-3.682336102706074e-10, discriminator_loss=2.20192805500119e-06\n",
            "step 3734: generator_loss=-4.289444355265459e-09, discriminator_loss=6.902334916958353e-07\n",
            "step 3735: generator_loss=-3.622585287299529e-10, discriminator_loss=1.3402496961134602e-06\n",
            "step 3736: generator_loss=-1.746159661308866e-08, discriminator_loss=8.505039659212343e-07\n",
            "step 3737: generator_loss=-1.8517673505691334e-10, discriminator_loss=1.4311843870018492e-06\n",
            "step 3738: generator_loss=-2.3076112132258686e-09, discriminator_loss=1.1082355740654748e-05\n",
            "step 3739: generator_loss=-4.99203234305412e-10, discriminator_loss=6.70741792418994e-06\n",
            "step 3740: generator_loss=-5.258942725738791e-10, discriminator_loss=6.188257088979299e-07\n",
            "step 3741: generator_loss=-6.562512200325443e-10, discriminator_loss=1.075432010111399e-06\n",
            "step 3742: generator_loss=-1.15951226398181e-09, discriminator_loss=7.975923494996096e-07\n",
            "step 3743: generator_loss=-1.8108566868235698e-09, discriminator_loss=1.422092736902414e-07\n",
            "step 3744: generator_loss=-8.670580364800173e-10, discriminator_loss=9.466191954743408e-07\n",
            "step 3745: generator_loss=-4.5242537494161184e-10, discriminator_loss=1.456322820558853e-06\n",
            "step 3746: generator_loss=-1.3274942922691935e-08, discriminator_loss=9.552863957651425e-07\n",
            "step 3747: generator_loss=-7.726022599463533e-11, discriminator_loss=8.393497523684346e-07\n",
            "step 3748: generator_loss=-1.0802859717884417e-09, discriminator_loss=1.2527972330644843e-06\n",
            "step 3749: generator_loss=-1.0072069844824227e-09, discriminator_loss=3.4653692182473605e-06\n",
            "step 3750: generator_loss=-4.945032383574244e-09, discriminator_loss=1.418752162862802e-06\n",
            "step 3751: generator_loss=-1.9780279636449905e-09, discriminator_loss=7.822910106369818e-07\n",
            "step 3752: generator_loss=-2.8034910504182164e-10, discriminator_loss=3.6965576555303414e-07\n",
            "step 3753: generator_loss=-2.5988882157435e-09, discriminator_loss=8.132493576340494e-07\n",
            "step 3754: generator_loss=-6.353511849965798e-08, discriminator_loss=9.134418519352039e-07\n",
            "step 3755: generator_loss=-3.0889490965080313e-10, discriminator_loss=8.306383278977592e-07\n",
            "step 3756: generator_loss=-4.188678293104431e-10, discriminator_loss=1.991309773075045e-06\n",
            "step 3757: generator_loss=-2.5168611639259098e-09, discriminator_loss=1.1053547268602415e-06\n",
            "step 3758: generator_loss=-1.0581986398250365e-09, discriminator_loss=1.1674437701003626e-06\n",
            "step 3759: generator_loss=-3.283707195045338e-10, discriminator_loss=1.809987679735059e-06\n",
            "step 3760: generator_loss=-8.762910397308588e-10, discriminator_loss=2.4535654574719956e-06\n",
            "step 3761: generator_loss=-1.7752632697209947e-10, discriminator_loss=2.644272399265901e-06\n",
            "step 3762: generator_loss=-7.384409195232422e-10, discriminator_loss=1.9329454516991973e-06\n",
            "step 3763: generator_loss=-6.452738343654119e-10, discriminator_loss=1.1073706218667212e-06\n",
            "step 3764: generator_loss=-2.1757449175652255e-09, discriminator_loss=3.128582193312468e-06\n",
            "step 3765: generator_loss=-7.749883934593527e-08, discriminator_loss=9.83936615739367e-07\n",
            "step 3766: generator_loss=-1.124368709248813e-09, discriminator_loss=3.108233386228676e-06\n",
            "step 3767: generator_loss=-8.44385450449181e-10, discriminator_loss=8.973057674666052e-07\n",
            "step 3768: generator_loss=-2.7074231745416455e-10, discriminator_loss=3.339213435538113e-06\n",
            "step 3769: generator_loss=-1.5376407092038136e-10, discriminator_loss=2.986202844112995e-06\n",
            "step 3770: generator_loss=-2.1481469936190933e-09, discriminator_loss=1.3807029972667806e-06\n",
            "step 3771: generator_loss=-2.5115950985643565e-10, discriminator_loss=5.47743684364832e-06\n",
            "step 3772: generator_loss=-1.6535527391781102e-09, discriminator_loss=7.46985961086466e-07\n",
            "step 3773: generator_loss=-6.729298007712714e-09, discriminator_loss=4.536219876172254e-06\n",
            "step 3774: generator_loss=-1.033423013829804e-09, discriminator_loss=5.284932740323711e-06\n",
            "step 3775: generator_loss=-6.546366115856017e-09, discriminator_loss=3.3411347430956084e-06\n",
            "step 3776: generator_loss=-3.346720123253988e-10, discriminator_loss=2.226158130724798e-06\n",
            "step 3777: generator_loss=-6.583206202392944e-10, discriminator_loss=2.236731461380259e-06\n",
            "step 3778: generator_loss=-5.2296149632979905e-09, discriminator_loss=1.4044157978787553e-06\n",
            "step 3779: generator_loss=-4.6329240444009656e-10, discriminator_loss=1.6073131519078743e-06\n",
            "step 3780: generator_loss=-5.620062637490264e-09, discriminator_loss=4.654670192394406e-06\n",
            "step 3781: generator_loss=-2.0599868477688688e-09, discriminator_loss=1.0253878599542077e-06\n",
            "step 3782: generator_loss=-2.978698121491874e-10, discriminator_loss=4.6481184767799277e-07\n",
            "step 3783: generator_loss=-2.8602125112797694e-09, discriminator_loss=2.022109129029559e-06\n",
            "step 3784: generator_loss=-3.166488182770877e-10, discriminator_loss=1.3226107284936006e-06\n",
            "step 3785: generator_loss=-6.053323398091948e-10, discriminator_loss=1.9712192624865565e-06\n",
            "step 3786: generator_loss=-2.2267649946172696e-09, discriminator_loss=3.1957222290657228e-06\n",
            "step 3787: generator_loss=-5.704725025701407e-10, discriminator_loss=4.362317156392237e-07\n",
            "step 3788: generator_loss=-4.67675398407863e-10, discriminator_loss=1.1932560255445424e-06\n",
            "step 3789: generator_loss=-3.2293279161876853e-09, discriminator_loss=2.4983960429381113e-06\n",
            "step 3790: generator_loss=-3.84046359158674e-08, discriminator_loss=2.169983190469793e-06\n",
            "step 3791: generator_loss=-2.432652301820326e-09, discriminator_loss=4.578767516250082e-07\n",
            "step 3792: generator_loss=-1.0882260370603802e-10, discriminator_loss=6.371577683239593e-07\n",
            "step 3793: generator_loss=-9.009409329685525e-10, discriminator_loss=5.222040044827736e-07\n",
            "step 3794: generator_loss=-7.416287584049996e-10, discriminator_loss=5.801879865430237e-07\n",
            "step 3795: generator_loss=-7.029968829286304e-10, discriminator_loss=2.668578872544458e-06\n",
            "step 3796: generator_loss=-4.531488517756088e-10, discriminator_loss=4.396156782604521e-06\n",
            "step 3797: generator_loss=-1.4921597291106536e-09, discriminator_loss=8.579141649533994e-06\n",
            "step 3798: generator_loss=-7.973021132201552e-10, discriminator_loss=8.016550623324292e-07\n",
            "step 3799: generator_loss=-2.7623073273197463e-10, discriminator_loss=6.414358040274237e-07\n",
            "step 3800: generator_loss=-1.7916257366579202e-10, discriminator_loss=7.322939836740261e-07\n",
            "step 3801: generator_loss=-2.3138786720000581e-10, discriminator_loss=5.902464181417599e-06\n",
            "step 3802: generator_loss=-1.6168468786048606e-09, discriminator_loss=1.456708332625567e-06\n",
            "step 3803: generator_loss=-1.0165808472795135e-10, discriminator_loss=3.942087005270878e-06\n",
            "step 3804: generator_loss=-6.046922962354984e-09, discriminator_loss=6.894217108310841e-07\n",
            "step 3805: generator_loss=-4.3251624504137e-09, discriminator_loss=6.175193334456708e-07\n",
            "step 3806: generator_loss=-2.94006197165686e-09, discriminator_loss=2.7038352072850103e-06\n",
            "step 3807: generator_loss=-4.18463097506816e-10, discriminator_loss=3.099389005001285e-06\n",
            "step 3808: generator_loss=-5.04056218986193e-09, discriminator_loss=7.377818747045239e-07\n",
            "step 3809: generator_loss=-1.7050082457004123e-09, discriminator_loss=1.421096567355562e-05\n",
            "step 3810: generator_loss=-8.126050388135297e-10, discriminator_loss=2.4660951112309704e-06\n",
            "step 3811: generator_loss=-1.7627435067169017e-09, discriminator_loss=2.919010739788064e-06\n",
            "step 3812: generator_loss=-1.0125912330849474e-09, discriminator_loss=2.8437989385565743e-06\n",
            "step 3813: generator_loss=-4.547068555016409e-10, discriminator_loss=1.2561590665427502e-06\n",
            "step 3814: generator_loss=-2.187430903077825e-09, discriminator_loss=1.6947270751188626e-06\n",
            "step 3815: generator_loss=-5.920808288095714e-10, discriminator_loss=1.6921214864851208e-06\n",
            "step 3816: generator_loss=-7.067696428109116e-10, discriminator_loss=9.16824831165286e-07\n",
            "step 3817: generator_loss=-4.545844811687516e-10, discriminator_loss=1.7269447880607913e-06\n",
            "step 3818: generator_loss=-6.107746308714468e-09, discriminator_loss=8.076185054051166e-07\n",
            "step 3819: generator_loss=-7.50490170009499e-10, discriminator_loss=2.0893876353511587e-06\n",
            "step 3820: generator_loss=-8.634323256373477e-10, discriminator_loss=1.3710272241951316e-06\n",
            "step 3821: generator_loss=-1.0757289503615652e-09, discriminator_loss=1.478624085393676e-06\n",
            "step 3822: generator_loss=-2.6742119629830086e-10, discriminator_loss=3.255146566516487e-06\n",
            "step 3823: generator_loss=-5.019160642660836e-10, discriminator_loss=5.719926775782369e-06\n",
            "step 3824: generator_loss=-6.417618658716151e-10, discriminator_loss=7.63533137160266e-07\n",
            "step 3825: generator_loss=-3.19348381072615e-10, discriminator_loss=3.541674686857732e-06\n",
            "step 3826: generator_loss=-3.965392281202185e-08, discriminator_loss=1.9588362647482427e-06\n",
            "step 3827: generator_loss=-9.029363923218625e-10, discriminator_loss=9.042900614986138e-07\n",
            "step 3828: generator_loss=-1.3889324135263337e-09, discriminator_loss=8.835794460537727e-07\n",
            "step 3829: generator_loss=-7.345411501269439e-10, discriminator_loss=2.9616148822242394e-06\n",
            "step 3830: generator_loss=-1.5390351215671672e-09, discriminator_loss=3.3568221624591388e-06\n",
            "step 3831: generator_loss=-1.36809535922211e-10, discriminator_loss=1.7275821164730587e-06\n",
            "step 3832: generator_loss=-1.3277740018580175e-09, discriminator_loss=1.1980888302787207e-05\n",
            "step 3833: generator_loss=-2.441220559035173e-10, discriminator_loss=7.794190537424583e-07\n",
            "step 3834: generator_loss=-6.454065060168546e-11, discriminator_loss=2.176898760808399e-06\n",
            "step 3835: generator_loss=-3.610793330999229e-10, discriminator_loss=8.541172746845405e-07\n",
            "step 3836: generator_loss=-2.616221461693158e-09, discriminator_loss=1.997460913116811e-06\n",
            "step 3837: generator_loss=-1.0703418151791766e-09, discriminator_loss=3.102892151218839e-06\n",
            "step 3838: generator_loss=-6.410564856729195e-10, discriminator_loss=5.643501026497688e-07\n",
            "step 3839: generator_loss=-1.1908409813798926e-09, discriminator_loss=2.351304146941402e-06\n",
            "step 3840: generator_loss=-1.4535623815703502e-09, discriminator_loss=1.047574642143445e-06\n",
            "step 3841: generator_loss=-1.4357588451474612e-09, discriminator_loss=6.011492246216221e-07\n",
            "step 3842: generator_loss=-1.8506602916801285e-09, discriminator_loss=9.926985740094096e-07\n",
            "step 3843: generator_loss=-2.514306263190491e-10, discriminator_loss=2.31522199101164e-06\n",
            "step 3844: generator_loss=-8.13079659156557e-10, discriminator_loss=3.5093348742520902e-06\n",
            "step 3845: generator_loss=-1.9242565318933202e-09, discriminator_loss=1.8257017018186161e-06\n",
            "step 3846: generator_loss=-1.0715266451910566e-09, discriminator_loss=1.3801671912005986e-06\n",
            "step 3847: generator_loss=-1.941471206023948e-09, discriminator_loss=1.9903259271814022e-06\n",
            "step 3848: generator_loss=-5.678427505984018e-09, discriminator_loss=5.372943178372225e-06\n",
            "step 3849: generator_loss=-3.765270872868598e-10, discriminator_loss=2.986731715282076e-06\n",
            "step 3850: generator_loss=-1.9086114633193318e-10, discriminator_loss=4.381966391520109e-06\n",
            "step 3851: generator_loss=-1.477528654980631e-10, discriminator_loss=7.063820817165833e-07\n",
            "step 3852: generator_loss=-2.677948973683897e-10, discriminator_loss=4.443429133971222e-06\n",
            "step 3853: generator_loss=-4.5678882898414486e-10, discriminator_loss=1.7470034663347178e-06\n",
            "step 3854: generator_loss=-1.4282502958096188e-10, discriminator_loss=3.4327547382417833e-06\n",
            "step 3855: generator_loss=-4.705997813658769e-10, discriminator_loss=5.172603323444491e-06\n",
            "step 3856: generator_loss=-8.401551121473005e-10, discriminator_loss=1.914490439958172e-06\n",
            "step 3857: generator_loss=-4.820593924037553e-10, discriminator_loss=1.229618419529288e-06\n",
            "step 3858: generator_loss=-2.366603579773141e-10, discriminator_loss=5.2093068916292395e-06\n",
            "step 3859: generator_loss=-4.15423562216688e-09, discriminator_loss=4.6516208840330364e-07\n",
            "step 3860: generator_loss=-1.4679594206867819e-09, discriminator_loss=2.229297706435318e-06\n",
            "step 3861: generator_loss=-1.2546261807244719e-09, discriminator_loss=3.970146451592882e-07\n",
            "step 3862: generator_loss=-1.1190280924111562e-09, discriminator_loss=3.6967758205719292e-06\n",
            "step 3863: generator_loss=-2.970018952996867e-10, discriminator_loss=3.203757387382211e-06\n",
            "step 3864: generator_loss=-7.874186858103371e-10, discriminator_loss=1.735421733428666e-06\n",
            "step 3865: generator_loss=-4.987567026049078e-10, discriminator_loss=5.335002128958877e-07\n",
            "step 3866: generator_loss=-7.456751660583905e-09, discriminator_loss=3.762909557281091e-07\n",
            "step 3867: generator_loss=-3.5429827960342664e-09, discriminator_loss=3.3203298244188773e-06\n",
            "step 3868: generator_loss=-2.4635429252128915e-09, discriminator_loss=1.1389756764401682e-05\n",
            "step 3869: generator_loss=-6.955109821404903e-10, discriminator_loss=1.0818702094184118e-06\n",
            "step 3870: generator_loss=-2.953495781277127e-10, discriminator_loss=4.538570919976337e-06\n",
            "step 3871: generator_loss=-3.9501282800280535e-10, discriminator_loss=8.497214025737776e-07\n",
            "step 3872: generator_loss=-5.823543314242841e-10, discriminator_loss=2.8012761958962074e-06\n",
            "step 3873: generator_loss=-1.9695987896195533e-10, discriminator_loss=1.2585060176206753e-06\n",
            "step 3874: generator_loss=-9.901116593269421e-10, discriminator_loss=1.593070123817597e-06\n",
            "step 3875: generator_loss=-1.7359198523081432e-09, discriminator_loss=1.2124572094762698e-05\n",
            "step 3876: generator_loss=-1.5318332713398775e-10, discriminator_loss=6.83185760408378e-07\n",
            "step 3877: generator_loss=-8.192293510234094e-10, discriminator_loss=4.575927960104309e-06\n",
            "step 3878: generator_loss=-6.105331351591303e-09, discriminator_loss=9.279191885980254e-07\n",
            "step 3879: generator_loss=-1.4188616948018762e-09, discriminator_loss=9.420093647349859e-07\n",
            "step 3880: generator_loss=-2.9236565946000326e-10, discriminator_loss=7.85316615292686e-07\n",
            "step 3881: generator_loss=-9.769950404248107e-10, discriminator_loss=1.290737259296293e-06\n",
            "step 3882: generator_loss=-4.726303792779163e-10, discriminator_loss=5.800029612146318e-06\n",
            "step 3883: generator_loss=-3.318448293931908e-10, discriminator_loss=1.030672592605697e-06\n",
            "step 3884: generator_loss=-5.574504746697073e-10, discriminator_loss=8.350191933459428e-07\n",
            "step 3885: generator_loss=-1.3260128550740546e-09, discriminator_loss=1.6847585584400804e-06\n",
            "step 3886: generator_loss=-2.10519579546542e-09, discriminator_loss=3.869272859446937e-06\n",
            "step 3887: generator_loss=-3.045597996020888e-09, discriminator_loss=2.136502416760777e-06\n",
            "step 3888: generator_loss=-7.703373494649668e-10, discriminator_loss=2.817786025843816e-06\n",
            "step 3889: generator_loss=-7.052785022665375e-10, discriminator_loss=1.1242896107432898e-06\n",
            "step 3890: generator_loss=-2.6652877127553154e-10, discriminator_loss=8.808539178062347e-07\n",
            "step 3891: generator_loss=-2.9090527764452645e-09, discriminator_loss=1.8265400285599753e-06\n",
            "step 3892: generator_loss=-1.353956502470055e-09, discriminator_loss=1.1753577382478397e-06\n",
            "step 3893: generator_loss=-1.2284604444801062e-09, discriminator_loss=1.2497542911660275e-06\n",
            "step 3894: generator_loss=-1.1861864268603028e-10, discriminator_loss=9.321401535089535e-07\n",
            "step 3895: generator_loss=-2.751427419234176e-10, discriminator_loss=1.0716503311414272e-06\n",
            "step 3896: generator_loss=-1.493438261945812e-08, discriminator_loss=2.406040721325553e-06\n",
            "step 3897: generator_loss=-7.425021708584723e-10, discriminator_loss=6.523542310787889e-07\n",
            "step 3898: generator_loss=-2.467178683573934e-10, discriminator_loss=1.139171786235238e-06\n",
            "step 3899: generator_loss=-9.081864427162856e-11, discriminator_loss=3.1314614261646057e-06\n",
            "step 3900: generator_loss=-6.15906881051842e-10, discriminator_loss=5.301045007399807e-07\n",
            "step 3901: generator_loss=-4.123580921167047e-10, discriminator_loss=4.5244570401337114e-07\n",
            "step 3902: generator_loss=-1.5178205359234198e-09, discriminator_loss=1.0935002592304954e-06\n",
            "step 3903: generator_loss=-2.3255017911338882e-09, discriminator_loss=8.095951670838986e-06\n",
            "step 3904: generator_loss=-1.4787884250466732e-09, discriminator_loss=2.6703935418481706e-06\n",
            "step 3905: generator_loss=-3.798098224816471e-10, discriminator_loss=1.2050054465362336e-06\n",
            "step 3906: generator_loss=-1.902935725661692e-10, discriminator_loss=6.431472229451174e-06\n",
            "step 3907: generator_loss=-5.6689963834344326e-09, discriminator_loss=1.4537008610204794e-06\n",
            "step 3908: generator_loss=-9.021214886217876e-10, discriminator_loss=1.9653989511425607e-06\n",
            "step 3909: generator_loss=-1.747232636351015e-10, discriminator_loss=7.312718821594899e-07\n",
            "step 3910: generator_loss=-8.58264570524625e-10, discriminator_loss=1.6288307733702823e-06\n",
            "step 3911: generator_loss=-2.654626518605596e-10, discriminator_loss=4.342476245255966e-07\n",
            "step 3912: generator_loss=-4.359672622911148e-10, discriminator_loss=1.3495481425707112e-06\n",
            "step 3913: generator_loss=-2.2566133683898926e-10, discriminator_loss=5.531401711778017e-06\n",
            "step 3914: generator_loss=-8.300592990728717e-10, discriminator_loss=1.5626337699359283e-06\n",
            "step 3915: generator_loss=-5.8827311910647495e-09, discriminator_loss=1.022622541313467e-06\n",
            "step 3916: generator_loss=-3.1161545566149584e-10, discriminator_loss=1.4034903870197013e-06\n",
            "step 3917: generator_loss=-3.898986411510208e-10, discriminator_loss=1.1547373105713632e-05\n",
            "step 3918: generator_loss=-1.4663498193456803e-09, discriminator_loss=5.948862735749572e-07\n",
            "step 3919: generator_loss=-1.1193882487603446e-09, discriminator_loss=1.0425563914395752e-06\n",
            "step 3920: generator_loss=-2.3296864437583054e-10, discriminator_loss=4.3764845258920104e-07\n",
            "step 3921: generator_loss=-9.161914560351647e-10, discriminator_loss=1.7246072729903972e-06\n",
            "step 3922: generator_loss=-5.889569720807231e-09, discriminator_loss=1.1973295386269456e-06\n",
            "step 3923: generator_loss=-1.0322089849523763e-09, discriminator_loss=2.3192947082861792e-06\n",
            "step 3924: generator_loss=-4.4263784304554576e-10, discriminator_loss=3.0122162115731044e-06\n",
            "step 3925: generator_loss=-5.200830877072349e-10, discriminator_loss=3.647612061286054e-07\n",
            "step 3926: generator_loss=-8.419028807438167e-10, discriminator_loss=2.2106662527221488e-06\n",
            "step 3927: generator_loss=-1.659096415806971e-09, discriminator_loss=5.378299192670966e-07\n",
            "step 3928: generator_loss=-9.85307724299389e-10, discriminator_loss=7.257116976688849e-06\n",
            "step 3929: generator_loss=-4.3573221419901387e-11, discriminator_loss=3.202321522621787e-06\n",
            "step 3930: generator_loss=-3.822592242741507e-10, discriminator_loss=1.0141533266505576e-06\n",
            "step 3931: generator_loss=-1.6881919473465956e-10, discriminator_loss=3.1947618026606506e-06\n",
            "step 3932: generator_loss=-8.925670758053172e-10, discriminator_loss=1.5084515325725079e-06\n",
            "step 3933: generator_loss=-4.180427531919051e-11, discriminator_loss=6.765258149243891e-07\n",
            "step 3934: generator_loss=-1.307177255327474e-09, discriminator_loss=9.105507956519432e-07\n",
            "step 3935: generator_loss=-1.2506060631523042e-09, discriminator_loss=5.27981228515273e-07\n",
            "step 3936: generator_loss=-4.574830736459035e-09, discriminator_loss=2.0101135760342004e-06\n",
            "step 3937: generator_loss=-2.117433783865863e-09, discriminator_loss=1.833153874031268e-06\n",
            "step 3938: generator_loss=-4.282915355702244e-09, discriminator_loss=3.3061899102904135e-06\n",
            "step 3939: generator_loss=-3.228068368166248e-10, discriminator_loss=2.0705383576569147e-06\n",
            "step 3940: generator_loss=-9.263775163637078e-11, discriminator_loss=2.9271457151480718e-06\n",
            "step 3941: generator_loss=-1.59758928308662e-09, discriminator_loss=7.368246883743268e-07\n",
            "step 3942: generator_loss=-4.976104417409033e-09, discriminator_loss=6.522039711853722e-06\n",
            "step 3943: generator_loss=-7.720581951531358e-10, discriminator_loss=5.096443942420592e-07\n",
            "step 3944: generator_loss=-2.987987191005459e-09, discriminator_loss=6.508905130431231e-07\n",
            "step 3945: generator_loss=-1.926061532486756e-09, discriminator_loss=4.6875102270860225e-06\n",
            "step 3946: generator_loss=-6.422385401272379e-10, discriminator_loss=4.94064397571492e-06\n",
            "step 3947: generator_loss=-1.5497048089230248e-10, discriminator_loss=4.477760285226395e-06\n",
            "step 3948: generator_loss=-4.511734874590445e-10, discriminator_loss=1.0218121815341874e-06\n",
            "step 3949: generator_loss=-5.338135489196816e-10, discriminator_loss=9.731346608532476e-07\n",
            "step 3950: generator_loss=-1.6885964848611934e-10, discriminator_loss=3.0448143206740497e-06\n",
            "step 3951: generator_loss=-5.129191515962361e-10, discriminator_loss=2.7501403110363754e-06\n",
            "step 3952: generator_loss=-1.8150150826734546e-10, discriminator_loss=1.75143679825851e-06\n",
            "step 3953: generator_loss=-2.2784688025190292e-10, discriminator_loss=1.0033455737357144e-06\n",
            "step 3954: generator_loss=-7.985558880818644e-10, discriminator_loss=2.1186942831263877e-06\n",
            "step 3955: generator_loss=-1.654024278652244e-10, discriminator_loss=1.1671994570860988e-06\n",
            "step 3956: generator_loss=-2.1349330636688535e-10, discriminator_loss=1.9266833533038152e-06\n",
            "step 3957: generator_loss=-3.655308500327692e-09, discriminator_loss=1.129252154896676e-06\n",
            "step 3958: generator_loss=-3.5839231582457387e-10, discriminator_loss=9.298602208218654e-07\n",
            "step 3959: generator_loss=-3.322010000417208e-09, discriminator_loss=1.2854574151788256e-06\n",
            "step 3960: generator_loss=-2.9932240019903134e-10, discriminator_loss=2.3053230506775435e-06\n",
            "step 3961: generator_loss=-2.7421886983347576e-09, discriminator_loss=1.3533312994695734e-06\n",
            "step 3962: generator_loss=-9.112018695134338e-09, discriminator_loss=1.654800712458382e-06\n",
            "step 3963: generator_loss=-1.9916794880003863e-09, discriminator_loss=1.8170724160881946e-06\n",
            "step 3964: generator_loss=-6.558746878937427e-10, discriminator_loss=7.901173830759944e-07\n",
            "step 3965: generator_loss=-5.587429408038247e-10, discriminator_loss=5.011012490285793e-06\n",
            "step 3966: generator_loss=-1.0567322017429603e-10, discriminator_loss=5.081301424070261e-07\n",
            "step 3967: generator_loss=-4.570307687856712e-09, discriminator_loss=2.581973149062833e-06\n",
            "step 3968: generator_loss=-2.8895372206072523e-10, discriminator_loss=1.9017337535842671e-06\n",
            "step 3969: generator_loss=-1.9296633180232448e-09, discriminator_loss=1.1853020396301872e-06\n",
            "step 3970: generator_loss=-1.0853054011050745e-09, discriminator_loss=1.2526361388154328e-06\n",
            "step 3971: generator_loss=-8.375610760502639e-10, discriminator_loss=5.827756126564054e-07\n",
            "step 3972: generator_loss=-4.3867398602515095e-10, discriminator_loss=4.045982393563463e-07\n",
            "step 3973: generator_loss=-6.516079675833453e-09, discriminator_loss=3.1412156431542826e-07\n",
            "step 3974: generator_loss=-2.887151850927694e-09, discriminator_loss=2.0560980829031905e-06\n",
            "step 3975: generator_loss=-9.131699840736474e-10, discriminator_loss=3.4607230645633535e-06\n",
            "step 3976: generator_loss=-2.23730450832349e-10, discriminator_loss=9.249644108422217e-07\n",
            "step 3977: generator_loss=-3.511182455895323e-09, discriminator_loss=2.271077164550661e-06\n",
            "step 3978: generator_loss=-5.507992395514805e-10, discriminator_loss=1.85800797680713e-06\n",
            "step 3979: generator_loss=-1.1274406963579509e-09, discriminator_loss=1.966882109627477e-06\n",
            "step 3980: generator_loss=-3.0628741209959287e-10, discriminator_loss=1.4843822100374382e-06\n",
            "step 3981: generator_loss=-5.005631908971964e-09, discriminator_loss=3.914959961548448e-06\n",
            "step 3982: generator_loss=-1.487917122844351e-09, discriminator_loss=4.944327884004451e-06\n",
            "step 3983: generator_loss=-6.06017236393086e-10, discriminator_loss=9.204943012264266e-07\n",
            "step 3984: generator_loss=-4.00856403626193e-10, discriminator_loss=2.40096323977923e-06\n",
            "step 3985: generator_loss=-2.0533937217237508e-08, discriminator_loss=2.5407965154045087e-07\n",
            "step 3986: generator_loss=-2.376557006744662e-10, discriminator_loss=1.1221465001653996e-06\n",
            "step 3987: generator_loss=-2.1905693925461378e-10, discriminator_loss=5.186524845157692e-07\n",
            "step 3988: generator_loss=-2.7543274327967993e-09, discriminator_loss=4.075991455465555e-06\n",
            "step 3989: generator_loss=-1.3290930855891503e-10, discriminator_loss=1.2908536746181198e-06\n",
            "step 3990: generator_loss=-7.886360897657596e-09, discriminator_loss=4.0598814621262136e-07\n",
            "step 3991: generator_loss=-1.6691565907223094e-09, discriminator_loss=6.293939236456936e-07\n",
            "step 3992: generator_loss=-1.68719238580195e-09, discriminator_loss=3.090223799517844e-06\n",
            "step 3993: generator_loss=-5.356237675613329e-10, discriminator_loss=3.4839317208934517e-07\n",
            "step 3994: generator_loss=-1.6548091785750785e-09, discriminator_loss=1.0563278465269832e-06\n",
            "step 3995: generator_loss=-5.643540634814315e-10, discriminator_loss=1.2949140000273474e-06\n",
            "step 3996: generator_loss=-3.227267342253981e-10, discriminator_loss=3.14452250904651e-07\n",
            "step 3997: generator_loss=-2.2343665806445756e-10, discriminator_loss=2.3991046873561572e-06\n",
            "step 3998: generator_loss=-8.388545968962546e-10, discriminator_loss=1.3980621815790073e-06\n",
            "step 3999: generator_loss=-5.760617538541624e-10, discriminator_loss=2.5837807697826065e-06\n",
            "step 4000: generator_loss=-9.872402451094331e-09, discriminator_loss=4.00388358912096e-07\n",
            "step 4001: generator_loss=-1.3138903298681726e-09, discriminator_loss=4.439365056896349e-06\n",
            "step 4002: generator_loss=-3.329847508837247e-10, discriminator_loss=5.717618591916107e-07\n",
            "step 4003: generator_loss=-2.611057758894475e-10, discriminator_loss=1.540878201922169e-06\n",
            "step 4004: generator_loss=-5.444634743057009e-10, discriminator_loss=1.0011831363954116e-06\n",
            "step 4005: generator_loss=-1.2869498799972234e-09, discriminator_loss=4.507632638706127e-06\n",
            "step 4006: generator_loss=-7.702487536676017e-10, discriminator_loss=1.665046966081718e-06\n",
            "step 4007: generator_loss=-3.5890040939179357e-10, discriminator_loss=2.2944254851609003e-06\n",
            "step 4008: generator_loss=-2.1522662763118205e-08, discriminator_loss=5.070764927950222e-07\n",
            "step 4009: generator_loss=-9.06780692200293e-11, discriminator_loss=8.879744655132527e-07\n",
            "step 4010: generator_loss=-7.565593707070661e-10, discriminator_loss=2.081632374029141e-06\n",
            "step 4011: generator_loss=-6.752861603231963e-10, discriminator_loss=9.13385861167626e-07\n",
            "step 4012: generator_loss=-1.1555880558011822e-10, discriminator_loss=2.755788841568574e-07\n",
            "step 4013: generator_loss=-3.397436998398007e-09, discriminator_loss=1.0907866681009182e-06\n",
            "step 4014: generator_loss=-1.727155918285206e-10, discriminator_loss=4.163377411714464e-07\n",
            "step 4015: generator_loss=-1.7432764953806412e-10, discriminator_loss=2.2327769784169504e-06\n",
            "step 4016: generator_loss=-2.8090199055696985e-09, discriminator_loss=4.4309008444543e-06\n",
            "step 4017: generator_loss=-8.324939348991478e-11, discriminator_loss=2.014656502069556e-06\n",
            "step 4018: generator_loss=-3.0191704691873156e-10, discriminator_loss=1.288075395677879e-06\n",
            "step 4019: generator_loss=-2.098829998686824e-09, discriminator_loss=7.128618335627834e-07\n",
            "step 4020: generator_loss=-1.6852921835841528e-10, discriminator_loss=1.8360373132964014e-06\n",
            "step 4021: generator_loss=-7.167093030169269e-10, discriminator_loss=1.3814284329782822e-06\n",
            "step 4022: generator_loss=-9.59414103718359e-10, discriminator_loss=4.465113647711405e-07\n",
            "step 4023: generator_loss=-3.7564346078156063e-10, discriminator_loss=1.0207450031884946e-06\n",
            "step 4024: generator_loss=-2.2684526479466172e-10, discriminator_loss=4.769554379890906e-06\n",
            "step 4025: generator_loss=-1.1820318335242774e-10, discriminator_loss=2.225403022748651e-06\n",
            "step 4026: generator_loss=-3.9286063291399387e-10, discriminator_loss=8.255216243924224e-07\n",
            "step 4027: generator_loss=-2.7081641373882803e-09, discriminator_loss=8.270084776995645e-07\n",
            "step 4028: generator_loss=-2.1268650840511327e-08, discriminator_loss=4.65787792336414e-07\n",
            "step 4029: generator_loss=-8.061551981519699e-10, discriminator_loss=8.467117709187733e-07\n",
            "step 4030: generator_loss=-2.946548838256291e-10, discriminator_loss=2.663392479007598e-06\n",
            "step 4031: generator_loss=-3.9762201864412816e-10, discriminator_loss=1.2071393484802684e-06\n",
            "step 4032: generator_loss=-9.484131258119533e-10, discriminator_loss=9.386147326040373e-07\n",
            "step 4033: generator_loss=-2.678595401039985e-10, discriminator_loss=3.076172561122803e-06\n",
            "step 4034: generator_loss=-1.5277608067520987e-09, discriminator_loss=3.061801635340089e-06\n",
            "step 4035: generator_loss=-6.471860825030262e-10, discriminator_loss=3.415421588215395e-06\n",
            "step 4036: generator_loss=-2.1008833561708684e-10, discriminator_loss=7.570796242362121e-06\n",
            "step 4037: generator_loss=-6.470270541569789e-09, discriminator_loss=2.630164544825675e-06\n",
            "step 4038: generator_loss=-1.2314096409227204e-09, discriminator_loss=1.0697989409891306e-06\n",
            "step 4039: generator_loss=-1.143170558215445e-09, discriminator_loss=3.987850618614175e-07\n",
            "step 4040: generator_loss=-7.607375840379405e-10, discriminator_loss=7.722906048002187e-06\n",
            "step 4041: generator_loss=-2.5936919278990445e-10, discriminator_loss=1.2108364444429753e-06\n",
            "step 4042: generator_loss=-2.16771955940942e-09, discriminator_loss=1.073719658961636e-06\n",
            "step 4043: generator_loss=-1.5787401941302903e-10, discriminator_loss=1.5663224530726438e-06\n",
            "step 4044: generator_loss=-9.576435200386868e-10, discriminator_loss=6.9899397203698754e-06\n",
            "step 4045: generator_loss=-1.2516322200895047e-08, discriminator_loss=1.9082917788182385e-06\n",
            "step 4046: generator_loss=-2.453212633035662e-10, discriminator_loss=3.45486171227094e-07\n",
            "step 4047: generator_loss=-5.365721755801189e-10, discriminator_loss=3.5149623727193102e-06\n",
            "step 4048: generator_loss=-7.249238986872797e-10, discriminator_loss=2.5711351554491557e-06\n",
            "step 4049: generator_loss=-1.393879012212551e-09, discriminator_loss=1.9900901406799676e-06\n",
            "step 4050: generator_loss=-2.0160957625581233e-10, discriminator_loss=1.818465193537122e-06\n",
            "step 4051: generator_loss=-9.829009606221462e-09, discriminator_loss=9.903234285957296e-07\n",
            "step 4052: generator_loss=-1.3452083891252187e-10, discriminator_loss=1.7476635321145295e-06\n",
            "step 4053: generator_loss=-2.300839296864865e-09, discriminator_loss=3.163357860103133e-06\n",
            "step 4054: generator_loss=-8.465987910710737e-10, discriminator_loss=7.322463488890207e-07\n",
            "step 4055: generator_loss=-5.689946847020622e-10, discriminator_loss=4.6741394044147455e-07\n",
            "step 4056: generator_loss=-4.4951647959479146e-10, discriminator_loss=4.860195303990622e-07\n",
            "step 4057: generator_loss=-4.1384731197524616e-09, discriminator_loss=1.2143091225880198e-06\n",
            "step 4058: generator_loss=-2.4212812310686616e-10, discriminator_loss=1.567810954838933e-06\n",
            "step 4059: generator_loss=-8.826362973834989e-10, discriminator_loss=3.684746729959443e-07\n",
            "step 4060: generator_loss=-7.763533566018666e-11, discriminator_loss=7.737501618976239e-06\n",
            "step 4061: generator_loss=-9.93470528065643e-10, discriminator_loss=1.4355904340845882e-06\n",
            "step 4062: generator_loss=-1.1197423432918185e-08, discriminator_loss=2.063061629087315e-06\n",
            "step 4063: generator_loss=-1.154960127536242e-09, discriminator_loss=1.1749348232115153e-06\n",
            "step 4064: generator_loss=-1.2430300122545646e-09, discriminator_loss=2.6938673727272544e-06\n",
            "step 4065: generator_loss=-1.4449509366798452e-09, discriminator_loss=3.6144244859315222e-06\n",
            "step 4066: generator_loss=-2.567194234970316e-09, discriminator_loss=1.630617987302685e-07\n",
            "step 4067: generator_loss=-1.6804818647742081e-09, discriminator_loss=2.256011413237502e-07\n",
            "step 4068: generator_loss=-2.8990321254696028e-09, discriminator_loss=4.7677167458459735e-06\n",
            "step 4069: generator_loss=-6.26051885888046e-08, discriminator_loss=8.846744776747073e-07\n",
            "step 4070: generator_loss=-3.079729804511544e-09, discriminator_loss=1.4532568002323387e-06\n",
            "step 4071: generator_loss=-2.1943280525960063e-10, discriminator_loss=2.089271447403007e-06\n",
            "step 4072: generator_loss=-1.1505460584260163e-08, discriminator_loss=4.2085326867891126e-07\n",
            "step 4073: generator_loss=-1.214454314890645e-09, discriminator_loss=6.426145091609214e-07\n",
            "step 4074: generator_loss=-1.7950918529408e-09, discriminator_loss=1.6191542044907692e-06\n",
            "step 4075: generator_loss=-2.9630355946608233e-09, discriminator_loss=1.7702666355035035e-06\n",
            "step 4076: generator_loss=-1.2977888763643364e-09, discriminator_loss=9.87730459200975e-07\n",
            "step 4077: generator_loss=-4.091834926445159e-10, discriminator_loss=3.3688255030028813e-07\n",
            "step 4078: generator_loss=-4.677055409629816e-10, discriminator_loss=6.906157068442553e-07\n",
            "step 4079: generator_loss=-1.1668497279515577e-09, discriminator_loss=2.092233444273006e-06\n",
            "step 4080: generator_loss=-3.7729935842278906e-10, discriminator_loss=1.4795347169638262e-06\n",
            "step 4081: generator_loss=-5.776856770722816e-10, discriminator_loss=3.8760995835218637e-07\n",
            "step 4082: generator_loss=-1.687683048867683e-10, discriminator_loss=3.197220905803988e-07\n",
            "step 4083: generator_loss=-9.327651540047555e-09, discriminator_loss=1.4965567061153706e-06\n",
            "step 4084: generator_loss=-9.722636029607656e-10, discriminator_loss=1.7130948890553555e-06\n",
            "step 4085: generator_loss=-6.655693218782233e-10, discriminator_loss=4.895679808214481e-07\n",
            "step 4086: generator_loss=-4.577569712171936e-10, discriminator_loss=1.1828792594315019e-06\n",
            "step 4087: generator_loss=-2.024109768683502e-09, discriminator_loss=5.402305873758451e-07\n",
            "step 4088: generator_loss=-1.6450782402976927e-10, discriminator_loss=2.2369363250618335e-06\n",
            "step 4089: generator_loss=-1.5293362409796174e-10, discriminator_loss=1.0008000117522897e-06\n",
            "step 4090: generator_loss=-1.2850757791227352e-08, discriminator_loss=1.9160559077135986e-06\n",
            "step 4091: generator_loss=-2.1140503236871666e-10, discriminator_loss=6.538325578731019e-07\n",
            "step 4092: generator_loss=-6.422534171157679e-10, discriminator_loss=4.0812219026520324e-07\n",
            "step 4093: generator_loss=-1.029957341636134e-09, discriminator_loss=2.430731001368258e-06\n",
            "step 4094: generator_loss=-2.13938999849006e-09, discriminator_loss=1.1318071528876317e-06\n",
            "step 4095: generator_loss=-7.092890719206935e-10, discriminator_loss=2.6123173029191094e-06\n",
            "step 4096: generator_loss=-1.1051169701570274e-10, discriminator_loss=2.5175947939715115e-06\n",
            "step 4097: generator_loss=-7.721424610807048e-10, discriminator_loss=7.36435026738036e-07\n",
            "step 4098: generator_loss=-1.433360097280456e-09, discriminator_loss=1.6648926930429297e-06\n",
            "step 4099: generator_loss=-6.556659104539619e-10, discriminator_loss=2.896370460803155e-06\n",
            "step 4100: generator_loss=-2.2160545620764083e-10, discriminator_loss=2.1497542093129596e-06\n",
            "step 4101: generator_loss=-4.6745260995351146e-09, discriminator_loss=5.925664936512476e-07\n",
            "step 4102: generator_loss=-4.342582293759278e-09, discriminator_loss=2.1037697024439694e-06\n",
            "step 4103: generator_loss=-3.193881159546663e-09, discriminator_loss=1.0244467603115481e-06\n",
            "step 4104: generator_loss=-2.3128206294575904e-10, discriminator_loss=4.45816658611875e-06\n",
            "step 4105: generator_loss=-2.1408879113948842e-09, discriminator_loss=9.825488405112992e-07\n",
            "step 4106: generator_loss=-1.4998968733692664e-10, discriminator_loss=4.819849550585786e-07\n",
            "step 4107: generator_loss=-1.882935474206704e-10, discriminator_loss=8.368704698114016e-07\n",
            "step 4108: generator_loss=-6.617127401575829e-10, discriminator_loss=8.577092103223549e-07\n",
            "step 4109: generator_loss=-9.040294624007572e-10, discriminator_loss=1.789005864338833e-06\n",
            "step 4110: generator_loss=-4.40400604873048e-10, discriminator_loss=1.6242453284576186e-06\n",
            "step 4111: generator_loss=-1.3840447676827239e-09, discriminator_loss=1.6728182572478545e-06\n",
            "step 4112: generator_loss=-1.4578772855600164e-08, discriminator_loss=9.581284530213452e-07\n",
            "step 4113: generator_loss=-5.345830444980493e-10, discriminator_loss=7.627147056155081e-07\n",
            "step 4114: generator_loss=-6.222203308148266e-10, discriminator_loss=2.8622016543522477e-06\n",
            "step 4115: generator_loss=-6.715804024004512e-10, discriminator_loss=9.459842544856656e-07\n",
            "step 4116: generator_loss=-3.5224001493361357e-10, discriminator_loss=3.3302893598374794e-07\n",
            "step 4117: generator_loss=-1.0920230275601739e-09, discriminator_loss=3.4335796499362914e-06\n",
            "step 4118: generator_loss=-8.794529549049912e-10, discriminator_loss=1.9078768218605546e-06\n",
            "step 4119: generator_loss=-7.659996942299685e-11, discriminator_loss=2.6814982447831426e-06\n",
            "step 4120: generator_loss=-6.551640563401406e-09, discriminator_loss=6.506249405902054e-07\n",
            "step 4121: generator_loss=-1.0948300044333337e-09, discriminator_loss=1.8153042447011103e-06\n",
            "step 4122: generator_loss=-3.9886177694015146e-10, discriminator_loss=8.532933861715719e-07\n",
            "step 4123: generator_loss=-1.335510729782996e-10, discriminator_loss=5.075130502518732e-07\n",
            "step 4124: generator_loss=-1.921390380132948e-09, discriminator_loss=1.2009236343146767e-06\n",
            "step 4125: generator_loss=-1.5723223611985304e-08, discriminator_loss=4.121611709706485e-06\n",
            "step 4126: generator_loss=-3.297018125181239e-08, discriminator_loss=9.521624519948091e-07\n",
            "step 4127: generator_loss=-8.519148053665049e-09, discriminator_loss=2.2021565655450104e-06\n",
            "step 4128: generator_loss=-4.4274357513529594e-09, discriminator_loss=3.4020234807030647e-07\n",
            "step 4129: generator_loss=-2.410044108724918e-10, discriminator_loss=7.3278279160149395e-06\n",
            "step 4130: generator_loss=-4.379388407471652e-09, discriminator_loss=2.4347551175196713e-07\n",
            "step 4131: generator_loss=-6.738271052242339e-10, discriminator_loss=8.44159501411923e-07\n",
            "step 4132: generator_loss=-2.3368125212641644e-09, discriminator_loss=4.3218790324317524e-07\n",
            "step 4133: generator_loss=-1.8889551034462215e-10, discriminator_loss=1.1341614936100086e-06\n",
            "step 4134: generator_loss=-1.6029375049519956e-10, discriminator_loss=3.7961990528856404e-07\n",
            "step 4135: generator_loss=-3.832226203037692e-10, discriminator_loss=1.0464995057191118e-06\n",
            "step 4136: generator_loss=-1.2420153794323596e-09, discriminator_loss=7.423920465043921e-07\n",
            "step 4137: generator_loss=-6.022070619948749e-10, discriminator_loss=5.232748776506924e-07\n",
            "step 4138: generator_loss=-6.582483447203913e-10, discriminator_loss=9.920387356032734e-07\n",
            "step 4139: generator_loss=-6.190136181416506e-10, discriminator_loss=2.39323503592459e-06\n",
            "step 4140: generator_loss=-3.9330866341558135e-10, discriminator_loss=1.6244598555203993e-06\n",
            "step 4141: generator_loss=-9.929087413373949e-11, discriminator_loss=9.285033684136579e-07\n",
            "step 4142: generator_loss=-1.9111288107609425e-09, discriminator_loss=3.8416416714426305e-07\n",
            "step 4143: generator_loss=-3.911344581553067e-10, discriminator_loss=1.3973318573334836e-06\n",
            "step 4144: generator_loss=-1.5984685797221232e-10, discriminator_loss=9.527076372251031e-07\n",
            "step 4145: generator_loss=-2.3689250561176323e-09, discriminator_loss=2.3911520656838547e-06\n",
            "step 4146: generator_loss=-8.65852811671175e-09, discriminator_loss=2.077718818327412e-06\n",
            "step 4147: generator_loss=-2.1889672019437256e-10, discriminator_loss=1.0758855069070705e-06\n",
            "step 4148: generator_loss=-1.4892400646004944e-09, discriminator_loss=1.177459125756286e-06\n",
            "step 4149: generator_loss=-3.7457828505615964e-10, discriminator_loss=3.362461029610131e-07\n",
            "step 4150: generator_loss=-3.9570241527897565e-10, discriminator_loss=1.9931378574256087e-06\n",
            "step 4151: generator_loss=-1.168218022318257e-10, discriminator_loss=4.182851398581988e-07\n",
            "step 4152: generator_loss=-1.9507816195751815e-10, discriminator_loss=2.911041974584805e-06\n",
            "step 4153: generator_loss=-2.1592144738846741e-10, discriminator_loss=4.690798789397377e-07\n",
            "step 4154: generator_loss=-3.9162144638282825e-09, discriminator_loss=7.800298931215366e-07\n",
            "step 4155: generator_loss=-4.6761282346263755e-11, discriminator_loss=9.87910539151926e-07\n",
            "step 4156: generator_loss=-1.0643472769800155e-09, discriminator_loss=4.814553449250525e-07\n",
            "step 4157: generator_loss=-6.978843059002315e-10, discriminator_loss=1.6951655652519548e-06\n",
            "step 4158: generator_loss=-4.458956814890058e-10, discriminator_loss=1.118316163228883e-06\n",
            "step 4159: generator_loss=-1.5123782226567073e-09, discriminator_loss=7.493886755582935e-07\n",
            "step 4160: generator_loss=-2.3262272108581783e-09, discriminator_loss=4.771770250044938e-07\n",
            "step 4161: generator_loss=-8.682348173749688e-10, discriminator_loss=4.713780867859896e-07\n",
            "step 4162: generator_loss=-1.1112606390639712e-09, discriminator_loss=3.4785023217409616e-06\n",
            "step 4163: generator_loss=-2.4199133008551144e-07, discriminator_loss=8.235210771090351e-07\n",
            "step 4164: generator_loss=-8.862816036625532e-10, discriminator_loss=2.5094797706515237e-07\n",
            "step 4165: generator_loss=-3.8959860337861585e-10, discriminator_loss=1.1910349257959751e-06\n",
            "step 4166: generator_loss=-3.8827545623121296e-09, discriminator_loss=4.4101204821345164e-07\n",
            "step 4167: generator_loss=-2.1754287260478122e-09, discriminator_loss=4.91143964609364e-07\n",
            "step 4168: generator_loss=-9.759415497967439e-09, discriminator_loss=5.918660122006258e-07\n",
            "step 4169: generator_loss=-6.768173799187593e-10, discriminator_loss=5.136412823958381e-07\n",
            "step 4170: generator_loss=-4.580606172144286e-10, discriminator_loss=5.376340368457022e-07\n",
            "step 4171: generator_loss=-4.509695727961116e-09, discriminator_loss=3.649156212759408e-07\n",
            "step 4172: generator_loss=-2.5157336214221004e-09, discriminator_loss=4.139749592013686e-07\n",
            "step 4173: generator_loss=-1.792337528394583e-10, discriminator_loss=1.4225120139599312e-06\n",
            "step 4174: generator_loss=-1.0007666917388747e-09, discriminator_loss=4.568615622702055e-06\n",
            "step 4175: generator_loss=-1.9868970357883597e-10, discriminator_loss=2.0528559616650455e-06\n",
            "step 4176: generator_loss=-4.259679831086771e-10, discriminator_loss=1.414802227373002e-06\n",
            "step 4177: generator_loss=-4.147214516247999e-10, discriminator_loss=6.192856858433515e-07\n",
            "step 4178: generator_loss=-5.425285221072329e-10, discriminator_loss=8.896156487026019e-07\n",
            "step 4179: generator_loss=-1.0266427707961157e-09, discriminator_loss=1.1131676274089841e-06\n",
            "step 4180: generator_loss=-1.922420889144405e-09, discriminator_loss=2.8343604299152503e-06\n",
            "step 4181: generator_loss=-3.2509963610038994e-09, discriminator_loss=1.5363252714450937e-06\n",
            "step 4182: generator_loss=-3.1494786778551997e-09, discriminator_loss=1.855073321621603e-07\n",
            "step 4183: generator_loss=-2.475923355227394e-10, discriminator_loss=9.670483223089832e-07\n",
            "step 4184: generator_loss=-4.427933020245689e-10, discriminator_loss=7.022514978416439e-07\n",
            "step 4185: generator_loss=-2.0310872428375149e-10, discriminator_loss=1.2226499848111416e-06\n",
            "step 4186: generator_loss=-6.328647383924135e-09, discriminator_loss=7.641470460839628e-07\n",
            "step 4187: generator_loss=-1.7585864708902221e-10, discriminator_loss=2.7908065476367483e-06\n",
            "step 4188: generator_loss=-1.229996438034675e-09, discriminator_loss=8.944378464548208e-07\n",
            "step 4189: generator_loss=-2.1179027420714647e-09, discriminator_loss=1.9966066702181706e-06\n",
            "step 4190: generator_loss=-5.314013118429273e-10, discriminator_loss=3.928026671928819e-06\n",
            "step 4191: generator_loss=-7.69504637787577e-09, discriminator_loss=5.453993026094395e-07\n",
            "step 4192: generator_loss=-1.7571571975238953e-09, discriminator_loss=1.297413859902008e-06\n",
            "step 4193: generator_loss=-5.590765628227246e-10, discriminator_loss=6.046612384125183e-07\n",
            "step 4194: generator_loss=-6.026893428767721e-10, discriminator_loss=5.428055374068208e-07\n",
            "step 4195: generator_loss=-3.77765624337556e-10, discriminator_loss=6.272485819636131e-08\n",
            "step 4196: generator_loss=-7.181235051056944e-10, discriminator_loss=8.077738016254443e-07\n",
            "step 4197: generator_loss=-1.203716570863378e-10, discriminator_loss=5.267770120553905e-06\n",
            "step 4198: generator_loss=-5.044300088741238e-09, discriminator_loss=6.939849299669731e-07\n",
            "step 4199: generator_loss=-2.1043505826767728e-10, discriminator_loss=2.0103900624235393e-06\n",
            "step 4200: generator_loss=-8.320759081748008e-10, discriminator_loss=1.3560677416535327e-06\n",
            "step 4201: generator_loss=-2.5829218763817607e-09, discriminator_loss=2.4811970433802344e-06\n",
            "step 4202: generator_loss=-2.8351737624277007e-10, discriminator_loss=2.69673273578519e-06\n",
            "step 4203: generator_loss=-5.933177282813062e-10, discriminator_loss=1.3294118161866209e-06\n",
            "step 4204: generator_loss=-7.021031533938071e-10, discriminator_loss=2.5210424610122573e-06\n",
            "step 4205: generator_loss=-1.3321881375816247e-09, discriminator_loss=1.5096765082489583e-06\n",
            "step 4206: generator_loss=-4.049940938166685e-10, discriminator_loss=8.037728775889263e-07\n",
            "step 4207: generator_loss=-1.988176512313089e-09, discriminator_loss=4.566934990180016e-07\n",
            "step 4208: generator_loss=-8.377524784997092e-10, discriminator_loss=4.857262752011593e-07\n",
            "step 4209: generator_loss=-2.0058632532737874e-10, discriminator_loss=4.40171248783372e-07\n",
            "step 4210: generator_loss=-7.125852685696543e-10, discriminator_loss=4.524326584487426e-07\n",
            "step 4211: generator_loss=-2.807531984672096e-10, discriminator_loss=9.799206054594833e-06\n",
            "step 4212: generator_loss=-3.7795166996090757e-10, discriminator_loss=8.507852840011765e-07\n",
            "step 4213: generator_loss=-1.9758467084685094e-10, discriminator_loss=5.704467639588984e-06\n",
            "step 4214: generator_loss=-6.092387705436408e-10, discriminator_loss=1.48700576119154e-06\n",
            "step 4215: generator_loss=-5.5790101427533045e-09, discriminator_loss=1.0632693374645896e-06\n",
            "step 4216: generator_loss=-2.49748638436742e-10, discriminator_loss=9.112363272834045e-07\n",
            "step 4217: generator_loss=-5.769281719025798e-10, discriminator_loss=1.0883502454817062e-06\n",
            "step 4218: generator_loss=-4.584832513643278e-09, discriminator_loss=1.974085080291843e-06\n",
            "step 4219: generator_loss=-1.3945438137596966e-09, discriminator_loss=1.2436011047611828e-06\n",
            "step 4220: generator_loss=-2.4103646856232785e-10, discriminator_loss=7.567653028672794e-07\n",
            "step 4221: generator_loss=-2.5283561910782737e-09, discriminator_loss=1.2210015256641782e-06\n",
            "step 4222: generator_loss=-1.2589838060961256e-09, discriminator_loss=7.834139523765771e-07\n",
            "step 4223: generator_loss=-1.1317040360392383e-10, discriminator_loss=1.1959242556258687e-06\n",
            "step 4224: generator_loss=-1.0521704341126537e-10, discriminator_loss=5.723899221266038e-07\n",
            "step 4225: generator_loss=-4.909119222240577e-10, discriminator_loss=2.6153957151109353e-06\n",
            "step 4226: generator_loss=-2.062210180397983e-09, discriminator_loss=7.741414833617455e-07\n",
            "step 4227: generator_loss=-3.1491116381232587e-09, discriminator_loss=1.3598996702057775e-06\n",
            "step 4228: generator_loss=-4.789062479915174e-10, discriminator_loss=1.820200850488618e-06\n",
            "step 4229: generator_loss=-2.0131263323008852e-10, discriminator_loss=1.5613446748830029e-06\n",
            "step 4230: generator_loss=-4.5498768641571985e-10, discriminator_loss=1.3652328334501362e-06\n",
            "step 4231: generator_loss=-4.1404260575639285e-10, discriminator_loss=5.710108439416217e-07\n",
            "step 4232: generator_loss=-1.4413537030577572e-10, discriminator_loss=2.542803940741578e-06\n",
            "step 4233: generator_loss=-4.400961817196958e-09, discriminator_loss=8.925660495151533e-07\n",
            "step 4234: generator_loss=-1.516882869312397e-10, discriminator_loss=2.066193928840221e-06\n",
            "step 4235: generator_loss=-7.126437218119008e-10, discriminator_loss=3.207579538866412e-06\n",
            "step 4236: generator_loss=-2.0490664720540508e-10, discriminator_loss=1.456067195704236e-07\n",
            "step 4237: generator_loss=-2.791285425018941e-09, discriminator_loss=3.809369957252784e-07\n",
            "step 4238: generator_loss=-4.0100897602535213e-10, discriminator_loss=1.9589865587477107e-06\n",
            "step 4239: generator_loss=-2.5909248080324687e-09, discriminator_loss=5.355739176593488e-07\n",
            "step 4240: generator_loss=-1.900654522657419e-09, discriminator_loss=2.5685387754492695e-06\n",
            "step 4241: generator_loss=-3.5168876144631156e-10, discriminator_loss=1.3881123095416115e-06\n",
            "step 4242: generator_loss=-1.0177697795654694e-08, discriminator_loss=1.1945022606596467e-06\n",
            "step 4243: generator_loss=-7.805908142088924e-10, discriminator_loss=3.8071361814218108e-06\n",
            "step 4244: generator_loss=-6.3527143545627496e-09, discriminator_loss=5.540676966120373e-07\n",
            "step 4245: generator_loss=-3.150574023891295e-09, discriminator_loss=1.0532619398873067e-06\n",
            "step 4246: generator_loss=-2.679261257299004e-10, discriminator_loss=1.980839670068235e-06\n",
            "step 4247: generator_loss=-1.3385605956983682e-09, discriminator_loss=1.925604919961188e-07\n",
            "step 4248: generator_loss=-1.1247226761046392e-10, discriminator_loss=8.790806305114529e-07\n",
            "step 4249: generator_loss=-9.426421865299517e-10, discriminator_loss=6.858896881567489e-07\n",
            "step 4250: generator_loss=-1.28593802273258e-09, discriminator_loss=1.092827005777508e-06\n",
            "step 4251: generator_loss=-3.9110600869030065e-10, discriminator_loss=1.036787693919905e-06\n",
            "step 4252: generator_loss=-2.7635198573960906e-09, discriminator_loss=6.4109467530215625e-06\n",
            "step 4253: generator_loss=-2.199224358179208e-09, discriminator_loss=3.0995778388387407e-07\n",
            "step 4254: generator_loss=-1.3691255074110842e-10, discriminator_loss=3.1528011277259793e-06\n",
            "step 4255: generator_loss=-7.033349458396287e-10, discriminator_loss=1.59136845923058e-06\n",
            "step 4256: generator_loss=-5.583208895210134e-10, discriminator_loss=6.322198373709398e-07\n",
            "step 4257: generator_loss=-1.8509431487512273e-10, discriminator_loss=2.5490732014077366e-07\n",
            "step 4258: generator_loss=-3.3407907551463722e-09, discriminator_loss=1.4061625961403479e-06\n",
            "step 4259: generator_loss=-2.5729568475796327e-10, discriminator_loss=3.501603487165994e-07\n",
            "step 4260: generator_loss=-2.895071959940765e-10, discriminator_loss=3.493596750558936e-06\n",
            "step 4261: generator_loss=-8.600470891018119e-10, discriminator_loss=2.5234617169189733e-06\n",
            "step 4262: generator_loss=-3.515927549102571e-10, discriminator_loss=7.279040232788248e-07\n",
            "step 4263: generator_loss=-2.741820326335187e-09, discriminator_loss=5.226698363003379e-07\n",
            "step 4264: generator_loss=-2.524883635501851e-09, discriminator_loss=1.1855316870423849e-06\n",
            "step 4265: generator_loss=-2.6549280551790844e-09, discriminator_loss=2.477363295838586e-06\n",
            "step 4266: generator_loss=-4.3215235834281884e-09, discriminator_loss=7.394263548121671e-07\n",
            "step 4267: generator_loss=-6.858273948751048e-10, discriminator_loss=4.869526151196624e-07\n",
            "step 4268: generator_loss=-1.021985829297023e-09, discriminator_loss=9.461149602429941e-06\n",
            "step 4269: generator_loss=-6.671297958504852e-10, discriminator_loss=3.4767638226185227e-06\n",
            "step 4270: generator_loss=-1.453936082640439e-09, discriminator_loss=2.8741112600982888e-06\n",
            "step 4271: generator_loss=-1.6339148922739355e-09, discriminator_loss=3.866163922339183e-07\n",
            "step 4272: generator_loss=-1.6029200189393578e-10, discriminator_loss=2.80109543382423e-06\n",
            "step 4273: generator_loss=-7.951041602893838e-09, discriminator_loss=9.587009799361113e-07\n",
            "step 4274: generator_loss=-2.3483690547720926e-09, discriminator_loss=5.060043122284696e-07\n",
            "step 4275: generator_loss=-7.024519854681444e-10, discriminator_loss=2.3220231071263697e-07\n",
            "step 4276: generator_loss=-6.917649786331026e-10, discriminator_loss=2.559590939199552e-06\n",
            "step 4277: generator_loss=-8.207164947648948e-10, discriminator_loss=5.894814876228338e-07\n",
            "step 4278: generator_loss=-5.587464380063523e-10, discriminator_loss=7.502491143895895e-07\n",
            "step 4279: generator_loss=-2.533719456465633e-09, discriminator_loss=3.9353807324005174e-07\n",
            "step 4280: generator_loss=-1.485986000915318e-09, discriminator_loss=4.843941042054212e-06\n",
            "step 4281: generator_loss=-6.245369998936212e-09, discriminator_loss=1.19752291993791e-06\n",
            "step 4282: generator_loss=-2.8105477944961876e-09, discriminator_loss=1.2858398577009211e-06\n",
            "step 4283: generator_loss=-1.8024837178387543e-10, discriminator_loss=1.3483069096764666e-06\n",
            "step 4284: generator_loss=-2.89547164022963e-10, discriminator_loss=2.63200354311266e-06\n",
            "step 4285: generator_loss=-5.142303249883184e-10, discriminator_loss=1.52646111928334e-06\n",
            "step 4286: generator_loss=-1.8611118202116472e-10, discriminator_loss=1.0587129963823827e-06\n",
            "step 4287: generator_loss=-7.168947657731906e-10, discriminator_loss=1.206809793075081e-05\n",
            "step 4288: generator_loss=-1.0855203402826419e-09, discriminator_loss=3.262011034621537e-07\n",
            "step 4289: generator_loss=-1.247430270190364e-09, discriminator_loss=6.536216119457094e-07\n",
            "step 4290: generator_loss=-2.369899554377497e-10, discriminator_loss=8.668296800351527e-07\n",
            "step 4291: generator_loss=-1.783789921327994e-10, discriminator_loss=2.296497314091539e-06\n",
            "step 4292: generator_loss=-1.9336923173796094e-09, discriminator_loss=1.4627015616497374e-06\n",
            "step 4293: generator_loss=-1.329003712635668e-10, discriminator_loss=1.3199704653743538e-06\n",
            "step 4294: generator_loss=-4.5619408250985316e-10, discriminator_loss=5.317262434800796e-07\n",
            "step 4295: generator_loss=-6.298187749109729e-09, discriminator_loss=2.6202799290331313e-06\n",
            "step 4296: generator_loss=-4.2476483441689084e-10, discriminator_loss=4.767667576288659e-07\n",
            "step 4297: generator_loss=-2.321497161172914e-10, discriminator_loss=7.565950568277913e-07\n",
            "step 4298: generator_loss=-2.5037799389338034e-08, discriminator_loss=3.490071549094864e-06\n",
            "step 4299: generator_loss=-5.115923240595066e-10, discriminator_loss=7.479170704982607e-08\n",
            "step 4300: generator_loss=-1.1520741305393045e-10, discriminator_loss=7.985142360666941e-07\n",
            "step 4301: generator_loss=-2.659973630247947e-10, discriminator_loss=2.146239012290607e-06\n",
            "step 4302: generator_loss=-1.0006930006856152e-10, discriminator_loss=4.797735755346366e-07\n",
            "step 4303: generator_loss=-5.0374215909698705e-09, discriminator_loss=4.229765124819096e-07\n",
            "step 4304: generator_loss=-5.119664692188053e-10, discriminator_loss=2.0684544779214775e-06\n",
            "step 4305: generator_loss=-2.0306092363142625e-09, discriminator_loss=6.612318088627944e-07\n",
            "step 4306: generator_loss=-1.7113823691516927e-09, discriminator_loss=1.1815080824817414e-06\n",
            "step 4307: generator_loss=-1.0508450776214318e-09, discriminator_loss=1.7049153484549606e-06\n",
            "step 4308: generator_loss=-9.642338039128617e-10, discriminator_loss=5.046282467446872e-07\n",
            "step 4309: generator_loss=-2.416143951577965e-09, discriminator_loss=2.268667003590963e-06\n",
            "step 4310: generator_loss=-3.633716438855572e-09, discriminator_loss=1.049180468726263e-06\n",
            "step 4311: generator_loss=-1.0523810711760007e-09, discriminator_loss=7.053980652926839e-07\n",
            "step 4312: generator_loss=-5.566183625127508e-10, discriminator_loss=6.704689212710946e-07\n",
            "step 4313: generator_loss=-6.956254461343292e-10, discriminator_loss=1.6219248664128827e-06\n",
            "step 4314: generator_loss=-1.223109530323896e-10, discriminator_loss=6.022550564921403e-07\n",
            "step 4315: generator_loss=-5.517885592887239e-10, discriminator_loss=1.0943314237010782e-06\n",
            "step 4316: generator_loss=-7.841516880269239e-10, discriminator_loss=2.457506980135804e-06\n",
            "step 4317: generator_loss=-8.43843217523954e-09, discriminator_loss=5.846176804880088e-07\n",
            "step 4318: generator_loss=-1.1502523378226215e-09, discriminator_loss=3.1449765174329514e-06\n",
            "step 4319: generator_loss=-2.347463057272847e-10, discriminator_loss=7.747436825411569e-07\n",
            "step 4320: generator_loss=-5.84389914237704e-09, discriminator_loss=4.366220878182503e-07\n",
            "step 4321: generator_loss=-1.7467468582665902e-09, discriminator_loss=2.9128568712621927e-06\n",
            "step 4322: generator_loss=-3.1816055345856853e-10, discriminator_loss=6.77312016250653e-07\n",
            "step 4323: generator_loss=-2.7994151441390613e-09, discriminator_loss=6.092139415159181e-07\n",
            "step 4324: generator_loss=-2.5417798976690165e-09, discriminator_loss=8.683226724315318e-07\n",
            "step 4325: generator_loss=-2.978790325514069e-09, discriminator_loss=8.030294793570647e-07\n",
            "step 4326: generator_loss=-4.868129788171416e-10, discriminator_loss=4.6555453536711866e-07\n",
            "step 4327: generator_loss=-1.3621025418686372e-09, discriminator_loss=5.101629767523264e-07\n",
            "step 4328: generator_loss=-2.974689938817221e-10, discriminator_loss=5.24633321674628e-07\n",
            "step 4329: generator_loss=-3.6506297984573166e-10, discriminator_loss=2.6467887437320314e-07\n",
            "step 4330: generator_loss=-9.087101737748071e-09, discriminator_loss=8.642855959806184e-07\n",
            "step 4331: generator_loss=-5.636065503189513e-10, discriminator_loss=4.1094537550634413e-07\n",
            "step 4332: generator_loss=-4.625844152172931e-10, discriminator_loss=1.4341618452817784e-06\n",
            "step 4333: generator_loss=-5.773609368375787e-10, discriminator_loss=5.578769446401566e-07\n",
            "step 4334: generator_loss=-8.786956579021066e-11, discriminator_loss=2.4376761302846717e-06\n",
            "step 4335: generator_loss=-1.4769468981157274e-09, discriminator_loss=4.418738228650909e-07\n",
            "step 4336: generator_loss=-8.150161656672594e-10, discriminator_loss=8.611974635641673e-07\n",
            "step 4337: generator_loss=-4.988490953650171e-09, discriminator_loss=6.669580443485756e-07\n",
            "step 4338: generator_loss=-8.640723692110441e-09, discriminator_loss=7.080330419739767e-07\n",
            "step 4339: generator_loss=-3.451535168785824e-10, discriminator_loss=2.6012203306891024e-06\n",
            "step 4340: generator_loss=-6.030573818094354e-10, discriminator_loss=2.2913349084774381e-07\n",
            "step 4341: generator_loss=-1.360606027844824e-08, discriminator_loss=2.5289543827966554e-06\n",
            "step 4342: generator_loss=-7.622287800934657e-10, discriminator_loss=1.3633709841087693e-06\n",
            "step 4343: generator_loss=-2.3474738819473373e-10, discriminator_loss=1.9177822707661107e-07\n",
            "step 4344: generator_loss=-2.330952542095588e-09, discriminator_loss=1.0919168289547088e-06\n",
            "step 4345: generator_loss=-2.2099042595868923e-09, discriminator_loss=1.1507796671139658e-06\n",
            "step 4346: generator_loss=-3.339838683391605e-10, discriminator_loss=3.186072490279912e-07\n",
            "step 4347: generator_loss=-1.0923923987604667e-09, discriminator_loss=5.462981675918854e-07\n",
            "step 4348: generator_loss=-9.230152198114183e-10, discriminator_loss=1.8609713379191817e-06\n",
            "step 4349: generator_loss=-4.281124066363162e-10, discriminator_loss=4.940342250847607e-07\n",
            "step 4350: generator_loss=-8.179593669055407e-10, discriminator_loss=1.818105488382571e-06\n",
            "step 4351: generator_loss=-1.5662917629555295e-09, discriminator_loss=4.7493779220530996e-07\n",
            "step 4352: generator_loss=-8.551909735921015e-10, discriminator_loss=2.5471588287473423e-06\n",
            "step 4353: generator_loss=-7.953548930572651e-10, discriminator_loss=2.8884062430734048e-06\n",
            "step 4354: generator_loss=-3.264946368819466e-10, discriminator_loss=7.018363703537034e-07\n",
            "step 4355: generator_loss=-3.5034913858922323e-10, discriminator_loss=9.103127354137541e-07\n",
            "step 4356: generator_loss=-2.555618605626364e-09, discriminator_loss=7.399019068543566e-07\n",
            "step 4357: generator_loss=-1.5460466240568849e-10, discriminator_loss=1.725751189951552e-06\n",
            "step 4358: generator_loss=-1.5360867022806701e-09, discriminator_loss=4.067682937147765e-07\n",
            "step 4359: generator_loss=-8.654360561521912e-10, discriminator_loss=1.4045886018720921e-06\n",
            "step 4360: generator_loss=-1.560270468381475e-09, discriminator_loss=1.0751589343271917e-06\n",
            "step 4361: generator_loss=-1.7981525601840076e-08, discriminator_loss=2.7403448257246055e-06\n",
            "step 4362: generator_loss=-7.247994426862192e-10, discriminator_loss=6.725881576130632e-07\n",
            "step 4363: generator_loss=-3.0246433135872053e-10, discriminator_loss=4.655973668832303e-07\n",
            "step 4364: generator_loss=-2.4712849544528126e-09, discriminator_loss=1.6445153505628696e-06\n",
            "step 4365: generator_loss=-1.7463602786094157e-10, discriminator_loss=3.506009988996084e-06\n",
            "step 4366: generator_loss=-2.300445522962491e-08, discriminator_loss=1.6735907593101729e-06\n",
            "step 4367: generator_loss=-4.252151408756788e-10, discriminator_loss=1.3603847719423356e-06\n",
            "step 4368: generator_loss=-5.379180434417208e-10, discriminator_loss=5.141337169334292e-07\n",
            "step 4369: generator_loss=-4.696342204013604e-10, discriminator_loss=2.4454554932162864e-06\n",
            "step 4370: generator_loss=-1.6896194166005074e-10, discriminator_loss=8.842616807669401e-07\n",
            "step 4371: generator_loss=-4.67810790105716e-10, discriminator_loss=9.523196808913781e-07\n",
            "step 4372: generator_loss=-6.328132462485314e-10, discriminator_loss=1.5864483202676638e-06\n",
            "step 4373: generator_loss=-1.7671544783048887e-10, discriminator_loss=1.230382508765615e-06\n",
            "step 4374: generator_loss=-6.686357023610867e-10, discriminator_loss=2.1939713406027295e-06\n",
            "step 4375: generator_loss=-2.2459172299704733e-09, discriminator_loss=2.924588784480875e-07\n",
            "step 4376: generator_loss=-1.0769873881599779e-09, discriminator_loss=6.235953264877026e-07\n",
            "step 4377: generator_loss=-2.6483788495568206e-09, discriminator_loss=2.7451126243249746e-06\n",
            "step 4378: generator_loss=-7.797297252309932e-10, discriminator_loss=9.815886414799024e-07\n",
            "step 4379: generator_loss=-8.719044375382623e-10, discriminator_loss=5.929646704316838e-06\n",
            "step 4380: generator_loss=-7.726537187835447e-10, discriminator_loss=9.701853969090735e-07\n",
            "step 4381: generator_loss=-4.974407691316074e-11, discriminator_loss=7.420035217364784e-07\n",
            "step 4382: generator_loss=-1.1360354879030865e-09, discriminator_loss=1.6276887890853686e-06\n",
            "step 4383: generator_loss=-2.1431238728109037e-10, discriminator_loss=2.50561834036489e-06\n",
            "step 4384: generator_loss=-2.434793477945618e-10, discriminator_loss=2.3532013528893003e-06\n",
            "step 4385: generator_loss=-1.7079455905122387e-10, discriminator_loss=6.294725380939781e-07\n",
            "step 4386: generator_loss=-1.3213932725797406e-10, discriminator_loss=2.429083679089672e-06\n",
            "step 4387: generator_loss=-3.919551627706852e-10, discriminator_loss=2.4715816380194155e-06\n",
            "step 4388: generator_loss=-6.42682407292483e-10, discriminator_loss=1.1465297120594187e-06\n",
            "step 4389: generator_loss=-1.7180624978241354e-10, discriminator_loss=1.4312765870272415e-06\n",
            "step 4390: generator_loss=-1.6297635463402571e-09, discriminator_loss=1.785540689525078e-06\n",
            "step 4391: generator_loss=-2.0049175653014117e-09, discriminator_loss=4.4448296421251143e-07\n",
            "step 4392: generator_loss=-8.769736048463983e-09, discriminator_loss=7.485314768018725e-07\n",
            "step 4393: generator_loss=-4.234494976884662e-10, discriminator_loss=1.4233938827601378e-06\n",
            "step 4394: generator_loss=-3.317934815783019e-09, discriminator_loss=3.530287813191535e-07\n",
            "step 4395: generator_loss=-1.6711571015903814e-09, discriminator_loss=1.154719257101533e-06\n",
            "step 4396: generator_loss=-4.775290163294699e-10, discriminator_loss=2.2728477233613376e-06\n",
            "step 4397: generator_loss=-4.408516607323776e-10, discriminator_loss=4.806720880878856e-06\n",
            "step 4398: generator_loss=-1.2741843691266297e-10, discriminator_loss=6.920310511304706e-07\n",
            "step 4399: generator_loss=-4.568345257638384e-09, discriminator_loss=2.779427859422867e-06\n",
            "step 4400: generator_loss=-1.1603769056733881e-09, discriminator_loss=2.7329183467372786e-06\n",
            "step 4401: generator_loss=-2.852540981201912e-10, discriminator_loss=4.919882030662848e-07\n",
            "step 4402: generator_loss=-2.2627884288528577e-10, discriminator_loss=7.878031738073332e-07\n",
            "step 4403: generator_loss=-4.884467497134892e-09, discriminator_loss=7.057458901726932e-07\n",
            "step 4404: generator_loss=-3.201890974580124e-09, discriminator_loss=9.625246093492024e-07\n",
            "step 4405: generator_loss=-6.11413852880105e-08, discriminator_loss=1.8537499499871046e-06\n",
            "step 4406: generator_loss=-3.549375515721209e-10, discriminator_loss=1.525901609511493e-07\n",
            "step 4407: generator_loss=-1.563503326806881e-09, discriminator_loss=1.278177023777971e-06\n",
            "step 4408: generator_loss=-8.071983970125984e-09, discriminator_loss=6.152491778266267e-07\n",
            "step 4409: generator_loss=-3.00962033072949e-09, discriminator_loss=7.383873139588104e-07\n",
            "step 4410: generator_loss=-1.4741212417401783e-10, discriminator_loss=1.8050953087822563e-07\n",
            "step 4411: generator_loss=-6.342108505030808e-10, discriminator_loss=4.076986897416646e-06\n",
            "step 4412: generator_loss=-2.8010433972269766e-09, discriminator_loss=1.7812218402468716e-06\n",
            "step 4413: generator_loss=-6.119774687007862e-10, discriminator_loss=9.558364126860397e-07\n",
            "step 4414: generator_loss=-1.074590638694417e-09, discriminator_loss=1.5361288205895107e-06\n",
            "step 4415: generator_loss=-1.6757262244482263e-09, discriminator_loss=2.9045696692264755e-07\n",
            "step 4416: generator_loss=-1.1580130188093563e-09, discriminator_loss=1.3153792224329663e-06\n",
            "step 4417: generator_loss=-3.5013627552871185e-09, discriminator_loss=5.85246084483515e-07\n",
            "step 4418: generator_loss=-6.602012825318582e-10, discriminator_loss=3.0249964311224176e-06\n",
            "step 4419: generator_loss=-6.780814798545975e-10, discriminator_loss=4.309706127969548e-06\n",
            "step 4420: generator_loss=-1.4385008739736804e-09, discriminator_loss=1.0032666750703356e-06\n",
            "step 4421: generator_loss=-9.79853531646313e-10, discriminator_loss=2.484702008587192e-07\n",
            "step 4422: generator_loss=-1.774191571435324e-09, discriminator_loss=6.51642380944395e-07\n",
            "step 4423: generator_loss=-8.371104920357197e-10, discriminator_loss=3.1022781854517234e-07\n",
            "step 4424: generator_loss=-6.063041735338004e-10, discriminator_loss=2.5922670374711743e-06\n",
            "step 4425: generator_loss=-5.81844961100586e-10, discriminator_loss=5.504925866262056e-07\n",
            "step 4426: generator_loss=-1.6869786123585584e-10, discriminator_loss=6.224589924386237e-06\n",
            "step 4427: generator_loss=-1.297246754461412e-09, discriminator_loss=6.93329127443576e-07\n",
            "step 4428: generator_loss=-2.301691892636626e-10, discriminator_loss=4.454089719274634e-07\n",
            "step 4429: generator_loss=-3.108779900173886e-10, discriminator_loss=2.4191217562474776e-06\n",
            "step 4430: generator_loss=-6.30967000869731e-10, discriminator_loss=1.1012873528670752e-06\n",
            "step 4431: generator_loss=-4.005166753806577e-10, discriminator_loss=4.227449608151801e-07\n",
            "step 4432: generator_loss=-6.598495083665057e-10, discriminator_loss=6.626835897804995e-07\n",
            "step 4433: generator_loss=-8.276925256289758e-10, discriminator_loss=1.8617541854837327e-06\n",
            "step 4434: generator_loss=-5.453505425023764e-10, discriminator_loss=8.566546966903843e-06\n",
            "step 4435: generator_loss=-8.022241204663771e-10, discriminator_loss=8.249890584011155e-07\n",
            "step 4436: generator_loss=-3.953801452905026e-10, discriminator_loss=6.391530860128114e-06\n",
            "step 4437: generator_loss=-3.2255711435169587e-09, discriminator_loss=5.912226015425404e-07\n",
            "step 4438: generator_loss=-1.0860416732594302e-10, discriminator_loss=3.5191612823837204e-06\n",
            "step 4439: generator_loss=-5.282563275699204e-10, discriminator_loss=1.0390188435849268e-05\n",
            "step 4440: generator_loss=-2.931830334063079e-09, discriminator_loss=3.890389507432701e-06\n",
            "step 4441: generator_loss=-1.333896104682708e-09, discriminator_loss=4.400513375912851e-07\n",
            "step 4442: generator_loss=-1.807304639278584e-09, discriminator_loss=2.567719320722972e-06\n",
            "step 4443: generator_loss=-1.6933646151962023e-10, discriminator_loss=6.0637744354608e-06\n",
            "step 4444: generator_loss=-6.481870151731073e-09, discriminator_loss=1.9768760921579087e-06\n",
            "step 4445: generator_loss=-6.20669471373958e-09, discriminator_loss=1.330377585873066e-06\n",
            "step 4446: generator_loss=-6.882585057432777e-10, discriminator_loss=7.704761628701817e-07\n",
            "step 4447: generator_loss=-9.642006637555767e-11, discriminator_loss=2.3073195620781917e-07\n",
            "step 4448: generator_loss=-3.60189993386939e-08, discriminator_loss=1.5764683212182717e-06\n",
            "step 4449: generator_loss=-1.9403820217256396e-10, discriminator_loss=6.856213872197259e-07\n",
            "step 4450: generator_loss=-2.088553552326289e-09, discriminator_loss=8.33313970360905e-06\n",
            "step 4451: generator_loss=-1.8945716107054977e-09, discriminator_loss=1.93742167198252e-07\n",
            "step 4452: generator_loss=-6.912389771684957e-09, discriminator_loss=3.473590481917199e-07\n",
            "step 4453: generator_loss=-3.3659025566734613e-10, discriminator_loss=2.1176570044190157e-06\n",
            "step 4454: generator_loss=-3.33256355844469e-09, discriminator_loss=1.1907537782462896e-06\n",
            "step 4455: generator_loss=-2.0689282231867168e-10, discriminator_loss=4.3158215135008504e-07\n",
            "step 4456: generator_loss=-6.433074073441958e-10, discriminator_loss=8.448180324194254e-07\n",
            "step 4457: generator_loss=-3.269576276387909e-10, discriminator_loss=1.6902058632695116e-06\n",
            "step 4458: generator_loss=-1.1174056346874295e-08, discriminator_loss=2.2678659661323763e-06\n",
            "step 4459: generator_loss=-1.2144176775308324e-09, discriminator_loss=2.0314180346758803e-06\n",
            "step 4460: generator_loss=-9.023943370323195e-09, discriminator_loss=7.125271963559499e-07\n",
            "step 4461: generator_loss=-8.295738318508938e-09, discriminator_loss=2.4928232278398355e-07\n",
            "step 4462: generator_loss=-1.7132594232194265e-09, discriminator_loss=1.2348256177574513e-06\n",
            "step 4463: generator_loss=-1.8233996534888774e-09, discriminator_loss=5.757607937084686e-07\n",
            "step 4464: generator_loss=-5.936750202550911e-09, discriminator_loss=6.36961885902565e-07\n",
            "step 4465: generator_loss=-9.645335641295105e-10, discriminator_loss=1.6287000335069024e-06\n",
            "step 4466: generator_loss=-2.0001734990504616e-10, discriminator_loss=5.0847138481913134e-06\n",
            "step 4467: generator_loss=-1.9437330911475925e-10, discriminator_loss=4.1882381651703326e-07\n",
            "step 4468: generator_loss=-6.587032030935802e-10, discriminator_loss=9.274832564187818e-07\n",
            "step 4469: generator_loss=-3.9492569214871764e-09, discriminator_loss=4.54306757546874e-07\n",
            "step 4470: generator_loss=-5.843887151968374e-09, discriminator_loss=2.5031833956745686e-06\n",
            "step 4471: generator_loss=-4.965454714067619e-10, discriminator_loss=4.285070929199719e-07\n",
            "step 4472: generator_loss=-1.4200759457239087e-09, discriminator_loss=2.220853730250383e-06\n",
            "step 4473: generator_loss=-6.472967162274301e-10, discriminator_loss=3.3183482628373895e-07\n",
            "step 4474: generator_loss=-4.231277994648508e-09, discriminator_loss=8.81861888046842e-06\n",
            "step 4475: generator_loss=-1.7676009989031627e-08, discriminator_loss=5.7301108427054714e-06\n",
            "step 4476: generator_loss=-1.0373955028342152e-09, discriminator_loss=1.6256580011031474e-06\n",
            "step 4477: generator_loss=-5.898231347778449e-10, discriminator_loss=1.0896234243773506e-06\n",
            "step 4478: generator_loss=-2.889571026898352e-09, discriminator_loss=2.3302327463170514e-06\n",
            "step 4479: generator_loss=-1.199349647373893e-10, discriminator_loss=8.734709240343363e-07\n",
            "step 4480: generator_loss=-1.2933051296570852e-09, discriminator_loss=5.985172037981101e-07\n",
            "step 4481: generator_loss=-8.079937829919004e-10, discriminator_loss=1.089615921046061e-06\n",
            "step 4482: generator_loss=-9.984675308771784e-10, discriminator_loss=1.3275428045744775e-06\n",
            "step 4483: generator_loss=-9.131429834496885e-09, discriminator_loss=1.2920303333885386e-06\n",
            "step 4484: generator_loss=-6.252866557865389e-10, discriminator_loss=2.8305043997534085e-06\n",
            "step 4485: generator_loss=-1.1651248854605e-09, discriminator_loss=7.135548685255344e-07\n",
            "step 4486: generator_loss=-3.086886080083673e-09, discriminator_loss=5.083607561573444e-07\n",
            "step 4487: generator_loss=-4.0692355041116457e-10, discriminator_loss=2.0931358903908404e-06\n",
            "step 4488: generator_loss=-1.600543919622055e-09, discriminator_loss=7.509087254220503e-07\n",
            "step 4489: generator_loss=-2.502213714006274e-10, discriminator_loss=5.957530902378494e-06\n",
            "step 4490: generator_loss=-1.4460489472511995e-09, discriminator_loss=2.2329236344376113e-06\n",
            "step 4491: generator_loss=-1.4924779190295112e-09, discriminator_loss=3.402537060992472e-07\n",
            "step 4492: generator_loss=-2.795379483444549e-10, discriminator_loss=4.3831525431414775e-07\n",
            "step 4493: generator_loss=-2.1243218295552424e-10, discriminator_loss=6.985384857216559e-07\n",
            "step 4494: generator_loss=-2.9265727619076642e-09, discriminator_loss=3.178066663167556e-07\n",
            "step 4495: generator_loss=-2.3334527643470437e-09, discriminator_loss=6.062340958123968e-07\n",
            "step 4496: generator_loss=-1.6845309869228942e-10, discriminator_loss=1.3823811286783894e-06\n",
            "step 4497: generator_loss=-2.3474816535085097e-10, discriminator_loss=2.62799721895135e-06\n",
            "step 4498: generator_loss=-1.0183067722380201e-09, discriminator_loss=6.915532253515266e-07\n",
            "step 4499: generator_loss=-7.776993493635587e-10, discriminator_loss=1.0449789442645852e-06\n",
            "step 4500: generator_loss=-2.808399734988143e-09, discriminator_loss=8.233708967964048e-07\n",
            "step 4501: generator_loss=-3.584405217083031e-09, discriminator_loss=2.487964138708776e-06\n",
            "step 4502: generator_loss=-2.730247694593402e-10, discriminator_loss=1.3599324120150413e-06\n",
            "step 4503: generator_loss=-8.522274552724696e-10, discriminator_loss=2.0627730918931775e-06\n",
            "step 4504: generator_loss=-3.00338598435701e-09, discriminator_loss=4.637245183403138e-07\n",
            "step 4505: generator_loss=-1.3873222570737198e-09, discriminator_loss=4.732255547423847e-07\n",
            "step 4506: generator_loss=-4.212953874649372e-10, discriminator_loss=1.4143655562293134e-06\n",
            "step 4507: generator_loss=-9.801548461751963e-10, discriminator_loss=1.3772704505754518e-06\n",
            "step 4508: generator_loss=-1.158236173637306e-09, discriminator_loss=2.6409688302919676e-07\n",
            "step 4509: generator_loss=-6.147173048365318e-11, discriminator_loss=1.3453770009164145e-07\n",
            "step 4510: generator_loss=-3.748807930747944e-10, discriminator_loss=1.402615339429758e-06\n",
            "step 4511: generator_loss=-9.174638826436876e-11, discriminator_loss=2.533235146984225e-06\n",
            "step 4512: generator_loss=-2.8485389602650457e-09, discriminator_loss=1.081828486348968e-06\n",
            "step 4513: generator_loss=-2.781514740757274e-10, discriminator_loss=1.4611570122724515e-06\n",
            "step 4514: generator_loss=-1.3354662931064354e-09, discriminator_loss=6.745288487763901e-07\n",
            "step 4515: generator_loss=-1.1921791331914733e-09, discriminator_loss=1.4368018810273497e-06\n",
            "step 4516: generator_loss=-1.4086454225292755e-10, discriminator_loss=9.492774779573665e-07\n",
            "step 4517: generator_loss=-2.275000854368159e-09, discriminator_loss=6.181754201861622e-07\n",
            "step 4518: generator_loss=-2.3865143194967686e-10, discriminator_loss=9.689579201221932e-07\n",
            "step 4519: generator_loss=-4.046765422760501e-10, discriminator_loss=1.6024043247853115e-07\n",
            "step 4520: generator_loss=-1.4411624116306143e-09, discriminator_loss=6.482135631813435e-06\n",
            "step 4521: generator_loss=-5.1376942700187556e-09, discriminator_loss=5.625810786114016e-07\n",
            "step 4522: generator_loss=-3.670606485428607e-09, discriminator_loss=1.3160802154743578e-06\n",
            "step 4523: generator_loss=-7.602689144903252e-09, discriminator_loss=1.6962601421255386e-06\n",
            "step 4524: generator_loss=-1.5392978558459447e-10, discriminator_loss=2.5764561542018782e-06\n",
            "step 4525: generator_loss=-3.365449252612507e-09, discriminator_loss=8.685162242727529e-07\n",
            "step 4526: generator_loss=-2.353690353729121e-09, discriminator_loss=1.9013308474313817e-06\n",
            "step 4527: generator_loss=-4.4213752103949844e-10, discriminator_loss=1.487320218984678e-06\n",
            "step 4528: generator_loss=-9.690966917830224e-10, discriminator_loss=1.0192454737989465e-06\n",
            "step 4529: generator_loss=-1.894058909712726e-09, discriminator_loss=1.2504459618867259e-06\n",
            "step 4530: generator_loss=-4.0038250492813177e-10, discriminator_loss=6.261760177039832e-07\n",
            "step 4531: generator_loss=-8.222404979107978e-10, discriminator_loss=2.3706747924734373e-06\n",
            "step 4532: generator_loss=-6.72180200389505e-10, discriminator_loss=4.91273453917529e-07\n",
            "step 4533: generator_loss=-1.3571498369557844e-09, discriminator_loss=4.2693321233855386e-07\n",
            "step 4534: generator_loss=-8.29777080380012e-10, discriminator_loss=1.5566305364700384e-06\n",
            "step 4535: generator_loss=-4.838043854427099e-10, discriminator_loss=7.277492386492668e-07\n",
            "step 4536: generator_loss=-6.280563291660712e-10, discriminator_loss=2.4146247596945614e-06\n",
            "step 4537: generator_loss=-4.397834874048101e-10, discriminator_loss=7.416314815600344e-07\n",
            "step 4538: generator_loss=-4.931367536542552e-10, discriminator_loss=1.787495193639188e-06\n",
            "step 4539: generator_loss=-1.404230953738761e-09, discriminator_loss=9.700105465526576e-07\n",
            "step 4540: generator_loss=-2.2180726699794207e-10, discriminator_loss=1.5616274140484165e-06\n",
            "step 4541: generator_loss=-5.029913152654331e-10, discriminator_loss=9.862965271167923e-07\n",
            "step 4542: generator_loss=-6.7562018202238505e-09, discriminator_loss=1.88433716630243e-06\n",
            "step 4543: generator_loss=-1.6686566017831694e-10, discriminator_loss=2.8510299898698577e-07\n",
            "step 4544: generator_loss=-1.4910135348600306e-09, discriminator_loss=3.693864130127622e-07\n",
            "step 4545: generator_loss=-1.0563046271006016e-10, discriminator_loss=2.9514601465052692e-06\n",
            "step 4546: generator_loss=-4.36920499780058e-10, discriminator_loss=6.807053409829678e-07\n",
            "step 4547: generator_loss=-3.977245643937977e-09, discriminator_loss=8.568003067921381e-06\n",
            "step 4548: generator_loss=-4.744240555965007e-10, discriminator_loss=1.6762527366154245e-06\n",
            "step 4549: generator_loss=-1.4036413142903825e-09, discriminator_loss=7.269870252457622e-07\n",
            "step 4550: generator_loss=-7.481533170761168e-10, discriminator_loss=7.561591246485477e-07\n",
            "step 4551: generator_loss=-9.367724651543341e-11, discriminator_loss=7.926468583718815e-07\n",
            "step 4552: generator_loss=-4.149371513051392e-09, discriminator_loss=1.1716573453668389e-06\n",
            "step 4553: generator_loss=-9.13810083158495e-10, discriminator_loss=4.359873742032505e-07\n",
            "step 4554: generator_loss=-3.696390138419048e-10, discriminator_loss=1.6875538904059795e-06\n",
            "step 4555: generator_loss=-1.69992075971237e-10, discriminator_loss=3.330924585043249e-07\n",
            "step 4556: generator_loss=-7.946722169194231e-10, discriminator_loss=6.522378726003808e-07\n",
            "step 4557: generator_loss=-1.3012826927116805e-10, discriminator_loss=3.391989821466268e-06\n",
            "step 4558: generator_loss=-6.657595585934928e-10, discriminator_loss=4.174318348759698e-07\n",
            "step 4559: generator_loss=-8.149591557149449e-10, discriminator_loss=7.681742317799944e-07\n",
            "step 4560: generator_loss=-3.025818262614166e-09, discriminator_loss=2.5270736614402267e-07\n",
            "step 4561: generator_loss=-1.552352968392512e-10, discriminator_loss=1.879657531844714e-07\n",
            "step 4562: generator_loss=-3.4388128455908884e-10, discriminator_loss=1.1727122455340577e-06\n",
            "step 4563: generator_loss=-1.0195906341436967e-09, discriminator_loss=1.383749349770369e-06\n",
            "step 4564: generator_loss=-5.591800356086196e-10, discriminator_loss=1.1499978427309543e-06\n",
            "step 4565: generator_loss=-6.017167875072005e-10, discriminator_loss=5.062968853053462e-07\n",
            "step 4566: generator_loss=-9.438476666900897e-10, discriminator_loss=4.209633175378258e-07\n",
            "step 4567: generator_loss=-3.872905607327226e-10, discriminator_loss=1.296274490414362e-06\n",
            "step 4568: generator_loss=-6.831849530541945e-10, discriminator_loss=9.496375810158497e-07\n",
            "step 4569: generator_loss=-7.424216796891869e-10, discriminator_loss=4.009913482150296e-06\n",
            "step 4570: generator_loss=-5.113088841213198e-10, discriminator_loss=4.082023679075064e-07\n",
            "step 4571: generator_loss=-3.620925226321958e-10, discriminator_loss=5.899120765207044e-07\n",
            "step 4572: generator_loss=-3.450569163732098e-09, discriminator_loss=5.589371880887484e-07\n",
            "step 4573: generator_loss=-1.2335275856312222e-10, discriminator_loss=5.35979381766083e-07\n",
            "step 4574: generator_loss=-1.3968132428487934e-08, discriminator_loss=4.150768972976948e-07\n",
            "step 4575: generator_loss=-2.216992367465309e-09, discriminator_loss=6.378179477906087e-07\n",
            "step 4576: generator_loss=-8.265038098365096e-10, discriminator_loss=2.8447932436392875e-06\n",
            "step 4577: generator_loss=-1.7681378583489504e-10, discriminator_loss=6.974290158723306e-07\n",
            "step 4578: generator_loss=-3.832622275101727e-10, discriminator_loss=2.671187644409656e-07\n",
            "step 4579: generator_loss=-3.407703563773623e-10, discriminator_loss=7.45273609936703e-07\n",
            "step 4580: generator_loss=-2.868468129690882e-09, discriminator_loss=3.3492683542135637e-06\n",
            "step 4581: generator_loss=-2.5548503312933235e-09, discriminator_loss=3.4131846859963844e-07\n",
            "step 4582: generator_loss=-3.0827616015471904e-09, discriminator_loss=3.253517434131936e-06\n",
            "step 4583: generator_loss=-1.7327141943468405e-09, discriminator_loss=2.3386729708363418e-07\n",
            "step 4584: generator_loss=-1.0125779104086519e-09, discriminator_loss=7.005708084761864e-07\n",
            "step 4585: generator_loss=-4.062908676161214e-09, discriminator_loss=7.43867531127762e-07\n",
            "step 4586: generator_loss=-2.998647441465607e-10, discriminator_loss=1.2651285032916348e-06\n",
            "step 4587: generator_loss=-4.768739292337898e-10, discriminator_loss=3.3487677342236566e-07\n",
            "step 4588: generator_loss=-1.3777416985050195e-09, discriminator_loss=5.1523752517823596e-06\n",
            "step 4589: generator_loss=-5.016665971524503e-10, discriminator_loss=1.357300760673752e-07\n",
            "step 4590: generator_loss=-1.3586438640800225e-09, discriminator_loss=2.018992290686583e-06\n",
            "step 4591: generator_loss=-6.361957072265056e-10, discriminator_loss=8.849264077070984e-07\n",
            "step 4592: generator_loss=-1.6167518435139527e-09, discriminator_loss=1.9062848650719388e-06\n",
            "step 4593: generator_loss=-1.634546109574586e-10, discriminator_loss=7.493855719076237e-06\n",
            "step 4594: generator_loss=-4.553255550376889e-09, discriminator_loss=1.278150875805295e-06\n",
            "step 4595: generator_loss=-1.8721570071988936e-08, discriminator_loss=2.870153593903524e-06\n",
            "step 4596: generator_loss=-1.8367833920507337e-09, discriminator_loss=4.531276260877348e-07\n",
            "step 4597: generator_loss=-9.63279012111684e-10, discriminator_loss=1.6573407037867582e-06\n",
            "step 4598: generator_loss=-5.324056751021544e-09, discriminator_loss=9.050146445588325e-07\n",
            "step 4599: generator_loss=-3.442620077898084e-10, discriminator_loss=1.9806773252639687e-06\n",
            "step 4600: generator_loss=-1.5116922991165183e-10, discriminator_loss=4.988297632735339e-07\n",
            "step 4601: generator_loss=-3.080074151284862e-08, discriminator_loss=6.570959385499009e-07\n",
            "step 4602: generator_loss=-2.020202893859846e-09, discriminator_loss=2.461799567754497e-06\n",
            "step 4603: generator_loss=-2.331434778568564e-08, discriminator_loss=1.1463516784715466e-06\n",
            "step 4604: generator_loss=-2.1918791781594393e-10, discriminator_loss=1.4019253740116255e-06\n",
            "step 4605: generator_loss=-1.8575073701398992e-09, discriminator_loss=2.8984438813495217e-06\n",
            "step 4606: generator_loss=-1.315988829020398e-08, discriminator_loss=6.211378149600932e-07\n",
            "step 4607: generator_loss=-8.20296941483889e-10, discriminator_loss=1.6505130133737111e-06\n",
            "step 4608: generator_loss=-6.418919284989499e-10, discriminator_loss=1.0779045851450064e-06\n",
            "step 4609: generator_loss=-7.366212972925723e-09, discriminator_loss=1.8609085827847593e-06\n",
            "step 4610: generator_loss=-3.373374912740701e-09, discriminator_loss=3.0204887480067555e-06\n",
            "step 4611: generator_loss=-4.882451110077568e-10, discriminator_loss=1.7287898401718849e-07\n",
            "step 4612: generator_loss=-2.7408206815238145e-09, discriminator_loss=2.6593052098178305e-06\n",
            "step 4613: generator_loss=-4.3876399735687244e-10, discriminator_loss=1.7147696098618326e-06\n",
            "step 4614: generator_loss=-9.612037832340548e-10, discriminator_loss=7.4503268479020335e-06\n",
            "step 4615: generator_loss=-1.5237322514849438e-09, discriminator_loss=1.6104826272567152e-06\n",
            "step 4616: generator_loss=-1.6657112356099901e-09, discriminator_loss=1.6518572465429315e-06\n",
            "step 4617: generator_loss=-2.066941617862028e-10, discriminator_loss=6.460045369749423e-07\n",
            "step 4618: generator_loss=-3.3183831238403627e-09, discriminator_loss=1.0974595170409884e-06\n",
            "step 4619: generator_loss=-2.33614461109255e-09, discriminator_loss=1.7553791167301824e-06\n",
            "step 4620: generator_loss=-1.4081041888047707e-09, discriminator_loss=2.2552886491666868e-07\n",
            "step 4621: generator_loss=-5.589592344534822e-09, discriminator_loss=1.8571705595604726e-06\n",
            "step 4622: generator_loss=-1.222408008150211e-10, discriminator_loss=7.358545985880482e-07\n",
            "step 4623: generator_loss=-2.6817911780163683e-10, discriminator_loss=7.440662557200994e-07\n",
            "step 4624: generator_loss=-4.019506949504148e-10, discriminator_loss=1.477463115406863e-06\n",
            "step 4625: generator_loss=-1.6200707442237672e-10, discriminator_loss=7.106139605639328e-07\n",
            "step 4626: generator_loss=-1.123419801629666e-09, discriminator_loss=1.0102492069563596e-06\n",
            "step 4627: generator_loss=-9.801220945959699e-10, discriminator_loss=6.552923537128663e-07\n",
            "step 4628: generator_loss=-2.3541535387749946e-10, discriminator_loss=1.8301178670299123e-06\n",
            "step 4629: generator_loss=-2.7888241715956497e-10, discriminator_loss=7.825607895028952e-07\n",
            "step 4630: generator_loss=-1.1800604937661774e-10, discriminator_loss=4.678205186792184e-06\n",
            "step 4631: generator_loss=-2.7167806893046986e-10, discriminator_loss=2.4926532660174416e-06\n",
            "step 4632: generator_loss=-1.9699450959365095e-09, discriminator_loss=5.872401516171522e-07\n",
            "step 4633: generator_loss=-2.0595547489676846e-10, discriminator_loss=1.3172998478694353e-06\n",
            "step 4634: generator_loss=-1.753928113856773e-09, discriminator_loss=2.3504667012730351e-07\n",
            "step 4635: generator_loss=-6.5797461923367e-10, discriminator_loss=1.0294559160684003e-06\n",
            "step 4636: generator_loss=-1.9263910466804646e-09, discriminator_loss=1.330069267169165e-06\n",
            "step 4637: generator_loss=-6.006377173406463e-09, discriminator_loss=4.412078851601109e-06\n",
            "step 4638: generator_loss=-1.8046015792805292e-09, discriminator_loss=4.814106659978279e-07\n",
            "step 4639: generator_loss=-2.9386060251823665e-09, discriminator_loss=2.348592488488066e-06\n",
            "step 4640: generator_loss=-7.046179195668856e-10, discriminator_loss=1.694312345534854e-06\n",
            "step 4641: generator_loss=-3.1870989181115306e-10, discriminator_loss=1.0059268788609188e-05\n",
            "step 4642: generator_loss=-4.093705929797409e-10, discriminator_loss=7.741665513094631e-07\n",
            "step 4643: generator_loss=-1.6239132261119948e-10, discriminator_loss=7.218575888146006e-07\n",
            "step 4644: generator_loss=-4.4100451068729285e-10, discriminator_loss=1.9285957932879683e-06\n",
            "step 4645: generator_loss=-5.282086990021639e-10, discriminator_loss=3.8991422002254694e-07\n",
            "step 4646: generator_loss=-1.174300923167948e-08, discriminator_loss=7.213239427983353e-07\n",
            "step 4647: generator_loss=-7.837684945499745e-10, discriminator_loss=8.955319117376348e-07\n",
            "step 4648: generator_loss=-1.5329013058895669e-10, discriminator_loss=8.177603376680054e-07\n",
            "step 4649: generator_loss=-1.1991684312206985e-09, discriminator_loss=2.6866095481636876e-07\n",
            "step 4650: generator_loss=-4.0554432034767274e-10, discriminator_loss=4.521106120591867e-07\n",
            "step 4651: generator_loss=-3.0749161550325255e-10, discriminator_loss=1.4872740905502724e-07\n",
            "step 4652: generator_loss=-4.105546125288129e-09, discriminator_loss=2.477396719768876e-06\n",
            "step 4653: generator_loss=-8.031083575943399e-10, discriminator_loss=4.0370125020672276e-07\n",
            "step 4654: generator_loss=-4.669110653665598e-10, discriminator_loss=6.012867856952653e-07\n",
            "step 4655: generator_loss=-8.610566148981036e-10, discriminator_loss=3.753083888113906e-07\n",
            "step 4656: generator_loss=-3.942352555519335e-10, discriminator_loss=1.8165995925301104e-06\n",
            "step 4657: generator_loss=-9.464836692174572e-10, discriminator_loss=2.9906348686381534e-07\n",
            "step 4658: generator_loss=-3.2884234224539455e-10, discriminator_loss=6.535548777719669e-07\n",
            "step 4659: generator_loss=-5.541084258098294e-10, discriminator_loss=1.2618354503501905e-06\n",
            "step 4660: generator_loss=-7.629838427725133e-10, discriminator_loss=6.871812843201042e-07\n",
            "step 4661: generator_loss=-1.3606126225695903e-09, discriminator_loss=4.682706276071258e-07\n",
            "step 4662: generator_loss=-2.3194584031216436e-09, discriminator_loss=1.1622175861703e-06\n",
            "step 4663: generator_loss=-1.5942293041248945e-09, discriminator_loss=3.266982275818009e-06\n",
            "step 4664: generator_loss=-4.698740285746794e-10, discriminator_loss=1.2380652378851664e-06\n",
            "step 4665: generator_loss=-3.643972590339217e-08, discriminator_loss=7.888324375926459e-07\n",
            "step 4666: generator_loss=-5.470172093069436e-10, discriminator_loss=2.0193540422042133e-06\n",
            "step 4667: generator_loss=-2.0139645506844772e-09, discriminator_loss=8.027641911212413e-07\n",
            "step 4668: generator_loss=-3.3785813036146806e-10, discriminator_loss=2.69631209448562e-06\n",
            "step 4669: generator_loss=-7.858943495975268e-10, discriminator_loss=6.860625489935046e-07\n",
            "step 4670: generator_loss=-4.527203056881035e-10, discriminator_loss=2.703624204514199e-07\n",
            "step 4671: generator_loss=-2.724618863858552e-10, discriminator_loss=2.3475345187762287e-06\n",
            "step 4672: generator_loss=-1.733597293496203e-10, discriminator_loss=1.4295075061454554e-06\n",
            "step 4673: generator_loss=-3.197530018539396e-10, discriminator_loss=1.158628265329753e-06\n",
            "step 4674: generator_loss=-8.704373888335226e-10, discriminator_loss=7.669433443879825e-07\n",
            "step 4675: generator_loss=-2.930068188078394e-09, discriminator_loss=1.8217297110822983e-06\n",
            "step 4676: generator_loss=-5.778104106290982e-10, discriminator_loss=1.1824321290987427e-06\n",
            "step 4677: generator_loss=-3.7369979333234937e-10, discriminator_loss=1.5550250509477337e-07\n",
            "step 4678: generator_loss=-1.9868235945352808e-09, discriminator_loss=2.758473840458464e-07\n",
            "step 4679: generator_loss=-4.4662293308128653e-10, discriminator_loss=1.1963707038376015e-06\n",
            "step 4680: generator_loss=-4.2574885839030685e-09, discriminator_loss=8.828035902297415e-07\n",
            "step 4681: generator_loss=-3.0956592844688657e-10, discriminator_loss=5.172513283469016e-06\n",
            "step 4682: generator_loss=-9.9447894363891e-10, discriminator_loss=2.2421411927098234e-07\n",
            "step 4683: generator_loss=-1.6020909043845677e-09, discriminator_loss=1.1005250826201518e-06\n",
            "step 4684: generator_loss=-1.3906410467612318e-09, discriminator_loss=2.391849989180628e-07\n",
            "step 4685: generator_loss=-1.451648024008989e-09, discriminator_loss=3.744163734609174e-07\n",
            "step 4686: generator_loss=-7.090896203543195e-10, discriminator_loss=5.056703002992435e-07\n",
            "step 4687: generator_loss=-5.396577629213084e-10, discriminator_loss=1.241072709490254e-06\n",
            "step 4688: generator_loss=-1.345835942689888e-10, discriminator_loss=5.215412329562241e-06\n",
            "step 4689: generator_loss=-5.202013930727389e-09, discriminator_loss=2.040151457549655e-06\n",
            "step 4690: generator_loss=-3.334452713943392e-09, discriminator_loss=8.99624637895613e-07\n",
            "step 4691: generator_loss=-2.9305968762827206e-10, discriminator_loss=4.288546335828869e-07\n",
            "step 4692: generator_loss=-3.428237027591763e-09, discriminator_loss=5.202480224397732e-07\n",
            "step 4693: generator_loss=-5.304085504143075e-10, discriminator_loss=4.835329946217826e-06\n",
            "step 4694: generator_loss=-3.3989995262828643e-09, discriminator_loss=2.1035120312262734e-07\n",
            "step 4695: generator_loss=-4.451490565049454e-10, discriminator_loss=9.980830100175808e-07\n",
            "step 4696: generator_loss=-8.063689715953615e-10, discriminator_loss=7.102219115040498e-07\n",
            "step 4697: generator_loss=-5.351244780626985e-09, discriminator_loss=2.5173028461722424e-07\n",
            "step 4698: generator_loss=-5.501854527523165e-10, discriminator_loss=1.7524293980386574e-06\n",
            "step 4699: generator_loss=-2.6518085505244926e-09, discriminator_loss=7.59774025027582e-07\n",
            "step 4700: generator_loss=-5.9861018364415486e-09, discriminator_loss=9.368297355649702e-07\n",
            "step 4701: generator_loss=-4.4720421810140465e-10, discriminator_loss=1.4520287550112698e-06\n",
            "step 4702: generator_loss=-9.546984314212636e-10, discriminator_loss=7.348518238359247e-07\n",
            "step 4703: generator_loss=-1.4201725906382023e-10, discriminator_loss=2.0784059415746015e-06\n",
            "step 4704: generator_loss=-2.5986504059716253e-09, discriminator_loss=3.6381402424012776e-07\n",
            "step 4705: generator_loss=-1.5716635770601783e-09, discriminator_loss=2.3760816247886396e-07\n",
            "step 4706: generator_loss=-1.0475389444764005e-09, discriminator_loss=4.0495069697499275e-07\n",
            "step 4707: generator_loss=-1.2225878642802002e-10, discriminator_loss=2.67454907998399e-07\n",
            "step 4708: generator_loss=-4.230439110131101e-09, discriminator_loss=8.060724780989403e-07\n",
            "step 4709: generator_loss=-3.411313731493948e-10, discriminator_loss=7.156692390708486e-06\n",
            "step 4710: generator_loss=-2.6168209821264554e-09, discriminator_loss=1.3347820413400768e-06\n",
            "step 4711: generator_loss=-7.188432959992497e-09, discriminator_loss=1.4931995906408702e-07\n",
            "step 4712: generator_loss=-3.817545390916166e-09, discriminator_loss=2.215381158521268e-07\n",
            "step 4713: generator_loss=-8.564970954694218e-10, discriminator_loss=1.3552576092479285e-06\n",
            "step 4714: generator_loss=-4.594416846970262e-09, discriminator_loss=4.981455390407064e-07\n",
            "step 4715: generator_loss=-2.2494504037240404e-09, discriminator_loss=8.044198693824001e-07\n",
            "step 4716: generator_loss=-1.3302903223433304e-09, discriminator_loss=6.820378644079028e-07\n",
            "step 4717: generator_loss=-7.793861112048717e-10, discriminator_loss=3.565068880106992e-07\n",
            "step 4718: generator_loss=-1.6487694542988152e-10, discriminator_loss=4.2221714124934806e-07\n",
            "step 4719: generator_loss=-3.712474772044061e-09, discriminator_loss=2.274668077006936e-06\n",
            "step 4720: generator_loss=-3.729783593087177e-09, discriminator_loss=5.720130502595566e-07\n",
            "step 4721: generator_loss=-7.906182375450044e-09, discriminator_loss=1.4376910257851705e-06\n",
            "step 4722: generator_loss=-1.8412937841105759e-09, discriminator_loss=7.888063464633888e-07\n",
            "step 4723: generator_loss=-7.449229233458254e-09, discriminator_loss=5.00304395245621e-07\n",
            "step 4724: generator_loss=-3.3151943412690343e-09, discriminator_loss=1.0333648106097826e-06\n",
            "step 4725: generator_loss=-9.646344140135099e-11, discriminator_loss=2.8226213544257917e-07\n",
            "step 4726: generator_loss=-1.2602346943779708e-09, discriminator_loss=4.9273044169240166e-06\n",
            "step 4727: generator_loss=-3.0841529330416506e-10, discriminator_loss=3.458856667748478e-07\n",
            "step 4728: generator_loss=-3.8594391571500353e-10, discriminator_loss=1.5611719561547943e-07\n",
            "step 4729: generator_loss=-8.514474680865192e-10, discriminator_loss=1.5218476789868873e-07\n",
            "step 4730: generator_loss=-4.919211704645932e-10, discriminator_loss=9.698976555228e-07\n",
            "step 4731: generator_loss=-7.233764698355571e-10, discriminator_loss=1.2011439594061812e-06\n",
            "step 4732: generator_loss=-1.5338769143724562e-09, discriminator_loss=5.840232688569813e-07\n",
            "step 4733: generator_loss=-3.36853500648715e-09, discriminator_loss=4.172849799033429e-07\n",
            "step 4734: generator_loss=-5.16094611491269e-10, discriminator_loss=9.617785963200731e-07\n",
            "step 4735: generator_loss=-2.116518960093572e-09, discriminator_loss=3.6949575132894097e-07\n",
            "step 4736: generator_loss=-1.5356175220304635e-09, discriminator_loss=9.824418611970032e-07\n",
            "step 4737: generator_loss=-1.8370928389632724e-10, discriminator_loss=2.3379307094728574e-06\n",
            "step 4738: generator_loss=-5.181485240868255e-10, discriminator_loss=7.362638143604272e-08\n",
            "step 4739: generator_loss=-4.893860316990128e-10, discriminator_loss=2.2988734826867585e-07\n",
            "step 4740: generator_loss=-1.484524392303399e-09, discriminator_loss=1.8212139707429742e-07\n",
            "step 4741: generator_loss=-5.623034815549488e-10, discriminator_loss=6.103499572418514e-07\n",
            "step 4742: generator_loss=-2.1677573625034086e-10, discriminator_loss=3.2433183605462546e-07\n",
            "step 4743: generator_loss=-5.866447327917967e-10, discriminator_loss=2.4893238332879264e-06\n",
            "step 4744: generator_loss=-3.0782373872106916e-10, discriminator_loss=5.317980367181008e-07\n",
            "step 4745: generator_loss=-2.1954964513071218e-09, discriminator_loss=2.82006965335313e-07\n",
            "step 4746: generator_loss=-1.8003276647249322e-10, discriminator_loss=1.883210416053771e-06\n",
            "step 4747: generator_loss=-6.152563258865484e-08, discriminator_loss=6.248257591323636e-07\n",
            "step 4748: generator_loss=-3.9334505097521344e-10, discriminator_loss=2.5637884846219094e-06\n",
            "step 4749: generator_loss=-1.5398730068838518e-09, discriminator_loss=1.2744308151013684e-06\n",
            "step 4750: generator_loss=-2.8729887358025508e-09, discriminator_loss=1.605059424036881e-06\n",
            "step 4751: generator_loss=-1.3796226383533394e-09, discriminator_loss=5.996311642775254e-07\n",
            "step 4752: generator_loss=-2.63117305721039e-10, discriminator_loss=1.1627796681068503e-07\n",
            "step 4753: generator_loss=-8.663819661691718e-10, discriminator_loss=1.327441481180358e-07\n",
            "step 4754: generator_loss=-5.139936809506196e-10, discriminator_loss=1.0329132464903523e-06\n",
            "step 4755: generator_loss=-3.6004481618334694e-09, discriminator_loss=1.1345742478852117e-07\n",
            "step 4756: generator_loss=-4.220342120220266e-08, discriminator_loss=2.760435336313094e-06\n",
            "step 4757: generator_loss=-2.086994882466442e-10, discriminator_loss=7.774534651616705e-07\n",
            "step 4758: generator_loss=-1.266358906626408e-09, discriminator_loss=5.415682835518965e-07\n",
            "step 4759: generator_loss=-9.266375167182872e-11, discriminator_loss=1.2153483339716331e-06\n",
            "step 4760: generator_loss=-5.274934378185492e-10, discriminator_loss=2.956116986752022e-07\n",
            "step 4761: generator_loss=-5.548104198282999e-09, discriminator_loss=4.746737261029921e-07\n",
            "step 4762: generator_loss=-2.1274761952128074e-09, discriminator_loss=1.9989806787634734e-06\n",
            "step 4763: generator_loss=-2.3708224272667167e-10, discriminator_loss=2.8462139312068757e-07\n",
            "step 4764: generator_loss=-5.296526550679914e-10, discriminator_loss=1.4986661653892952e-06\n",
            "step 4765: generator_loss=-4.497172356732193e-10, discriminator_loss=5.526425752577779e-07\n",
            "step 4766: generator_loss=-1.4392884661873495e-09, discriminator_loss=9.03092995940824e-07\n",
            "step 4767: generator_loss=-9.071860485043715e-10, discriminator_loss=3.6169913641970197e-07\n",
            "step 4768: generator_loss=-6.7236527456771e-09, discriminator_loss=4.699068085756153e-06\n",
            "step 4769: generator_loss=-1.407385097351721e-09, discriminator_loss=2.2403539787774207e-06\n",
            "step 4770: generator_loss=-1.7297409060645919e-09, discriminator_loss=1.5986440757842502e-06\n",
            "step 4771: generator_loss=-4.3871922761340443e-10, discriminator_loss=7.591792723360413e-07\n",
            "step 4772: generator_loss=-5.131279290360169e-10, discriminator_loss=5.769761060037126e-07\n",
            "step 4773: generator_loss=-3.2178766318224916e-09, discriminator_loss=1.475224735258962e-06\n",
            "step 4774: generator_loss=-1.2892557854637943e-10, discriminator_loss=2.977121312142117e-06\n",
            "step 4775: generator_loss=-7.430269177710613e-10, discriminator_loss=2.2363406060321722e-06\n",
            "step 4776: generator_loss=-3.9409342456053764e-10, discriminator_loss=6.089960606914246e-07\n",
            "step 4777: generator_loss=-1.6034711336487817e-09, discriminator_loss=3.3095582807618484e-07\n",
            "step 4778: generator_loss=-5.121429391685695e-10, discriminator_loss=4.680717324845318e-07\n",
            "step 4779: generator_loss=-3.762574696253296e-10, discriminator_loss=5.153153779247077e-07\n",
            "step 4780: generator_loss=-1.4869002029627154e-08, discriminator_loss=2.4967221179394983e-07\n",
            "step 4781: generator_loss=-8.591013234138245e-09, discriminator_loss=5.514817189578025e-07\n",
            "step 4782: generator_loss=-8.531942929934644e-10, discriminator_loss=3.7170934774621855e-07\n",
            "step 4783: generator_loss=-1.7169291544050225e-09, discriminator_loss=8.81917628703377e-07\n",
            "step 4784: generator_loss=-8.721557365198862e-10, discriminator_loss=1.2484977673921094e-07\n",
            "step 4785: generator_loss=-7.086313758009055e-10, discriminator_loss=5.615826808025304e-07\n",
            "step 4786: generator_loss=-8.391274342045563e-10, discriminator_loss=1.2764509165208437e-06\n",
            "step 4787: generator_loss=-2.0040150094935427e-10, discriminator_loss=4.698182749507396e-07\n",
            "step 4788: generator_loss=-2.0734897132612673e-10, discriminator_loss=5.495681421052723e-07\n",
            "step 4789: generator_loss=-1.710707686619628e-09, discriminator_loss=7.136910653571249e-07\n",
            "step 4790: generator_loss=-2.6925213170159168e-09, discriminator_loss=1.0819951512530679e-06\n",
            "step 4791: generator_loss=-5.3788109966035336e-08, discriminator_loss=6.328183985715441e-07\n",
            "step 4792: generator_loss=-1.1499674545945027e-09, discriminator_loss=1.4526499114708713e-07\n",
            "step 4793: generator_loss=-2.7126603741045585e-10, discriminator_loss=3.8398766832870024e-07\n",
            "step 4794: generator_loss=-2.3806971949369427e-09, discriminator_loss=2.2800234091846505e-06\n",
            "step 4795: generator_loss=-5.496370025781516e-09, discriminator_loss=5.592331149273377e-07\n",
            "step 4796: generator_loss=-1.3741285886936794e-09, discriminator_loss=1.616096710677084e-06\n",
            "step 4797: generator_loss=-1.0233397063075245e-07, discriminator_loss=2.954440105895628e-07\n",
            "step 4798: generator_loss=-1.4174282858547826e-09, discriminator_loss=2.3471973520372558e-07\n",
            "step 4799: generator_loss=-1.81118942066405e-09, discriminator_loss=6.987985671003116e-06\n",
            "step 4800: generator_loss=-1.6563015403647796e-09, discriminator_loss=7.584584409414674e-07\n",
            "step 4801: generator_loss=-6.345032943499973e-09, discriminator_loss=1.0952273896691622e-06\n",
            "step 4802: generator_loss=-2.8616733982467224e-10, discriminator_loss=3.154510295644286e-06\n",
            "step 4803: generator_loss=-2.3858181208424867e-08, discriminator_loss=5.589434977082419e-07\n",
            "step 4804: generator_loss=-5.018050419636211e-10, discriminator_loss=7.819453458068892e-07\n",
            "step 4805: generator_loss=-5.614563036715481e-09, discriminator_loss=1.1033305327146081e-06\n",
            "step 4806: generator_loss=-1.1618996043072372e-10, discriminator_loss=1.6661787185512367e-06\n",
            "step 4807: generator_loss=-1.0717717824348938e-09, discriminator_loss=9.462385719416488e-07\n",
            "step 4808: generator_loss=-4.5851628049931037e-10, discriminator_loss=4.1097832763625775e-06\n",
            "step 4809: generator_loss=-3.0164676312338656e-10, discriminator_loss=3.121976135389559e-07\n",
            "step 4810: generator_loss=-2.2892132633955953e-10, discriminator_loss=5.033938577980734e-06\n",
            "step 4811: generator_loss=-4.401752740079701e-09, discriminator_loss=1.1071255130445934e-06\n",
            "step 4812: generator_loss=-9.592344696329747e-10, discriminator_loss=1.976551544657923e-07\n",
            "step 4813: generator_loss=-1.0598891764246332e-09, discriminator_loss=9.022159019878018e-08\n",
            "step 4814: generator_loss=-1.4595878949918983e-09, discriminator_loss=4.8873994273890276e-06\n",
            "step 4815: generator_loss=-4.58328619501458e-09, discriminator_loss=7.240371360239806e-07\n",
            "step 4816: generator_loss=-6.7978924711553645e-09, discriminator_loss=2.6940261932395515e-07\n",
            "step 4817: generator_loss=-4.926358210255444e-10, discriminator_loss=1.3934820799477166e-06\n",
            "step 4818: generator_loss=-2.380006192126416e-10, discriminator_loss=2.685235074295633e-07\n",
            "step 4819: generator_loss=-1.908067481792841e-09, discriminator_loss=9.981922630686313e-07\n",
            "step 4820: generator_loss=-4.726691038570152e-09, discriminator_loss=1.9007504761248128e-06\n",
            "step 4821: generator_loss=-1.0643079750849438e-09, discriminator_loss=5.9181320466450416e-06\n",
            "step 4822: generator_loss=-6.934925411705706e-10, discriminator_loss=3.4108992963410856e-07\n",
            "step 4823: generator_loss=-1.1100473873426608e-09, discriminator_loss=6.033254749127082e-07\n",
            "step 4824: generator_loss=-2.145902344707906e-09, discriminator_loss=8.583164117226261e-07\n",
            "step 4825: generator_loss=-5.734815955449335e-10, discriminator_loss=1.0443241080793086e-06\n",
            "step 4826: generator_loss=-9.001206724423838e-11, discriminator_loss=8.163626716850558e-07\n",
            "step 4827: generator_loss=-5.538260072768253e-09, discriminator_loss=1.102568944588711e-06\n",
            "step 4828: generator_loss=-4.560220645544177e-09, discriminator_loss=5.620820502372226e-07\n",
            "step 4829: generator_loss=-7.44339867519983e-10, discriminator_loss=8.505583650730841e-07\n",
            "step 4830: generator_loss=-2.889372741066154e-09, discriminator_loss=7.521677503063984e-07\n",
            "step 4831: generator_loss=-6.019383325117644e-10, discriminator_loss=5.546383476939809e-07\n",
            "step 4832: generator_loss=-1.1279802647479187e-09, discriminator_loss=5.759814598604862e-07\n",
            "step 4833: generator_loss=-2.375731833481609e-10, discriminator_loss=4.6901311634428566e-07\n",
            "step 4834: generator_loss=-5.900298583050301e-10, discriminator_loss=2.7846971306644264e-07\n",
            "step 4835: generator_loss=-8.237177051562128e-10, discriminator_loss=9.515222814115987e-07\n",
            "step 4836: generator_loss=-6.287316223207995e-10, discriminator_loss=5.307636001816718e-07\n",
            "step 4837: generator_loss=-1.3578990709639527e-10, discriminator_loss=5.210118843024247e-07\n",
            "step 4838: generator_loss=-1.2665408721801441e-09, discriminator_loss=4.0929219835561526e-07\n",
            "step 4839: generator_loss=-6.599951696273365e-10, discriminator_loss=2.007423290706356e-06\n",
            "step 4840: generator_loss=-2.555752587340976e-08, discriminator_loss=5.071834721093182e-07\n",
            "step 4841: generator_loss=-9.409524270864722e-10, discriminator_loss=1.5421723276176635e-07\n",
            "step 4842: generator_loss=-6.135768004789099e-10, discriminator_loss=3.6005238257530436e-07\n",
            "step 4843: generator_loss=-2.128022869030133e-09, discriminator_loss=3.2149591788765974e-07\n",
            "step 4844: generator_loss=-6.022640164360382e-10, discriminator_loss=1.8711001814608608e-07\n",
            "step 4845: generator_loss=-2.79527223590037e-09, discriminator_loss=8.624942324786389e-07\n",
            "step 4846: generator_loss=-7.920998301713666e-10, discriminator_loss=1.8464083950675558e-07\n",
            "step 4847: generator_loss=-3.9856268285731744e-10, discriminator_loss=1.972692871277104e-06\n",
            "step 4848: generator_loss=-4.123606345274311e-09, discriminator_loss=4.032640106288454e-07\n",
            "step 4849: generator_loss=-2.2221002815570046e-09, discriminator_loss=6.342843903439643e-07\n",
            "step 4850: generator_loss=-2.4167703949196095e-10, discriminator_loss=9.172333079732198e-07\n",
            "step 4851: generator_loss=-3.3676836874718674e-09, discriminator_loss=4.1723725985320925e-07\n",
            "step 4852: generator_loss=-6.82201406476679e-10, discriminator_loss=1.3853568816557527e-06\n",
            "step 4853: generator_loss=-1.5493289984291891e-10, discriminator_loss=7.339787089222227e-07\n",
            "step 4854: generator_loss=-8.688589292482618e-10, discriminator_loss=3.842982607693557e-07\n",
            "step 4855: generator_loss=-1.9791672745128608e-09, discriminator_loss=2.3311032748551952e-07\n",
            "step 4856: generator_loss=-3.2483091216839455e-10, discriminator_loss=8.853598387759121e-07\n",
            "step 4857: generator_loss=-1.708644781217572e-09, discriminator_loss=3.0779958137827634e-07\n",
            "step 4858: generator_loss=-2.400358245502332e-10, discriminator_loss=6.966624823689926e-06\n",
            "step 4859: generator_loss=-1.2845835506425374e-08, discriminator_loss=2.786702452794998e-06\n",
            "step 4860: generator_loss=-2.0349849583212176e-10, discriminator_loss=6.112439905336942e-07\n",
            "step 4861: generator_loss=-6.912974082062817e-10, discriminator_loss=5.210296762925282e-07\n",
            "step 4862: generator_loss=-1.694142492958406e-09, discriminator_loss=5.845895429956727e-07\n",
            "step 4863: generator_loss=-6.696717846921274e-09, discriminator_loss=6.034247235220391e-07\n",
            "step 4864: generator_loss=-3.3017094613896347e-10, discriminator_loss=3.1267506983567728e-06\n",
            "step 4865: generator_loss=-9.92650073250445e-10, discriminator_loss=5.457534939523612e-07\n",
            "step 4866: generator_loss=-2.0084496288319542e-09, discriminator_loss=9.146225465883617e-07\n",
            "step 4867: generator_loss=-1.6979170847086777e-10, discriminator_loss=1.2886799822808825e-06\n",
            "step 4868: generator_loss=-8.55416959488764e-10, discriminator_loss=1.1310014542686986e-06\n",
            "step 4869: generator_loss=-9.782848975348202e-10, discriminator_loss=5.543266183849482e-07\n",
            "step 4870: generator_loss=-1.6544425551767716e-10, discriminator_loss=9.462149250794027e-07\n",
            "step 4871: generator_loss=-3.617723010052032e-09, discriminator_loss=5.568510914599756e-07\n",
            "step 4872: generator_loss=-4.314495871682311e-09, discriminator_loss=2.1243431547190994e-07\n",
            "step 4873: generator_loss=-2.102520824109888e-09, discriminator_loss=4.861240086029284e-07\n",
            "step 4874: generator_loss=-2.7347860087623133e-10, discriminator_loss=5.11577354700421e-07\n",
            "step 4875: generator_loss=-1.066744692579391e-09, discriminator_loss=1.4433135220315307e-06\n",
            "step 4876: generator_loss=-4.521359953102433e-10, discriminator_loss=5.110831011734263e-07\n",
            "step 4877: generator_loss=-3.6061623132077614e-10, discriminator_loss=3.0292983410618035e-07\n",
            "step 4878: generator_loss=-1.41035749745555e-09, discriminator_loss=7.692227654843009e-07\n",
            "step 4879: generator_loss=-1.3459022785156094e-09, discriminator_loss=1.0968294645863352e-06\n",
            "step 4880: generator_loss=-1.6515306899833604e-09, discriminator_loss=1.0858578889383352e-06\n",
            "step 4881: generator_loss=-1.495394086337143e-10, discriminator_loss=1.9711444565473357e-06\n",
            "step 4882: generator_loss=-1.115620928970884e-09, discriminator_loss=3.112826050255535e-07\n",
            "step 4883: generator_loss=-1.4298563444370416e-09, discriminator_loss=1.3958584759166115e-06\n",
            "step 4884: generator_loss=-8.501117587655926e-10, discriminator_loss=1.9684644314565958e-07\n",
            "step 4885: generator_loss=-1.2697335405320587e-09, discriminator_loss=6.113717745392933e-07\n",
            "step 4886: generator_loss=-2.507767049575449e-10, discriminator_loss=1.3417360378298326e-06\n",
            "step 4887: generator_loss=-1.6346901610120312e-10, discriminator_loss=9.532481044516317e-07\n",
            "step 4888: generator_loss=-3.7119600726498447e-09, discriminator_loss=7.406582085422997e-07\n",
            "step 4889: generator_loss=-2.335910798123564e-09, discriminator_loss=4.4653376107817166e-07\n",
            "step 4890: generator_loss=-5.676377146102141e-09, discriminator_loss=8.446350534541125e-07\n",
            "step 4891: generator_loss=-4.851868906641243e-10, discriminator_loss=5.131495299792732e-07\n",
            "step 4892: generator_loss=-1.1827024914978779e-09, discriminator_loss=3.7886309200985124e-07\n",
            "step 4893: generator_loss=-1.0255939431047523e-09, discriminator_loss=2.742290462265373e-06\n",
            "step 4894: generator_loss=-8.61228588444618e-10, discriminator_loss=1.1832366908492986e-06\n",
            "step 4895: generator_loss=-1.8735502038680352e-08, discriminator_loss=1.0849860245798482e-06\n",
            "step 4896: generator_loss=-3.190969932731491e-09, discriminator_loss=2.649744033078605e-07\n",
            "step 4897: generator_loss=-4.0850478555398695e-09, discriminator_loss=5.177883508622472e-07\n",
            "step 4898: generator_loss=-4.519740692821017e-10, discriminator_loss=2.8120908268647327e-07\n",
            "step 4899: generator_loss=-3.023072625563117e-10, discriminator_loss=4.807351956515049e-07\n",
            "step 4900: generator_loss=-2.6546937981208885e-09, discriminator_loss=5.355651069294254e-07\n",
            "step 4901: generator_loss=-6.182397371823356e-10, discriminator_loss=1.6685836499163997e-06\n",
            "step 4902: generator_loss=-1.5234712380518545e-09, discriminator_loss=2.0234765543136746e-06\n",
            "step 4903: generator_loss=-1.4621584498719642e-10, discriminator_loss=4.2676333578128833e-07\n",
            "step 4904: generator_loss=-6.325425516706673e-09, discriminator_loss=7.697070145695761e-07\n",
            "step 4905: generator_loss=-4.0332140405219263e-10, discriminator_loss=1.0834911563506466e-06\n",
            "step 4906: generator_loss=-9.076059903634359e-10, discriminator_loss=4.5265659309734474e-07\n",
            "step 4907: generator_loss=-7.553749292732448e-10, discriminator_loss=4.4570805357579957e-07\n",
            "step 4908: generator_loss=-2.267080212448036e-08, discriminator_loss=5.536586513699149e-07\n",
            "step 4909: generator_loss=-4.0037074350296464e-11, discriminator_loss=2.0634697648347355e-06\n",
            "step 4910: generator_loss=-1.4907871603853096e-09, discriminator_loss=4.853419000028225e-07\n",
            "step 4911: generator_loss=-1.0729689137178866e-08, discriminator_loss=5.171818884264212e-06\n",
            "step 4912: generator_loss=-4.587411783774087e-09, discriminator_loss=5.123789037497772e-07\n",
            "step 4913: generator_loss=-7.486714359572488e-09, discriminator_loss=1.174787939817179e-06\n",
            "step 4914: generator_loss=-2.5821753624200028e-09, discriminator_loss=5.744148552366823e-07\n",
            "step 4915: generator_loss=-8.516808924774466e-10, discriminator_loss=1.1204632528460934e-06\n",
            "step 4916: generator_loss=-1.5164959288327395e-09, discriminator_loss=9.65289473242592e-07\n",
            "step 4917: generator_loss=-8.981921317818831e-10, discriminator_loss=5.690261559720966e-07\n",
            "step 4918: generator_loss=-2.25362750683189e-09, discriminator_loss=6.702852033413365e-07\n",
            "step 4919: generator_loss=-1.6091444843269187e-09, discriminator_loss=2.739923502304009e-06\n",
            "step 4920: generator_loss=-1.0891625379372272e-09, discriminator_loss=3.9996157852328906e-07\n",
            "step 4921: generator_loss=-3.7935851682213695e-10, discriminator_loss=4.135214481948424e-08\n",
            "step 4922: generator_loss=-1.5469898695386064e-09, discriminator_loss=6.15975579876249e-07\n",
            "step 4923: generator_loss=-8.648600724470157e-10, discriminator_loss=1.563114153668721e-07\n",
            "step 4924: generator_loss=-2.7491071641350118e-09, discriminator_loss=1.001528858068923e-06\n",
            "step 4925: generator_loss=-3.7332523183941646e-10, discriminator_loss=4.0129307876668463e-07\n",
            "step 4926: generator_loss=-8.270357731987588e-10, discriminator_loss=1.0535405863265623e-06\n",
            "step 4927: generator_loss=-1.0369781699992586e-09, discriminator_loss=2.683299840100517e-07\n",
            "step 4928: generator_loss=-6.806883390275686e-10, discriminator_loss=2.931390383764665e-07\n",
            "step 4929: generator_loss=-9.615623852710087e-09, discriminator_loss=5.052531378169078e-06\n",
            "step 4930: generator_loss=-2.680497490636924e-10, discriminator_loss=1.7511270016257185e-06\n",
            "step 4931: generator_loss=-9.196003958322763e-10, discriminator_loss=9.527540782983124e-07\n",
            "step 4932: generator_loss=-4.248326135325442e-10, discriminator_loss=1.2043080914736493e-06\n",
            "step 4933: generator_loss=-1.505320978978375e-09, discriminator_loss=1.353826064587338e-06\n",
            "step 4934: generator_loss=-2.2091042328753474e-09, discriminator_loss=1.0087628652399871e-06\n",
            "step 4935: generator_loss=-1.1908009023287036e-09, discriminator_loss=4.662699950586102e-07\n",
            "step 4936: generator_loss=-1.6072200237360335e-09, discriminator_loss=4.243624402988644e-07\n",
            "step 4937: generator_loss=-1.4055945296576056e-10, discriminator_loss=2.496644242455659e-07\n",
            "step 4938: generator_loss=-2.5032023120985514e-09, discriminator_loss=8.594096243541571e-07\n",
            "step 4939: generator_loss=-5.688037818529779e-10, discriminator_loss=4.11758520613148e-07\n",
            "step 4940: generator_loss=-1.375892111354915e-08, discriminator_loss=2.7119117476104293e-06\n",
            "step 4941: generator_loss=-4.38031888538859e-10, discriminator_loss=1.5598865275023854e-06\n",
            "step 4942: generator_loss=-1.9167575859846409e-10, discriminator_loss=3.1184634963210556e-07\n",
            "step 4943: generator_loss=-1.3215137872890637e-09, discriminator_loss=1.3237436178314965e-06\n",
            "step 4944: generator_loss=-2.651537878151089e-10, discriminator_loss=1.7508834844193188e-06\n",
            "step 4945: generator_loss=-5.207173581212032e-10, discriminator_loss=2.179881221309188e-06\n",
            "step 4946: generator_loss=-1.946067473834745e-10, discriminator_loss=2.077658336929744e-06\n",
            "step 4947: generator_loss=-8.054852895789111e-10, discriminator_loss=1.1183556125615723e-06\n",
            "step 4948: generator_loss=-1.353513634505532e-09, discriminator_loss=1.9976441478775087e-07\n",
            "step 4949: generator_loss=-1.0847623910237303e-09, discriminator_loss=9.921769361653787e-08\n",
            "step 4950: generator_loss=-2.828900891316266e-09, discriminator_loss=2.8669103357970016e-07\n",
            "step 4951: generator_loss=-2.0419479440647592e-09, discriminator_loss=3.5677794585353695e-07\n",
            "step 4952: generator_loss=-9.700720227101556e-09, discriminator_loss=3.6931047020516417e-07\n",
            "step 4953: generator_loss=-9.208223517020997e-09, discriminator_loss=3.0689514005644014e-06\n",
            "step 4954: generator_loss=-1.1519825093841973e-08, discriminator_loss=3.1767578434482857e-07\n",
            "step 4955: generator_loss=-1.504979141309093e-09, discriminator_loss=8.447880190942669e-07\n",
            "step 4956: generator_loss=-6.116778195064398e-10, discriminator_loss=4.0072754359243845e-07\n",
            "step 4957: generator_loss=-5.808689640396381e-10, discriminator_loss=3.9998306533561845e-07\n",
            "step 4958: generator_loss=-2.0113355425621648e-10, discriminator_loss=1.429807866770716e-06\n",
            "step 4959: generator_loss=-9.455007610181809e-11, discriminator_loss=1.4500637917080894e-06\n",
            "step 4960: generator_loss=-2.5411620030446613e-10, discriminator_loss=2.416336428723298e-07\n",
            "step 4961: generator_loss=-1.2741636634672204e-09, discriminator_loss=4.371552222437458e-07\n",
            "step 4962: generator_loss=-2.298695234159709e-09, discriminator_loss=3.5486586966726463e-06\n",
            "step 4963: generator_loss=-1.0269508854410248e-10, discriminator_loss=2.1271627304031426e-07\n",
            "step 4964: generator_loss=-1.9351857893923352e-09, discriminator_loss=3.709334919221874e-07\n",
            "step 4965: generator_loss=-7.826440606706342e-10, discriminator_loss=9.342085149910417e-07\n",
            "step 4966: generator_loss=-1.0727527754994526e-09, discriminator_loss=5.256973736322834e-07\n",
            "step 4967: generator_loss=-6.589762624464868e-10, discriminator_loss=1.9570389042655734e-07\n",
            "step 4968: generator_loss=-1.328606114014974e-10, discriminator_loss=1.266300500901707e-06\n",
            "step 4969: generator_loss=-1.129288329515532e-09, discriminator_loss=1.758407393026573e-07\n",
            "step 4970: generator_loss=-1.6290913062988466e-10, discriminator_loss=2.4594996261839697e-07\n",
            "step 4971: generator_loss=-7.075163788172745e-10, discriminator_loss=1.0598797217653555e-07\n",
            "step 4972: generator_loss=-1.2629080892168076e-08, discriminator_loss=6.235395630938001e-07\n",
            "step 4973: generator_loss=-4.013600563013142e-10, discriminator_loss=5.451513516163686e-07\n",
            "step 4974: generator_loss=-1.887332290451127e-09, discriminator_loss=5.276347678773163e-07\n",
            "step 4975: generator_loss=-2.4688048827492537e-10, discriminator_loss=5.039486268287874e-07\n",
            "step 4976: generator_loss=-4.744982184945457e-10, discriminator_loss=8.892139362615126e-07\n",
            "step 4977: generator_loss=-3.139517534833658e-10, discriminator_loss=4.5187314867689565e-07\n",
            "step 4978: generator_loss=-2.446682856316329e-10, discriminator_loss=4.801519253305742e-07\n",
            "step 4979: generator_loss=-2.0767883246453067e-10, discriminator_loss=2.0223538399477548e-07\n",
            "step 4980: generator_loss=-1.0201455236114043e-09, discriminator_loss=1.1871536571561592e-06\n",
            "step 4981: generator_loss=-4.702024325453635e-10, discriminator_loss=6.857593461973011e-07\n",
            "step 4982: generator_loss=-2.0449892446094964e-08, discriminator_loss=3.1130417710301117e-07\n",
            "step 4983: generator_loss=-3.055387054473613e-09, discriminator_loss=5.350910896595451e-07\n",
            "step 4984: generator_loss=-9.81885461825982e-10, discriminator_loss=1.02675494417781e-06\n",
            "step 4985: generator_loss=-2.540062826739131e-09, discriminator_loss=5.57064481654379e-07\n",
            "step 4986: generator_loss=-1.0848113518591163e-09, discriminator_loss=6.574779121137908e-08\n",
            "step 4987: generator_loss=-2.7187261331107493e-09, discriminator_loss=1.9141066331940237e-06\n",
            "step 4988: generator_loss=-2.4263355213882676e-10, discriminator_loss=3.61801176040899e-06\n",
            "step 4989: generator_loss=-5.621082488360685e-10, discriminator_loss=8.911452482607274e-07\n",
            "step 4990: generator_loss=-9.730377614758368e-10, discriminator_loss=1.1700885806931183e-06\n",
            "step 4991: generator_loss=-1.0016811824442584e-09, discriminator_loss=1.564235958539939e-07\n",
            "step 4992: generator_loss=-2.733930415388386e-09, discriminator_loss=1.523992807506147e-07\n",
            "step 4993: generator_loss=-1.1195160709576157e-07, discriminator_loss=6.535349825753656e-07\n",
            "step 4994: generator_loss=-1.1512641950872649e-09, discriminator_loss=3.2358232715523627e-07\n",
            "step 4995: generator_loss=-3.076308541238859e-09, discriminator_loss=2.1187449306125927e-07\n",
            "step 4996: generator_loss=-1.0373935044327709e-09, discriminator_loss=1.124747768699308e-06\n",
            "step 4997: generator_loss=-2.9901658926689834e-09, discriminator_loss=4.1154740415549895e-07\n",
            "step 4998: generator_loss=-3.2905065339150497e-09, discriminator_loss=1.332292072220298e-07\n",
            "step 4999: generator_loss=-1.3142630039819636e-10, discriminator_loss=3.678597124689986e-07\n",
            "step 5000: generator_loss=-2.245124086641681e-10, discriminator_loss=8.25367010293121e-07\n",
            "=== Running experiment with loss_type=nonsaturating ===\n",
            "step 1: generator_loss=0.2220316231250763, discriminator_loss=1.2541497945785522\n",
            "step 2: generator_loss=0.14998844265937805, discriminator_loss=1.4278154373168945\n",
            "step 3: generator_loss=0.1237812414765358, discriminator_loss=1.5277761220932007\n",
            "step 4: generator_loss=0.11636380106210709, discriminator_loss=1.5653491020202637\n",
            "step 5: generator_loss=0.07775133848190308, discriminator_loss=1.6967415809631348\n",
            "step 6: generator_loss=0.061135489493608475, discriminator_loss=1.9087190628051758\n",
            "step 7: generator_loss=0.03795145824551582, discriminator_loss=2.0578203201293945\n",
            "step 8: generator_loss=0.03673314303159714, discriminator_loss=2.0697999000549316\n",
            "step 9: generator_loss=0.05259712412953377, discriminator_loss=1.9056003093719482\n",
            "step 10: generator_loss=0.05362449213862419, discriminator_loss=1.8202672004699707\n",
            "step 11: generator_loss=0.05633144825696945, discriminator_loss=1.7800620794296265\n",
            "step 12: generator_loss=0.06859070062637329, discriminator_loss=1.7085665464401245\n",
            "step 13: generator_loss=0.06811254471540451, discriminator_loss=1.7070403099060059\n",
            "step 14: generator_loss=0.09769327938556671, discriminator_loss=1.5205540657043457\n",
            "step 15: generator_loss=0.09688453376293182, discriminator_loss=1.5331820249557495\n",
            "step 16: generator_loss=0.10736502707004547, discriminator_loss=1.4396343231201172\n",
            "step 17: generator_loss=0.13035151362419128, discriminator_loss=1.3473249673843384\n",
            "step 18: generator_loss=0.12951546907424927, discriminator_loss=1.3730931282043457\n",
            "step 19: generator_loss=0.1353861689567566, discriminator_loss=1.3175216913223267\n",
            "step 20: generator_loss=0.1686975210905075, discriminator_loss=1.2328863143920898\n",
            "step 21: generator_loss=0.17630061507225037, discriminator_loss=1.2576541900634766\n",
            "step 22: generator_loss=0.1751212477684021, discriminator_loss=1.2236403226852417\n",
            "step 23: generator_loss=0.1718911975622177, discriminator_loss=1.2945002317428589\n",
            "step 24: generator_loss=0.16527056694030762, discriminator_loss=1.2408620119094849\n",
            "step 25: generator_loss=0.16532911360263824, discriminator_loss=1.2812293767929077\n",
            "step 26: generator_loss=0.19239696860313416, discriminator_loss=1.2460335493087769\n",
            "step 27: generator_loss=0.16591259837150574, discriminator_loss=1.3655352592468262\n",
            "step 28: generator_loss=0.1472129076719284, discriminator_loss=1.2921737432479858\n",
            "step 29: generator_loss=0.1465025544166565, discriminator_loss=1.295636534690857\n",
            "step 30: generator_loss=0.14844851195812225, discriminator_loss=1.3548880815505981\n",
            "step 31: generator_loss=0.1444673091173172, discriminator_loss=1.3229718208312988\n",
            "step 32: generator_loss=0.19037002325057983, discriminator_loss=1.30048668384552\n",
            "step 33: generator_loss=0.14986276626586914, discriminator_loss=1.362483263015747\n",
            "step 34: generator_loss=0.15673786401748657, discriminator_loss=1.3451987504959106\n",
            "step 35: generator_loss=0.18019814789295197, discriminator_loss=1.2787140607833862\n",
            "step 36: generator_loss=0.17323444783687592, discriminator_loss=1.293242335319519\n",
            "step 37: generator_loss=0.16725674271583557, discriminator_loss=1.3599663972854614\n",
            "step 38: generator_loss=0.19675461947917938, discriminator_loss=1.2161484956741333\n",
            "step 39: generator_loss=0.23234714567661285, discriminator_loss=1.1241731643676758\n",
            "step 40: generator_loss=0.23014019429683685, discriminator_loss=1.0865941047668457\n",
            "step 41: generator_loss=0.23249301314353943, discriminator_loss=1.080981731414795\n",
            "step 42: generator_loss=0.2584690451622009, discriminator_loss=1.036180019378662\n",
            "step 43: generator_loss=0.3605993390083313, discriminator_loss=0.884117603302002\n",
            "step 44: generator_loss=0.39541471004486084, discriminator_loss=0.8088847994804382\n",
            "step 45: generator_loss=0.48792508244514465, discriminator_loss=0.7056024074554443\n",
            "step 46: generator_loss=0.5375533103942871, discriminator_loss=0.6402605772018433\n",
            "step 47: generator_loss=0.7296860218048096, discriminator_loss=0.536407470703125\n",
            "step 48: generator_loss=0.8610175848007202, discriminator_loss=0.4559279680252075\n",
            "step 49: generator_loss=1.169452428817749, discriminator_loss=0.3417690694332123\n",
            "step 50: generator_loss=1.1698023080825806, discriminator_loss=0.30327677726745605\n",
            "step 51: generator_loss=1.3782613277435303, discriminator_loss=0.2793750762939453\n",
            "step 52: generator_loss=1.568969964981079, discriminator_loss=0.24107448756694794\n",
            "step 53: generator_loss=1.7460265159606934, discriminator_loss=0.19864842295646667\n",
            "step 54: generator_loss=1.7577083110809326, discriminator_loss=0.18868359923362732\n",
            "step 55: generator_loss=1.8973937034606934, discriminator_loss=0.17682430148124695\n",
            "step 56: generator_loss=2.075270414352417, discriminator_loss=0.16086561977863312\n",
            "step 57: generator_loss=1.9464902877807617, discriminator_loss=0.16797272861003876\n",
            "step 58: generator_loss=2.0820469856262207, discriminator_loss=0.1578790247440338\n",
            "step 59: generator_loss=2.014538049697876, discriminator_loss=0.16639378666877747\n",
            "step 60: generator_loss=2.204519748687744, discriminator_loss=0.1254706084728241\n",
            "step 61: generator_loss=2.4651126861572266, discriminator_loss=0.11454091966152191\n",
            "step 62: generator_loss=2.3828091621398926, discriminator_loss=0.10241973400115967\n",
            "step 63: generator_loss=2.4113636016845703, discriminator_loss=0.11720368266105652\n",
            "step 64: generator_loss=2.6318917274475098, discriminator_loss=0.0801135003566742\n",
            "step 65: generator_loss=2.6604843139648438, discriminator_loss=0.08811673521995544\n",
            "step 66: generator_loss=2.7924752235412598, discriminator_loss=0.07177728414535522\n",
            "step 67: generator_loss=2.861130714416504, discriminator_loss=0.06999783217906952\n",
            "step 68: generator_loss=2.94643497467041, discriminator_loss=0.07402971386909485\n",
            "step 69: generator_loss=2.911705493927002, discriminator_loss=0.07508301734924316\n",
            "step 70: generator_loss=2.961705207824707, discriminator_loss=0.07110252231359482\n",
            "step 71: generator_loss=2.985090494155884, discriminator_loss=0.06829030811786652\n",
            "step 72: generator_loss=3.0604019165039062, discriminator_loss=0.06211978569626808\n",
            "step 73: generator_loss=2.9782328605651855, discriminator_loss=0.060733381658792496\n",
            "step 74: generator_loss=2.852743625640869, discriminator_loss=0.07066761702299118\n",
            "step 75: generator_loss=2.993412733078003, discriminator_loss=0.06760632991790771\n",
            "step 76: generator_loss=2.901167392730713, discriminator_loss=0.06868108361959457\n",
            "step 77: generator_loss=3.061964750289917, discriminator_loss=0.07113052904605865\n",
            "step 78: generator_loss=3.0198702812194824, discriminator_loss=0.05488311126828194\n",
            "step 79: generator_loss=3.1777634620666504, discriminator_loss=0.054271090775728226\n",
            "step 80: generator_loss=3.681828022003174, discriminator_loss=0.04285014420747757\n",
            "step 81: generator_loss=3.5458922386169434, discriminator_loss=0.04983937367796898\n",
            "step 82: generator_loss=3.592609405517578, discriminator_loss=0.04385245591402054\n",
            "step 83: generator_loss=3.801510810852051, discriminator_loss=0.051465533673763275\n",
            "step 84: generator_loss=3.747161388397217, discriminator_loss=0.03684965521097183\n",
            "step 85: generator_loss=3.9393208026885986, discriminator_loss=0.05395829305052757\n",
            "step 86: generator_loss=3.6485137939453125, discriminator_loss=0.04154810309410095\n",
            "step 87: generator_loss=3.433199405670166, discriminator_loss=0.06218655779957771\n",
            "step 88: generator_loss=3.368899345397949, discriminator_loss=0.05555487796664238\n",
            "step 89: generator_loss=3.3969645500183105, discriminator_loss=0.0642191469669342\n",
            "step 90: generator_loss=3.3217201232910156, discriminator_loss=0.07135792076587677\n",
            "step 91: generator_loss=3.5857834815979004, discriminator_loss=0.04891035705804825\n",
            "step 92: generator_loss=3.707742214202881, discriminator_loss=0.05817364156246185\n",
            "step 93: generator_loss=4.035467147827148, discriminator_loss=0.038640618324279785\n",
            "step 94: generator_loss=4.169470310211182, discriminator_loss=0.046390388160943985\n",
            "step 95: generator_loss=4.6679840087890625, discriminator_loss=0.03228139132261276\n",
            "step 96: generator_loss=4.306598663330078, discriminator_loss=0.03745285049080849\n",
            "step 97: generator_loss=4.274764537811279, discriminator_loss=0.03147999197244644\n",
            "step 98: generator_loss=3.811032772064209, discriminator_loss=0.04942389577627182\n",
            "step 99: generator_loss=3.9565460681915283, discriminator_loss=0.043703675270080566\n",
            "step 100: generator_loss=3.8275110721588135, discriminator_loss=0.03917611390352249\n",
            "step 101: generator_loss=3.848954200744629, discriminator_loss=0.04236595332622528\n",
            "step 102: generator_loss=3.7493581771850586, discriminator_loss=0.043278150260448456\n",
            "step 103: generator_loss=4.039673328399658, discriminator_loss=0.04714920371770859\n",
            "step 104: generator_loss=4.279834747314453, discriminator_loss=0.035470105707645416\n",
            "step 105: generator_loss=4.743220806121826, discriminator_loss=0.031422536820173264\n",
            "step 106: generator_loss=4.784129619598389, discriminator_loss=0.03430045023560524\n",
            "step 107: generator_loss=5.123572826385498, discriminator_loss=0.0237247534096241\n",
            "step 108: generator_loss=5.235337257385254, discriminator_loss=0.021251406520605087\n",
            "step 109: generator_loss=5.335696697235107, discriminator_loss=0.02691604197025299\n",
            "step 110: generator_loss=5.144436836242676, discriminator_loss=0.025315068662166595\n",
            "step 111: generator_loss=5.097031116485596, discriminator_loss=0.025817815214395523\n",
            "step 112: generator_loss=4.709521770477295, discriminator_loss=0.031504277139902115\n",
            "step 113: generator_loss=4.715863227844238, discriminator_loss=0.031126663088798523\n",
            "step 114: generator_loss=4.68941068649292, discriminator_loss=0.03326835855841637\n",
            "step 115: generator_loss=4.416384696960449, discriminator_loss=0.041807565838098526\n",
            "step 116: generator_loss=4.545174598693848, discriminator_loss=0.03365899622440338\n",
            "step 117: generator_loss=4.913252830505371, discriminator_loss=0.034279923886060715\n",
            "step 118: generator_loss=5.2525129318237305, discriminator_loss=0.027108561247587204\n",
            "step 119: generator_loss=5.151203155517578, discriminator_loss=0.024676872417330742\n",
            "step 120: generator_loss=5.4216413497924805, discriminator_loss=0.024323448538780212\n",
            "step 121: generator_loss=5.681604862213135, discriminator_loss=0.02472500503063202\n",
            "step 122: generator_loss=5.608428955078125, discriminator_loss=0.01850266382098198\n",
            "step 123: generator_loss=5.062988758087158, discriminator_loss=0.02519380673766136\n",
            "step 124: generator_loss=5.22777795791626, discriminator_loss=0.022711724042892456\n",
            "step 125: generator_loss=4.665884494781494, discriminator_loss=0.038663242012262344\n",
            "step 126: generator_loss=4.756706237792969, discriminator_loss=0.02649696171283722\n",
            "step 127: generator_loss=4.7652974128723145, discriminator_loss=0.02887476235628128\n",
            "step 128: generator_loss=5.075076103210449, discriminator_loss=0.02472063899040222\n",
            "step 129: generator_loss=5.044195175170898, discriminator_loss=0.027062926441431046\n",
            "step 130: generator_loss=5.143517971038818, discriminator_loss=0.03208073228597641\n",
            "step 131: generator_loss=5.774734020233154, discriminator_loss=0.02233949303627014\n",
            "step 132: generator_loss=5.666394233703613, discriminator_loss=0.0252288356423378\n",
            "step 133: generator_loss=5.444471836090088, discriminator_loss=0.029833637177944183\n",
            "step 134: generator_loss=5.703616142272949, discriminator_loss=0.027155961841344833\n",
            "step 135: generator_loss=6.0072736740112305, discriminator_loss=0.026216723024845123\n",
            "step 136: generator_loss=5.842658996582031, discriminator_loss=0.027280718088150024\n",
            "step 137: generator_loss=6.071410179138184, discriminator_loss=0.017645979300141335\n",
            "step 138: generator_loss=6.043720245361328, discriminator_loss=0.025886358693242073\n",
            "step 139: generator_loss=5.6168317794799805, discriminator_loss=0.03452380746603012\n",
            "step 140: generator_loss=5.35290002822876, discriminator_loss=0.02531450241804123\n",
            "step 141: generator_loss=4.777935028076172, discriminator_loss=0.03894015774130821\n",
            "step 142: generator_loss=5.070342540740967, discriminator_loss=0.03181140124797821\n",
            "step 143: generator_loss=5.348675727844238, discriminator_loss=0.036507438868284225\n",
            "step 144: generator_loss=5.340420246124268, discriminator_loss=0.04257940500974655\n",
            "step 145: generator_loss=6.093153953552246, discriminator_loss=0.0263502299785614\n",
            "step 146: generator_loss=6.286384105682373, discriminator_loss=0.026334842666983604\n",
            "step 147: generator_loss=6.435161590576172, discriminator_loss=0.024363035336136818\n",
            "step 148: generator_loss=6.365784645080566, discriminator_loss=0.02410932630300522\n",
            "step 149: generator_loss=6.16149377822876, discriminator_loss=0.028133252635598183\n",
            "step 150: generator_loss=5.9824981689453125, discriminator_loss=0.03194301575422287\n",
            "step 151: generator_loss=6.196871757507324, discriminator_loss=0.03689934313297272\n",
            "step 152: generator_loss=5.980558395385742, discriminator_loss=0.03059127740561962\n",
            "step 153: generator_loss=6.201433181762695, discriminator_loss=0.02685270458459854\n",
            "step 154: generator_loss=5.741693496704102, discriminator_loss=0.03638923540711403\n",
            "step 155: generator_loss=6.2649149894714355, discriminator_loss=0.028796683996915817\n",
            "step 156: generator_loss=6.0512847900390625, discriminator_loss=0.031023146584630013\n",
            "step 157: generator_loss=5.283021926879883, discriminator_loss=0.03137427195906639\n",
            "step 158: generator_loss=5.368646621704102, discriminator_loss=0.04749543219804764\n",
            "step 159: generator_loss=5.447092533111572, discriminator_loss=0.05311693623661995\n",
            "step 160: generator_loss=5.882143020629883, discriminator_loss=0.030528444796800613\n",
            "step 161: generator_loss=6.197324752807617, discriminator_loss=0.034013841301202774\n",
            "step 162: generator_loss=5.637385368347168, discriminator_loss=0.03221650794148445\n",
            "step 163: generator_loss=5.8125433921813965, discriminator_loss=0.032918401062488556\n",
            "step 164: generator_loss=5.4997406005859375, discriminator_loss=0.03789559751749039\n",
            "step 165: generator_loss=5.848476886749268, discriminator_loss=0.030851341784000397\n",
            "step 166: generator_loss=6.348305702209473, discriminator_loss=0.02393774688243866\n",
            "step 167: generator_loss=5.691239356994629, discriminator_loss=0.03178608417510986\n",
            "step 168: generator_loss=5.931100845336914, discriminator_loss=0.026515664532780647\n",
            "step 169: generator_loss=5.864358901977539, discriminator_loss=0.036330148577690125\n",
            "step 170: generator_loss=5.4810075759887695, discriminator_loss=0.027812410145998\n",
            "step 171: generator_loss=5.627302169799805, discriminator_loss=0.030559996142983437\n",
            "step 172: generator_loss=5.481863975524902, discriminator_loss=0.03303229436278343\n",
            "step 173: generator_loss=5.442270755767822, discriminator_loss=0.034101106226444244\n",
            "step 174: generator_loss=5.217981338500977, discriminator_loss=0.029470283538103104\n",
            "step 175: generator_loss=5.260010719299316, discriminator_loss=0.02739160694181919\n",
            "step 176: generator_loss=5.649405002593994, discriminator_loss=0.02940554916858673\n",
            "step 177: generator_loss=5.391505241394043, discriminator_loss=0.03145834058523178\n",
            "step 178: generator_loss=5.088920593261719, discriminator_loss=0.02795727178454399\n",
            "step 179: generator_loss=5.042520523071289, discriminator_loss=0.027950827032327652\n",
            "step 180: generator_loss=5.255162715911865, discriminator_loss=0.026333406567573547\n",
            "step 181: generator_loss=5.016644477844238, discriminator_loss=0.02377934940159321\n",
            "step 182: generator_loss=5.593820571899414, discriminator_loss=0.027104180306196213\n",
            "step 183: generator_loss=5.364845275878906, discriminator_loss=0.02176074869930744\n",
            "step 184: generator_loss=5.309950828552246, discriminator_loss=0.02183980494737625\n",
            "step 185: generator_loss=5.105922222137451, discriminator_loss=0.02910786308348179\n",
            "step 186: generator_loss=4.976376056671143, discriminator_loss=0.03206469863653183\n",
            "step 187: generator_loss=5.252713203430176, discriminator_loss=0.02039363794028759\n",
            "step 188: generator_loss=5.284553050994873, discriminator_loss=0.029460236430168152\n",
            "step 189: generator_loss=5.1641154289245605, discriminator_loss=0.031117500737309456\n",
            "step 190: generator_loss=5.057628154754639, discriminator_loss=0.032595716416835785\n",
            "step 191: generator_loss=5.419800281524658, discriminator_loss=0.02973167970776558\n",
            "step 192: generator_loss=5.225717544555664, discriminator_loss=0.026597000658512115\n",
            "step 193: generator_loss=5.433272361755371, discriminator_loss=0.027051705867052078\n",
            "step 194: generator_loss=5.453727722167969, discriminator_loss=0.026075806468725204\n",
            "step 195: generator_loss=5.256172180175781, discriminator_loss=0.03007093071937561\n",
            "step 196: generator_loss=5.279586315155029, discriminator_loss=0.02423791028559208\n",
            "step 197: generator_loss=5.1645894050598145, discriminator_loss=0.026953181251883507\n",
            "step 198: generator_loss=5.055279731750488, discriminator_loss=0.03614591807126999\n",
            "step 199: generator_loss=5.250583171844482, discriminator_loss=0.024676598608493805\n",
            "step 200: generator_loss=4.600081443786621, discriminator_loss=0.03320106863975525\n",
            "step 201: generator_loss=5.09158992767334, discriminator_loss=0.025731192901730537\n",
            "step 202: generator_loss=5.02755880355835, discriminator_loss=0.02834748663008213\n",
            "step 203: generator_loss=5.264705657958984, discriminator_loss=0.032017454504966736\n",
            "step 204: generator_loss=5.054538249969482, discriminator_loss=0.036595433950424194\n",
            "step 205: generator_loss=5.030555725097656, discriminator_loss=0.028980929404497147\n",
            "step 206: generator_loss=4.932575702667236, discriminator_loss=0.029924124479293823\n",
            "step 207: generator_loss=5.396721839904785, discriminator_loss=0.030690379440784454\n",
            "step 208: generator_loss=5.0572099685668945, discriminator_loss=0.03545355051755905\n",
            "step 209: generator_loss=5.196750164031982, discriminator_loss=0.03488954156637192\n",
            "step 210: generator_loss=5.12379264831543, discriminator_loss=0.03514079749584198\n",
            "step 211: generator_loss=5.250953674316406, discriminator_loss=0.0283932127058506\n",
            "step 212: generator_loss=5.369915962219238, discriminator_loss=0.03290198743343353\n",
            "step 213: generator_loss=5.451470375061035, discriminator_loss=0.033241793513298035\n",
            "step 214: generator_loss=5.519962310791016, discriminator_loss=0.02924717590212822\n",
            "step 215: generator_loss=5.258929252624512, discriminator_loss=0.025048350915312767\n",
            "step 216: generator_loss=4.930541515350342, discriminator_loss=0.038676947355270386\n",
            "step 217: generator_loss=4.951160907745361, discriminator_loss=0.043514326214790344\n",
            "step 218: generator_loss=5.046830177307129, discriminator_loss=0.0392918698489666\n",
            "step 219: generator_loss=4.828418254852295, discriminator_loss=0.03720627725124359\n",
            "step 220: generator_loss=5.101032257080078, discriminator_loss=0.04365639388561249\n",
            "step 221: generator_loss=4.990583896636963, discriminator_loss=0.036135368049144745\n",
            "step 222: generator_loss=4.615076065063477, discriminator_loss=0.042459432035684586\n",
            "step 223: generator_loss=4.94316291809082, discriminator_loss=0.044763773679733276\n",
            "step 224: generator_loss=5.001785755157471, discriminator_loss=0.041829854249954224\n",
            "step 225: generator_loss=5.005255699157715, discriminator_loss=0.03946226090192795\n",
            "step 226: generator_loss=4.899105072021484, discriminator_loss=0.04801738262176514\n",
            "step 227: generator_loss=5.17596435546875, discriminator_loss=0.03602086752653122\n",
            "step 228: generator_loss=5.165672302246094, discriminator_loss=0.045688845217227936\n",
            "step 229: generator_loss=5.337854385375977, discriminator_loss=0.036392517387866974\n",
            "step 230: generator_loss=5.074995040893555, discriminator_loss=0.039059028029441833\n",
            "step 231: generator_loss=4.960154056549072, discriminator_loss=0.03810865059494972\n",
            "step 232: generator_loss=5.171978950500488, discriminator_loss=0.03585764765739441\n",
            "step 233: generator_loss=5.094638347625732, discriminator_loss=0.034343279898166656\n",
            "step 234: generator_loss=4.798589706420898, discriminator_loss=0.041124727576971054\n",
            "step 235: generator_loss=4.412532329559326, discriminator_loss=0.04425562545657158\n",
            "step 236: generator_loss=4.533830642700195, discriminator_loss=0.04266771301627159\n",
            "step 237: generator_loss=4.335676670074463, discriminator_loss=0.041056305170059204\n",
            "step 238: generator_loss=4.335968017578125, discriminator_loss=0.04833614081144333\n",
            "step 239: generator_loss=4.49069881439209, discriminator_loss=0.03972905874252319\n",
            "step 240: generator_loss=4.3047685623168945, discriminator_loss=0.04796965420246124\n",
            "step 241: generator_loss=4.532661437988281, discriminator_loss=0.03504753112792969\n",
            "step 242: generator_loss=4.164681911468506, discriminator_loss=0.04679424315690994\n",
            "step 243: generator_loss=4.248631477355957, discriminator_loss=0.05239362269639969\n",
            "step 244: generator_loss=3.9867007732391357, discriminator_loss=0.05023808032274246\n",
            "step 245: generator_loss=4.0672173500061035, discriminator_loss=0.0526331290602684\n",
            "step 246: generator_loss=4.496265411376953, discriminator_loss=0.04471813142299652\n",
            "step 247: generator_loss=4.547730922698975, discriminator_loss=0.04594113305211067\n",
            "step 248: generator_loss=4.5257568359375, discriminator_loss=0.05365511775016785\n",
            "step 249: generator_loss=4.603941917419434, discriminator_loss=0.03832782804965973\n",
            "step 250: generator_loss=4.7108001708984375, discriminator_loss=0.040894515812397\n",
            "step 251: generator_loss=4.538540363311768, discriminator_loss=0.046466175466775894\n",
            "step 252: generator_loss=4.539229393005371, discriminator_loss=0.0411604605615139\n",
            "step 253: generator_loss=4.303153038024902, discriminator_loss=0.05502281337976456\n",
            "step 254: generator_loss=4.168442726135254, discriminator_loss=0.0544477179646492\n",
            "step 255: generator_loss=4.172612190246582, discriminator_loss=0.04578804224729538\n",
            "step 256: generator_loss=4.249243259429932, discriminator_loss=0.04495750740170479\n",
            "step 257: generator_loss=4.347108364105225, discriminator_loss=0.05237453058362007\n",
            "step 258: generator_loss=4.030947685241699, discriminator_loss=0.057907022535800934\n",
            "step 259: generator_loss=4.017829418182373, discriminator_loss=0.06144218146800995\n",
            "step 260: generator_loss=4.130893707275391, discriminator_loss=0.05938538536429405\n",
            "step 261: generator_loss=4.269975185394287, discriminator_loss=0.05290091782808304\n",
            "step 262: generator_loss=3.9154703617095947, discriminator_loss=0.07872363924980164\n",
            "step 263: generator_loss=3.5864620208740234, discriminator_loss=0.0765589252114296\n",
            "step 264: generator_loss=4.29732084274292, discriminator_loss=0.06856193393468857\n",
            "step 265: generator_loss=4.228095054626465, discriminator_loss=0.05673466622829437\n",
            "step 266: generator_loss=4.044827938079834, discriminator_loss=0.06976686418056488\n",
            "step 267: generator_loss=4.048833847045898, discriminator_loss=0.05736297741532326\n",
            "step 268: generator_loss=4.338856220245361, discriminator_loss=0.0726703554391861\n",
            "step 269: generator_loss=3.9556565284729004, discriminator_loss=0.0686655044555664\n",
            "step 270: generator_loss=4.093344688415527, discriminator_loss=0.06800927966833115\n",
            "step 271: generator_loss=3.919264316558838, discriminator_loss=0.09070934355258942\n",
            "step 272: generator_loss=3.9507429599761963, discriminator_loss=0.07539074867963791\n",
            "step 273: generator_loss=4.014482498168945, discriminator_loss=0.07963433861732483\n",
            "step 274: generator_loss=3.833767890930176, discriminator_loss=0.07100244611501694\n",
            "step 275: generator_loss=3.6140260696411133, discriminator_loss=0.09006178379058838\n",
            "step 276: generator_loss=3.7882394790649414, discriminator_loss=0.08111406862735748\n",
            "step 277: generator_loss=3.6463634967803955, discriminator_loss=0.09025406092405319\n",
            "step 278: generator_loss=3.6426448822021484, discriminator_loss=0.08129018545150757\n",
            "step 279: generator_loss=3.5917868614196777, discriminator_loss=0.07727421820163727\n",
            "step 280: generator_loss=3.6677675247192383, discriminator_loss=0.0947791114449501\n",
            "step 281: generator_loss=3.6477174758911133, discriminator_loss=0.07654011249542236\n",
            "step 282: generator_loss=3.428201913833618, discriminator_loss=0.08237224817276001\n",
            "step 283: generator_loss=3.2454655170440674, discriminator_loss=0.09156540781259537\n",
            "step 284: generator_loss=3.257627248764038, discriminator_loss=0.0917568951845169\n",
            "step 285: generator_loss=3.511929750442505, discriminator_loss=0.08328532427549362\n",
            "step 286: generator_loss=3.253868818283081, discriminator_loss=0.08489362895488739\n",
            "step 287: generator_loss=3.243288516998291, discriminator_loss=0.11031955480575562\n",
            "step 288: generator_loss=2.9447433948516846, discriminator_loss=0.11303932964801788\n",
            "step 289: generator_loss=3.166198492050171, discriminator_loss=0.09162373840808868\n",
            "step 290: generator_loss=3.093277931213379, discriminator_loss=0.08832557499408722\n",
            "step 291: generator_loss=3.0112972259521484, discriminator_loss=0.10280938446521759\n",
            "step 292: generator_loss=3.105508327484131, discriminator_loss=0.08442430198192596\n",
            "step 293: generator_loss=3.0250535011291504, discriminator_loss=0.09530068933963776\n",
            "step 294: generator_loss=3.078361988067627, discriminator_loss=0.09489138424396515\n",
            "step 295: generator_loss=2.9002370834350586, discriminator_loss=0.11082051694393158\n",
            "step 296: generator_loss=2.92311692237854, discriminator_loss=0.10206867754459381\n",
            "step 297: generator_loss=2.7760961055755615, discriminator_loss=0.10920724272727966\n",
            "step 298: generator_loss=2.9674153327941895, discriminator_loss=0.09264200180768967\n",
            "step 299: generator_loss=2.991914987564087, discriminator_loss=0.10339616239070892\n",
            "step 300: generator_loss=3.1430106163024902, discriminator_loss=0.08707018196582794\n",
            "step 301: generator_loss=2.9850711822509766, discriminator_loss=0.0956258624792099\n",
            "step 302: generator_loss=2.9437060356140137, discriminator_loss=0.10628880560398102\n",
            "step 303: generator_loss=2.9537923336029053, discriminator_loss=0.09312449395656586\n",
            "step 304: generator_loss=2.8907899856567383, discriminator_loss=0.08339543640613556\n",
            "step 305: generator_loss=2.8461484909057617, discriminator_loss=0.0883767306804657\n",
            "step 306: generator_loss=2.799732208251953, discriminator_loss=0.10201968252658844\n",
            "step 307: generator_loss=2.7503371238708496, discriminator_loss=0.10361248254776001\n",
            "step 308: generator_loss=2.661081314086914, discriminator_loss=0.10291219502687454\n",
            "step 309: generator_loss=2.766509771347046, discriminator_loss=0.09355428814888\n",
            "step 310: generator_loss=2.902003049850464, discriminator_loss=0.08501105010509491\n",
            "step 311: generator_loss=2.8390955924987793, discriminator_loss=0.12337963283061981\n",
            "step 312: generator_loss=2.717346668243408, discriminator_loss=0.09449967741966248\n",
            "step 313: generator_loss=2.7154431343078613, discriminator_loss=0.10640114545822144\n",
            "step 314: generator_loss=2.767977714538574, discriminator_loss=0.0877966582775116\n",
            "step 315: generator_loss=2.6583805084228516, discriminator_loss=0.10189782083034515\n",
            "step 316: generator_loss=2.7938246726989746, discriminator_loss=0.09115007519721985\n",
            "step 317: generator_loss=2.7369375228881836, discriminator_loss=0.09846971929073334\n",
            "step 318: generator_loss=2.6024258136749268, discriminator_loss=0.10148245096206665\n",
            "step 319: generator_loss=2.672312021255493, discriminator_loss=0.0934656411409378\n",
            "step 320: generator_loss=2.6326725482940674, discriminator_loss=0.0995866134762764\n",
            "step 321: generator_loss=2.520191192626953, discriminator_loss=0.10784760117530823\n",
            "step 322: generator_loss=2.5275073051452637, discriminator_loss=0.10625721514225006\n",
            "step 323: generator_loss=2.5952749252319336, discriminator_loss=0.12137270718812943\n",
            "step 324: generator_loss=2.561880588531494, discriminator_loss=0.0953088030219078\n",
            "step 325: generator_loss=2.640089511871338, discriminator_loss=0.11516906321048737\n",
            "step 326: generator_loss=2.591994047164917, discriminator_loss=0.0927821546792984\n",
            "step 327: generator_loss=2.62282133102417, discriminator_loss=0.09019937366247177\n",
            "step 328: generator_loss=2.5843210220336914, discriminator_loss=0.10979198664426804\n",
            "step 329: generator_loss=2.4873595237731934, discriminator_loss=0.0952996239066124\n",
            "step 330: generator_loss=2.502009868621826, discriminator_loss=0.0927778035402298\n",
            "step 331: generator_loss=2.6470723152160645, discriminator_loss=0.0975346490740776\n",
            "step 332: generator_loss=2.5999317169189453, discriminator_loss=0.09724372625350952\n",
            "step 333: generator_loss=2.4978487491607666, discriminator_loss=0.09346076101064682\n",
            "step 334: generator_loss=2.4973766803741455, discriminator_loss=0.10503219813108444\n",
            "step 335: generator_loss=2.429436683654785, discriminator_loss=0.1058155968785286\n",
            "step 336: generator_loss=2.4437222480773926, discriminator_loss=0.10232973098754883\n",
            "step 337: generator_loss=2.3510687351226807, discriminator_loss=0.11920911818742752\n",
            "step 338: generator_loss=2.470947742462158, discriminator_loss=0.10939262062311172\n",
            "step 339: generator_loss=2.420111656188965, discriminator_loss=0.11641521751880646\n",
            "step 340: generator_loss=2.409669876098633, discriminator_loss=0.11284871399402618\n",
            "step 341: generator_loss=2.393829345703125, discriminator_loss=0.11604991555213928\n",
            "step 342: generator_loss=2.4089181423187256, discriminator_loss=0.10816013813018799\n",
            "step 343: generator_loss=2.369748115539551, discriminator_loss=0.11895887553691864\n",
            "step 344: generator_loss=2.612480401992798, discriminator_loss=0.11312144994735718\n",
            "step 345: generator_loss=2.6320652961730957, discriminator_loss=0.09416099637746811\n",
            "step 346: generator_loss=2.518026113510132, discriminator_loss=0.11154690384864807\n",
            "step 347: generator_loss=2.5790767669677734, discriminator_loss=0.10596984624862671\n",
            "step 348: generator_loss=2.4263033866882324, discriminator_loss=0.11634203791618347\n",
            "step 349: generator_loss=2.515838623046875, discriminator_loss=0.1208515465259552\n",
            "step 350: generator_loss=2.4641144275665283, discriminator_loss=0.11887206137180328\n",
            "step 351: generator_loss=2.365825653076172, discriminator_loss=0.1226867288351059\n",
            "step 352: generator_loss=2.447326183319092, discriminator_loss=0.11911313235759735\n",
            "step 353: generator_loss=2.4570422172546387, discriminator_loss=0.11768078058958054\n",
            "step 354: generator_loss=2.368980884552002, discriminator_loss=0.12621736526489258\n",
            "step 355: generator_loss=2.481865167617798, discriminator_loss=0.11952266842126846\n",
            "step 356: generator_loss=2.5077741146087646, discriminator_loss=0.13255593180656433\n",
            "step 357: generator_loss=2.6971917152404785, discriminator_loss=0.09937870502471924\n",
            "step 358: generator_loss=2.6562037467956543, discriminator_loss=0.11268803477287292\n",
            "step 359: generator_loss=2.701899290084839, discriminator_loss=0.11071700602769852\n",
            "step 360: generator_loss=2.807612895965576, discriminator_loss=0.12036550045013428\n",
            "step 361: generator_loss=2.672452688217163, discriminator_loss=0.12479183077812195\n",
            "step 362: generator_loss=2.8100295066833496, discriminator_loss=0.111220583319664\n",
            "step 363: generator_loss=2.8152520656585693, discriminator_loss=0.12187670916318893\n",
            "step 364: generator_loss=2.685474157333374, discriminator_loss=0.13241629302501678\n",
            "step 365: generator_loss=2.60152530670166, discriminator_loss=0.1332601010799408\n",
            "step 366: generator_loss=2.879969835281372, discriminator_loss=0.12081480026245117\n",
            "step 367: generator_loss=2.958813190460205, discriminator_loss=0.1410154104232788\n",
            "step 368: generator_loss=2.793325901031494, discriminator_loss=0.11451173573732376\n",
            "step 369: generator_loss=2.90891695022583, discriminator_loss=0.12336492538452148\n",
            "step 370: generator_loss=2.9843690395355225, discriminator_loss=0.1409435272216797\n",
            "step 371: generator_loss=2.9928207397460938, discriminator_loss=0.12342823296785355\n",
            "step 372: generator_loss=2.9496631622314453, discriminator_loss=0.12500867247581482\n",
            "step 373: generator_loss=2.985626697540283, discriminator_loss=0.12748265266418457\n",
            "step 374: generator_loss=3.121645212173462, discriminator_loss=0.11687913537025452\n",
            "step 375: generator_loss=2.828235387802124, discriminator_loss=0.12065517157316208\n",
            "step 376: generator_loss=2.7958924770355225, discriminator_loss=0.11830946803092957\n",
            "step 377: generator_loss=2.786046028137207, discriminator_loss=0.11656463146209717\n",
            "step 378: generator_loss=2.8910558223724365, discriminator_loss=0.12314623594284058\n",
            "step 379: generator_loss=2.9381625652313232, discriminator_loss=0.11187905073165894\n",
            "step 380: generator_loss=2.8383431434631348, discriminator_loss=0.09296034276485443\n",
            "step 381: generator_loss=2.8114922046661377, discriminator_loss=0.09618149697780609\n",
            "step 382: generator_loss=2.933159828186035, discriminator_loss=0.09978334605693817\n",
            "step 383: generator_loss=2.8614439964294434, discriminator_loss=0.10126001387834549\n",
            "step 384: generator_loss=2.868741750717163, discriminator_loss=0.09983426332473755\n",
            "step 385: generator_loss=2.8245911598205566, discriminator_loss=0.10622437298297882\n",
            "step 386: generator_loss=2.8564560413360596, discriminator_loss=0.09839366376399994\n",
            "step 387: generator_loss=2.7724838256835938, discriminator_loss=0.10923692584037781\n",
            "step 388: generator_loss=2.8578128814697266, discriminator_loss=0.09975329786539078\n",
            "step 389: generator_loss=2.7765655517578125, discriminator_loss=0.11490733921527863\n",
            "step 390: generator_loss=2.538848638534546, discriminator_loss=0.12366357445716858\n",
            "step 391: generator_loss=2.482779026031494, discriminator_loss=0.14277000725269318\n",
            "step 392: generator_loss=2.583937883377075, discriminator_loss=0.10981422662734985\n",
            "step 393: generator_loss=2.5529565811157227, discriminator_loss=0.11169132590293884\n",
            "step 394: generator_loss=2.4755148887634277, discriminator_loss=0.12505531311035156\n",
            "step 395: generator_loss=2.4964663982391357, discriminator_loss=0.13409122824668884\n",
            "step 396: generator_loss=2.541959524154663, discriminator_loss=0.13160206377506256\n",
            "step 397: generator_loss=2.3445992469787598, discriminator_loss=0.13562896847724915\n",
            "step 398: generator_loss=2.408627510070801, discriminator_loss=0.1346493363380432\n",
            "step 399: generator_loss=2.226093292236328, discriminator_loss=0.1365172564983368\n",
            "step 400: generator_loss=2.1835691928863525, discriminator_loss=0.13999207317829132\n",
            "step 401: generator_loss=2.3115782737731934, discriminator_loss=0.14507468044757843\n",
            "step 402: generator_loss=2.3651978969573975, discriminator_loss=0.12584450840950012\n",
            "step 403: generator_loss=2.192121982574463, discriminator_loss=0.13963571190834045\n",
            "step 404: generator_loss=2.30336856842041, discriminator_loss=0.1183735802769661\n",
            "step 405: generator_loss=2.1927223205566406, discriminator_loss=0.13445864617824554\n",
            "step 406: generator_loss=2.231785774230957, discriminator_loss=0.12828147411346436\n",
            "step 407: generator_loss=2.329970359802246, discriminator_loss=0.13623544573783875\n",
            "step 408: generator_loss=2.2535102367401123, discriminator_loss=0.1356799453496933\n",
            "step 409: generator_loss=2.2382278442382812, discriminator_loss=0.13932369649410248\n",
            "step 410: generator_loss=2.1888809204101562, discriminator_loss=0.14752532541751862\n",
            "step 411: generator_loss=2.316209316253662, discriminator_loss=0.13916751742362976\n",
            "step 412: generator_loss=2.2396416664123535, discriminator_loss=0.16690248250961304\n",
            "step 413: generator_loss=2.243593692779541, discriminator_loss=0.1623164564371109\n",
            "step 414: generator_loss=2.2566518783569336, discriminator_loss=0.17072175443172455\n",
            "step 415: generator_loss=2.243029832839966, discriminator_loss=0.180173859000206\n",
            "step 416: generator_loss=2.1378159523010254, discriminator_loss=0.1968894898891449\n",
            "step 417: generator_loss=2.2248668670654297, discriminator_loss=0.18210101127624512\n",
            "step 418: generator_loss=2.2374320030212402, discriminator_loss=0.20537644624710083\n",
            "step 419: generator_loss=2.080979824066162, discriminator_loss=0.19940122961997986\n",
            "step 420: generator_loss=2.23317289352417, discriminator_loss=0.17742949724197388\n",
            "step 421: generator_loss=2.2070465087890625, discriminator_loss=0.17894138395786285\n",
            "step 422: generator_loss=1.9903292655944824, discriminator_loss=0.19215019047260284\n",
            "step 423: generator_loss=2.135608196258545, discriminator_loss=0.19164583086967468\n",
            "step 424: generator_loss=2.0836615562438965, discriminator_loss=0.19867722690105438\n",
            "step 425: generator_loss=2.007842540740967, discriminator_loss=0.19710713624954224\n",
            "step 426: generator_loss=1.9565242528915405, discriminator_loss=0.21994689106941223\n",
            "step 427: generator_loss=2.0799953937530518, discriminator_loss=0.21705196797847748\n",
            "step 428: generator_loss=2.1578288078308105, discriminator_loss=0.1889081448316574\n",
            "step 429: generator_loss=2.001659870147705, discriminator_loss=0.21047714352607727\n",
            "step 430: generator_loss=2.0610547065734863, discriminator_loss=0.20677593350410461\n",
            "step 431: generator_loss=2.044394016265869, discriminator_loss=0.20921126008033752\n",
            "step 432: generator_loss=2.174264669418335, discriminator_loss=0.2088388204574585\n",
            "step 433: generator_loss=2.030452251434326, discriminator_loss=0.20539434254169464\n",
            "step 434: generator_loss=1.9689762592315674, discriminator_loss=0.20018219947814941\n",
            "step 435: generator_loss=1.9337810277938843, discriminator_loss=0.22083163261413574\n",
            "step 436: generator_loss=1.8131481409072876, discriminator_loss=0.24829339981079102\n",
            "step 437: generator_loss=1.9540271759033203, discriminator_loss=0.23201823234558105\n",
            "step 438: generator_loss=1.9859814643859863, discriminator_loss=0.20048674941062927\n",
            "step 439: generator_loss=1.7518928050994873, discriminator_loss=0.24302226305007935\n",
            "step 440: generator_loss=1.7774584293365479, discriminator_loss=0.23791074752807617\n",
            "step 441: generator_loss=1.8676807880401611, discriminator_loss=0.22982820868492126\n",
            "step 442: generator_loss=1.921506404876709, discriminator_loss=0.2423880696296692\n",
            "step 443: generator_loss=1.9342249631881714, discriminator_loss=0.2352692186832428\n",
            "step 444: generator_loss=1.8761824369430542, discriminator_loss=0.2272365242242813\n",
            "step 445: generator_loss=1.6755330562591553, discriminator_loss=0.27320781350135803\n",
            "step 446: generator_loss=1.714451551437378, discriminator_loss=0.26979726552963257\n",
            "step 447: generator_loss=1.7516298294067383, discriminator_loss=0.26598799228668213\n",
            "step 448: generator_loss=1.7242794036865234, discriminator_loss=0.26844877004623413\n",
            "step 449: generator_loss=1.7613508701324463, discriminator_loss=0.24913433194160461\n",
            "step 450: generator_loss=1.7723336219787598, discriminator_loss=0.268710732460022\n",
            "step 451: generator_loss=1.6561393737792969, discriminator_loss=0.27469372749328613\n",
            "step 452: generator_loss=1.915910243988037, discriminator_loss=0.24972940981388092\n",
            "step 453: generator_loss=1.7854924201965332, discriminator_loss=0.26997110247612\n",
            "step 454: generator_loss=1.7464617490768433, discriminator_loss=0.23421725630760193\n",
            "step 455: generator_loss=1.77977454662323, discriminator_loss=0.2575600743293762\n",
            "step 456: generator_loss=1.803273320198059, discriminator_loss=0.24390411376953125\n",
            "step 457: generator_loss=1.8812611103057861, discriminator_loss=0.22745579481124878\n",
            "step 458: generator_loss=1.7853827476501465, discriminator_loss=0.24813520908355713\n",
            "step 459: generator_loss=1.8725076913833618, discriminator_loss=0.23950958251953125\n",
            "step 460: generator_loss=1.7830235958099365, discriminator_loss=0.2328031063079834\n",
            "step 461: generator_loss=1.8013417720794678, discriminator_loss=0.2424909770488739\n",
            "step 462: generator_loss=1.975916862487793, discriminator_loss=0.18866750597953796\n",
            "step 463: generator_loss=2.0191493034362793, discriminator_loss=0.21743011474609375\n",
            "step 464: generator_loss=2.1189823150634766, discriminator_loss=0.2085723876953125\n",
            "step 465: generator_loss=1.9467766284942627, discriminator_loss=0.20823980867862701\n",
            "step 466: generator_loss=2.0971250534057617, discriminator_loss=0.20189300179481506\n",
            "step 467: generator_loss=2.070951461791992, discriminator_loss=0.20260053873062134\n",
            "step 468: generator_loss=2.192093849182129, discriminator_loss=0.22499126195907593\n",
            "step 469: generator_loss=2.0428872108459473, discriminator_loss=0.2344055026769638\n",
            "step 470: generator_loss=1.8284119367599487, discriminator_loss=0.24272948503494263\n",
            "step 471: generator_loss=1.741592526435852, discriminator_loss=0.24432814121246338\n",
            "step 472: generator_loss=1.7681562900543213, discriminator_loss=0.24183475971221924\n",
            "step 473: generator_loss=1.6216773986816406, discriminator_loss=0.26322752237319946\n",
            "step 474: generator_loss=1.6092965602874756, discriminator_loss=0.270633339881897\n",
            "step 475: generator_loss=1.495131492614746, discriminator_loss=0.3180730938911438\n",
            "step 476: generator_loss=1.5285840034484863, discriminator_loss=0.294772744178772\n",
            "step 477: generator_loss=1.4731030464172363, discriminator_loss=0.3367711305618286\n",
            "step 478: generator_loss=1.4414300918579102, discriminator_loss=0.3638332188129425\n",
            "step 479: generator_loss=1.4024591445922852, discriminator_loss=0.3371400833129883\n",
            "step 480: generator_loss=1.5024280548095703, discriminator_loss=0.34640800952911377\n",
            "step 481: generator_loss=1.4316580295562744, discriminator_loss=0.36773815751075745\n",
            "step 482: generator_loss=1.3049064874649048, discriminator_loss=0.40271490812301636\n",
            "step 483: generator_loss=1.397283673286438, discriminator_loss=0.37717515230178833\n",
            "step 484: generator_loss=1.333441972732544, discriminator_loss=0.3701520264148712\n",
            "step 485: generator_loss=1.4362163543701172, discriminator_loss=0.35460829734802246\n",
            "step 486: generator_loss=1.5383615493774414, discriminator_loss=0.3455055058002472\n",
            "step 487: generator_loss=1.6521761417388916, discriminator_loss=0.3084847927093506\n",
            "step 488: generator_loss=1.7164353132247925, discriminator_loss=0.29239052534103394\n",
            "step 489: generator_loss=2.0684852600097656, discriminator_loss=0.2613992393016815\n",
            "step 490: generator_loss=1.8924418687820435, discriminator_loss=0.24206185340881348\n",
            "step 491: generator_loss=2.069934844970703, discriminator_loss=0.23782137036323547\n",
            "step 492: generator_loss=1.8788282871246338, discriminator_loss=0.23877981305122375\n",
            "step 493: generator_loss=2.0589518547058105, discriminator_loss=0.23362094163894653\n",
            "step 494: generator_loss=2.042119026184082, discriminator_loss=0.2254364788532257\n",
            "step 495: generator_loss=2.157111644744873, discriminator_loss=0.20786529779434204\n",
            "step 496: generator_loss=1.9976214170455933, discriminator_loss=0.2261408269405365\n",
            "step 497: generator_loss=2.1146535873413086, discriminator_loss=0.23543620109558105\n",
            "step 498: generator_loss=1.8777384757995605, discriminator_loss=0.23666658997535706\n",
            "step 499: generator_loss=2.193350315093994, discriminator_loss=0.23851385712623596\n",
            "step 500: generator_loss=2.1734604835510254, discriminator_loss=0.2500050663948059\n",
            "step 501: generator_loss=2.089648962020874, discriminator_loss=0.25368526577949524\n",
            "step 502: generator_loss=2.070617198944092, discriminator_loss=0.24811607599258423\n",
            "step 503: generator_loss=1.7934765815734863, discriminator_loss=0.2697322368621826\n",
            "step 504: generator_loss=1.7282496690750122, discriminator_loss=0.2968598008155823\n",
            "step 505: generator_loss=1.6608901023864746, discriminator_loss=0.29839688539505005\n",
            "step 506: generator_loss=1.6788817644119263, discriminator_loss=0.30168795585632324\n",
            "step 507: generator_loss=1.7994807958602905, discriminator_loss=0.3189159333705902\n",
            "step 508: generator_loss=1.9253044128417969, discriminator_loss=0.29601988196372986\n",
            "step 509: generator_loss=1.680100679397583, discriminator_loss=0.3166593313217163\n",
            "step 510: generator_loss=1.7263224124908447, discriminator_loss=0.33607757091522217\n",
            "step 511: generator_loss=1.6637496948242188, discriminator_loss=0.36210471391677856\n",
            "step 512: generator_loss=1.5553789138793945, discriminator_loss=0.397417277097702\n",
            "step 513: generator_loss=1.7094701528549194, discriminator_loss=0.3338600993156433\n",
            "step 514: generator_loss=1.4883071184158325, discriminator_loss=0.35508906841278076\n",
            "step 515: generator_loss=1.4913592338562012, discriminator_loss=0.3414289355278015\n",
            "step 516: generator_loss=1.3177566528320312, discriminator_loss=0.3834933340549469\n",
            "step 517: generator_loss=1.3160951137542725, discriminator_loss=0.44702818989753723\n",
            "step 518: generator_loss=1.2763304710388184, discriminator_loss=0.42029568552970886\n",
            "step 519: generator_loss=1.2609460353851318, discriminator_loss=0.41315269470214844\n",
            "step 520: generator_loss=1.300879716873169, discriminator_loss=0.450295627117157\n",
            "step 521: generator_loss=1.5226056575775146, discriminator_loss=0.44396984577178955\n",
            "step 522: generator_loss=1.502201795578003, discriminator_loss=0.39544254541397095\n",
            "step 523: generator_loss=1.4609894752502441, discriminator_loss=0.41100072860717773\n",
            "step 524: generator_loss=1.4982330799102783, discriminator_loss=0.4071800112724304\n",
            "step 525: generator_loss=1.4885013103485107, discriminator_loss=0.36229509115219116\n",
            "step 526: generator_loss=1.292151927947998, discriminator_loss=0.38225650787353516\n",
            "step 527: generator_loss=1.1611106395721436, discriminator_loss=0.41710832715034485\n",
            "step 528: generator_loss=1.2520644664764404, discriminator_loss=0.40199601650238037\n",
            "step 529: generator_loss=1.2252397537231445, discriminator_loss=0.4133581817150116\n",
            "step 530: generator_loss=1.253603458404541, discriminator_loss=0.381888747215271\n",
            "step 531: generator_loss=1.3566815853118896, discriminator_loss=0.3831106424331665\n",
            "step 532: generator_loss=1.5207918882369995, discriminator_loss=0.3643787205219269\n",
            "step 533: generator_loss=1.3517510890960693, discriminator_loss=0.3821948170661926\n",
            "step 534: generator_loss=1.4720497131347656, discriminator_loss=0.35302847623825073\n",
            "step 535: generator_loss=1.4800810813903809, discriminator_loss=0.34519848227500916\n",
            "step 536: generator_loss=1.468993902206421, discriminator_loss=0.3816990852355957\n",
            "step 537: generator_loss=1.4070093631744385, discriminator_loss=0.31758302450180054\n",
            "step 538: generator_loss=1.3845012187957764, discriminator_loss=0.33624881505966187\n",
            "step 539: generator_loss=1.3980636596679688, discriminator_loss=0.3270675241947174\n",
            "step 540: generator_loss=1.4520816802978516, discriminator_loss=0.3373957574367523\n",
            "step 541: generator_loss=1.5319792032241821, discriminator_loss=0.27734315395355225\n",
            "step 542: generator_loss=1.5067214965820312, discriminator_loss=0.2918478846549988\n",
            "step 543: generator_loss=1.6366015672683716, discriminator_loss=0.26459670066833496\n",
            "step 544: generator_loss=1.5845513343811035, discriminator_loss=0.2857546806335449\n",
            "step 545: generator_loss=1.660682201385498, discriminator_loss=0.27566635608673096\n",
            "step 546: generator_loss=1.5984128713607788, discriminator_loss=0.29178282618522644\n",
            "step 547: generator_loss=1.673027515411377, discriminator_loss=0.28333520889282227\n",
            "step 548: generator_loss=1.6054105758666992, discriminator_loss=0.305830717086792\n",
            "step 549: generator_loss=1.6290478706359863, discriminator_loss=0.31531092524528503\n",
            "step 550: generator_loss=1.4623305797576904, discriminator_loss=0.3053285479545593\n",
            "step 551: generator_loss=1.4301503896713257, discriminator_loss=0.32449522614479065\n",
            "step 552: generator_loss=1.327341079711914, discriminator_loss=0.3349611759185791\n",
            "step 553: generator_loss=1.400987148284912, discriminator_loss=0.32081735134124756\n",
            "step 554: generator_loss=1.387352705001831, discriminator_loss=0.34899768233299255\n",
            "step 555: generator_loss=1.2870136499404907, discriminator_loss=0.3813468813896179\n",
            "step 556: generator_loss=1.3105567693710327, discriminator_loss=0.3728443682193756\n",
            "step 557: generator_loss=1.3480250835418701, discriminator_loss=0.3805698752403259\n",
            "step 558: generator_loss=1.3232251405715942, discriminator_loss=0.44798552989959717\n",
            "step 559: generator_loss=1.231079339981079, discriminator_loss=0.43767619132995605\n",
            "step 560: generator_loss=1.2399078607559204, discriminator_loss=0.4605644643306732\n",
            "step 561: generator_loss=1.1958532333374023, discriminator_loss=0.435451865196228\n",
            "step 562: generator_loss=1.21705961227417, discriminator_loss=0.41249915957450867\n",
            "step 563: generator_loss=1.2842073440551758, discriminator_loss=0.4368104934692383\n",
            "step 564: generator_loss=1.1813440322875977, discriminator_loss=0.45281127095222473\n",
            "step 565: generator_loss=1.2214730978012085, discriminator_loss=0.44794589281082153\n",
            "step 566: generator_loss=1.3223521709442139, discriminator_loss=0.4263196587562561\n",
            "step 567: generator_loss=1.3215309381484985, discriminator_loss=0.44132760167121887\n",
            "step 568: generator_loss=1.3630149364471436, discriminator_loss=0.3899112939834595\n",
            "step 569: generator_loss=1.4205539226531982, discriminator_loss=0.41845816373825073\n",
            "step 570: generator_loss=1.4586163759231567, discriminator_loss=0.3930455148220062\n",
            "step 571: generator_loss=1.4347511529922485, discriminator_loss=0.35639113187789917\n",
            "step 572: generator_loss=1.500409483909607, discriminator_loss=0.3939429819583893\n",
            "step 573: generator_loss=1.58010733127594, discriminator_loss=0.331169456243515\n",
            "step 574: generator_loss=1.5503482818603516, discriminator_loss=0.3709765672683716\n",
            "step 575: generator_loss=1.5194635391235352, discriminator_loss=0.3973519504070282\n",
            "step 576: generator_loss=1.5775446891784668, discriminator_loss=0.3664131164550781\n",
            "step 577: generator_loss=1.5755164623260498, discriminator_loss=0.37174123525619507\n",
            "step 578: generator_loss=1.4591808319091797, discriminator_loss=0.36820077896118164\n",
            "step 579: generator_loss=1.5637768507003784, discriminator_loss=0.359454482793808\n",
            "step 580: generator_loss=1.5871448516845703, discriminator_loss=0.3382984697818756\n",
            "step 581: generator_loss=1.6917521953582764, discriminator_loss=0.3178677260875702\n",
            "step 582: generator_loss=1.8505938053131104, discriminator_loss=0.29266732931137085\n",
            "step 583: generator_loss=1.8154151439666748, discriminator_loss=0.30160942673683167\n",
            "step 584: generator_loss=1.8089673519134521, discriminator_loss=0.30116164684295654\n",
            "step 585: generator_loss=1.824182152748108, discriminator_loss=0.285066694021225\n",
            "step 586: generator_loss=2.005202293395996, discriminator_loss=0.2555265724658966\n",
            "step 587: generator_loss=2.0479111671447754, discriminator_loss=0.22117656469345093\n",
            "step 588: generator_loss=2.082512855529785, discriminator_loss=0.21131984889507294\n",
            "step 589: generator_loss=2.045790195465088, discriminator_loss=0.22167083621025085\n",
            "step 590: generator_loss=2.1461284160614014, discriminator_loss=0.20226611196994781\n",
            "step 591: generator_loss=2.072270393371582, discriminator_loss=0.19808515906333923\n",
            "step 592: generator_loss=2.083404541015625, discriminator_loss=0.17218957841396332\n",
            "step 593: generator_loss=2.2009918689727783, discriminator_loss=0.1698777973651886\n",
            "step 594: generator_loss=2.1607139110565186, discriminator_loss=0.1867334395647049\n",
            "step 595: generator_loss=2.1570568084716797, discriminator_loss=0.1798766702413559\n",
            "step 596: generator_loss=2.1864547729492188, discriminator_loss=0.16499367356300354\n",
            "step 597: generator_loss=2.213526725769043, discriminator_loss=0.14954239130020142\n",
            "step 598: generator_loss=1.9737768173217773, discriminator_loss=0.18025198578834534\n",
            "step 599: generator_loss=2.0387234687805176, discriminator_loss=0.1689826250076294\n",
            "step 600: generator_loss=1.9499857425689697, discriminator_loss=0.19401562213897705\n",
            "step 601: generator_loss=1.9444481134414673, discriminator_loss=0.18172587454319\n",
            "step 602: generator_loss=2.124809741973877, discriminator_loss=0.17748023569583893\n",
            "step 603: generator_loss=1.986365556716919, discriminator_loss=0.18552890419960022\n",
            "step 604: generator_loss=2.0517077445983887, discriminator_loss=0.1921617090702057\n",
            "step 605: generator_loss=1.96751070022583, discriminator_loss=0.21270178258419037\n",
            "step 606: generator_loss=1.951560378074646, discriminator_loss=0.21107211709022522\n",
            "step 607: generator_loss=1.9417788982391357, discriminator_loss=0.21936510503292084\n",
            "step 608: generator_loss=2.0420143604278564, discriminator_loss=0.20024380087852478\n",
            "step 609: generator_loss=1.953753113746643, discriminator_loss=0.1932906210422516\n",
            "step 610: generator_loss=1.882359266281128, discriminator_loss=0.20589406788349152\n",
            "step 611: generator_loss=1.7765684127807617, discriminator_loss=0.24126717448234558\n",
            "step 612: generator_loss=1.8094459772109985, discriminator_loss=0.23150736093521118\n",
            "step 613: generator_loss=1.8530824184417725, discriminator_loss=0.21035966277122498\n",
            "step 614: generator_loss=1.8275147676467896, discriminator_loss=0.23759953677654266\n",
            "step 615: generator_loss=1.8288328647613525, discriminator_loss=0.23828700184822083\n",
            "step 616: generator_loss=1.8786447048187256, discriminator_loss=0.2247912734746933\n",
            "step 617: generator_loss=1.8737539052963257, discriminator_loss=0.2492641806602478\n",
            "step 618: generator_loss=1.7419366836547852, discriminator_loss=0.28209277987480164\n",
            "step 619: generator_loss=1.8353453874588013, discriminator_loss=0.22448158264160156\n",
            "step 620: generator_loss=1.7093737125396729, discriminator_loss=0.26920995116233826\n",
            "step 621: generator_loss=1.658596158027649, discriminator_loss=0.27052080631256104\n",
            "step 622: generator_loss=1.6234766244888306, discriminator_loss=0.2804090976715088\n",
            "step 623: generator_loss=1.712123155593872, discriminator_loss=0.2538197934627533\n",
            "step 624: generator_loss=1.6208281517028809, discriminator_loss=0.2865436375141144\n",
            "step 625: generator_loss=1.6996182203292847, discriminator_loss=0.23635606467723846\n",
            "step 626: generator_loss=1.7651821374893188, discriminator_loss=0.24344566464424133\n",
            "step 627: generator_loss=2.0331053733825684, discriminator_loss=0.2378976047039032\n",
            "step 628: generator_loss=2.0109877586364746, discriminator_loss=0.22748064994812012\n",
            "step 629: generator_loss=1.8738034963607788, discriminator_loss=0.2421082705259323\n",
            "step 630: generator_loss=2.0863394737243652, discriminator_loss=0.20666201412677765\n",
            "step 631: generator_loss=1.903382420539856, discriminator_loss=0.24721887707710266\n",
            "step 632: generator_loss=1.9673274755477905, discriminator_loss=0.23570625483989716\n",
            "step 633: generator_loss=1.8400052785873413, discriminator_loss=0.2440611571073532\n",
            "step 634: generator_loss=1.9293458461761475, discriminator_loss=0.27361613512039185\n",
            "step 635: generator_loss=1.7119345664978027, discriminator_loss=0.2810770869255066\n",
            "step 636: generator_loss=1.7188942432403564, discriminator_loss=0.2655886113643646\n",
            "step 637: generator_loss=1.6392652988433838, discriminator_loss=0.30293887853622437\n",
            "step 638: generator_loss=1.5282751321792603, discriminator_loss=0.32604488730430603\n",
            "step 639: generator_loss=1.7704217433929443, discriminator_loss=0.296470046043396\n",
            "step 640: generator_loss=1.5916050672531128, discriminator_loss=0.34363633394241333\n",
            "step 641: generator_loss=1.7377986907958984, discriminator_loss=0.30314114689826965\n",
            "step 642: generator_loss=1.5206249952316284, discriminator_loss=0.3890835642814636\n",
            "step 643: generator_loss=1.8598604202270508, discriminator_loss=0.2955359220504761\n",
            "step 644: generator_loss=1.6443994045257568, discriminator_loss=0.30532306432724\n",
            "step 645: generator_loss=1.579688549041748, discriminator_loss=0.30515989661216736\n",
            "step 646: generator_loss=1.642183780670166, discriminator_loss=0.28115910291671753\n",
            "step 647: generator_loss=1.7485780715942383, discriminator_loss=0.27674245834350586\n",
            "step 648: generator_loss=1.6233055591583252, discriminator_loss=0.30219483375549316\n",
            "step 649: generator_loss=1.58824622631073, discriminator_loss=0.2876107692718506\n",
            "step 650: generator_loss=1.7987598180770874, discriminator_loss=0.2733384966850281\n",
            "step 651: generator_loss=1.846509575843811, discriminator_loss=0.2665800452232361\n",
            "step 652: generator_loss=1.6393263339996338, discriminator_loss=0.28760862350463867\n",
            "step 653: generator_loss=1.8918180465698242, discriminator_loss=0.26472124457359314\n",
            "step 654: generator_loss=1.770171880722046, discriminator_loss=0.25629809498786926\n",
            "step 655: generator_loss=1.8389239311218262, discriminator_loss=0.2584695816040039\n",
            "step 656: generator_loss=1.8524054288864136, discriminator_loss=0.27886807918548584\n",
            "step 657: generator_loss=1.7828583717346191, discriminator_loss=0.2808900475502014\n",
            "step 658: generator_loss=1.6796995401382446, discriminator_loss=0.29340624809265137\n",
            "step 659: generator_loss=1.6513197422027588, discriminator_loss=0.2964215874671936\n",
            "step 660: generator_loss=1.9551827907562256, discriminator_loss=0.26965638995170593\n",
            "step 661: generator_loss=1.8436294794082642, discriminator_loss=0.28063327074050903\n",
            "step 662: generator_loss=1.772398591041565, discriminator_loss=0.2974403500556946\n",
            "step 663: generator_loss=1.8067246675491333, discriminator_loss=0.29377999901771545\n",
            "step 664: generator_loss=1.8006541728973389, discriminator_loss=0.3055880665779114\n",
            "step 665: generator_loss=1.8699431419372559, discriminator_loss=0.30481821298599243\n",
            "step 666: generator_loss=1.7676478624343872, discriminator_loss=0.3195940852165222\n",
            "step 667: generator_loss=1.7896003723144531, discriminator_loss=0.29766568541526794\n",
            "step 668: generator_loss=1.6670030355453491, discriminator_loss=0.3214244246482849\n",
            "step 669: generator_loss=1.6457219123840332, discriminator_loss=0.3470696210861206\n",
            "step 670: generator_loss=1.554652214050293, discriminator_loss=0.3479301333427429\n",
            "step 671: generator_loss=1.6486091613769531, discriminator_loss=0.3451513946056366\n",
            "step 672: generator_loss=1.7634117603302002, discriminator_loss=0.33009517192840576\n",
            "step 673: generator_loss=1.846588134765625, discriminator_loss=0.3075810670852661\n",
            "step 674: generator_loss=1.4884235858917236, discriminator_loss=0.3604351878166199\n",
            "step 675: generator_loss=1.5739940404891968, discriminator_loss=0.35850122570991516\n",
            "step 676: generator_loss=1.619696021080017, discriminator_loss=0.3716322183609009\n",
            "step 677: generator_loss=1.7012380361557007, discriminator_loss=0.36074885725975037\n",
            "step 678: generator_loss=1.781524896621704, discriminator_loss=0.3330899775028229\n",
            "step 679: generator_loss=1.6373071670532227, discriminator_loss=0.34753191471099854\n",
            "step 680: generator_loss=1.7190933227539062, discriminator_loss=0.3592884838581085\n",
            "step 681: generator_loss=1.5404020547866821, discriminator_loss=0.3922104239463806\n",
            "step 682: generator_loss=1.6047139167785645, discriminator_loss=0.3404219150543213\n",
            "step 683: generator_loss=1.533997654914856, discriminator_loss=0.370538592338562\n",
            "step 684: generator_loss=1.4723479747772217, discriminator_loss=0.3887272775173187\n",
            "step 685: generator_loss=1.4608306884765625, discriminator_loss=0.33038240671157837\n",
            "step 686: generator_loss=1.379854679107666, discriminator_loss=0.3425513505935669\n",
            "step 687: generator_loss=1.36307954788208, discriminator_loss=0.3404756784439087\n",
            "step 688: generator_loss=1.4658445119857788, discriminator_loss=0.3238871693611145\n",
            "step 689: generator_loss=1.5814690589904785, discriminator_loss=0.31463345885276794\n",
            "step 690: generator_loss=1.640304684638977, discriminator_loss=0.30334994196891785\n",
            "step 691: generator_loss=1.6669832468032837, discriminator_loss=0.28793734312057495\n",
            "step 692: generator_loss=1.6379984617233276, discriminator_loss=0.29361915588378906\n",
            "step 693: generator_loss=1.543476939201355, discriminator_loss=0.3418180048465729\n",
            "step 694: generator_loss=1.5593541860580444, discriminator_loss=0.3138330280780792\n",
            "step 695: generator_loss=1.518436312675476, discriminator_loss=0.31006425619125366\n",
            "step 696: generator_loss=1.4366475343704224, discriminator_loss=0.32417765259742737\n",
            "step 697: generator_loss=1.4649012088775635, discriminator_loss=0.32707053422927856\n",
            "step 698: generator_loss=1.3799844980239868, discriminator_loss=0.3220122456550598\n",
            "step 699: generator_loss=1.3139718770980835, discriminator_loss=0.32907187938690186\n",
            "step 700: generator_loss=1.3147320747375488, discriminator_loss=0.35182321071624756\n",
            "step 701: generator_loss=1.4296324253082275, discriminator_loss=0.33644717931747437\n",
            "step 702: generator_loss=1.358757495880127, discriminator_loss=0.35861408710479736\n",
            "step 703: generator_loss=1.5076526403427124, discriminator_loss=0.35296761989593506\n",
            "step 704: generator_loss=1.5313999652862549, discriminator_loss=0.3324965834617615\n",
            "step 705: generator_loss=1.5892696380615234, discriminator_loss=0.3031710088253021\n",
            "step 706: generator_loss=1.5903148651123047, discriminator_loss=0.3310180902481079\n",
            "step 707: generator_loss=1.518790602684021, discriminator_loss=0.28354698419570923\n",
            "step 708: generator_loss=1.5462545156478882, discriminator_loss=0.2799810767173767\n",
            "step 709: generator_loss=1.5826892852783203, discriminator_loss=0.2726432681083679\n",
            "step 710: generator_loss=1.5677235126495361, discriminator_loss=0.2784311771392822\n",
            "step 711: generator_loss=1.6453452110290527, discriminator_loss=0.25811290740966797\n",
            "step 712: generator_loss=1.6639388799667358, discriminator_loss=0.267009437084198\n",
            "step 713: generator_loss=1.686958909034729, discriminator_loss=0.2419690489768982\n",
            "step 714: generator_loss=1.6345186233520508, discriminator_loss=0.2408321648836136\n",
            "step 715: generator_loss=1.7014827728271484, discriminator_loss=0.2712852656841278\n",
            "step 716: generator_loss=1.699947476387024, discriminator_loss=0.2707960903644562\n",
            "step 717: generator_loss=1.6825988292694092, discriminator_loss=0.2573486566543579\n",
            "step 718: generator_loss=1.6527533531188965, discriminator_loss=0.2561558187007904\n",
            "step 719: generator_loss=1.5070922374725342, discriminator_loss=0.2819865345954895\n",
            "step 720: generator_loss=1.5378062725067139, discriminator_loss=0.29828304052352905\n",
            "step 721: generator_loss=1.4066135883331299, discriminator_loss=0.34170860052108765\n",
            "step 722: generator_loss=1.3758130073547363, discriminator_loss=0.3359838128089905\n",
            "step 723: generator_loss=1.3364121913909912, discriminator_loss=0.3589463531970978\n",
            "step 724: generator_loss=1.2791638374328613, discriminator_loss=0.3499865233898163\n",
            "step 725: generator_loss=1.2796757221221924, discriminator_loss=0.3758535385131836\n",
            "step 726: generator_loss=1.3135263919830322, discriminator_loss=0.39850109815597534\n",
            "step 727: generator_loss=1.26554274559021, discriminator_loss=0.39748677611351013\n",
            "step 728: generator_loss=1.3031914234161377, discriminator_loss=0.3699977695941925\n",
            "step 729: generator_loss=1.3383432626724243, discriminator_loss=0.35242629051208496\n",
            "step 730: generator_loss=1.4727203845977783, discriminator_loss=0.3509729504585266\n",
            "step 731: generator_loss=1.4484553337097168, discriminator_loss=0.30798137187957764\n",
            "step 732: generator_loss=1.522679328918457, discriminator_loss=0.3287616968154907\n",
            "step 733: generator_loss=1.6461875438690186, discriminator_loss=0.2749013900756836\n",
            "step 734: generator_loss=1.627784252166748, discriminator_loss=0.28064092993736267\n",
            "step 735: generator_loss=1.7377703189849854, discriminator_loss=0.24535413086414337\n",
            "step 736: generator_loss=1.724616527557373, discriminator_loss=0.21717536449432373\n",
            "step 737: generator_loss=1.831272840499878, discriminator_loss=0.2150186151266098\n",
            "step 738: generator_loss=1.7132127285003662, discriminator_loss=0.23219414055347443\n",
            "step 739: generator_loss=1.8884053230285645, discriminator_loss=0.19798150658607483\n",
            "step 740: generator_loss=1.9163386821746826, discriminator_loss=0.1953243911266327\n",
            "step 741: generator_loss=1.8077967166900635, discriminator_loss=0.18984337151050568\n",
            "step 742: generator_loss=1.8822261095046997, discriminator_loss=0.21922311186790466\n",
            "step 743: generator_loss=1.8332602977752686, discriminator_loss=0.21086332201957703\n",
            "step 744: generator_loss=1.7814044952392578, discriminator_loss=0.20869939029216766\n",
            "step 745: generator_loss=1.7950634956359863, discriminator_loss=0.20069760084152222\n",
            "step 746: generator_loss=1.9025720357894897, discriminator_loss=0.21167804300785065\n",
            "step 747: generator_loss=1.8360679149627686, discriminator_loss=0.1991288810968399\n",
            "step 748: generator_loss=1.7999207973480225, discriminator_loss=0.2096855342388153\n",
            "step 749: generator_loss=1.7638381719589233, discriminator_loss=0.22562091052532196\n",
            "step 750: generator_loss=1.7642722129821777, discriminator_loss=0.2086104452610016\n",
            "step 751: generator_loss=1.7082912921905518, discriminator_loss=0.2365860939025879\n",
            "step 752: generator_loss=1.7799733877182007, discriminator_loss=0.23494797945022583\n",
            "step 753: generator_loss=1.7588601112365723, discriminator_loss=0.2549680173397064\n",
            "step 754: generator_loss=1.8582136631011963, discriminator_loss=0.24157358705997467\n",
            "step 755: generator_loss=1.6991280317306519, discriminator_loss=0.2560786306858063\n",
            "step 756: generator_loss=1.6454812288284302, discriminator_loss=0.2658725380897522\n",
            "step 757: generator_loss=1.67656409740448, discriminator_loss=0.24662600457668304\n",
            "step 758: generator_loss=1.5789767503738403, discriminator_loss=0.2624993324279785\n",
            "step 759: generator_loss=1.6233797073364258, discriminator_loss=0.24162675440311432\n",
            "step 760: generator_loss=1.5863063335418701, discriminator_loss=0.2697950005531311\n",
            "step 761: generator_loss=1.689164161682129, discriminator_loss=0.2566009759902954\n",
            "step 762: generator_loss=1.6086337566375732, discriminator_loss=0.26278382539749146\n",
            "step 763: generator_loss=1.6659477949142456, discriminator_loss=0.26904234290122986\n",
            "step 764: generator_loss=1.6610757112503052, discriminator_loss=0.27636340260505676\n",
            "step 765: generator_loss=1.5371475219726562, discriminator_loss=0.29994529485702515\n",
            "step 766: generator_loss=1.5291460752487183, discriminator_loss=0.3106818199157715\n",
            "step 767: generator_loss=1.4146366119384766, discriminator_loss=0.3293633460998535\n",
            "step 768: generator_loss=1.3956410884857178, discriminator_loss=0.36164194345474243\n",
            "step 769: generator_loss=1.3182740211486816, discriminator_loss=0.39084720611572266\n",
            "step 770: generator_loss=1.3212311267852783, discriminator_loss=0.39886951446533203\n",
            "step 771: generator_loss=1.2515807151794434, discriminator_loss=0.4231330454349518\n",
            "step 772: generator_loss=1.1491022109985352, discriminator_loss=0.4471995234489441\n",
            "step 773: generator_loss=1.0787067413330078, discriminator_loss=0.4926925301551819\n",
            "step 774: generator_loss=1.0657618045806885, discriminator_loss=0.510229229927063\n",
            "step 775: generator_loss=1.1056487560272217, discriminator_loss=0.5394842624664307\n",
            "step 776: generator_loss=1.0575504302978516, discriminator_loss=0.505987823009491\n",
            "step 777: generator_loss=0.9864940643310547, discriminator_loss=0.546614408493042\n",
            "step 778: generator_loss=1.0414104461669922, discriminator_loss=0.5660809278488159\n",
            "step 779: generator_loss=0.9909440279006958, discriminator_loss=0.6015467047691345\n",
            "step 780: generator_loss=0.9317243099212646, discriminator_loss=0.6226055026054382\n",
            "step 781: generator_loss=0.9005351066589355, discriminator_loss=0.6599714159965515\n",
            "step 782: generator_loss=0.8922441601753235, discriminator_loss=0.6249996423721313\n",
            "step 783: generator_loss=0.9785369634628296, discriminator_loss=0.5620230436325073\n",
            "step 784: generator_loss=1.0249974727630615, discriminator_loss=0.5280565023422241\n",
            "step 785: generator_loss=0.9602648019790649, discriminator_loss=0.5334980487823486\n",
            "step 786: generator_loss=1.0522035360336304, discriminator_loss=0.4818876385688782\n",
            "step 787: generator_loss=1.188407063484192, discriminator_loss=0.4264969527721405\n",
            "step 788: generator_loss=1.352301001548767, discriminator_loss=0.34910205006599426\n",
            "step 789: generator_loss=1.4401192665100098, discriminator_loss=0.3497999906539917\n",
            "step 790: generator_loss=1.5374730825424194, discriminator_loss=0.30021214485168457\n",
            "step 791: generator_loss=1.7120400667190552, discriminator_loss=0.26694685220718384\n",
            "step 792: generator_loss=1.701995849609375, discriminator_loss=0.25770533084869385\n",
            "step 793: generator_loss=1.8076231479644775, discriminator_loss=0.2438967078924179\n",
            "step 794: generator_loss=1.8566925525665283, discriminator_loss=0.24143074452877045\n",
            "step 795: generator_loss=1.9236340522766113, discriminator_loss=0.21952089667320251\n",
            "step 796: generator_loss=1.9480196237564087, discriminator_loss=0.21800968050956726\n",
            "step 797: generator_loss=2.048036575317383, discriminator_loss=0.19564536213874817\n",
            "step 798: generator_loss=1.7754693031311035, discriminator_loss=0.2217893898487091\n",
            "step 799: generator_loss=1.7634950876235962, discriminator_loss=0.20585733652114868\n",
            "step 800: generator_loss=1.7282634973526, discriminator_loss=0.21288838982582092\n",
            "step 801: generator_loss=1.865433692932129, discriminator_loss=0.1907769739627838\n",
            "step 802: generator_loss=1.7387669086456299, discriminator_loss=0.2056085169315338\n",
            "step 803: generator_loss=1.6755675077438354, discriminator_loss=0.21833926439285278\n",
            "step 804: generator_loss=1.8130741119384766, discriminator_loss=0.22649279236793518\n",
            "step 805: generator_loss=1.8607323169708252, discriminator_loss=0.20937666296958923\n",
            "step 806: generator_loss=1.8685033321380615, discriminator_loss=0.2071089744567871\n",
            "step 807: generator_loss=1.9509247541427612, discriminator_loss=0.19562691450119019\n",
            "step 808: generator_loss=1.979050636291504, discriminator_loss=0.2011936902999878\n",
            "step 809: generator_loss=1.9101629257202148, discriminator_loss=0.20003050565719604\n",
            "step 810: generator_loss=1.9302211999893188, discriminator_loss=0.21941673755645752\n",
            "step 811: generator_loss=1.988637089729309, discriminator_loss=0.20580199360847473\n",
            "step 812: generator_loss=1.8783745765686035, discriminator_loss=0.21892257034778595\n",
            "step 813: generator_loss=1.8379583358764648, discriminator_loss=0.23246049880981445\n",
            "step 814: generator_loss=1.8009047508239746, discriminator_loss=0.2542872428894043\n",
            "step 815: generator_loss=1.8967044353485107, discriminator_loss=0.23262065649032593\n",
            "step 816: generator_loss=1.9069808721542358, discriminator_loss=0.24105766415596008\n",
            "step 817: generator_loss=1.7252596616744995, discriminator_loss=0.2842656075954437\n",
            "step 818: generator_loss=1.7446470260620117, discriminator_loss=0.2645546793937683\n",
            "step 819: generator_loss=1.840154767036438, discriminator_loss=0.2588357925415039\n",
            "step 820: generator_loss=1.6469804048538208, discriminator_loss=0.3298257887363434\n",
            "step 821: generator_loss=1.530901551246643, discriminator_loss=0.40868470072746277\n",
            "step 822: generator_loss=1.449964165687561, discriminator_loss=0.3736186623573303\n",
            "step 823: generator_loss=1.500077724456787, discriminator_loss=0.39679598808288574\n",
            "step 824: generator_loss=1.535935401916504, discriminator_loss=0.38658154010772705\n",
            "step 825: generator_loss=1.3996071815490723, discriminator_loss=0.4051118791103363\n",
            "step 826: generator_loss=1.3142707347869873, discriminator_loss=0.4122854471206665\n",
            "step 827: generator_loss=1.2608895301818848, discriminator_loss=0.4392563998699188\n",
            "step 828: generator_loss=1.257555365562439, discriminator_loss=0.4281526505947113\n",
            "step 829: generator_loss=1.2089422941207886, discriminator_loss=0.4349808096885681\n",
            "step 830: generator_loss=1.274080753326416, discriminator_loss=0.42969709634780884\n",
            "step 831: generator_loss=1.2775022983551025, discriminator_loss=0.400852233171463\n",
            "step 832: generator_loss=1.1684842109680176, discriminator_loss=0.4546865224838257\n",
            "step 833: generator_loss=1.2151834964752197, discriminator_loss=0.4037376046180725\n",
            "step 834: generator_loss=1.235802173614502, discriminator_loss=0.36890000104904175\n",
            "step 835: generator_loss=1.2271232604980469, discriminator_loss=0.3805631995201111\n",
            "step 836: generator_loss=1.217238426208496, discriminator_loss=0.3458808660507202\n",
            "step 837: generator_loss=1.2459979057312012, discriminator_loss=0.3499770164489746\n",
            "step 838: generator_loss=1.2303766012191772, discriminator_loss=0.3110462427139282\n",
            "step 839: generator_loss=1.2762997150421143, discriminator_loss=0.3002481460571289\n",
            "step 840: generator_loss=1.3322705030441284, discriminator_loss=0.286815881729126\n",
            "step 841: generator_loss=1.4348478317260742, discriminator_loss=0.24978329241275787\n",
            "step 842: generator_loss=1.5750190019607544, discriminator_loss=0.2508057951927185\n",
            "step 843: generator_loss=1.5957133769989014, discriminator_loss=0.2390088140964508\n",
            "step 844: generator_loss=1.6094179153442383, discriminator_loss=0.23500102758407593\n",
            "step 845: generator_loss=1.707540512084961, discriminator_loss=0.23034259676933289\n",
            "step 846: generator_loss=1.698699712753296, discriminator_loss=0.21594581007957458\n",
            "step 847: generator_loss=1.7105491161346436, discriminator_loss=0.19974032044410706\n",
            "step 848: generator_loss=1.678253412246704, discriminator_loss=0.20717960596084595\n",
            "step 849: generator_loss=1.7228960990905762, discriminator_loss=0.20145714282989502\n",
            "step 850: generator_loss=1.6957871913909912, discriminator_loss=0.21371158957481384\n",
            "step 851: generator_loss=1.6871616840362549, discriminator_loss=0.20631662011146545\n",
            "step 852: generator_loss=1.6696884632110596, discriminator_loss=0.22590583562850952\n",
            "step 853: generator_loss=1.674008846282959, discriminator_loss=0.20662494003772736\n",
            "step 854: generator_loss=1.5922635793685913, discriminator_loss=0.23671558499336243\n",
            "step 855: generator_loss=1.5934462547302246, discriminator_loss=0.24753467738628387\n",
            "step 856: generator_loss=1.5682594776153564, discriminator_loss=0.24098584055900574\n",
            "step 857: generator_loss=1.5797325372695923, discriminator_loss=0.24287420511245728\n",
            "step 858: generator_loss=1.542539119720459, discriminator_loss=0.2653944790363312\n",
            "step 859: generator_loss=1.5518869161605835, discriminator_loss=0.258716881275177\n",
            "step 860: generator_loss=1.5224355459213257, discriminator_loss=0.27882838249206543\n",
            "step 861: generator_loss=1.4905080795288086, discriminator_loss=0.2611123025417328\n",
            "step 862: generator_loss=1.4550085067749023, discriminator_loss=0.29375213384628296\n",
            "step 863: generator_loss=1.3933584690093994, discriminator_loss=0.29536673426628113\n",
            "step 864: generator_loss=1.4165458679199219, discriminator_loss=0.2813960611820221\n",
            "step 865: generator_loss=1.389714002609253, discriminator_loss=0.29901570081710815\n",
            "step 866: generator_loss=1.392301082611084, discriminator_loss=0.3107343912124634\n",
            "step 867: generator_loss=1.3947820663452148, discriminator_loss=0.3084753751754761\n",
            "step 868: generator_loss=1.4620616436004639, discriminator_loss=0.3022324740886688\n",
            "step 869: generator_loss=1.5103771686553955, discriminator_loss=0.3160703182220459\n",
            "step 870: generator_loss=1.481750726699829, discriminator_loss=0.32956376671791077\n",
            "step 871: generator_loss=1.4616436958312988, discriminator_loss=0.32649242877960205\n",
            "step 872: generator_loss=1.3783330917358398, discriminator_loss=0.3456682562828064\n",
            "step 873: generator_loss=1.2983345985412598, discriminator_loss=0.350013792514801\n",
            "step 874: generator_loss=1.2297818660736084, discriminator_loss=0.3638054132461548\n",
            "step 875: generator_loss=1.285684585571289, discriminator_loss=0.34548720717430115\n",
            "step 876: generator_loss=1.2410149574279785, discriminator_loss=0.3476974070072174\n",
            "step 877: generator_loss=1.3400803804397583, discriminator_loss=0.3273452818393707\n",
            "step 878: generator_loss=1.3289794921875, discriminator_loss=0.3677067160606384\n",
            "step 879: generator_loss=1.3578999042510986, discriminator_loss=0.3679257929325104\n",
            "step 880: generator_loss=1.5191720724105835, discriminator_loss=0.3435772657394409\n",
            "step 881: generator_loss=1.4773756265640259, discriminator_loss=0.37111538648605347\n",
            "step 882: generator_loss=1.470167875289917, discriminator_loss=0.371746689081192\n",
            "step 883: generator_loss=1.3636691570281982, discriminator_loss=0.3868759870529175\n",
            "step 884: generator_loss=1.3505513668060303, discriminator_loss=0.39804190397262573\n",
            "step 885: generator_loss=1.3084659576416016, discriminator_loss=0.41079390048980713\n",
            "step 886: generator_loss=1.3456645011901855, discriminator_loss=0.3700079321861267\n",
            "step 887: generator_loss=1.4450263977050781, discriminator_loss=0.380095899105072\n",
            "step 888: generator_loss=1.2894681692123413, discriminator_loss=0.39297303557395935\n",
            "step 889: generator_loss=1.2643967866897583, discriminator_loss=0.41377919912338257\n",
            "step 890: generator_loss=1.1976935863494873, discriminator_loss=0.4438682198524475\n",
            "step 891: generator_loss=1.2905917167663574, discriminator_loss=0.4292987585067749\n",
            "step 892: generator_loss=1.297428011894226, discriminator_loss=0.43735140562057495\n",
            "step 893: generator_loss=1.2826788425445557, discriminator_loss=0.4036802649497986\n",
            "step 894: generator_loss=1.2619249820709229, discriminator_loss=0.39961445331573486\n",
            "step 895: generator_loss=1.1392912864685059, discriminator_loss=0.4176867604255676\n",
            "step 896: generator_loss=1.211653232574463, discriminator_loss=0.3827204406261444\n",
            "step 897: generator_loss=1.3371803760528564, discriminator_loss=0.3967995047569275\n",
            "step 898: generator_loss=1.376819372177124, discriminator_loss=0.35343265533447266\n",
            "step 899: generator_loss=1.4836485385894775, discriminator_loss=0.3812028765678406\n",
            "step 900: generator_loss=1.4539614915847778, discriminator_loss=0.335227370262146\n",
            "step 901: generator_loss=1.3745386600494385, discriminator_loss=0.34272676706314087\n",
            "step 902: generator_loss=1.386343240737915, discriminator_loss=0.32808154821395874\n",
            "step 903: generator_loss=1.438746452331543, discriminator_loss=0.3421732187271118\n",
            "step 904: generator_loss=1.428814172744751, discriminator_loss=0.333854079246521\n",
            "step 905: generator_loss=1.3304810523986816, discriminator_loss=0.3477836847305298\n",
            "step 906: generator_loss=1.3600645065307617, discriminator_loss=0.3318302631378174\n",
            "step 907: generator_loss=1.5119521617889404, discriminator_loss=0.3133465647697449\n",
            "step 908: generator_loss=1.55082368850708, discriminator_loss=0.3335511088371277\n",
            "step 909: generator_loss=1.5475273132324219, discriminator_loss=0.28990423679351807\n",
            "step 910: generator_loss=1.5906200408935547, discriminator_loss=0.3291056156158447\n",
            "step 911: generator_loss=1.5231733322143555, discriminator_loss=0.2986467778682709\n",
            "step 912: generator_loss=1.5106720924377441, discriminator_loss=0.3056894540786743\n",
            "step 913: generator_loss=1.6107372045516968, discriminator_loss=0.2993074953556061\n",
            "step 914: generator_loss=1.4040385484695435, discriminator_loss=0.33182063698768616\n",
            "step 915: generator_loss=1.4204022884368896, discriminator_loss=0.3121500015258789\n",
            "step 916: generator_loss=1.4150457382202148, discriminator_loss=0.3015850782394409\n",
            "step 917: generator_loss=1.450363278388977, discriminator_loss=0.3038250505924225\n",
            "step 918: generator_loss=1.4596874713897705, discriminator_loss=0.3178391456604004\n",
            "step 919: generator_loss=1.5259827375411987, discriminator_loss=0.3071573078632355\n",
            "step 920: generator_loss=1.51949143409729, discriminator_loss=0.3159137964248657\n",
            "step 921: generator_loss=1.4710540771484375, discriminator_loss=0.29750949144363403\n",
            "step 922: generator_loss=1.5330628156661987, discriminator_loss=0.2811529338359833\n",
            "step 923: generator_loss=1.5533530712127686, discriminator_loss=0.293849915266037\n",
            "step 924: generator_loss=1.6041721105575562, discriminator_loss=0.29610252380371094\n",
            "step 925: generator_loss=1.614856481552124, discriminator_loss=0.2527637183666229\n",
            "step 926: generator_loss=1.694893717765808, discriminator_loss=0.25081485509872437\n",
            "step 927: generator_loss=1.6206815242767334, discriminator_loss=0.25407320261001587\n",
            "step 928: generator_loss=1.7641301155090332, discriminator_loss=0.2413843870162964\n",
            "step 929: generator_loss=1.7540674209594727, discriminator_loss=0.24920502305030823\n",
            "step 930: generator_loss=1.723328948020935, discriminator_loss=0.2521390914916992\n",
            "step 931: generator_loss=1.690727710723877, discriminator_loss=0.2603788673877716\n",
            "step 932: generator_loss=1.7503317594528198, discriminator_loss=0.2485581934452057\n",
            "step 933: generator_loss=1.5235764980316162, discriminator_loss=0.26558351516723633\n",
            "step 934: generator_loss=1.581581711769104, discriminator_loss=0.25463056564331055\n",
            "step 935: generator_loss=1.4046649932861328, discriminator_loss=0.29727989435195923\n",
            "step 936: generator_loss=1.4742696285247803, discriminator_loss=0.2929653525352478\n",
            "step 937: generator_loss=1.4493558406829834, discriminator_loss=0.3095642924308777\n",
            "step 938: generator_loss=1.3958234786987305, discriminator_loss=0.3215281367301941\n",
            "step 939: generator_loss=1.4418017864227295, discriminator_loss=0.3165251612663269\n",
            "step 940: generator_loss=1.4191811084747314, discriminator_loss=0.31472247838974\n",
            "step 941: generator_loss=1.3110628128051758, discriminator_loss=0.33653074502944946\n",
            "step 942: generator_loss=1.2861419916152954, discriminator_loss=0.35779422521591187\n",
            "step 943: generator_loss=1.2616091966629028, discriminator_loss=0.34653225541114807\n",
            "step 944: generator_loss=1.2355947494506836, discriminator_loss=0.37013736367225647\n",
            "step 945: generator_loss=1.176458477973938, discriminator_loss=0.383835107088089\n",
            "step 946: generator_loss=1.1599586009979248, discriminator_loss=0.3784692883491516\n",
            "step 947: generator_loss=1.1539466381072998, discriminator_loss=0.38216131925582886\n",
            "step 948: generator_loss=1.1084709167480469, discriminator_loss=0.39428311586380005\n",
            "step 949: generator_loss=1.1369245052337646, discriminator_loss=0.41621601581573486\n",
            "step 950: generator_loss=1.1179511547088623, discriminator_loss=0.39913874864578247\n",
            "step 951: generator_loss=1.105635404586792, discriminator_loss=0.4099913239479065\n",
            "step 952: generator_loss=1.07538902759552, discriminator_loss=0.42000535130500793\n",
            "step 953: generator_loss=1.099827527999878, discriminator_loss=0.41250795125961304\n",
            "step 954: generator_loss=1.0244871377944946, discriminator_loss=0.4376879930496216\n",
            "step 955: generator_loss=1.1364085674285889, discriminator_loss=0.4456199109554291\n",
            "step 956: generator_loss=1.203255534172058, discriminator_loss=0.42257797718048096\n",
            "step 957: generator_loss=1.2358126640319824, discriminator_loss=0.393265962600708\n",
            "step 958: generator_loss=1.2463363409042358, discriminator_loss=0.40998613834381104\n",
            "step 959: generator_loss=1.260784387588501, discriminator_loss=0.39987289905548096\n",
            "step 960: generator_loss=1.4336411952972412, discriminator_loss=0.3603813648223877\n",
            "step 961: generator_loss=1.3968526124954224, discriminator_loss=0.3343055546283722\n",
            "step 962: generator_loss=1.5056805610656738, discriminator_loss=0.29652053117752075\n",
            "step 963: generator_loss=1.7037690877914429, discriminator_loss=0.2679491341114044\n",
            "step 964: generator_loss=1.7942453622817993, discriminator_loss=0.2683861255645752\n",
            "step 965: generator_loss=1.8150928020477295, discriminator_loss=0.25567084550857544\n",
            "step 966: generator_loss=1.7554991245269775, discriminator_loss=0.2576402425765991\n",
            "step 967: generator_loss=1.7047195434570312, discriminator_loss=0.2596385180950165\n",
            "step 968: generator_loss=1.7903393507003784, discriminator_loss=0.2243053913116455\n",
            "step 969: generator_loss=1.7807163000106812, discriminator_loss=0.23148716986179352\n",
            "step 970: generator_loss=1.7471377849578857, discriminator_loss=0.23653234541416168\n",
            "step 971: generator_loss=1.7439439296722412, discriminator_loss=0.2368045449256897\n",
            "step 972: generator_loss=1.7062045335769653, discriminator_loss=0.23543080687522888\n",
            "step 973: generator_loss=1.6258488893508911, discriminator_loss=0.254453182220459\n",
            "step 974: generator_loss=1.6428461074829102, discriminator_loss=0.2325212061405182\n",
            "step 975: generator_loss=1.5616075992584229, discriminator_loss=0.24086274206638336\n",
            "step 976: generator_loss=1.5369863510131836, discriminator_loss=0.23588594794273376\n",
            "step 977: generator_loss=1.53078031539917, discriminator_loss=0.2428894340991974\n",
            "step 978: generator_loss=1.626415729522705, discriminator_loss=0.22886832058429718\n",
            "step 979: generator_loss=1.5546464920043945, discriminator_loss=0.24009552597999573\n",
            "step 980: generator_loss=1.499558925628662, discriminator_loss=0.2414994090795517\n",
            "step 981: generator_loss=1.5552926063537598, discriminator_loss=0.23660656809806824\n",
            "step 982: generator_loss=1.6725064516067505, discriminator_loss=0.22087033092975616\n",
            "step 983: generator_loss=1.6401219367980957, discriminator_loss=0.2025790959596634\n",
            "step 984: generator_loss=1.5798757076263428, discriminator_loss=0.2230227291584015\n",
            "step 985: generator_loss=1.6451709270477295, discriminator_loss=0.20076650381088257\n",
            "step 986: generator_loss=1.6339852809906006, discriminator_loss=0.21945089101791382\n",
            "step 987: generator_loss=1.6759241819381714, discriminator_loss=0.20680934190750122\n",
            "step 988: generator_loss=1.5787593126296997, discriminator_loss=0.2406940907239914\n",
            "step 989: generator_loss=1.5907161235809326, discriminator_loss=0.2526373863220215\n",
            "step 990: generator_loss=1.5791096687316895, discriminator_loss=0.2215219885110855\n",
            "step 991: generator_loss=1.5723307132720947, discriminator_loss=0.23662355542182922\n",
            "step 992: generator_loss=1.4909902811050415, discriminator_loss=0.24169176816940308\n",
            "step 993: generator_loss=1.492728352546692, discriminator_loss=0.23268157243728638\n",
            "step 994: generator_loss=1.4381545782089233, discriminator_loss=0.27312132716178894\n",
            "step 995: generator_loss=1.4292068481445312, discriminator_loss=0.24103333055973053\n",
            "step 996: generator_loss=1.4436166286468506, discriminator_loss=0.25664401054382324\n",
            "step 997: generator_loss=1.4224557876586914, discriminator_loss=0.2589341402053833\n",
            "step 998: generator_loss=1.453611969947815, discriminator_loss=0.2600610852241516\n",
            "step 999: generator_loss=1.43117356300354, discriminator_loss=0.2521999478340149\n",
            "step 1000: generator_loss=1.4196785688400269, discriminator_loss=0.26944229006767273\n",
            "step 1001: generator_loss=1.4166584014892578, discriminator_loss=0.26189661026000977\n",
            "step 1002: generator_loss=1.5142641067504883, discriminator_loss=0.2434442639350891\n",
            "step 1003: generator_loss=1.4900308847427368, discriminator_loss=0.25061941146850586\n",
            "step 1004: generator_loss=1.594308614730835, discriminator_loss=0.26057398319244385\n",
            "step 1005: generator_loss=1.6184598207473755, discriminator_loss=0.25033408403396606\n",
            "step 1006: generator_loss=1.6037696599960327, discriminator_loss=0.2496558427810669\n",
            "step 1007: generator_loss=1.6665879487991333, discriminator_loss=0.22685736417770386\n",
            "step 1008: generator_loss=1.7708940505981445, discriminator_loss=0.21866542100906372\n",
            "step 1009: generator_loss=1.726372480392456, discriminator_loss=0.21217571198940277\n",
            "step 1010: generator_loss=1.8058750629425049, discriminator_loss=0.1907620131969452\n",
            "step 1011: generator_loss=1.8339042663574219, discriminator_loss=0.1804172396659851\n",
            "step 1012: generator_loss=1.9292981624603271, discriminator_loss=0.18099063634872437\n",
            "step 1013: generator_loss=1.9074171781539917, discriminator_loss=0.17377124726772308\n",
            "step 1014: generator_loss=1.9919795989990234, discriminator_loss=0.19242390990257263\n",
            "step 1015: generator_loss=1.9010652303695679, discriminator_loss=0.16566622257232666\n",
            "step 1016: generator_loss=1.9409122467041016, discriminator_loss=0.18021133542060852\n",
            "step 1017: generator_loss=1.9463562965393066, discriminator_loss=0.18633383512496948\n",
            "step 1018: generator_loss=1.9608416557312012, discriminator_loss=0.21002930402755737\n",
            "step 1019: generator_loss=1.838024377822876, discriminator_loss=0.18785205483436584\n",
            "step 1020: generator_loss=1.7523691654205322, discriminator_loss=0.21113288402557373\n",
            "step 1021: generator_loss=1.7927584648132324, discriminator_loss=0.20649239420890808\n",
            "step 1022: generator_loss=1.7794864177703857, discriminator_loss=0.2263098657131195\n",
            "step 1023: generator_loss=1.782472848892212, discriminator_loss=0.23353582620620728\n",
            "step 1024: generator_loss=1.7421464920043945, discriminator_loss=0.24515390396118164\n",
            "step 1025: generator_loss=1.7752009630203247, discriminator_loss=0.21864092350006104\n",
            "step 1026: generator_loss=1.7630712985992432, discriminator_loss=0.2510389983654022\n",
            "step 1027: generator_loss=1.8516066074371338, discriminator_loss=0.25114309787750244\n",
            "step 1028: generator_loss=1.855576515197754, discriminator_loss=0.24055905640125275\n",
            "step 1029: generator_loss=1.8650636672973633, discriminator_loss=0.21751029789447784\n",
            "step 1030: generator_loss=1.7407958507537842, discriminator_loss=0.2376880943775177\n",
            "step 1031: generator_loss=1.7849924564361572, discriminator_loss=0.25146791338920593\n",
            "step 1032: generator_loss=1.6962566375732422, discriminator_loss=0.26787281036376953\n",
            "step 1033: generator_loss=1.8320778608322144, discriminator_loss=0.23261070251464844\n",
            "step 1034: generator_loss=1.7053574323654175, discriminator_loss=0.23159052431583405\n",
            "step 1035: generator_loss=1.7924779653549194, discriminator_loss=0.24558818340301514\n",
            "step 1036: generator_loss=1.7257401943206787, discriminator_loss=0.2239314615726471\n",
            "step 1037: generator_loss=1.7514305114746094, discriminator_loss=0.21461175382137299\n",
            "step 1038: generator_loss=1.7871036529541016, discriminator_loss=0.232606440782547\n",
            "step 1039: generator_loss=1.8571088314056396, discriminator_loss=0.2185540795326233\n",
            "step 1040: generator_loss=1.8770180940628052, discriminator_loss=0.19161085784435272\n",
            "step 1041: generator_loss=1.908184289932251, discriminator_loss=0.2321873903274536\n",
            "step 1042: generator_loss=1.850893259048462, discriminator_loss=0.21238484978675842\n",
            "step 1043: generator_loss=1.8129312992095947, discriminator_loss=0.2214849293231964\n",
            "step 1044: generator_loss=1.6970484256744385, discriminator_loss=0.23089644312858582\n",
            "step 1045: generator_loss=1.5932878255844116, discriminator_loss=0.24084435403347015\n",
            "step 1046: generator_loss=1.5719964504241943, discriminator_loss=0.2614612579345703\n",
            "step 1047: generator_loss=1.5939847230911255, discriminator_loss=0.26138949394226074\n",
            "step 1048: generator_loss=1.6835339069366455, discriminator_loss=0.2411080002784729\n",
            "step 1049: generator_loss=1.6781765222549438, discriminator_loss=0.25951722264289856\n",
            "step 1050: generator_loss=1.5715171098709106, discriminator_loss=0.281865656375885\n",
            "step 1051: generator_loss=1.5341296195983887, discriminator_loss=0.27525919675827026\n",
            "step 1052: generator_loss=1.6241216659545898, discriminator_loss=0.26510781049728394\n",
            "step 1053: generator_loss=1.6108107566833496, discriminator_loss=0.24469536542892456\n",
            "step 1054: generator_loss=1.754097580909729, discriminator_loss=0.2523277997970581\n",
            "step 1055: generator_loss=1.7723973989486694, discriminator_loss=0.261382520198822\n",
            "step 1056: generator_loss=1.776329755783081, discriminator_loss=0.24731557071208954\n",
            "step 1057: generator_loss=1.6018781661987305, discriminator_loss=0.27751424908638\n",
            "step 1058: generator_loss=1.520194411277771, discriminator_loss=0.26542022824287415\n",
            "step 1059: generator_loss=1.4826624393463135, discriminator_loss=0.2726573646068573\n",
            "step 1060: generator_loss=1.4358028173446655, discriminator_loss=0.26339536905288696\n",
            "step 1061: generator_loss=1.5047428607940674, discriminator_loss=0.25646546483039856\n",
            "step 1062: generator_loss=1.657055139541626, discriminator_loss=0.26309460401535034\n",
            "step 1063: generator_loss=1.6593043804168701, discriminator_loss=0.27303624153137207\n",
            "step 1064: generator_loss=1.717242956161499, discriminator_loss=0.25813472270965576\n",
            "step 1065: generator_loss=1.7275028228759766, discriminator_loss=0.25933846831321716\n",
            "step 1066: generator_loss=1.7442296743392944, discriminator_loss=0.2666028141975403\n",
            "step 1067: generator_loss=1.589799165725708, discriminator_loss=0.2595241665840149\n",
            "step 1068: generator_loss=1.5470998287200928, discriminator_loss=0.25380444526672363\n",
            "step 1069: generator_loss=1.539010763168335, discriminator_loss=0.2539593577384949\n",
            "step 1070: generator_loss=1.5780394077301025, discriminator_loss=0.25593194365501404\n",
            "step 1071: generator_loss=1.6055188179016113, discriminator_loss=0.2659425735473633\n",
            "step 1072: generator_loss=1.7772190570831299, discriminator_loss=0.23168249428272247\n",
            "step 1073: generator_loss=1.8268595933914185, discriminator_loss=0.2644122540950775\n",
            "step 1074: generator_loss=1.9323512315750122, discriminator_loss=0.24279862642288208\n",
            "step 1075: generator_loss=1.929830551147461, discriminator_loss=0.24283379316329956\n",
            "step 1076: generator_loss=1.9030619859695435, discriminator_loss=0.27880859375\n",
            "step 1077: generator_loss=1.835251808166504, discriminator_loss=0.2948247194290161\n",
            "step 1078: generator_loss=1.8638916015625, discriminator_loss=0.26316505670547485\n",
            "step 1079: generator_loss=2.020275115966797, discriminator_loss=0.2679521143436432\n",
            "step 1080: generator_loss=1.7877373695373535, discriminator_loss=0.28932639956474304\n",
            "step 1081: generator_loss=1.9489954710006714, discriminator_loss=0.2907533049583435\n",
            "step 1082: generator_loss=1.8965234756469727, discriminator_loss=0.29501673579216003\n",
            "step 1083: generator_loss=2.0193467140197754, discriminator_loss=0.2583657205104828\n",
            "step 1084: generator_loss=2.1252522468566895, discriminator_loss=0.23752695322036743\n",
            "step 1085: generator_loss=1.9861359596252441, discriminator_loss=0.25300586223602295\n",
            "step 1086: generator_loss=2.0815038681030273, discriminator_loss=0.25619184970855713\n",
            "step 1087: generator_loss=2.227431297302246, discriminator_loss=0.23812317848205566\n",
            "step 1088: generator_loss=2.459543228149414, discriminator_loss=0.20130185782909393\n",
            "step 1089: generator_loss=2.4541175365448, discriminator_loss=0.21466974914073944\n",
            "step 1090: generator_loss=2.4299309253692627, discriminator_loss=0.1994948387145996\n",
            "step 1091: generator_loss=2.246269941329956, discriminator_loss=0.2072628140449524\n",
            "step 1092: generator_loss=2.2036869525909424, discriminator_loss=0.22461548447608948\n",
            "step 1093: generator_loss=2.1590969562530518, discriminator_loss=0.21248027682304382\n",
            "step 1094: generator_loss=2.3186683654785156, discriminator_loss=0.18495643138885498\n",
            "step 1095: generator_loss=2.2042324542999268, discriminator_loss=0.20996302366256714\n",
            "step 1096: generator_loss=2.133175849914551, discriminator_loss=0.19483819603919983\n",
            "step 1097: generator_loss=2.1376378536224365, discriminator_loss=0.2196049690246582\n",
            "step 1098: generator_loss=2.1873600482940674, discriminator_loss=0.2356625497341156\n",
            "step 1099: generator_loss=2.1883676052093506, discriminator_loss=0.2570727467536926\n",
            "step 1100: generator_loss=2.2163000106811523, discriminator_loss=0.19698625802993774\n",
            "step 1101: generator_loss=2.1038050651550293, discriminator_loss=0.2200150042772293\n",
            "step 1102: generator_loss=2.0668184757232666, discriminator_loss=0.2287844568490982\n",
            "step 1103: generator_loss=2.00250244140625, discriminator_loss=0.23776546120643616\n",
            "step 1104: generator_loss=1.9903764724731445, discriminator_loss=0.21849550306797028\n",
            "step 1105: generator_loss=1.7471587657928467, discriminator_loss=0.24539418518543243\n",
            "step 1106: generator_loss=1.864638328552246, discriminator_loss=0.26713502407073975\n",
            "step 1107: generator_loss=1.8971877098083496, discriminator_loss=0.22915688157081604\n",
            "step 1108: generator_loss=1.921004056930542, discriminator_loss=0.24373069405555725\n",
            "step 1109: generator_loss=1.975569725036621, discriminator_loss=0.2283152937889099\n",
            "step 1110: generator_loss=1.955691933631897, discriminator_loss=0.23901480436325073\n",
            "step 1111: generator_loss=1.8748501539230347, discriminator_loss=0.243223637342453\n",
            "step 1112: generator_loss=1.9006381034851074, discriminator_loss=0.210212841629982\n",
            "step 1113: generator_loss=1.7718485593795776, discriminator_loss=0.24159708619117737\n",
            "step 1114: generator_loss=1.8151919841766357, discriminator_loss=0.23253287374973297\n",
            "step 1115: generator_loss=1.8149977922439575, discriminator_loss=0.256339430809021\n",
            "step 1116: generator_loss=1.9467072486877441, discriminator_loss=0.24809479713439941\n",
            "step 1117: generator_loss=1.9768139123916626, discriminator_loss=0.24645507335662842\n",
            "step 1118: generator_loss=1.9525728225708008, discriminator_loss=0.26813653111457825\n",
            "step 1119: generator_loss=1.8244613409042358, discriminator_loss=0.26801326870918274\n",
            "step 1120: generator_loss=1.941575527191162, discriminator_loss=0.2895941138267517\n",
            "step 1121: generator_loss=1.9630153179168701, discriminator_loss=0.2831417918205261\n",
            "step 1122: generator_loss=1.738269329071045, discriminator_loss=0.33912643790245056\n",
            "step 1123: generator_loss=1.6247012615203857, discriminator_loss=0.3093903362751007\n",
            "step 1124: generator_loss=1.812990665435791, discriminator_loss=0.2672628164291382\n",
            "step 1125: generator_loss=1.750657558441162, discriminator_loss=0.2916191816329956\n",
            "step 1126: generator_loss=1.8336398601531982, discriminator_loss=0.22631028294563293\n",
            "step 1127: generator_loss=1.8493549823760986, discriminator_loss=0.21084105968475342\n",
            "step 1128: generator_loss=1.8992607593536377, discriminator_loss=0.22522667050361633\n",
            "step 1129: generator_loss=2.009308338165283, discriminator_loss=0.2228643298149109\n",
            "step 1130: generator_loss=2.1553258895874023, discriminator_loss=0.2098207324743271\n",
            "step 1131: generator_loss=2.1124160289764404, discriminator_loss=0.22175709903240204\n",
            "step 1132: generator_loss=2.038644552230835, discriminator_loss=0.20028822124004364\n",
            "step 1133: generator_loss=2.1080398559570312, discriminator_loss=0.18157410621643066\n",
            "step 1134: generator_loss=1.8372282981872559, discriminator_loss=0.19134509563446045\n",
            "step 1135: generator_loss=1.8709173202514648, discriminator_loss=0.19192788004875183\n",
            "step 1136: generator_loss=1.8974242210388184, discriminator_loss=0.20438280701637268\n",
            "step 1137: generator_loss=1.9851816892623901, discriminator_loss=0.18974852561950684\n",
            "step 1138: generator_loss=1.8176673650741577, discriminator_loss=0.20701634883880615\n",
            "step 1139: generator_loss=1.8738234043121338, discriminator_loss=0.2413315325975418\n",
            "step 1140: generator_loss=1.8928098678588867, discriminator_loss=0.1927991509437561\n",
            "step 1141: generator_loss=1.865058422088623, discriminator_loss=0.19423052668571472\n",
            "step 1142: generator_loss=1.9061315059661865, discriminator_loss=0.18077704310417175\n",
            "step 1143: generator_loss=1.9600502252578735, discriminator_loss=0.16960306465625763\n",
            "step 1144: generator_loss=2.0169777870178223, discriminator_loss=0.17763078212738037\n",
            "step 1145: generator_loss=1.950500726699829, discriminator_loss=0.1673974096775055\n",
            "step 1146: generator_loss=1.905818223953247, discriminator_loss=0.2078523188829422\n",
            "step 1147: generator_loss=1.8682293891906738, discriminator_loss=0.20850753784179688\n",
            "step 1148: generator_loss=1.838895559310913, discriminator_loss=0.19482743740081787\n",
            "step 1149: generator_loss=1.7705535888671875, discriminator_loss=0.21319735050201416\n",
            "step 1150: generator_loss=1.7156107425689697, discriminator_loss=0.2271573841571808\n",
            "step 1151: generator_loss=1.681161642074585, discriminator_loss=0.2149856984615326\n",
            "step 1152: generator_loss=1.6537413597106934, discriminator_loss=0.23151685297489166\n",
            "step 1153: generator_loss=1.6697293519973755, discriminator_loss=0.19600041210651398\n",
            "step 1154: generator_loss=1.7561595439910889, discriminator_loss=0.2031840682029724\n",
            "step 1155: generator_loss=1.761500358581543, discriminator_loss=0.22070440649986267\n",
            "step 1156: generator_loss=1.8198528289794922, discriminator_loss=0.20970012247562408\n",
            "step 1157: generator_loss=1.801190733909607, discriminator_loss=0.210896298289299\n",
            "step 1158: generator_loss=1.8179500102996826, discriminator_loss=0.2291615754365921\n",
            "step 1159: generator_loss=1.768135905265808, discriminator_loss=0.22898311913013458\n",
            "step 1160: generator_loss=1.790794849395752, discriminator_loss=0.2172081470489502\n",
            "step 1161: generator_loss=1.804518461227417, discriminator_loss=0.20504224300384521\n",
            "step 1162: generator_loss=1.7712409496307373, discriminator_loss=0.21450787782669067\n",
            "step 1163: generator_loss=1.8104164600372314, discriminator_loss=0.22019755840301514\n",
            "step 1164: generator_loss=1.8906426429748535, discriminator_loss=0.2126045525074005\n",
            "step 1165: generator_loss=1.8581234216690063, discriminator_loss=0.24535579979419708\n",
            "step 1166: generator_loss=1.7660460472106934, discriminator_loss=0.2537054717540741\n",
            "step 1167: generator_loss=1.7161355018615723, discriminator_loss=0.2699218988418579\n",
            "step 1168: generator_loss=1.5834574699401855, discriminator_loss=0.2533920109272003\n",
            "step 1169: generator_loss=1.6147313117980957, discriminator_loss=0.2492346465587616\n",
            "step 1170: generator_loss=1.6019923686981201, discriminator_loss=0.30689430236816406\n",
            "step 1171: generator_loss=1.570671558380127, discriminator_loss=0.2876458168029785\n",
            "step 1172: generator_loss=1.5504264831542969, discriminator_loss=0.3096711039543152\n",
            "step 1173: generator_loss=1.6199592351913452, discriminator_loss=0.3164943754673004\n",
            "step 1174: generator_loss=1.5214121341705322, discriminator_loss=0.34883832931518555\n",
            "step 1175: generator_loss=1.5463809967041016, discriminator_loss=0.3038187026977539\n",
            "step 1176: generator_loss=1.5503408908843994, discriminator_loss=0.31756481528282166\n",
            "step 1177: generator_loss=1.4765340089797974, discriminator_loss=0.3067910671234131\n",
            "step 1178: generator_loss=1.4121339321136475, discriminator_loss=0.32439398765563965\n",
            "step 1179: generator_loss=1.5047554969787598, discriminator_loss=0.29912427067756653\n",
            "step 1180: generator_loss=1.6378836631774902, discriminator_loss=0.31147652864456177\n",
            "step 1181: generator_loss=1.8074231147766113, discriminator_loss=0.2599928379058838\n",
            "step 1182: generator_loss=1.9536364078521729, discriminator_loss=0.24419289827346802\n",
            "step 1183: generator_loss=1.9367930889129639, discriminator_loss=0.24951720237731934\n",
            "step 1184: generator_loss=1.796623706817627, discriminator_loss=0.24761784076690674\n",
            "step 1185: generator_loss=1.8151838779449463, discriminator_loss=0.22398771345615387\n",
            "step 1186: generator_loss=1.8038209676742554, discriminator_loss=0.22651639580726624\n",
            "step 1187: generator_loss=1.7099584341049194, discriminator_loss=0.253470242023468\n",
            "step 1188: generator_loss=1.7914984226226807, discriminator_loss=0.1849861741065979\n",
            "step 1189: generator_loss=1.8633949756622314, discriminator_loss=0.20401328802108765\n",
            "step 1190: generator_loss=1.8830993175506592, discriminator_loss=0.1954677700996399\n",
            "step 1191: generator_loss=2.1813719272613525, discriminator_loss=0.1837584674358368\n",
            "step 1192: generator_loss=2.2915353775024414, discriminator_loss=0.17814846336841583\n",
            "step 1193: generator_loss=2.370790481567383, discriminator_loss=0.16833889484405518\n",
            "step 1194: generator_loss=2.3829312324523926, discriminator_loss=0.14841485023498535\n",
            "step 1195: generator_loss=2.2891411781311035, discriminator_loss=0.15703777968883514\n",
            "step 1196: generator_loss=2.2713518142700195, discriminator_loss=0.15006563067436218\n",
            "step 1197: generator_loss=2.4107882976531982, discriminator_loss=0.1356494128704071\n",
            "step 1198: generator_loss=2.226318120956421, discriminator_loss=0.14882904291152954\n",
            "step 1199: generator_loss=2.2039098739624023, discriminator_loss=0.1492965817451477\n",
            "step 1200: generator_loss=2.1793460845947266, discriminator_loss=0.14371073246002197\n",
            "step 1201: generator_loss=2.139181613922119, discriminator_loss=0.14696960151195526\n",
            "step 1202: generator_loss=2.3290014266967773, discriminator_loss=0.14351733028888702\n",
            "step 1203: generator_loss=2.3194797039031982, discriminator_loss=0.15731742978096008\n",
            "step 1204: generator_loss=2.5059680938720703, discriminator_loss=0.14976581931114197\n",
            "step 1205: generator_loss=2.5039422512054443, discriminator_loss=0.1893911361694336\n",
            "step 1206: generator_loss=2.4229187965393066, discriminator_loss=0.18834149837493896\n",
            "step 1207: generator_loss=2.467629909515381, discriminator_loss=0.15661004185676575\n",
            "step 1208: generator_loss=2.3899965286254883, discriminator_loss=0.16183114051818848\n",
            "step 1209: generator_loss=2.4463181495666504, discriminator_loss=0.16809120774269104\n",
            "step 1210: generator_loss=2.26658296585083, discriminator_loss=0.19899281859397888\n",
            "step 1211: generator_loss=2.3392868041992188, discriminator_loss=0.2192695587873459\n",
            "step 1212: generator_loss=2.4397926330566406, discriminator_loss=0.1985560953617096\n",
            "step 1213: generator_loss=2.7570762634277344, discriminator_loss=0.18000872433185577\n",
            "step 1214: generator_loss=2.4506757259368896, discriminator_loss=0.2170134037733078\n",
            "step 1215: generator_loss=2.601841926574707, discriminator_loss=0.23824386298656464\n",
            "step 1216: generator_loss=2.1434707641601562, discriminator_loss=0.3267131447792053\n",
            "step 1217: generator_loss=2.0382490158081055, discriminator_loss=0.3134877681732178\n",
            "step 1218: generator_loss=2.2069835662841797, discriminator_loss=0.25447747111320496\n",
            "step 1219: generator_loss=1.9927538633346558, discriminator_loss=0.35264748334884644\n",
            "step 1220: generator_loss=2.133355140686035, discriminator_loss=0.3163616955280304\n",
            "step 1221: generator_loss=2.2071096897125244, discriminator_loss=0.34787023067474365\n",
            "step 1222: generator_loss=2.379037857055664, discriminator_loss=0.24983619153499603\n",
            "step 1223: generator_loss=2.4498772621154785, discriminator_loss=0.23982632160186768\n",
            "step 1224: generator_loss=2.3814868927001953, discriminator_loss=0.2548682987689972\n",
            "step 1225: generator_loss=2.280271053314209, discriminator_loss=0.2883530259132385\n",
            "step 1226: generator_loss=2.2467851638793945, discriminator_loss=0.23980870842933655\n",
            "step 1227: generator_loss=2.074331283569336, discriminator_loss=0.26163679361343384\n",
            "step 1228: generator_loss=1.9382314682006836, discriminator_loss=0.2580402195453644\n",
            "step 1229: generator_loss=2.0580477714538574, discriminator_loss=0.25947505235671997\n",
            "step 1230: generator_loss=2.1097259521484375, discriminator_loss=0.2247399389743805\n",
            "step 1231: generator_loss=2.104396343231201, discriminator_loss=0.23043985664844513\n",
            "step 1232: generator_loss=2.094461441040039, discriminator_loss=0.1890873908996582\n",
            "step 1233: generator_loss=2.161522388458252, discriminator_loss=0.17398127913475037\n",
            "step 1234: generator_loss=2.183821201324463, discriminator_loss=0.16124683618545532\n",
            "step 1235: generator_loss=2.320056915283203, discriminator_loss=0.1864933967590332\n",
            "step 1236: generator_loss=2.3831958770751953, discriminator_loss=0.16297656297683716\n",
            "step 1237: generator_loss=2.6344425678253174, discriminator_loss=0.14688411355018616\n",
            "step 1238: generator_loss=2.7238261699676514, discriminator_loss=0.1528935730457306\n",
            "step 1239: generator_loss=2.3636250495910645, discriminator_loss=0.14840567111968994\n",
            "step 1240: generator_loss=2.464423656463623, discriminator_loss=0.16205406188964844\n",
            "step 1241: generator_loss=2.180382251739502, discriminator_loss=0.15510046482086182\n",
            "step 1242: generator_loss=2.3810269832611084, discriminator_loss=0.17404893040657043\n",
            "step 1243: generator_loss=2.1909284591674805, discriminator_loss=0.1604611873626709\n",
            "step 1244: generator_loss=2.2535884380340576, discriminator_loss=0.1809193640947342\n",
            "step 1245: generator_loss=2.3846888542175293, discriminator_loss=0.15514583885669708\n",
            "step 1246: generator_loss=2.3607630729675293, discriminator_loss=0.17361244559288025\n",
            "step 1247: generator_loss=2.326901435852051, discriminator_loss=0.17894206941127777\n",
            "step 1248: generator_loss=2.3375627994537354, discriminator_loss=0.18261347711086273\n",
            "step 1249: generator_loss=2.3479437828063965, discriminator_loss=0.17258808016777039\n",
            "step 1250: generator_loss=2.166473388671875, discriminator_loss=0.17913228273391724\n",
            "step 1251: generator_loss=2.3240785598754883, discriminator_loss=0.15804272890090942\n",
            "step 1252: generator_loss=2.1674857139587402, discriminator_loss=0.16678214073181152\n",
            "step 1253: generator_loss=2.1139888763427734, discriminator_loss=0.18522793054580688\n",
            "step 1254: generator_loss=2.3399858474731445, discriminator_loss=0.1706199049949646\n",
            "step 1255: generator_loss=2.2789154052734375, discriminator_loss=0.1573522388935089\n",
            "step 1256: generator_loss=2.1460351943969727, discriminator_loss=0.1865452378988266\n",
            "step 1257: generator_loss=2.3104279041290283, discriminator_loss=0.14696498215198517\n",
            "step 1258: generator_loss=2.368692398071289, discriminator_loss=0.16669903695583344\n",
            "step 1259: generator_loss=2.1419472694396973, discriminator_loss=0.20145033299922943\n",
            "step 1260: generator_loss=1.9858404397964478, discriminator_loss=0.21448802947998047\n",
            "step 1261: generator_loss=1.8400719165802002, discriminator_loss=0.23601174354553223\n",
            "step 1262: generator_loss=1.7958760261535645, discriminator_loss=0.24636618793010712\n",
            "step 1263: generator_loss=1.8898169994354248, discriminator_loss=0.22489047050476074\n",
            "step 1264: generator_loss=1.8766419887542725, discriminator_loss=0.24358294904232025\n",
            "step 1265: generator_loss=1.8647198677062988, discriminator_loss=0.2683710753917694\n",
            "step 1266: generator_loss=1.9193849563598633, discriminator_loss=0.22156141698360443\n",
            "step 1267: generator_loss=1.944023847579956, discriminator_loss=0.2633082866668701\n",
            "step 1268: generator_loss=2.1304068565368652, discriminator_loss=0.25059574842453003\n",
            "step 1269: generator_loss=2.1655097007751465, discriminator_loss=0.2537461519241333\n",
            "step 1270: generator_loss=2.1039581298828125, discriminator_loss=0.22583746910095215\n",
            "step 1271: generator_loss=2.095391273498535, discriminator_loss=0.258172869682312\n",
            "step 1272: generator_loss=1.9964392185211182, discriminator_loss=0.28542742133140564\n",
            "step 1273: generator_loss=1.6795170307159424, discriminator_loss=0.3119933009147644\n",
            "step 1274: generator_loss=1.5153716802597046, discriminator_loss=0.30478236079216003\n",
            "step 1275: generator_loss=1.586841344833374, discriminator_loss=0.2876402735710144\n",
            "step 1276: generator_loss=1.7933475971221924, discriminator_loss=0.24452772736549377\n",
            "step 1277: generator_loss=1.6470897197723389, discriminator_loss=0.2839934527873993\n",
            "step 1278: generator_loss=1.8740906715393066, discriminator_loss=0.2762412428855896\n",
            "step 1279: generator_loss=1.8723559379577637, discriminator_loss=0.2240237295627594\n",
            "step 1280: generator_loss=1.8911457061767578, discriminator_loss=0.25572195649147034\n",
            "step 1281: generator_loss=1.9194749593734741, discriminator_loss=0.22965958714485168\n",
            "step 1282: generator_loss=1.7719886302947998, discriminator_loss=0.2041209638118744\n",
            "step 1283: generator_loss=1.8347338438034058, discriminator_loss=0.21931159496307373\n",
            "step 1284: generator_loss=1.781860113143921, discriminator_loss=0.2369699478149414\n",
            "step 1285: generator_loss=1.7116271257400513, discriminator_loss=0.2261342704296112\n",
            "step 1286: generator_loss=1.6609851121902466, discriminator_loss=0.23187872767448425\n",
            "step 1287: generator_loss=1.7233511209487915, discriminator_loss=0.21460947394371033\n",
            "step 1288: generator_loss=1.8486697673797607, discriminator_loss=0.16283588111400604\n",
            "step 1289: generator_loss=2.041257381439209, discriminator_loss=0.181554913520813\n",
            "step 1290: generator_loss=1.9806252717971802, discriminator_loss=0.18329152464866638\n",
            "step 1291: generator_loss=2.0254101753234863, discriminator_loss=0.18171529471874237\n",
            "step 1292: generator_loss=2.0823469161987305, discriminator_loss=0.20342043042182922\n",
            "step 1293: generator_loss=1.9552884101867676, discriminator_loss=0.2046109139919281\n",
            "step 1294: generator_loss=1.8521292209625244, discriminator_loss=0.18697690963745117\n",
            "step 1295: generator_loss=1.755128264427185, discriminator_loss=0.19833175837993622\n",
            "step 1296: generator_loss=1.667919397354126, discriminator_loss=0.20218248665332794\n",
            "step 1297: generator_loss=1.735896348953247, discriminator_loss=0.2092384696006775\n",
            "step 1298: generator_loss=1.7328112125396729, discriminator_loss=0.20318159461021423\n",
            "step 1299: generator_loss=1.8605036735534668, discriminator_loss=0.20866388082504272\n",
            "step 1300: generator_loss=1.8268787860870361, discriminator_loss=0.20581156015396118\n",
            "step 1301: generator_loss=1.8757094144821167, discriminator_loss=0.20654813945293427\n",
            "step 1302: generator_loss=1.8417448997497559, discriminator_loss=0.19319605827331543\n",
            "step 1303: generator_loss=1.9048100709915161, discriminator_loss=0.17272911965847015\n",
            "step 1304: generator_loss=1.9085769653320312, discriminator_loss=0.2025224268436432\n",
            "step 1305: generator_loss=1.839181900024414, discriminator_loss=0.2076473832130432\n",
            "step 1306: generator_loss=1.8288631439208984, discriminator_loss=0.16655781865119934\n",
            "step 1307: generator_loss=1.899951696395874, discriminator_loss=0.1571703851222992\n",
            "step 1308: generator_loss=2.0093631744384766, discriminator_loss=0.14988671243190765\n",
            "step 1309: generator_loss=2.0964674949645996, discriminator_loss=0.152398481965065\n",
            "step 1310: generator_loss=2.202986240386963, discriminator_loss=0.14609281718730927\n",
            "step 1311: generator_loss=2.1907284259796143, discriminator_loss=0.16266870498657227\n",
            "step 1312: generator_loss=2.2474799156188965, discriminator_loss=0.1220436841249466\n",
            "step 1313: generator_loss=2.217433214187622, discriminator_loss=0.11744658648967743\n",
            "step 1314: generator_loss=2.2170000076293945, discriminator_loss=0.1374785453081131\n",
            "step 1315: generator_loss=2.219796657562256, discriminator_loss=0.11821532994508743\n",
            "step 1316: generator_loss=2.2503468990325928, discriminator_loss=0.12525494396686554\n",
            "step 1317: generator_loss=2.229879856109619, discriminator_loss=0.1162409782409668\n",
            "step 1318: generator_loss=2.246473789215088, discriminator_loss=0.13765883445739746\n",
            "step 1319: generator_loss=2.1736984252929688, discriminator_loss=0.15275788307189941\n",
            "step 1320: generator_loss=2.1616406440734863, discriminator_loss=0.1518084704875946\n",
            "step 1321: generator_loss=2.093299150466919, discriminator_loss=0.1274898499250412\n",
            "step 1322: generator_loss=2.0648844242095947, discriminator_loss=0.15643732249736786\n",
            "step 1323: generator_loss=2.091620445251465, discriminator_loss=0.14646023511886597\n",
            "step 1324: generator_loss=2.150202751159668, discriminator_loss=0.14264847338199615\n",
            "step 1325: generator_loss=2.1934499740600586, discriminator_loss=0.1434612274169922\n",
            "step 1326: generator_loss=2.2205610275268555, discriminator_loss=0.17203710973262787\n",
            "step 1327: generator_loss=2.2863874435424805, discriminator_loss=0.13056302070617676\n",
            "step 1328: generator_loss=2.3557004928588867, discriminator_loss=0.14077135920524597\n",
            "step 1329: generator_loss=2.411644697189331, discriminator_loss=0.14592063426971436\n",
            "step 1330: generator_loss=2.3609459400177, discriminator_loss=0.11782364547252655\n",
            "step 1331: generator_loss=2.3699471950531006, discriminator_loss=0.1526370495557785\n",
            "step 1332: generator_loss=2.3274447917938232, discriminator_loss=0.13247478008270264\n",
            "step 1333: generator_loss=2.313173294067383, discriminator_loss=0.15052580833435059\n",
            "step 1334: generator_loss=2.3983657360076904, discriminator_loss=0.11812970787286758\n",
            "step 1335: generator_loss=2.500481128692627, discriminator_loss=0.14178940653800964\n",
            "step 1336: generator_loss=2.457362413406372, discriminator_loss=0.16322043538093567\n",
            "step 1337: generator_loss=2.4859066009521484, discriminator_loss=0.15421058237552643\n",
            "step 1338: generator_loss=2.3516287803649902, discriminator_loss=0.18844932317733765\n",
            "step 1339: generator_loss=2.378169059753418, discriminator_loss=0.1450374871492386\n",
            "step 1340: generator_loss=2.359076499938965, discriminator_loss=0.1647123396396637\n",
            "step 1341: generator_loss=2.1957926750183105, discriminator_loss=0.17339056730270386\n",
            "step 1342: generator_loss=2.180722713470459, discriminator_loss=0.17343057692050934\n",
            "step 1343: generator_loss=2.1239500045776367, discriminator_loss=0.1543252170085907\n",
            "step 1344: generator_loss=2.1793439388275146, discriminator_loss=0.1450720727443695\n",
            "step 1345: generator_loss=2.21899151802063, discriminator_loss=0.14657115936279297\n",
            "step 1346: generator_loss=2.244938373565674, discriminator_loss=0.16118089854717255\n",
            "step 1347: generator_loss=2.2297918796539307, discriminator_loss=0.15248803794384003\n",
            "step 1348: generator_loss=2.1963047981262207, discriminator_loss=0.16983339190483093\n",
            "step 1349: generator_loss=2.1859145164489746, discriminator_loss=0.17199605703353882\n",
            "step 1350: generator_loss=2.130949020385742, discriminator_loss=0.1636163890361786\n",
            "step 1351: generator_loss=2.1366820335388184, discriminator_loss=0.1531410962343216\n",
            "step 1352: generator_loss=2.0164546966552734, discriminator_loss=0.1886514574289322\n",
            "step 1353: generator_loss=2.025136947631836, discriminator_loss=0.17922993004322052\n",
            "step 1354: generator_loss=2.114366054534912, discriminator_loss=0.13815397024154663\n",
            "step 1355: generator_loss=2.0653109550476074, discriminator_loss=0.16423948109149933\n",
            "step 1356: generator_loss=2.209243059158325, discriminator_loss=0.1587895154953003\n",
            "step 1357: generator_loss=2.227952480316162, discriminator_loss=0.1873163878917694\n",
            "step 1358: generator_loss=2.288238525390625, discriminator_loss=0.20861929655075073\n",
            "step 1359: generator_loss=2.3734512329101562, discriminator_loss=0.1761472523212433\n",
            "step 1360: generator_loss=2.2827022075653076, discriminator_loss=0.17769396305084229\n",
            "step 1361: generator_loss=2.1300554275512695, discriminator_loss=0.17902140319347382\n",
            "step 1362: generator_loss=2.0398783683776855, discriminator_loss=0.2023460865020752\n",
            "step 1363: generator_loss=1.9666870832443237, discriminator_loss=0.2081032693386078\n",
            "step 1364: generator_loss=1.9559614658355713, discriminator_loss=0.18069010972976685\n",
            "step 1365: generator_loss=1.8425393104553223, discriminator_loss=0.23648595809936523\n",
            "step 1366: generator_loss=1.8693293333053589, discriminator_loss=0.2374773621559143\n",
            "step 1367: generator_loss=1.9442236423492432, discriminator_loss=0.21763111650943756\n",
            "step 1368: generator_loss=2.1451663970947266, discriminator_loss=0.1787641942501068\n",
            "step 1369: generator_loss=2.299283504486084, discriminator_loss=0.20595766603946686\n",
            "step 1370: generator_loss=2.213745594024658, discriminator_loss=0.20997874438762665\n",
            "step 1371: generator_loss=2.10481595993042, discriminator_loss=0.2220911979675293\n",
            "step 1372: generator_loss=1.9068344831466675, discriminator_loss=0.2082686573266983\n",
            "step 1373: generator_loss=1.8451337814331055, discriminator_loss=0.2209734171628952\n",
            "step 1374: generator_loss=1.7204818725585938, discriminator_loss=0.21273916959762573\n",
            "step 1375: generator_loss=1.8250346183776855, discriminator_loss=0.2013348639011383\n",
            "step 1376: generator_loss=1.870392918586731, discriminator_loss=0.17356988787651062\n",
            "step 1377: generator_loss=1.9453932046890259, discriminator_loss=0.18700891733169556\n",
            "step 1378: generator_loss=2.0600805282592773, discriminator_loss=0.17904873192310333\n",
            "step 1379: generator_loss=2.2028839588165283, discriminator_loss=0.18688303232192993\n",
            "step 1380: generator_loss=2.3246803283691406, discriminator_loss=0.1602255403995514\n",
            "step 1381: generator_loss=2.1910934448242188, discriminator_loss=0.19523167610168457\n",
            "step 1382: generator_loss=2.165318012237549, discriminator_loss=0.19067546725273132\n",
            "step 1383: generator_loss=2.189530849456787, discriminator_loss=0.15651234984397888\n",
            "step 1384: generator_loss=2.2862548828125, discriminator_loss=0.13575822114944458\n",
            "step 1385: generator_loss=2.3224167823791504, discriminator_loss=0.11773473769426346\n",
            "step 1386: generator_loss=2.3445239067077637, discriminator_loss=0.11583308130502701\n",
            "step 1387: generator_loss=2.359696865081787, discriminator_loss=0.12759532034397125\n",
            "step 1388: generator_loss=2.3499557971954346, discriminator_loss=0.10718470066785812\n",
            "step 1389: generator_loss=2.418581485748291, discriminator_loss=0.10909262299537659\n",
            "step 1390: generator_loss=2.480257987976074, discriminator_loss=0.10549643635749817\n",
            "step 1391: generator_loss=2.4498703479766846, discriminator_loss=0.1101655513048172\n",
            "step 1392: generator_loss=2.653347969055176, discriminator_loss=0.11051373183727264\n",
            "step 1393: generator_loss=2.714878559112549, discriminator_loss=0.09906505048274994\n",
            "step 1394: generator_loss=2.5593583583831787, discriminator_loss=0.0987510159611702\n",
            "step 1395: generator_loss=2.6239278316497803, discriminator_loss=0.10438916087150574\n",
            "step 1396: generator_loss=2.5268301963806152, discriminator_loss=0.11319637298583984\n",
            "step 1397: generator_loss=2.5461697578430176, discriminator_loss=0.10052827000617981\n",
            "step 1398: generator_loss=2.473602056503296, discriminator_loss=0.09469318389892578\n",
            "step 1399: generator_loss=2.4365029335021973, discriminator_loss=0.11586343497037888\n",
            "step 1400: generator_loss=2.453356981277466, discriminator_loss=0.1217963919043541\n",
            "step 1401: generator_loss=2.4598560333251953, discriminator_loss=0.1093420460820198\n",
            "step 1402: generator_loss=2.2722649574279785, discriminator_loss=0.11160209774971008\n",
            "step 1403: generator_loss=2.4903156757354736, discriminator_loss=0.11153987795114517\n",
            "step 1404: generator_loss=2.4106407165527344, discriminator_loss=0.11368076503276825\n",
            "step 1405: generator_loss=2.588376522064209, discriminator_loss=0.08892279863357544\n",
            "step 1406: generator_loss=2.4433791637420654, discriminator_loss=0.12638649344444275\n",
            "step 1407: generator_loss=2.5482912063598633, discriminator_loss=0.11450161784887314\n",
            "step 1408: generator_loss=2.5035252571105957, discriminator_loss=0.10396576672792435\n",
            "step 1409: generator_loss=2.489964485168457, discriminator_loss=0.11316181719303131\n",
            "step 1410: generator_loss=2.4232468605041504, discriminator_loss=0.11888600140810013\n",
            "step 1411: generator_loss=2.4281980991363525, discriminator_loss=0.13338544964790344\n",
            "step 1412: generator_loss=2.4034693241119385, discriminator_loss=0.13410213589668274\n",
            "step 1413: generator_loss=2.448700428009033, discriminator_loss=0.1087685078382492\n",
            "step 1414: generator_loss=2.4523980617523193, discriminator_loss=0.1061125248670578\n",
            "step 1415: generator_loss=2.4177658557891846, discriminator_loss=0.13867121934890747\n",
            "step 1416: generator_loss=2.3399477005004883, discriminator_loss=0.1376584768295288\n",
            "step 1417: generator_loss=2.4090399742126465, discriminator_loss=0.11298860609531403\n",
            "step 1418: generator_loss=2.3302412033081055, discriminator_loss=0.11929643154144287\n",
            "step 1419: generator_loss=2.359745979309082, discriminator_loss=0.11351291835308075\n",
            "step 1420: generator_loss=2.370213031768799, discriminator_loss=0.10538991540670395\n",
            "step 1421: generator_loss=2.3935799598693848, discriminator_loss=0.12005648761987686\n",
            "step 1422: generator_loss=2.473001480102539, discriminator_loss=0.11515393108129501\n",
            "step 1423: generator_loss=2.404387950897217, discriminator_loss=0.12320229411125183\n",
            "step 1424: generator_loss=2.3607935905456543, discriminator_loss=0.11602182686328888\n",
            "step 1425: generator_loss=2.336973190307617, discriminator_loss=0.12887592613697052\n",
            "step 1426: generator_loss=2.3318405151367188, discriminator_loss=0.12603169679641724\n",
            "step 1427: generator_loss=2.318187713623047, discriminator_loss=0.13428401947021484\n",
            "step 1428: generator_loss=2.360255718231201, discriminator_loss=0.13176976144313812\n",
            "step 1429: generator_loss=2.366278886795044, discriminator_loss=0.13193227350711823\n",
            "step 1430: generator_loss=2.397933006286621, discriminator_loss=0.15491265058517456\n",
            "step 1431: generator_loss=2.2529449462890625, discriminator_loss=0.1454770714044571\n",
            "step 1432: generator_loss=2.247164487838745, discriminator_loss=0.1488925963640213\n",
            "step 1433: generator_loss=2.2839889526367188, discriminator_loss=0.1641155332326889\n",
            "step 1434: generator_loss=2.3228540420532227, discriminator_loss=0.1500130295753479\n",
            "step 1435: generator_loss=2.248061180114746, discriminator_loss=0.18173158168792725\n",
            "step 1436: generator_loss=2.39638614654541, discriminator_loss=0.1653352677822113\n",
            "step 1437: generator_loss=2.387542486190796, discriminator_loss=0.22572174668312073\n",
            "step 1438: generator_loss=2.6501636505126953, discriminator_loss=0.1735718548297882\n",
            "step 1439: generator_loss=2.406686305999756, discriminator_loss=0.24660871922969818\n",
            "step 1440: generator_loss=2.6917707920074463, discriminator_loss=0.19895288348197937\n",
            "step 1441: generator_loss=2.748870849609375, discriminator_loss=0.19459238648414612\n",
            "step 1442: generator_loss=2.7899811267852783, discriminator_loss=0.2617601454257965\n",
            "step 1443: generator_loss=2.7656631469726562, discriminator_loss=0.2682693302631378\n",
            "step 1444: generator_loss=2.821789264678955, discriminator_loss=0.25771069526672363\n",
            "step 1445: generator_loss=2.86197566986084, discriminator_loss=0.2584649920463562\n",
            "step 1446: generator_loss=2.9052412509918213, discriminator_loss=0.2595854103565216\n",
            "step 1447: generator_loss=2.9837045669555664, discriminator_loss=0.25322195887565613\n",
            "step 1448: generator_loss=3.3192288875579834, discriminator_loss=0.21525315940380096\n",
            "step 1449: generator_loss=3.1605615615844727, discriminator_loss=0.21727441251277924\n",
            "step 1450: generator_loss=3.7030680179595947, discriminator_loss=0.16249656677246094\n",
            "step 1451: generator_loss=3.4940476417541504, discriminator_loss=0.17041060328483582\n",
            "step 1452: generator_loss=3.46152400970459, discriminator_loss=0.18078893423080444\n",
            "step 1453: generator_loss=3.01594877243042, discriminator_loss=0.149767205119133\n",
            "step 1454: generator_loss=2.9790494441986084, discriminator_loss=0.14091160893440247\n",
            "step 1455: generator_loss=2.9133994579315186, discriminator_loss=0.13182364404201508\n",
            "step 1456: generator_loss=3.0552401542663574, discriminator_loss=0.11962496489286423\n",
            "step 1457: generator_loss=2.78013014793396, discriminator_loss=0.1447087824344635\n",
            "step 1458: generator_loss=2.7193822860717773, discriminator_loss=0.11513680219650269\n",
            "step 1459: generator_loss=2.7067441940307617, discriminator_loss=0.12067487835884094\n",
            "step 1460: generator_loss=2.884800910949707, discriminator_loss=0.0994010865688324\n",
            "step 1461: generator_loss=2.9140708446502686, discriminator_loss=0.09899915754795074\n",
            "step 1462: generator_loss=2.947573184967041, discriminator_loss=0.09299248456954956\n",
            "step 1463: generator_loss=2.814851760864258, discriminator_loss=0.10732805728912354\n",
            "step 1464: generator_loss=2.9728288650512695, discriminator_loss=0.10816661268472672\n",
            "step 1465: generator_loss=3.010305166244507, discriminator_loss=0.1164088323712349\n",
            "step 1466: generator_loss=3.084519624710083, discriminator_loss=0.1098421961069107\n",
            "step 1467: generator_loss=3.0695714950561523, discriminator_loss=0.12499195337295532\n",
            "step 1468: generator_loss=3.147336483001709, discriminator_loss=0.09682702273130417\n",
            "step 1469: generator_loss=2.815809965133667, discriminator_loss=0.14617124199867249\n",
            "step 1470: generator_loss=2.6594438552856445, discriminator_loss=0.11751548945903778\n",
            "step 1471: generator_loss=2.506479501724243, discriminator_loss=0.13749685883522034\n",
            "step 1472: generator_loss=2.5247392654418945, discriminator_loss=0.1547950655221939\n",
            "step 1473: generator_loss=2.3842077255249023, discriminator_loss=0.13676807284355164\n",
            "step 1474: generator_loss=2.441392183303833, discriminator_loss=0.16260108351707458\n",
            "step 1475: generator_loss=2.5797345638275146, discriminator_loss=0.1623712182044983\n",
            "step 1476: generator_loss=2.597106695175171, discriminator_loss=0.15941007435321808\n",
            "step 1477: generator_loss=2.516352653503418, discriminator_loss=0.1856355369091034\n",
            "step 1478: generator_loss=2.5200271606445312, discriminator_loss=0.18342024087905884\n",
            "step 1479: generator_loss=2.3339855670928955, discriminator_loss=0.1767100989818573\n",
            "step 1480: generator_loss=2.207758665084839, discriminator_loss=0.2134028971195221\n",
            "step 1481: generator_loss=2.146151065826416, discriminator_loss=0.16490231454372406\n",
            "step 1482: generator_loss=2.111215591430664, discriminator_loss=0.18999001383781433\n",
            "step 1483: generator_loss=2.094863176345825, discriminator_loss=0.18883799016475677\n",
            "step 1484: generator_loss=2.272691249847412, discriminator_loss=0.14269056916236877\n",
            "step 1485: generator_loss=2.4850497245788574, discriminator_loss=0.1649562418460846\n",
            "step 1486: generator_loss=2.5019917488098145, discriminator_loss=0.18884167075157166\n",
            "step 1487: generator_loss=2.400573492050171, discriminator_loss=0.16855917870998383\n",
            "step 1488: generator_loss=2.5439858436584473, discriminator_loss=0.1409957855939865\n",
            "step 1489: generator_loss=2.5072295665740967, discriminator_loss=0.15236443281173706\n",
            "step 1490: generator_loss=2.5050785541534424, discriminator_loss=0.16323424875736237\n",
            "step 1491: generator_loss=2.346487045288086, discriminator_loss=0.16466690599918365\n",
            "step 1492: generator_loss=2.3007514476776123, discriminator_loss=0.1827450841665268\n",
            "step 1493: generator_loss=2.2868142127990723, discriminator_loss=0.18424595892429352\n",
            "step 1494: generator_loss=2.209428548812866, discriminator_loss=0.14149820804595947\n",
            "step 1495: generator_loss=2.175309658050537, discriminator_loss=0.17482821643352509\n",
            "step 1496: generator_loss=2.241708755493164, discriminator_loss=0.15543487668037415\n",
            "step 1497: generator_loss=2.2808189392089844, discriminator_loss=0.1425285041332245\n",
            "step 1498: generator_loss=2.302687644958496, discriminator_loss=0.14713731408119202\n",
            "step 1499: generator_loss=2.4728193283081055, discriminator_loss=0.16723106801509857\n",
            "step 1500: generator_loss=2.3490376472473145, discriminator_loss=0.2001451849937439\n",
            "step 1501: generator_loss=2.3677196502685547, discriminator_loss=0.15754646062850952\n",
            "step 1502: generator_loss=2.3220388889312744, discriminator_loss=0.15988968312740326\n",
            "step 1503: generator_loss=2.0977907180786133, discriminator_loss=0.18533281981945038\n",
            "step 1504: generator_loss=2.2364306449890137, discriminator_loss=0.1411188542842865\n",
            "step 1505: generator_loss=2.117008924484253, discriminator_loss=0.19881345331668854\n",
            "step 1506: generator_loss=2.0646400451660156, discriminator_loss=0.20170114934444427\n",
            "step 1507: generator_loss=2.158982038497925, discriminator_loss=0.18696236610412598\n",
            "step 1508: generator_loss=2.1489152908325195, discriminator_loss=0.18329352140426636\n",
            "step 1509: generator_loss=2.0732765197753906, discriminator_loss=0.20172956585884094\n",
            "step 1510: generator_loss=2.202099323272705, discriminator_loss=0.16064751148223877\n",
            "step 1511: generator_loss=2.2289187908172607, discriminator_loss=0.16911587119102478\n",
            "step 1512: generator_loss=2.09859037399292, discriminator_loss=0.20587700605392456\n",
            "step 1513: generator_loss=2.2296805381774902, discriminator_loss=0.17399990558624268\n",
            "step 1514: generator_loss=2.0815720558166504, discriminator_loss=0.19343067705631256\n",
            "step 1515: generator_loss=2.168056011199951, discriminator_loss=0.17146334052085876\n",
            "step 1516: generator_loss=2.2065415382385254, discriminator_loss=0.19615063071250916\n",
            "step 1517: generator_loss=2.2231202125549316, discriminator_loss=0.19596847891807556\n",
            "step 1518: generator_loss=2.2011260986328125, discriminator_loss=0.19005508720874786\n",
            "step 1519: generator_loss=2.26045823097229, discriminator_loss=0.17843976616859436\n",
            "step 1520: generator_loss=2.0784871578216553, discriminator_loss=0.2094922661781311\n",
            "step 1521: generator_loss=2.183096408843994, discriminator_loss=0.19143709540367126\n",
            "step 1522: generator_loss=2.0532259941101074, discriminator_loss=0.20305103063583374\n",
            "step 1523: generator_loss=2.0614874362945557, discriminator_loss=0.180329829454422\n",
            "step 1524: generator_loss=2.296112060546875, discriminator_loss=0.18145765364170074\n",
            "step 1525: generator_loss=2.2314107418060303, discriminator_loss=0.2056780308485031\n",
            "step 1526: generator_loss=2.2052459716796875, discriminator_loss=0.19736093282699585\n",
            "step 1527: generator_loss=2.098456382751465, discriminator_loss=0.19111117720603943\n",
            "step 1528: generator_loss=2.040513038635254, discriminator_loss=0.1991686224937439\n",
            "step 1529: generator_loss=1.9421539306640625, discriminator_loss=0.18080158531665802\n",
            "step 1530: generator_loss=2.0599091053009033, discriminator_loss=0.15778882801532745\n",
            "step 1531: generator_loss=2.1027326583862305, discriminator_loss=0.16593343019485474\n",
            "step 1532: generator_loss=2.1853718757629395, discriminator_loss=0.1634761542081833\n",
            "step 1533: generator_loss=2.3046042919158936, discriminator_loss=0.17015960812568665\n",
            "step 1534: generator_loss=2.278350353240967, discriminator_loss=0.1394910216331482\n",
            "step 1535: generator_loss=2.3766603469848633, discriminator_loss=0.14457270503044128\n",
            "step 1536: generator_loss=2.4451382160186768, discriminator_loss=0.13190671801567078\n",
            "step 1537: generator_loss=2.362435817718506, discriminator_loss=0.1461433470249176\n",
            "step 1538: generator_loss=2.316725730895996, discriminator_loss=0.13884900510311127\n",
            "step 1539: generator_loss=2.2672882080078125, discriminator_loss=0.13342957198619843\n",
            "step 1540: generator_loss=2.2258167266845703, discriminator_loss=0.13645634055137634\n",
            "step 1541: generator_loss=2.2675604820251465, discriminator_loss=0.14294344186782837\n",
            "step 1542: generator_loss=2.1807146072387695, discriminator_loss=0.14340995252132416\n",
            "step 1543: generator_loss=2.1812405586242676, discriminator_loss=0.1402895748615265\n",
            "step 1544: generator_loss=2.21763014793396, discriminator_loss=0.1511056125164032\n",
            "step 1545: generator_loss=2.25589656829834, discriminator_loss=0.1684579849243164\n",
            "step 1546: generator_loss=2.1329870223999023, discriminator_loss=0.15474793314933777\n",
            "step 1547: generator_loss=2.20894193649292, discriminator_loss=0.1697407364845276\n",
            "step 1548: generator_loss=2.1757707595825195, discriminator_loss=0.15933763980865479\n",
            "step 1549: generator_loss=2.1628036499023438, discriminator_loss=0.16940811276435852\n",
            "step 1550: generator_loss=2.177891254425049, discriminator_loss=0.1554952710866928\n",
            "step 1551: generator_loss=2.1409642696380615, discriminator_loss=0.19747476279735565\n",
            "step 1552: generator_loss=2.137488842010498, discriminator_loss=0.19044597446918488\n",
            "step 1553: generator_loss=2.1056623458862305, discriminator_loss=0.18744376301765442\n",
            "step 1554: generator_loss=2.21429181098938, discriminator_loss=0.18269136548042297\n",
            "step 1555: generator_loss=2.145805835723877, discriminator_loss=0.18945574760437012\n",
            "step 1556: generator_loss=2.110905885696411, discriminator_loss=0.20716360211372375\n",
            "step 1557: generator_loss=2.068392753601074, discriminator_loss=0.19348672032356262\n",
            "step 1558: generator_loss=1.9988733530044556, discriminator_loss=0.1969223916530609\n",
            "step 1559: generator_loss=2.048983573913574, discriminator_loss=0.2171483039855957\n",
            "step 1560: generator_loss=2.090134859085083, discriminator_loss=0.20384271442890167\n",
            "step 1561: generator_loss=1.9894073009490967, discriminator_loss=0.19798089563846588\n",
            "step 1562: generator_loss=2.0563745498657227, discriminator_loss=0.17492884397506714\n",
            "step 1563: generator_loss=2.245889186859131, discriminator_loss=0.17960885167121887\n",
            "step 1564: generator_loss=2.210742712020874, discriminator_loss=0.16967755556106567\n",
            "step 1565: generator_loss=2.343480110168457, discriminator_loss=0.14349070191383362\n",
            "step 1566: generator_loss=2.3060429096221924, discriminator_loss=0.15962758660316467\n",
            "step 1567: generator_loss=2.2287981510162354, discriminator_loss=0.15295587480068207\n",
            "step 1568: generator_loss=2.2258505821228027, discriminator_loss=0.17545118927955627\n",
            "step 1569: generator_loss=2.1036481857299805, discriminator_loss=0.17458318173885345\n",
            "step 1570: generator_loss=2.049229621887207, discriminator_loss=0.19673563539981842\n",
            "step 1571: generator_loss=1.9848167896270752, discriminator_loss=0.169417142868042\n",
            "step 1572: generator_loss=1.9986916780471802, discriminator_loss=0.15449070930480957\n",
            "step 1573: generator_loss=2.0089831352233887, discriminator_loss=0.16502109169960022\n",
            "step 1574: generator_loss=2.015842914581299, discriminator_loss=0.15458984673023224\n",
            "step 1575: generator_loss=2.0121405124664307, discriminator_loss=0.16386976838111877\n",
            "step 1576: generator_loss=2.0241189002990723, discriminator_loss=0.1624346226453781\n",
            "step 1577: generator_loss=2.2314953804016113, discriminator_loss=0.13840442895889282\n",
            "step 1578: generator_loss=2.252908706665039, discriminator_loss=0.16513291001319885\n",
            "step 1579: generator_loss=2.1279144287109375, discriminator_loss=0.16922084987163544\n",
            "step 1580: generator_loss=2.119039535522461, discriminator_loss=0.15475010871887207\n",
            "step 1581: generator_loss=2.0440688133239746, discriminator_loss=0.17116034030914307\n",
            "step 1582: generator_loss=1.8796257972717285, discriminator_loss=0.16518303751945496\n",
            "step 1583: generator_loss=1.8381834030151367, discriminator_loss=0.17440882325172424\n",
            "step 1584: generator_loss=1.8544118404388428, discriminator_loss=0.1545776128768921\n",
            "step 1585: generator_loss=1.8695240020751953, discriminator_loss=0.1605549454689026\n",
            "step 1586: generator_loss=1.879531979560852, discriminator_loss=0.15559490025043488\n",
            "step 1587: generator_loss=1.925316572189331, discriminator_loss=0.14940226078033447\n",
            "step 1588: generator_loss=2.0763144493103027, discriminator_loss=0.17848405241966248\n",
            "step 1589: generator_loss=2.0547127723693848, discriminator_loss=0.17421787977218628\n",
            "step 1590: generator_loss=2.073984146118164, discriminator_loss=0.180544912815094\n",
            "step 1591: generator_loss=2.0515079498291016, discriminator_loss=0.16764500737190247\n",
            "step 1592: generator_loss=1.9527957439422607, discriminator_loss=0.181878924369812\n",
            "step 1593: generator_loss=1.9859113693237305, discriminator_loss=0.18801704049110413\n",
            "step 1594: generator_loss=1.9266284704208374, discriminator_loss=0.15969446301460266\n",
            "step 1595: generator_loss=1.835277795791626, discriminator_loss=0.18479040265083313\n",
            "step 1596: generator_loss=1.8324263095855713, discriminator_loss=0.1909562647342682\n",
            "step 1597: generator_loss=1.9283888339996338, discriminator_loss=0.16755974292755127\n",
            "step 1598: generator_loss=2.176595449447632, discriminator_loss=0.16268111765384674\n",
            "step 1599: generator_loss=2.222736120223999, discriminator_loss=0.18899807333946228\n",
            "step 1600: generator_loss=2.2046282291412354, discriminator_loss=0.2411881536245346\n",
            "step 1601: generator_loss=2.2984519004821777, discriminator_loss=0.17103412747383118\n",
            "step 1602: generator_loss=2.3004655838012695, discriminator_loss=0.18557199835777283\n",
            "step 1603: generator_loss=2.0871176719665527, discriminator_loss=0.19048023223876953\n",
            "step 1604: generator_loss=1.9096131324768066, discriminator_loss=0.2214241921901703\n",
            "step 1605: generator_loss=1.9115961790084839, discriminator_loss=0.22634533047676086\n",
            "step 1606: generator_loss=2.1509838104248047, discriminator_loss=0.17768514156341553\n",
            "step 1607: generator_loss=2.142280340194702, discriminator_loss=0.17559346556663513\n",
            "step 1608: generator_loss=2.1902034282684326, discriminator_loss=0.2328420877456665\n",
            "step 1609: generator_loss=2.243865966796875, discriminator_loss=0.22989976406097412\n",
            "step 1610: generator_loss=2.3162291049957275, discriminator_loss=0.19404679536819458\n",
            "step 1611: generator_loss=2.3275623321533203, discriminator_loss=0.21312382817268372\n",
            "step 1612: generator_loss=2.1074059009552, discriminator_loss=0.2123630940914154\n",
            "step 1613: generator_loss=1.894139051437378, discriminator_loss=0.21665021777153015\n",
            "step 1614: generator_loss=2.007308006286621, discriminator_loss=0.182472363114357\n",
            "step 1615: generator_loss=1.9899189472198486, discriminator_loss=0.1679019033908844\n",
            "step 1616: generator_loss=1.9967379570007324, discriminator_loss=0.17112863063812256\n",
            "step 1617: generator_loss=2.2200608253479004, discriminator_loss=0.1602165699005127\n",
            "step 1618: generator_loss=2.4148478507995605, discriminator_loss=0.15667065978050232\n",
            "step 1619: generator_loss=2.3965229988098145, discriminator_loss=0.18542368710041046\n",
            "step 1620: generator_loss=2.456388473510742, discriminator_loss=0.16561859846115112\n",
            "step 1621: generator_loss=2.4997072219848633, discriminator_loss=0.16735735535621643\n",
            "step 1622: generator_loss=2.4715957641601562, discriminator_loss=0.13519319891929626\n",
            "step 1623: generator_loss=2.330714464187622, discriminator_loss=0.17556457221508026\n",
            "step 1624: generator_loss=2.2085752487182617, discriminator_loss=0.18174216151237488\n",
            "step 1625: generator_loss=1.9965791702270508, discriminator_loss=0.17498615384101868\n",
            "step 1626: generator_loss=1.9824857711791992, discriminator_loss=0.18702614307403564\n",
            "step 1627: generator_loss=2.0343635082244873, discriminator_loss=0.1641126573085785\n",
            "step 1628: generator_loss=2.2433595657348633, discriminator_loss=0.13092657923698425\n",
            "step 1629: generator_loss=2.25872802734375, discriminator_loss=0.1515980362892151\n",
            "step 1630: generator_loss=2.3552167415618896, discriminator_loss=0.15101756155490875\n",
            "step 1631: generator_loss=2.400850772857666, discriminator_loss=0.13516011834144592\n",
            "step 1632: generator_loss=2.4874234199523926, discriminator_loss=0.1632051169872284\n",
            "step 1633: generator_loss=2.3610851764678955, discriminator_loss=0.17727181315422058\n",
            "step 1634: generator_loss=2.3444833755493164, discriminator_loss=0.18406963348388672\n",
            "step 1635: generator_loss=2.163087844848633, discriminator_loss=0.1660691648721695\n",
            "step 1636: generator_loss=2.0826187133789062, discriminator_loss=0.17253628373146057\n",
            "step 1637: generator_loss=1.9816582202911377, discriminator_loss=0.17298194766044617\n",
            "step 1638: generator_loss=1.9751462936401367, discriminator_loss=0.21209827065467834\n",
            "step 1639: generator_loss=1.8366566896438599, discriminator_loss=0.21360917389392853\n",
            "step 1640: generator_loss=1.8543263673782349, discriminator_loss=0.20922863483428955\n",
            "step 1641: generator_loss=1.9384889602661133, discriminator_loss=0.22234410047531128\n",
            "step 1642: generator_loss=2.07822847366333, discriminator_loss=0.2231045663356781\n",
            "step 1643: generator_loss=2.268886089324951, discriminator_loss=0.19021175801753998\n",
            "step 1644: generator_loss=2.462406635284424, discriminator_loss=0.18606042861938477\n",
            "step 1645: generator_loss=2.3055520057678223, discriminator_loss=0.21910633146762848\n",
            "step 1646: generator_loss=2.383439540863037, discriminator_loss=0.20865964889526367\n",
            "step 1647: generator_loss=2.0947160720825195, discriminator_loss=0.22065919637680054\n",
            "step 1648: generator_loss=2.000633955001831, discriminator_loss=0.23549993336200714\n",
            "step 1649: generator_loss=2.0889081954956055, discriminator_loss=0.21325595676898956\n",
            "step 1650: generator_loss=2.02091646194458, discriminator_loss=0.20989903807640076\n",
            "step 1651: generator_loss=2.210489273071289, discriminator_loss=0.17795857787132263\n",
            "step 1652: generator_loss=2.262484550476074, discriminator_loss=0.17978516221046448\n",
            "step 1653: generator_loss=2.452089309692383, discriminator_loss=0.15273457765579224\n",
            "step 1654: generator_loss=2.7250022888183594, discriminator_loss=0.14489370584487915\n",
            "step 1655: generator_loss=2.6439762115478516, discriminator_loss=0.13614633679389954\n",
            "step 1656: generator_loss=2.738262891769409, discriminator_loss=0.13768252730369568\n",
            "step 1657: generator_loss=2.7474708557128906, discriminator_loss=0.11457379162311554\n",
            "step 1658: generator_loss=2.6698365211486816, discriminator_loss=0.10244723409414291\n",
            "step 1659: generator_loss=2.580869197845459, discriminator_loss=0.12342393398284912\n",
            "step 1660: generator_loss=2.5858492851257324, discriminator_loss=0.0902288407087326\n",
            "step 1661: generator_loss=2.6165857315063477, discriminator_loss=0.11065925657749176\n",
            "step 1662: generator_loss=2.7760910987854004, discriminator_loss=0.09996703267097473\n",
            "step 1663: generator_loss=2.5253612995147705, discriminator_loss=0.12851083278656006\n",
            "step 1664: generator_loss=2.6138384342193604, discriminator_loss=0.10843189805746078\n",
            "step 1665: generator_loss=2.6253418922424316, discriminator_loss=0.09806185960769653\n",
            "step 1666: generator_loss=2.615671157836914, discriminator_loss=0.11597171425819397\n",
            "step 1667: generator_loss=2.4510650634765625, discriminator_loss=0.13597789406776428\n",
            "step 1668: generator_loss=2.5690391063690186, discriminator_loss=0.1239112839102745\n",
            "step 1669: generator_loss=2.491152048110962, discriminator_loss=0.13726398348808289\n",
            "step 1670: generator_loss=2.4608664512634277, discriminator_loss=0.15226176381111145\n",
            "step 1671: generator_loss=2.5024213790893555, discriminator_loss=0.14521481096744537\n",
            "step 1672: generator_loss=2.340911388397217, discriminator_loss=0.15835422277450562\n",
            "step 1673: generator_loss=2.34274959564209, discriminator_loss=0.14732897281646729\n",
            "step 1674: generator_loss=2.25858211517334, discriminator_loss=0.16995996236801147\n",
            "step 1675: generator_loss=2.270266056060791, discriminator_loss=0.18663805723190308\n",
            "step 1676: generator_loss=2.3458216190338135, discriminator_loss=0.18554306030273438\n",
            "step 1677: generator_loss=2.354515552520752, discriminator_loss=0.15706831216812134\n",
            "step 1678: generator_loss=2.1533546447753906, discriminator_loss=0.16750547289848328\n",
            "step 1679: generator_loss=2.1739871501922607, discriminator_loss=0.1656782329082489\n",
            "step 1680: generator_loss=2.3070764541625977, discriminator_loss=0.1832091063261032\n",
            "step 1681: generator_loss=2.279388904571533, discriminator_loss=0.17556843161582947\n",
            "step 1682: generator_loss=2.3437399864196777, discriminator_loss=0.1634678989648819\n",
            "step 1683: generator_loss=2.1901206970214844, discriminator_loss=0.1727842390537262\n",
            "step 1684: generator_loss=2.0802526473999023, discriminator_loss=0.17682936787605286\n",
            "step 1685: generator_loss=2.0623044967651367, discriminator_loss=0.16123338043689728\n",
            "step 1686: generator_loss=2.0831453800201416, discriminator_loss=0.169826939702034\n",
            "step 1687: generator_loss=2.1024484634399414, discriminator_loss=0.1910768747329712\n",
            "step 1688: generator_loss=2.2456159591674805, discriminator_loss=0.17585617303848267\n",
            "step 1689: generator_loss=2.3508553504943848, discriminator_loss=0.14165811240673065\n",
            "step 1690: generator_loss=2.3097245693206787, discriminator_loss=0.16536977887153625\n",
            "step 1691: generator_loss=2.3037328720092773, discriminator_loss=0.13089503347873688\n",
            "step 1692: generator_loss=2.257068395614624, discriminator_loss=0.13147477805614471\n",
            "step 1693: generator_loss=2.294477939605713, discriminator_loss=0.15183687210083008\n",
            "step 1694: generator_loss=2.2920496463775635, discriminator_loss=0.15445074439048767\n",
            "step 1695: generator_loss=2.218442440032959, discriminator_loss=0.14409957826137543\n",
            "step 1696: generator_loss=2.234292507171631, discriminator_loss=0.15557454526424408\n",
            "step 1697: generator_loss=2.1982479095458984, discriminator_loss=0.17414522171020508\n",
            "step 1698: generator_loss=2.2902793884277344, discriminator_loss=0.14083783328533173\n",
            "step 1699: generator_loss=2.2909908294677734, discriminator_loss=0.14467306435108185\n",
            "step 1700: generator_loss=2.278839588165283, discriminator_loss=0.17026889324188232\n",
            "step 1701: generator_loss=2.154834508895874, discriminator_loss=0.18266664445400238\n",
            "step 1702: generator_loss=2.146993398666382, discriminator_loss=0.19465407729148865\n",
            "step 1703: generator_loss=2.2116174697875977, discriminator_loss=0.16576462984085083\n",
            "step 1704: generator_loss=2.119739532470703, discriminator_loss=0.17836850881576538\n",
            "step 1705: generator_loss=2.210148811340332, discriminator_loss=0.19083866477012634\n",
            "step 1706: generator_loss=2.195828914642334, discriminator_loss=0.19188052415847778\n",
            "step 1707: generator_loss=2.3104021549224854, discriminator_loss=0.17841416597366333\n",
            "step 1708: generator_loss=2.384965658187866, discriminator_loss=0.17712616920471191\n",
            "step 1709: generator_loss=2.3396730422973633, discriminator_loss=0.16955329477787018\n",
            "step 1710: generator_loss=2.2350220680236816, discriminator_loss=0.18326252698898315\n",
            "step 1711: generator_loss=2.3174657821655273, discriminator_loss=0.17771506309509277\n",
            "step 1712: generator_loss=2.3482699394226074, discriminator_loss=0.15072891116142273\n",
            "step 1713: generator_loss=2.4949941635131836, discriminator_loss=0.1538579761981964\n",
            "step 1714: generator_loss=2.228745460510254, discriminator_loss=0.17546258866786957\n",
            "step 1715: generator_loss=2.301440715789795, discriminator_loss=0.16083979606628418\n",
            "step 1716: generator_loss=2.307067394256592, discriminator_loss=0.15032070875167847\n",
            "step 1717: generator_loss=2.322324275970459, discriminator_loss=0.16403482854366302\n",
            "step 1718: generator_loss=2.3673150539398193, discriminator_loss=0.14555658400058746\n",
            "step 1719: generator_loss=2.4341917037963867, discriminator_loss=0.17279741168022156\n",
            "step 1720: generator_loss=2.3933210372924805, discriminator_loss=0.16308216750621796\n",
            "step 1721: generator_loss=2.4291296005249023, discriminator_loss=0.11306814104318619\n",
            "step 1722: generator_loss=2.505692481994629, discriminator_loss=0.11999425292015076\n",
            "step 1723: generator_loss=2.5271365642547607, discriminator_loss=0.1088445708155632\n",
            "step 1724: generator_loss=2.789463520050049, discriminator_loss=0.1024995893239975\n",
            "step 1725: generator_loss=2.716329336166382, discriminator_loss=0.09625978022813797\n",
            "step 1726: generator_loss=2.7415614128112793, discriminator_loss=0.0989147424697876\n",
            "step 1727: generator_loss=2.6874990463256836, discriminator_loss=0.11829820275306702\n",
            "step 1728: generator_loss=2.586963176727295, discriminator_loss=0.10074050724506378\n",
            "step 1729: generator_loss=2.6708333492279053, discriminator_loss=0.10825303196907043\n",
            "step 1730: generator_loss=2.6948983669281006, discriminator_loss=0.1098068505525589\n",
            "step 1731: generator_loss=2.559189796447754, discriminator_loss=0.0961967408657074\n",
            "step 1732: generator_loss=2.5923328399658203, discriminator_loss=0.11060468852519989\n",
            "step 1733: generator_loss=2.5565309524536133, discriminator_loss=0.10207156836986542\n",
            "step 1734: generator_loss=2.428493022918701, discriminator_loss=0.11402086168527603\n",
            "step 1735: generator_loss=2.525688409805298, discriminator_loss=0.10043357312679291\n",
            "step 1736: generator_loss=2.5168824195861816, discriminator_loss=0.11721202731132507\n",
            "step 1737: generator_loss=2.532046318054199, discriminator_loss=0.10908669233322144\n",
            "step 1738: generator_loss=2.4030282497406006, discriminator_loss=0.1287153959274292\n",
            "step 1739: generator_loss=2.393479347229004, discriminator_loss=0.14029890298843384\n",
            "step 1740: generator_loss=2.371701717376709, discriminator_loss=0.16115278005599976\n",
            "step 1741: generator_loss=2.2221171855926514, discriminator_loss=0.14886294305324554\n",
            "step 1742: generator_loss=2.127584934234619, discriminator_loss=0.13949118554592133\n",
            "step 1743: generator_loss=2.168374538421631, discriminator_loss=0.1677960753440857\n",
            "step 1744: generator_loss=2.4784774780273438, discriminator_loss=0.1331704705953598\n",
            "step 1745: generator_loss=2.2442941665649414, discriminator_loss=0.16085612773895264\n",
            "step 1746: generator_loss=2.178840160369873, discriminator_loss=0.1561603546142578\n",
            "step 1747: generator_loss=2.104628801345825, discriminator_loss=0.21668961644172668\n",
            "step 1748: generator_loss=2.0569186210632324, discriminator_loss=0.19597935676574707\n",
            "step 1749: generator_loss=2.188223361968994, discriminator_loss=0.24211549758911133\n",
            "step 1750: generator_loss=2.1360549926757812, discriminator_loss=0.20076340436935425\n",
            "step 1751: generator_loss=2.283903121948242, discriminator_loss=0.24117878079414368\n",
            "step 1752: generator_loss=2.3529036045074463, discriminator_loss=0.25019168853759766\n",
            "step 1753: generator_loss=2.200758934020996, discriminator_loss=0.2838220000267029\n",
            "step 1754: generator_loss=2.320967197418213, discriminator_loss=0.2598792612552643\n",
            "step 1755: generator_loss=2.2094576358795166, discriminator_loss=0.2801389992237091\n",
            "step 1756: generator_loss=2.4578847885131836, discriminator_loss=0.23925182223320007\n",
            "step 1757: generator_loss=2.1862142086029053, discriminator_loss=0.2696824371814728\n",
            "step 1758: generator_loss=2.4630048274993896, discriminator_loss=0.2400396317243576\n",
            "step 1759: generator_loss=2.4735851287841797, discriminator_loss=0.21102255582809448\n",
            "step 1760: generator_loss=2.661106586456299, discriminator_loss=0.2028098851442337\n",
            "step 1761: generator_loss=2.756948947906494, discriminator_loss=0.18695631623268127\n",
            "step 1762: generator_loss=2.7705516815185547, discriminator_loss=0.17631679773330688\n",
            "step 1763: generator_loss=2.722790002822876, discriminator_loss=0.1689738631248474\n",
            "step 1764: generator_loss=2.53761887550354, discriminator_loss=0.1941131204366684\n",
            "step 1765: generator_loss=2.651205539703369, discriminator_loss=0.14171680808067322\n",
            "step 1766: generator_loss=2.554837942123413, discriminator_loss=0.14291296899318695\n",
            "step 1767: generator_loss=2.3945107460021973, discriminator_loss=0.1434182971715927\n",
            "step 1768: generator_loss=2.4581480026245117, discriminator_loss=0.14625957608222961\n",
            "step 1769: generator_loss=2.552337646484375, discriminator_loss=0.12078667432069778\n",
            "step 1770: generator_loss=2.4423179626464844, discriminator_loss=0.13627733290195465\n",
            "step 1771: generator_loss=2.6605234146118164, discriminator_loss=0.14074164628982544\n",
            "step 1772: generator_loss=2.8187475204467773, discriminator_loss=0.1485065221786499\n",
            "step 1773: generator_loss=2.500094413757324, discriminator_loss=0.18449652194976807\n",
            "step 1774: generator_loss=2.6668314933776855, discriminator_loss=0.16879548132419586\n",
            "step 1775: generator_loss=2.74147891998291, discriminator_loss=0.14474520087242126\n",
            "step 1776: generator_loss=2.893922805786133, discriminator_loss=0.1429099291563034\n",
            "step 1777: generator_loss=2.680001735687256, discriminator_loss=0.20107367634773254\n",
            "step 1778: generator_loss=2.6064295768737793, discriminator_loss=0.20579499006271362\n",
            "step 1779: generator_loss=2.5385148525238037, discriminator_loss=0.21431685984134674\n",
            "step 1780: generator_loss=2.303645610809326, discriminator_loss=0.3065475523471832\n",
            "step 1781: generator_loss=2.467405319213867, discriminator_loss=0.30150318145751953\n",
            "step 1782: generator_loss=2.5400900840759277, discriminator_loss=0.2780921757221222\n",
            "step 1783: generator_loss=2.3673253059387207, discriminator_loss=0.3206767439842224\n",
            "step 1784: generator_loss=2.4987967014312744, discriminator_loss=0.30935829877853394\n",
            "step 1785: generator_loss=2.62283992767334, discriminator_loss=0.36937111616134644\n",
            "step 1786: generator_loss=3.046757698059082, discriminator_loss=0.29349464178085327\n",
            "step 1787: generator_loss=3.071528434753418, discriminator_loss=0.279083788394928\n",
            "step 1788: generator_loss=3.0562551021575928, discriminator_loss=0.2749481797218323\n",
            "step 1789: generator_loss=3.029308319091797, discriminator_loss=0.22756385803222656\n",
            "step 1790: generator_loss=2.757812023162842, discriminator_loss=0.3778790831565857\n",
            "step 1791: generator_loss=2.6910769939422607, discriminator_loss=0.32955923676490784\n",
            "step 1792: generator_loss=2.811565399169922, discriminator_loss=0.3251846432685852\n",
            "step 1793: generator_loss=2.6713833808898926, discriminator_loss=0.2836482524871826\n",
            "step 1794: generator_loss=3.0019447803497314, discriminator_loss=0.24384623765945435\n",
            "step 1795: generator_loss=2.7372853755950928, discriminator_loss=0.2897096276283264\n",
            "step 1796: generator_loss=2.8209738731384277, discriminator_loss=0.21863143146038055\n",
            "step 1797: generator_loss=2.8399338722229004, discriminator_loss=0.24597182869911194\n",
            "step 1798: generator_loss=3.306702136993408, discriminator_loss=0.18487614393234253\n",
            "step 1799: generator_loss=2.7420663833618164, discriminator_loss=0.2176194190979004\n",
            "step 1800: generator_loss=2.781921863555908, discriminator_loss=0.17791175842285156\n",
            "step 1801: generator_loss=2.65946626663208, discriminator_loss=0.17674826085567474\n",
            "step 1802: generator_loss=2.7269058227539062, discriminator_loss=0.17699530720710754\n",
            "step 1803: generator_loss=3.0322341918945312, discriminator_loss=0.15007925033569336\n",
            "step 1804: generator_loss=2.866516351699829, discriminator_loss=0.14060701429843903\n",
            "step 1805: generator_loss=3.202848434448242, discriminator_loss=0.11561410129070282\n",
            "step 1806: generator_loss=3.182615280151367, discriminator_loss=0.12233534455299377\n",
            "step 1807: generator_loss=3.2490792274475098, discriminator_loss=0.11311496794223785\n",
            "step 1808: generator_loss=2.9959378242492676, discriminator_loss=0.12200985103845596\n",
            "step 1809: generator_loss=3.0252737998962402, discriminator_loss=0.1354970932006836\n",
            "step 1810: generator_loss=2.938140392303467, discriminator_loss=0.11576858907938004\n",
            "step 1811: generator_loss=2.996748208999634, discriminator_loss=0.1289602667093277\n",
            "step 1812: generator_loss=2.899177074432373, discriminator_loss=0.12224512547254562\n",
            "step 1813: generator_loss=2.7858223915100098, discriminator_loss=0.13279421627521515\n",
            "step 1814: generator_loss=2.710237503051758, discriminator_loss=0.13849025964736938\n",
            "step 1815: generator_loss=2.7569756507873535, discriminator_loss=0.15618786215782166\n",
            "step 1816: generator_loss=2.7979302406311035, discriminator_loss=0.14461329579353333\n",
            "step 1817: generator_loss=3.055026054382324, discriminator_loss=0.11988034844398499\n",
            "step 1818: generator_loss=2.6617183685302734, discriminator_loss=0.14057782292366028\n",
            "step 1819: generator_loss=2.364534616470337, discriminator_loss=0.16082970798015594\n",
            "step 1820: generator_loss=2.3852951526641846, discriminator_loss=0.18844273686408997\n",
            "step 1821: generator_loss=2.282212734222412, discriminator_loss=0.1670656055212021\n",
            "step 1822: generator_loss=2.426189422607422, discriminator_loss=0.15307849645614624\n",
            "step 1823: generator_loss=2.423079013824463, discriminator_loss=0.16250059008598328\n",
            "step 1824: generator_loss=2.6236486434936523, discriminator_loss=0.17642325162887573\n",
            "step 1825: generator_loss=2.406510353088379, discriminator_loss=0.16479802131652832\n",
            "step 1826: generator_loss=2.3501691818237305, discriminator_loss=0.17260019481182098\n",
            "step 1827: generator_loss=2.453169107437134, discriminator_loss=0.18185079097747803\n",
            "step 1828: generator_loss=2.254744291305542, discriminator_loss=0.16270571947097778\n",
            "step 1829: generator_loss=2.1598310470581055, discriminator_loss=0.1985822319984436\n",
            "step 1830: generator_loss=2.2487542629241943, discriminator_loss=0.16573016345500946\n",
            "step 1831: generator_loss=2.1952059268951416, discriminator_loss=0.16259057819843292\n",
            "step 1832: generator_loss=2.094913959503174, discriminator_loss=0.18814897537231445\n",
            "step 1833: generator_loss=2.0719146728515625, discriminator_loss=0.17901214957237244\n",
            "step 1834: generator_loss=2.190248489379883, discriminator_loss=0.17349091172218323\n",
            "step 1835: generator_loss=2.253608226776123, discriminator_loss=0.16976241767406464\n",
            "step 1836: generator_loss=2.2589364051818848, discriminator_loss=0.21324259042739868\n",
            "step 1837: generator_loss=2.235436201095581, discriminator_loss=0.17547836899757385\n",
            "step 1838: generator_loss=2.232524871826172, discriminator_loss=0.173972025513649\n",
            "step 1839: generator_loss=2.2116591930389404, discriminator_loss=0.16400712728500366\n",
            "step 1840: generator_loss=2.1935601234436035, discriminator_loss=0.18700426816940308\n",
            "step 1841: generator_loss=2.096667766571045, discriminator_loss=0.13983693718910217\n",
            "step 1842: generator_loss=2.0446949005126953, discriminator_loss=0.15351258218288422\n",
            "step 1843: generator_loss=2.0743868350982666, discriminator_loss=0.14098197221755981\n",
            "step 1844: generator_loss=2.18493914604187, discriminator_loss=0.14854954183101654\n",
            "step 1845: generator_loss=2.257452964782715, discriminator_loss=0.1268741488456726\n",
            "step 1846: generator_loss=2.2457175254821777, discriminator_loss=0.1366785764694214\n",
            "step 1847: generator_loss=2.309704303741455, discriminator_loss=0.14422456920146942\n",
            "step 1848: generator_loss=2.302330493927002, discriminator_loss=0.1542935073375702\n",
            "step 1849: generator_loss=2.283039093017578, discriminator_loss=0.15630242228507996\n",
            "step 1850: generator_loss=2.2332968711853027, discriminator_loss=0.16992442309856415\n",
            "step 1851: generator_loss=2.2043609619140625, discriminator_loss=0.17506557703018188\n",
            "step 1852: generator_loss=2.1660983562469482, discriminator_loss=0.18232306838035583\n",
            "step 1853: generator_loss=2.065511703491211, discriminator_loss=0.1567428708076477\n",
            "step 1854: generator_loss=2.0285608768463135, discriminator_loss=0.16767549514770508\n",
            "step 1855: generator_loss=1.9881396293640137, discriminator_loss=0.15475302934646606\n",
            "step 1856: generator_loss=2.150954246520996, discriminator_loss=0.15297859907150269\n",
            "step 1857: generator_loss=2.1737895011901855, discriminator_loss=0.1876550018787384\n",
            "step 1858: generator_loss=2.2799160480499268, discriminator_loss=0.15369459986686707\n",
            "step 1859: generator_loss=2.15939998626709, discriminator_loss=0.1578148752450943\n",
            "step 1860: generator_loss=2.2503936290740967, discriminator_loss=0.15212790668010712\n",
            "step 1861: generator_loss=2.215979814529419, discriminator_loss=0.1449870616197586\n",
            "step 1862: generator_loss=2.179290294647217, discriminator_loss=0.1576530635356903\n",
            "step 1863: generator_loss=2.067192554473877, discriminator_loss=0.14993727207183838\n",
            "step 1864: generator_loss=2.1177687644958496, discriminator_loss=0.14644521474838257\n",
            "step 1865: generator_loss=2.123000144958496, discriminator_loss=0.15032757818698883\n",
            "step 1866: generator_loss=2.228365898132324, discriminator_loss=0.1567101925611496\n",
            "step 1867: generator_loss=2.2192492485046387, discriminator_loss=0.1546054184436798\n",
            "step 1868: generator_loss=2.3027727603912354, discriminator_loss=0.19751498103141785\n",
            "step 1869: generator_loss=2.264059543609619, discriminator_loss=0.181290403008461\n",
            "step 1870: generator_loss=2.3195648193359375, discriminator_loss=0.17072774469852448\n",
            "step 1871: generator_loss=2.217175006866455, discriminator_loss=0.19404815137386322\n",
            "step 1872: generator_loss=2.2953076362609863, discriminator_loss=0.24944038689136505\n",
            "step 1873: generator_loss=2.4637317657470703, discriminator_loss=0.1917530596256256\n",
            "step 1874: generator_loss=2.1566500663757324, discriminator_loss=0.2778898775577545\n",
            "step 1875: generator_loss=2.487860679626465, discriminator_loss=0.2432558387517929\n",
            "step 1876: generator_loss=2.3314168453216553, discriminator_loss=0.35858353972435\n",
            "step 1877: generator_loss=2.42897367477417, discriminator_loss=0.3370024561882019\n",
            "step 1878: generator_loss=2.42421817779541, discriminator_loss=0.3509048819541931\n",
            "step 1879: generator_loss=2.2629218101501465, discriminator_loss=0.4169437885284424\n",
            "step 1880: generator_loss=2.3655967712402344, discriminator_loss=0.3655977249145508\n",
            "step 1881: generator_loss=2.1448473930358887, discriminator_loss=0.36579465866088867\n",
            "step 1882: generator_loss=2.239589214324951, discriminator_loss=0.3780273497104645\n",
            "step 1883: generator_loss=2.12504243850708, discriminator_loss=0.368124395608902\n",
            "step 1884: generator_loss=2.2918124198913574, discriminator_loss=0.39021432399749756\n",
            "step 1885: generator_loss=2.3748764991760254, discriminator_loss=0.4095056653022766\n",
            "step 1886: generator_loss=2.7139666080474854, discriminator_loss=0.34146225452423096\n",
            "step 1887: generator_loss=2.7095415592193604, discriminator_loss=0.3622843325138092\n",
            "step 1888: generator_loss=2.9204046726226807, discriminator_loss=0.27705705165863037\n",
            "step 1889: generator_loss=2.673454761505127, discriminator_loss=0.22803376615047455\n",
            "step 1890: generator_loss=2.467075824737549, discriminator_loss=0.22055919468402863\n",
            "step 1891: generator_loss=2.2743282318115234, discriminator_loss=0.1951526701450348\n",
            "step 1892: generator_loss=2.3796820640563965, discriminator_loss=0.16343247890472412\n",
            "step 1893: generator_loss=2.319810152053833, discriminator_loss=0.17702820897102356\n",
            "step 1894: generator_loss=2.318450927734375, discriminator_loss=0.15575310587882996\n",
            "step 1895: generator_loss=2.2226827144622803, discriminator_loss=0.1609836220741272\n",
            "step 1896: generator_loss=2.1199469566345215, discriminator_loss=0.17882110178470612\n",
            "step 1897: generator_loss=2.5633859634399414, discriminator_loss=0.15621723234653473\n",
            "step 1898: generator_loss=2.57597017288208, discriminator_loss=0.16560882329940796\n",
            "step 1899: generator_loss=2.6947617530822754, discriminator_loss=0.1803189069032669\n",
            "step 1900: generator_loss=2.4525837898254395, discriminator_loss=0.2146356999874115\n",
            "step 1901: generator_loss=2.5776710510253906, discriminator_loss=0.18689492344856262\n",
            "step 1902: generator_loss=2.2711498737335205, discriminator_loss=0.2041493058204651\n",
            "step 1903: generator_loss=2.1403608322143555, discriminator_loss=0.20735156536102295\n",
            "step 1904: generator_loss=1.917621374130249, discriminator_loss=0.24031898379325867\n",
            "step 1905: generator_loss=1.9484163522720337, discriminator_loss=0.2302924394607544\n",
            "step 1906: generator_loss=1.8585785627365112, discriminator_loss=0.24356576800346375\n",
            "step 1907: generator_loss=2.1645655632019043, discriminator_loss=0.24172724783420563\n",
            "step 1908: generator_loss=2.1116676330566406, discriminator_loss=0.24127478897571564\n",
            "step 1909: generator_loss=2.012448787689209, discriminator_loss=0.28700512647628784\n",
            "step 1910: generator_loss=2.281961441040039, discriminator_loss=0.2806161046028137\n",
            "step 1911: generator_loss=2.2909493446350098, discriminator_loss=0.29812464118003845\n",
            "step 1912: generator_loss=2.025692939758301, discriminator_loss=0.3200989365577698\n",
            "step 1913: generator_loss=1.9896059036254883, discriminator_loss=0.3038698434829712\n",
            "step 1914: generator_loss=1.9670687913894653, discriminator_loss=0.32939526438713074\n",
            "step 1915: generator_loss=2.0869250297546387, discriminator_loss=0.28849512338638306\n",
            "step 1916: generator_loss=2.1042118072509766, discriminator_loss=0.2967510223388672\n",
            "step 1917: generator_loss=2.009396553039551, discriminator_loss=0.3338169455528259\n",
            "step 1918: generator_loss=2.1592862606048584, discriminator_loss=0.2896798253059387\n",
            "step 1919: generator_loss=2.0753259658813477, discriminator_loss=0.3000869154930115\n",
            "step 1920: generator_loss=2.1961052417755127, discriminator_loss=0.30410754680633545\n",
            "step 1921: generator_loss=2.24326753616333, discriminator_loss=0.30012738704681396\n",
            "step 1922: generator_loss=2.0167770385742188, discriminator_loss=0.2947414815425873\n",
            "step 1923: generator_loss=2.3335251808166504, discriminator_loss=0.29854458570480347\n",
            "step 1924: generator_loss=2.4441585540771484, discriminator_loss=0.29294073581695557\n",
            "step 1925: generator_loss=2.390240430831909, discriminator_loss=0.2430170625448227\n",
            "step 1926: generator_loss=2.382758140563965, discriminator_loss=0.2584007978439331\n",
            "step 1927: generator_loss=2.7440309524536133, discriminator_loss=0.2325730323791504\n",
            "step 1928: generator_loss=2.4618148803710938, discriminator_loss=0.26054543256759644\n",
            "step 1929: generator_loss=2.8440470695495605, discriminator_loss=0.23654904961585999\n",
            "step 1930: generator_loss=2.6786813735961914, discriminator_loss=0.22411218285560608\n",
            "step 1931: generator_loss=2.6411845684051514, discriminator_loss=0.26020383834838867\n",
            "step 1932: generator_loss=2.3382205963134766, discriminator_loss=0.24692384898662567\n",
            "step 1933: generator_loss=2.4954824447631836, discriminator_loss=0.265321284532547\n",
            "step 1934: generator_loss=2.524484634399414, discriminator_loss=0.23931537568569183\n",
            "step 1935: generator_loss=2.6363167762756348, discriminator_loss=0.1917867362499237\n",
            "step 1936: generator_loss=2.7137744426727295, discriminator_loss=0.1975279152393341\n",
            "step 1937: generator_loss=2.6652140617370605, discriminator_loss=0.18274465203285217\n",
            "step 1938: generator_loss=2.5968544483184814, discriminator_loss=0.19355955719947815\n",
            "step 1939: generator_loss=2.9894886016845703, discriminator_loss=0.15503853559494019\n",
            "step 1940: generator_loss=2.7302565574645996, discriminator_loss=0.18024392426013947\n",
            "step 1941: generator_loss=3.12905216217041, discriminator_loss=0.14752885699272156\n",
            "step 1942: generator_loss=2.882533550262451, discriminator_loss=0.14818662405014038\n",
            "step 1943: generator_loss=3.170229434967041, discriminator_loss=0.12000185996294022\n",
            "step 1944: generator_loss=2.8886263370513916, discriminator_loss=0.15098297595977783\n",
            "step 1945: generator_loss=2.700134754180908, discriminator_loss=0.1262238472700119\n",
            "step 1946: generator_loss=2.649339199066162, discriminator_loss=0.1268244832754135\n",
            "step 1947: generator_loss=2.335989236831665, discriminator_loss=0.15048059821128845\n",
            "step 1948: generator_loss=2.555668830871582, discriminator_loss=0.1386982500553131\n",
            "step 1949: generator_loss=2.6746373176574707, discriminator_loss=0.1660226285457611\n",
            "step 1950: generator_loss=2.6230974197387695, discriminator_loss=0.14942531287670135\n",
            "step 1951: generator_loss=2.788511276245117, discriminator_loss=0.15812282264232635\n",
            "step 1952: generator_loss=2.630317449569702, discriminator_loss=0.14511626958847046\n",
            "step 1953: generator_loss=2.660041332244873, discriminator_loss=0.15553495287895203\n",
            "step 1954: generator_loss=2.6072592735290527, discriminator_loss=0.17645932734012604\n",
            "step 1955: generator_loss=2.5824482440948486, discriminator_loss=0.1768893152475357\n",
            "step 1956: generator_loss=2.4539847373962402, discriminator_loss=0.1565757691860199\n",
            "step 1957: generator_loss=2.38815975189209, discriminator_loss=0.165836900472641\n",
            "step 1958: generator_loss=2.27911376953125, discriminator_loss=0.171888530254364\n",
            "step 1959: generator_loss=2.0516104698181152, discriminator_loss=0.2049277275800705\n",
            "step 1960: generator_loss=2.1673834323883057, discriminator_loss=0.16410863399505615\n",
            "step 1961: generator_loss=2.324225902557373, discriminator_loss=0.1611834168434143\n",
            "step 1962: generator_loss=2.348806381225586, discriminator_loss=0.13055595755577087\n",
            "step 1963: generator_loss=2.595916271209717, discriminator_loss=0.1428593099117279\n",
            "step 1964: generator_loss=2.636651039123535, discriminator_loss=0.1579159051179886\n",
            "step 1965: generator_loss=2.6501283645629883, discriminator_loss=0.12669561803340912\n",
            "step 1966: generator_loss=2.8020365238189697, discriminator_loss=0.1498270332813263\n",
            "step 1967: generator_loss=2.653639316558838, discriminator_loss=0.12982146441936493\n",
            "step 1968: generator_loss=2.508268356323242, discriminator_loss=0.12704426050186157\n",
            "step 1969: generator_loss=2.4083945751190186, discriminator_loss=0.16853970289230347\n",
            "step 1970: generator_loss=2.6054422855377197, discriminator_loss=0.13951213657855988\n",
            "step 1971: generator_loss=2.4724600315093994, discriminator_loss=0.15718135237693787\n",
            "step 1972: generator_loss=2.776158332824707, discriminator_loss=0.13514584302902222\n",
            "step 1973: generator_loss=2.815535068511963, discriminator_loss=0.16086170077323914\n",
            "step 1974: generator_loss=2.757488250732422, discriminator_loss=0.15887723863124847\n",
            "step 1975: generator_loss=2.601977825164795, discriminator_loss=0.1533113420009613\n",
            "step 1976: generator_loss=2.794865608215332, discriminator_loss=0.19160759449005127\n",
            "step 1977: generator_loss=2.6512210369110107, discriminator_loss=0.21237725019454956\n",
            "step 1978: generator_loss=2.7959001064300537, discriminator_loss=0.20195798575878143\n",
            "step 1979: generator_loss=2.734851360321045, discriminator_loss=0.18989317119121552\n",
            "step 1980: generator_loss=2.7390079498291016, discriminator_loss=0.18615823984146118\n",
            "step 1981: generator_loss=2.7347464561462402, discriminator_loss=0.2062835842370987\n",
            "step 1982: generator_loss=2.5567617416381836, discriminator_loss=0.2057921588420868\n",
            "step 1983: generator_loss=2.50705623626709, discriminator_loss=0.2113317847251892\n",
            "step 1984: generator_loss=2.4976134300231934, discriminator_loss=0.1867837905883789\n",
            "step 1985: generator_loss=2.5722036361694336, discriminator_loss=0.1843402087688446\n",
            "step 1986: generator_loss=2.5976035594940186, discriminator_loss=0.1875041425228119\n",
            "step 1987: generator_loss=2.7081055641174316, discriminator_loss=0.14518922567367554\n",
            "step 1988: generator_loss=3.143341064453125, discriminator_loss=0.13708524405956268\n",
            "step 1989: generator_loss=2.9164586067199707, discriminator_loss=0.16284042596817017\n",
            "step 1990: generator_loss=2.767875909805298, discriminator_loss=0.1644485741853714\n",
            "step 1991: generator_loss=2.751023292541504, discriminator_loss=0.16199204325675964\n",
            "step 1992: generator_loss=2.681318998336792, discriminator_loss=0.16112112998962402\n",
            "step 1993: generator_loss=2.284173011779785, discriminator_loss=0.18791863322257996\n",
            "step 1994: generator_loss=2.316892147064209, discriminator_loss=0.17007628083229065\n",
            "step 1995: generator_loss=2.2482810020446777, discriminator_loss=0.19075003266334534\n",
            "step 1996: generator_loss=2.1966805458068848, discriminator_loss=0.1833375096321106\n",
            "step 1997: generator_loss=2.2414467334747314, discriminator_loss=0.1956876814365387\n",
            "step 1998: generator_loss=2.3250622749328613, discriminator_loss=0.17277753353118896\n",
            "step 1999: generator_loss=2.617600440979004, discriminator_loss=0.1656038761138916\n",
            "step 2000: generator_loss=2.4214324951171875, discriminator_loss=0.19472157955169678\n",
            "step 2001: generator_loss=2.31791615486145, discriminator_loss=0.1690065562725067\n",
            "step 2002: generator_loss=2.5334506034851074, discriminator_loss=0.16903726756572723\n",
            "step 2003: generator_loss=2.400836944580078, discriminator_loss=0.1778176724910736\n",
            "step 2004: generator_loss=2.5754952430725098, discriminator_loss=0.18509075045585632\n",
            "step 2005: generator_loss=2.33526611328125, discriminator_loss=0.20500248670578003\n",
            "step 2006: generator_loss=2.337106227874756, discriminator_loss=0.21074585616588593\n",
            "step 2007: generator_loss=2.29600191116333, discriminator_loss=0.2284056544303894\n",
            "step 2008: generator_loss=2.526110887527466, discriminator_loss=0.22845572233200073\n",
            "step 2009: generator_loss=2.6421656608581543, discriminator_loss=0.23450370132923126\n",
            "step 2010: generator_loss=2.864182472229004, discriminator_loss=0.2038993239402771\n",
            "step 2011: generator_loss=2.926788568496704, discriminator_loss=0.1752985715866089\n",
            "step 2012: generator_loss=2.737483501434326, discriminator_loss=0.1942998766899109\n",
            "step 2013: generator_loss=2.8364782333374023, discriminator_loss=0.18757572770118713\n",
            "step 2014: generator_loss=2.914654493331909, discriminator_loss=0.20419389009475708\n",
            "step 2015: generator_loss=2.809572458267212, discriminator_loss=0.20737650990486145\n",
            "step 2016: generator_loss=2.6003170013427734, discriminator_loss=0.17181715369224548\n",
            "step 2017: generator_loss=2.4847159385681152, discriminator_loss=0.1665109395980835\n",
            "step 2018: generator_loss=2.3977017402648926, discriminator_loss=0.19365057349205017\n",
            "step 2019: generator_loss=2.313973903656006, discriminator_loss=0.15116149187088013\n",
            "step 2020: generator_loss=2.3278346061706543, discriminator_loss=0.17693832516670227\n",
            "step 2021: generator_loss=2.534323215484619, discriminator_loss=0.17612788081169128\n",
            "step 2022: generator_loss=2.524608612060547, discriminator_loss=0.17088592052459717\n",
            "step 2023: generator_loss=2.4885358810424805, discriminator_loss=0.16694462299346924\n",
            "step 2024: generator_loss=2.5616064071655273, discriminator_loss=0.15797147154808044\n",
            "step 2025: generator_loss=2.701183795928955, discriminator_loss=0.17731362581253052\n",
            "step 2026: generator_loss=2.780247688293457, discriminator_loss=0.14672747254371643\n",
            "step 2027: generator_loss=2.6256890296936035, discriminator_loss=0.16781750321388245\n",
            "step 2028: generator_loss=2.6915578842163086, discriminator_loss=0.1546771079301834\n",
            "step 2029: generator_loss=2.366486072540283, discriminator_loss=0.1866474747657776\n",
            "step 2030: generator_loss=2.509819269180298, discriminator_loss=0.21270930767059326\n",
            "step 2031: generator_loss=2.1852784156799316, discriminator_loss=0.2104319930076599\n",
            "step 2032: generator_loss=2.2184720039367676, discriminator_loss=0.1889146864414215\n",
            "step 2033: generator_loss=2.2322146892547607, discriminator_loss=0.1918257176876068\n",
            "step 2034: generator_loss=2.1390163898468018, discriminator_loss=0.19694697856903076\n",
            "step 2035: generator_loss=2.158687114715576, discriminator_loss=0.20952385663986206\n",
            "step 2036: generator_loss=2.12927508354187, discriminator_loss=0.20309901237487793\n",
            "step 2037: generator_loss=2.1674113273620605, discriminator_loss=0.18306927382946014\n",
            "step 2038: generator_loss=2.089517116546631, discriminator_loss=0.1944720596075058\n",
            "step 2039: generator_loss=2.085909366607666, discriminator_loss=0.206393301486969\n",
            "step 2040: generator_loss=1.9274985790252686, discriminator_loss=0.2198381870985031\n",
            "step 2041: generator_loss=1.94340980052948, discriminator_loss=0.18422889709472656\n",
            "step 2042: generator_loss=2.0028295516967773, discriminator_loss=0.15474994480609894\n",
            "step 2043: generator_loss=2.1032843589782715, discriminator_loss=0.15910370647907257\n",
            "step 2044: generator_loss=2.2127084732055664, discriminator_loss=0.1617133915424347\n",
            "step 2045: generator_loss=2.260913133621216, discriminator_loss=0.1622898280620575\n",
            "step 2046: generator_loss=2.373316764831543, discriminator_loss=0.17773738503456116\n",
            "step 2047: generator_loss=2.235421657562256, discriminator_loss=0.17166432738304138\n",
            "step 2048: generator_loss=2.264039993286133, discriminator_loss=0.15843035280704498\n",
            "step 2049: generator_loss=2.176666259765625, discriminator_loss=0.16826465725898743\n",
            "step 2050: generator_loss=2.1294920444488525, discriminator_loss=0.17521923780441284\n",
            "step 2051: generator_loss=2.0799269676208496, discriminator_loss=0.19398808479309082\n",
            "step 2052: generator_loss=2.0353903770446777, discriminator_loss=0.18825054168701172\n",
            "step 2053: generator_loss=2.1078312397003174, discriminator_loss=0.17763842642307281\n",
            "step 2054: generator_loss=2.0629749298095703, discriminator_loss=0.17360317707061768\n",
            "step 2055: generator_loss=2.234830856323242, discriminator_loss=0.1620713323354721\n",
            "step 2056: generator_loss=2.174079418182373, discriminator_loss=0.15305227041244507\n",
            "step 2057: generator_loss=2.4032716751098633, discriminator_loss=0.12511688470840454\n",
            "step 2058: generator_loss=2.5008468627929688, discriminator_loss=0.12753288447856903\n",
            "step 2059: generator_loss=2.659717559814453, discriminator_loss=0.1315891444683075\n",
            "step 2060: generator_loss=2.6754088401794434, discriminator_loss=0.14425162971019745\n",
            "step 2061: generator_loss=2.5331063270568848, discriminator_loss=0.17473727464675903\n",
            "step 2062: generator_loss=2.4685025215148926, discriminator_loss=0.16718070209026337\n",
            "step 2063: generator_loss=2.299112319946289, discriminator_loss=0.15830093622207642\n",
            "step 2064: generator_loss=2.1597740650177, discriminator_loss=0.14929798245429993\n",
            "step 2065: generator_loss=2.112943172454834, discriminator_loss=0.17522995173931122\n",
            "step 2066: generator_loss=2.0223069190979004, discriminator_loss=0.16774246096611023\n",
            "step 2067: generator_loss=2.061493158340454, discriminator_loss=0.14713209867477417\n",
            "step 2068: generator_loss=2.255220413208008, discriminator_loss=0.13307389616966248\n",
            "step 2069: generator_loss=2.5054404735565186, discriminator_loss=0.14384737610816956\n",
            "step 2070: generator_loss=2.6880617141723633, discriminator_loss=0.16641566157341003\n",
            "step 2071: generator_loss=2.589926242828369, discriminator_loss=0.1417887806892395\n",
            "step 2072: generator_loss=2.6687421798706055, discriminator_loss=0.13971911370754242\n",
            "step 2073: generator_loss=2.5072312355041504, discriminator_loss=0.1444329023361206\n",
            "step 2074: generator_loss=2.3145699501037598, discriminator_loss=0.18493644893169403\n",
            "step 2075: generator_loss=2.135742664337158, discriminator_loss=0.16553017497062683\n",
            "step 2076: generator_loss=2.1345767974853516, discriminator_loss=0.17739230394363403\n",
            "step 2077: generator_loss=2.2101497650146484, discriminator_loss=0.1763855516910553\n",
            "step 2078: generator_loss=2.1877057552337646, discriminator_loss=0.17951413989067078\n",
            "step 2079: generator_loss=2.2230000495910645, discriminator_loss=0.19919145107269287\n",
            "step 2080: generator_loss=2.3077497482299805, discriminator_loss=0.18645000457763672\n",
            "step 2081: generator_loss=2.168102264404297, discriminator_loss=0.17872345447540283\n",
            "step 2082: generator_loss=2.142331123352051, discriminator_loss=0.20988315343856812\n",
            "step 2083: generator_loss=2.134903907775879, discriminator_loss=0.22765858471393585\n",
            "step 2084: generator_loss=2.075045585632324, discriminator_loss=0.2290118932723999\n",
            "step 2085: generator_loss=1.8752398490905762, discriminator_loss=0.22212693095207214\n",
            "step 2086: generator_loss=1.8660861253738403, discriminator_loss=0.2354186475276947\n",
            "step 2087: generator_loss=1.8127750158309937, discriminator_loss=0.23641186952590942\n",
            "step 2088: generator_loss=1.950388789176941, discriminator_loss=0.21886853873729706\n",
            "step 2089: generator_loss=2.0541577339172363, discriminator_loss=0.24486950039863586\n",
            "step 2090: generator_loss=2.086880683898926, discriminator_loss=0.23588699102401733\n",
            "step 2091: generator_loss=2.162659168243408, discriminator_loss=0.24994441866874695\n",
            "step 2092: generator_loss=2.2392799854278564, discriminator_loss=0.22936025261878967\n",
            "step 2093: generator_loss=2.125476837158203, discriminator_loss=0.25221115350723267\n",
            "step 2094: generator_loss=1.9574276208877563, discriminator_loss=0.24247238039970398\n",
            "step 2095: generator_loss=1.97454833984375, discriminator_loss=0.23179346323013306\n",
            "step 2096: generator_loss=1.9802064895629883, discriminator_loss=0.22418124973773956\n",
            "step 2097: generator_loss=1.9422966241836548, discriminator_loss=0.2362576574087143\n",
            "step 2098: generator_loss=2.255575656890869, discriminator_loss=0.2122756689786911\n",
            "step 2099: generator_loss=2.197052001953125, discriminator_loss=0.239299476146698\n",
            "step 2100: generator_loss=2.696878671646118, discriminator_loss=0.21599507331848145\n",
            "step 2101: generator_loss=2.637531280517578, discriminator_loss=0.20309948921203613\n",
            "step 2102: generator_loss=2.5295679569244385, discriminator_loss=0.21054621040821075\n",
            "step 2103: generator_loss=2.4603376388549805, discriminator_loss=0.24943417310714722\n",
            "step 2104: generator_loss=2.341555118560791, discriminator_loss=0.2429559826850891\n",
            "step 2105: generator_loss=2.5274181365966797, discriminator_loss=0.24043311178684235\n",
            "step 2106: generator_loss=2.6584386825561523, discriminator_loss=0.24642711877822876\n",
            "step 2107: generator_loss=2.3582797050476074, discriminator_loss=0.2929401099681854\n",
            "step 2108: generator_loss=2.3336853981018066, discriminator_loss=0.3451576232910156\n",
            "step 2109: generator_loss=2.507294178009033, discriminator_loss=0.33715033531188965\n",
            "step 2110: generator_loss=2.734801769256592, discriminator_loss=0.3455379009246826\n",
            "step 2111: generator_loss=2.819241523742676, discriminator_loss=0.3449261784553528\n",
            "step 2112: generator_loss=3.1706037521362305, discriminator_loss=0.3452044129371643\n",
            "step 2113: generator_loss=3.209641933441162, discriminator_loss=0.2793394923210144\n",
            "step 2114: generator_loss=2.676997661590576, discriminator_loss=0.2853798270225525\n",
            "step 2115: generator_loss=2.881135940551758, discriminator_loss=0.2739070951938629\n",
            "step 2116: generator_loss=2.634519100189209, discriminator_loss=0.2874353528022766\n",
            "step 2117: generator_loss=2.6798558235168457, discriminator_loss=0.21254408359527588\n",
            "step 2118: generator_loss=2.59926700592041, discriminator_loss=0.22467470169067383\n",
            "step 2119: generator_loss=2.5935521125793457, discriminator_loss=0.20366021990776062\n",
            "step 2120: generator_loss=2.236680030822754, discriminator_loss=0.24867601692676544\n",
            "step 2121: generator_loss=2.5979690551757812, discriminator_loss=0.18782560527324677\n",
            "step 2122: generator_loss=2.7326440811157227, discriminator_loss=0.1633806824684143\n",
            "step 2123: generator_loss=2.6382198333740234, discriminator_loss=0.1689273715019226\n",
            "step 2124: generator_loss=2.5829663276672363, discriminator_loss=0.1829366534948349\n",
            "step 2125: generator_loss=2.5911755561828613, discriminator_loss=0.15980160236358643\n",
            "step 2126: generator_loss=2.3638830184936523, discriminator_loss=0.19745633006095886\n",
            "step 2127: generator_loss=2.2938485145568848, discriminator_loss=0.18227890133857727\n",
            "step 2128: generator_loss=2.107168674468994, discriminator_loss=0.19851276278495789\n",
            "step 2129: generator_loss=2.1671788692474365, discriminator_loss=0.16960252821445465\n",
            "step 2130: generator_loss=2.2691242694854736, discriminator_loss=0.17155085504055023\n",
            "step 2131: generator_loss=2.2079036235809326, discriminator_loss=0.18835890293121338\n",
            "step 2132: generator_loss=2.339024066925049, discriminator_loss=0.17342939972877502\n",
            "step 2133: generator_loss=2.44670033454895, discriminator_loss=0.19786354899406433\n",
            "step 2134: generator_loss=2.401444673538208, discriminator_loss=0.20170578360557556\n",
            "step 2135: generator_loss=2.418013572692871, discriminator_loss=0.16817724704742432\n",
            "step 2136: generator_loss=2.583482265472412, discriminator_loss=0.15138371288776398\n",
            "step 2137: generator_loss=2.221806526184082, discriminator_loss=0.18109187483787537\n",
            "step 2138: generator_loss=2.4383530616760254, discriminator_loss=0.15711075067520142\n",
            "step 2139: generator_loss=2.2112550735473633, discriminator_loss=0.17941685020923615\n",
            "step 2140: generator_loss=2.2266926765441895, discriminator_loss=0.17164695262908936\n",
            "step 2141: generator_loss=2.265381336212158, discriminator_loss=0.16718849539756775\n",
            "step 2142: generator_loss=2.4334616661071777, discriminator_loss=0.17589236795902252\n",
            "step 2143: generator_loss=2.5063414573669434, discriminator_loss=0.1452091634273529\n",
            "step 2144: generator_loss=2.5072176456451416, discriminator_loss=0.1564975082874298\n",
            "step 2145: generator_loss=2.680410861968994, discriminator_loss=0.2124871015548706\n",
            "step 2146: generator_loss=2.7723593711853027, discriminator_loss=0.16610278189182281\n",
            "step 2147: generator_loss=3.0114340782165527, discriminator_loss=0.19037342071533203\n",
            "step 2148: generator_loss=2.9449639320373535, discriminator_loss=0.1923205554485321\n",
            "step 2149: generator_loss=2.9183199405670166, discriminator_loss=0.21642085909843445\n",
            "step 2150: generator_loss=2.928976535797119, discriminator_loss=0.19049999117851257\n",
            "step 2151: generator_loss=3.0805845260620117, discriminator_loss=0.17837491631507874\n",
            "step 2152: generator_loss=3.142110824584961, discriminator_loss=0.2055167257785797\n",
            "step 2153: generator_loss=3.477832794189453, discriminator_loss=0.21155279874801636\n",
            "step 2154: generator_loss=3.1792068481445312, discriminator_loss=0.2453337013721466\n",
            "step 2155: generator_loss=3.279615879058838, discriminator_loss=0.16651687026023865\n",
            "step 2156: generator_loss=3.445653200149536, discriminator_loss=0.15668253600597382\n",
            "step 2157: generator_loss=3.313776969909668, discriminator_loss=0.1730627417564392\n",
            "step 2158: generator_loss=3.0846660137176514, discriminator_loss=0.16720229387283325\n",
            "step 2159: generator_loss=3.0196170806884766, discriminator_loss=0.14681746065616608\n",
            "step 2160: generator_loss=2.918177843093872, discriminator_loss=0.1355566680431366\n",
            "step 2161: generator_loss=2.9006619453430176, discriminator_loss=0.14176449179649353\n",
            "step 2162: generator_loss=2.536482334136963, discriminator_loss=0.14841461181640625\n",
            "step 2163: generator_loss=2.7362234592437744, discriminator_loss=0.14949728548526764\n",
            "step 2164: generator_loss=2.9089133739471436, discriminator_loss=0.17221349477767944\n",
            "step 2165: generator_loss=2.825672149658203, discriminator_loss=0.14705847203731537\n",
            "step 2166: generator_loss=2.7258365154266357, discriminator_loss=0.16112762689590454\n",
            "step 2167: generator_loss=2.549041271209717, discriminator_loss=0.17913725972175598\n",
            "step 2168: generator_loss=2.66037654876709, discriminator_loss=0.1714901477098465\n",
            "step 2169: generator_loss=2.6701536178588867, discriminator_loss=0.19383791089057922\n",
            "step 2170: generator_loss=2.5136311054229736, discriminator_loss=0.21629489958286285\n",
            "step 2171: generator_loss=2.1545820236206055, discriminator_loss=0.24693846702575684\n",
            "step 2172: generator_loss=2.1722192764282227, discriminator_loss=0.21083393692970276\n",
            "step 2173: generator_loss=2.047473907470703, discriminator_loss=0.21807631850242615\n",
            "step 2174: generator_loss=2.087925910949707, discriminator_loss=0.283393919467926\n",
            "step 2175: generator_loss=2.29028058052063, discriminator_loss=0.22747761011123657\n",
            "step 2176: generator_loss=2.242738723754883, discriminator_loss=0.25265201926231384\n",
            "step 2177: generator_loss=2.3005728721618652, discriminator_loss=0.2622264623641968\n",
            "step 2178: generator_loss=2.3745522499084473, discriminator_loss=0.2809493839740753\n",
            "step 2179: generator_loss=2.442302942276001, discriminator_loss=0.228382408618927\n",
            "step 2180: generator_loss=2.428605079650879, discriminator_loss=0.2249583899974823\n",
            "step 2181: generator_loss=2.497715950012207, discriminator_loss=0.30079400539398193\n",
            "step 2182: generator_loss=2.408388137817383, discriminator_loss=0.2789738178253174\n",
            "step 2183: generator_loss=2.656914710998535, discriminator_loss=0.24668428301811218\n",
            "step 2184: generator_loss=2.8320045471191406, discriminator_loss=0.30912792682647705\n",
            "step 2185: generator_loss=2.8846845626831055, discriminator_loss=0.2861747145652771\n",
            "step 2186: generator_loss=3.2181382179260254, discriminator_loss=0.2768217921257019\n",
            "step 2187: generator_loss=3.173574924468994, discriminator_loss=0.23861311376094818\n",
            "step 2188: generator_loss=3.0522680282592773, discriminator_loss=0.2245202213525772\n",
            "step 2189: generator_loss=3.1998136043548584, discriminator_loss=0.2067369818687439\n",
            "step 2190: generator_loss=2.61641263961792, discriminator_loss=0.21605637669563293\n",
            "step 2191: generator_loss=3.1224453449249268, discriminator_loss=0.18582305312156677\n",
            "step 2192: generator_loss=3.270142078399658, discriminator_loss=0.16081413626670837\n",
            "step 2193: generator_loss=3.3982045650482178, discriminator_loss=0.20093661546707153\n",
            "step 2194: generator_loss=3.8054261207580566, discriminator_loss=0.11773934960365295\n",
            "step 2195: generator_loss=3.7659358978271484, discriminator_loss=0.15844546258449554\n",
            "step 2196: generator_loss=3.4681241512298584, discriminator_loss=0.14997094869613647\n",
            "step 2197: generator_loss=3.596223831176758, discriminator_loss=0.13113854825496674\n",
            "step 2198: generator_loss=3.7084901332855225, discriminator_loss=0.15526387095451355\n",
            "step 2199: generator_loss=3.516688346862793, discriminator_loss=0.1627373993396759\n",
            "step 2200: generator_loss=3.6165547370910645, discriminator_loss=0.13070079684257507\n",
            "step 2201: generator_loss=3.244619846343994, discriminator_loss=0.18767966330051422\n",
            "step 2202: generator_loss=3.424889087677002, discriminator_loss=0.15394356846809387\n",
            "step 2203: generator_loss=3.3576598167419434, discriminator_loss=0.11538048088550568\n",
            "step 2204: generator_loss=3.2024645805358887, discriminator_loss=0.1431785523891449\n",
            "step 2205: generator_loss=3.178128480911255, discriminator_loss=0.12697312235832214\n",
            "step 2206: generator_loss=3.271951675415039, discriminator_loss=0.12834760546684265\n",
            "step 2207: generator_loss=2.885918140411377, discriminator_loss=0.15412136912345886\n",
            "step 2208: generator_loss=2.754098415374756, discriminator_loss=0.16081148386001587\n",
            "step 2209: generator_loss=2.5999813079833984, discriminator_loss=0.15374189615249634\n",
            "step 2210: generator_loss=2.5131783485412598, discriminator_loss=0.1264454424381256\n",
            "step 2211: generator_loss=2.5918586254119873, discriminator_loss=0.12672418355941772\n",
            "step 2212: generator_loss=2.47233247756958, discriminator_loss=0.1366547793149948\n",
            "step 2213: generator_loss=2.5367414951324463, discriminator_loss=0.1376117318868637\n",
            "step 2214: generator_loss=2.8138794898986816, discriminator_loss=0.14397194981575012\n",
            "step 2215: generator_loss=2.926514148712158, discriminator_loss=0.14920102059841156\n",
            "step 2216: generator_loss=2.712583065032959, discriminator_loss=0.15796485543251038\n",
            "step 2217: generator_loss=2.5754752159118652, discriminator_loss=0.19280073046684265\n",
            "step 2218: generator_loss=2.6247105598449707, discriminator_loss=0.16021741926670074\n",
            "step 2219: generator_loss=2.3197243213653564, discriminator_loss=0.1898237019777298\n",
            "step 2220: generator_loss=2.125941038131714, discriminator_loss=0.19397513568401337\n",
            "step 2221: generator_loss=1.9561687707901, discriminator_loss=0.22331489622592926\n",
            "step 2222: generator_loss=2.1413633823394775, discriminator_loss=0.1978801041841507\n",
            "step 2223: generator_loss=2.257140636444092, discriminator_loss=0.1861657202243805\n",
            "step 2224: generator_loss=2.6886870861053467, discriminator_loss=0.1862858235836029\n",
            "step 2225: generator_loss=2.556891441345215, discriminator_loss=0.19046838581562042\n",
            "step 2226: generator_loss=2.5274226665496826, discriminator_loss=0.2202831655740738\n",
            "step 2227: generator_loss=2.5833542346954346, discriminator_loss=0.19879168272018433\n",
            "step 2228: generator_loss=2.3637990951538086, discriminator_loss=0.21850264072418213\n",
            "step 2229: generator_loss=2.3828113079071045, discriminator_loss=0.2341415286064148\n",
            "step 2230: generator_loss=1.9762380123138428, discriminator_loss=0.25898653268814087\n",
            "step 2231: generator_loss=1.8961303234100342, discriminator_loss=0.28098034858703613\n",
            "step 2232: generator_loss=1.8730802536010742, discriminator_loss=0.28584417700767517\n",
            "step 2233: generator_loss=2.1729750633239746, discriminator_loss=0.36907416582107544\n",
            "step 2234: generator_loss=2.290628433227539, discriminator_loss=0.3621615171432495\n",
            "step 2235: generator_loss=2.490528106689453, discriminator_loss=0.3789691925048828\n",
            "step 2236: generator_loss=2.6181912422180176, discriminator_loss=0.34622418880462646\n",
            "step 2237: generator_loss=2.8153254985809326, discriminator_loss=0.34911298751831055\n",
            "step 2238: generator_loss=2.3904147148132324, discriminator_loss=0.28845059871673584\n",
            "step 2239: generator_loss=2.231017589569092, discriminator_loss=0.3318314850330353\n",
            "step 2240: generator_loss=2.2972495555877686, discriminator_loss=0.30941444635391235\n",
            "step 2241: generator_loss=2.1665053367614746, discriminator_loss=0.31955933570861816\n",
            "step 2242: generator_loss=2.182558059692383, discriminator_loss=0.30032238364219666\n",
            "step 2243: generator_loss=2.486151933670044, discriminator_loss=0.26309531927108765\n",
            "step 2244: generator_loss=2.9231035709381104, discriminator_loss=0.2344602644443512\n",
            "step 2245: generator_loss=2.900496482849121, discriminator_loss=0.28221243619918823\n",
            "step 2246: generator_loss=3.3018546104431152, discriminator_loss=0.24756944179534912\n",
            "step 2247: generator_loss=3.27061128616333, discriminator_loss=0.23194192349910736\n",
            "step 2248: generator_loss=3.4601821899414062, discriminator_loss=0.19796958565711975\n",
            "step 2249: generator_loss=3.1369190216064453, discriminator_loss=0.18841060996055603\n",
            "step 2250: generator_loss=2.842625379562378, discriminator_loss=0.15919680893421173\n",
            "step 2251: generator_loss=2.6439743041992188, discriminator_loss=0.1519768238067627\n",
            "step 2252: generator_loss=2.787696361541748, discriminator_loss=0.14151354134082794\n",
            "step 2253: generator_loss=2.6178066730499268, discriminator_loss=0.13437217473983765\n",
            "step 2254: generator_loss=2.792349338531494, discriminator_loss=0.10908649861812592\n",
            "step 2255: generator_loss=2.735250949859619, discriminator_loss=0.12621507048606873\n",
            "step 2256: generator_loss=2.5881495475769043, discriminator_loss=0.14458665251731873\n",
            "step 2257: generator_loss=2.845860719680786, discriminator_loss=0.11469735950231552\n",
            "step 2258: generator_loss=2.4805736541748047, discriminator_loss=0.14419294893741608\n",
            "step 2259: generator_loss=2.5859498977661133, discriminator_loss=0.13179847598075867\n",
            "step 2260: generator_loss=2.4703903198242188, discriminator_loss=0.12453299760818481\n",
            "step 2261: generator_loss=2.341858386993408, discriminator_loss=0.13000796735286713\n",
            "step 2262: generator_loss=2.443653106689453, discriminator_loss=0.1411447525024414\n",
            "step 2263: generator_loss=2.3806519508361816, discriminator_loss=0.14497804641723633\n",
            "step 2264: generator_loss=2.4834134578704834, discriminator_loss=0.16032981872558594\n",
            "step 2265: generator_loss=2.3951807022094727, discriminator_loss=0.16085407137870789\n",
            "step 2266: generator_loss=2.405337333679199, discriminator_loss=0.1544237732887268\n",
            "step 2267: generator_loss=2.38820219039917, discriminator_loss=0.19446106255054474\n",
            "step 2268: generator_loss=2.2912774085998535, discriminator_loss=0.16452357172966003\n",
            "step 2269: generator_loss=2.206831455230713, discriminator_loss=0.19411112368106842\n",
            "step 2270: generator_loss=2.304370403289795, discriminator_loss=0.22487658262252808\n",
            "step 2271: generator_loss=2.0191025733947754, discriminator_loss=0.24019011855125427\n",
            "step 2272: generator_loss=2.13346529006958, discriminator_loss=0.22868458926677704\n",
            "step 2273: generator_loss=1.9785420894622803, discriminator_loss=0.2583375573158264\n",
            "step 2274: generator_loss=2.303471088409424, discriminator_loss=0.20079484581947327\n",
            "step 2275: generator_loss=2.2713451385498047, discriminator_loss=0.2754925787448883\n",
            "step 2276: generator_loss=2.346634864807129, discriminator_loss=0.2983207404613495\n",
            "step 2277: generator_loss=2.272874593734741, discriminator_loss=0.30868008732795715\n",
            "step 2278: generator_loss=2.1269948482513428, discriminator_loss=0.31960099935531616\n",
            "step 2279: generator_loss=1.9440507888793945, discriminator_loss=0.36689621210098267\n",
            "step 2280: generator_loss=2.0086402893066406, discriminator_loss=0.3015972077846527\n",
            "step 2281: generator_loss=1.8820185661315918, discriminator_loss=0.3584240972995758\n",
            "step 2282: generator_loss=2.013612985610962, discriminator_loss=0.34270042181015015\n",
            "step 2283: generator_loss=2.139557123184204, discriminator_loss=0.30393800139427185\n",
            "step 2284: generator_loss=2.4977521896362305, discriminator_loss=0.3192542493343353\n",
            "step 2285: generator_loss=2.5212624073028564, discriminator_loss=0.35684987902641296\n",
            "step 2286: generator_loss=2.6583449840545654, discriminator_loss=0.36394786834716797\n",
            "step 2287: generator_loss=2.6484899520874023, discriminator_loss=0.34522882103919983\n",
            "step 2288: generator_loss=2.5217299461364746, discriminator_loss=0.28689926862716675\n",
            "step 2289: generator_loss=2.1598775386810303, discriminator_loss=0.22745423018932343\n",
            "step 2290: generator_loss=2.143282413482666, discriminator_loss=0.22901949286460876\n",
            "step 2291: generator_loss=2.0653347969055176, discriminator_loss=0.2153014987707138\n",
            "step 2292: generator_loss=2.2856855392456055, discriminator_loss=0.17599141597747803\n",
            "step 2293: generator_loss=2.449885129928589, discriminator_loss=0.21802106499671936\n",
            "step 2294: generator_loss=2.5437355041503906, discriminator_loss=0.1762213408946991\n",
            "step 2295: generator_loss=2.7343931198120117, discriminator_loss=0.17596781253814697\n",
            "step 2296: generator_loss=2.756560802459717, discriminator_loss=0.19170063734054565\n",
            "step 2297: generator_loss=2.874450206756592, discriminator_loss=0.14685660600662231\n",
            "step 2298: generator_loss=2.7565085887908936, discriminator_loss=0.14443570375442505\n",
            "step 2299: generator_loss=2.8929572105407715, discriminator_loss=0.15095698833465576\n",
            "step 2300: generator_loss=2.661325693130493, discriminator_loss=0.18579654395580292\n",
            "step 2301: generator_loss=2.354882001876831, discriminator_loss=0.18123802542686462\n",
            "step 2302: generator_loss=2.244231700897217, discriminator_loss=0.200103297829628\n",
            "step 2303: generator_loss=2.0704121589660645, discriminator_loss=0.20524731278419495\n",
            "step 2304: generator_loss=1.928932547569275, discriminator_loss=0.23492147028446198\n",
            "step 2305: generator_loss=2.229278564453125, discriminator_loss=0.2589249014854431\n",
            "step 2306: generator_loss=2.3463873863220215, discriminator_loss=0.21363765001296997\n",
            "step 2307: generator_loss=2.393834114074707, discriminator_loss=0.23591348528862\n",
            "step 2308: generator_loss=2.563490390777588, discriminator_loss=0.21851274371147156\n",
            "step 2309: generator_loss=2.614589214324951, discriminator_loss=0.22261330485343933\n",
            "step 2310: generator_loss=2.68740177154541, discriminator_loss=0.22445738315582275\n",
            "step 2311: generator_loss=2.3684945106506348, discriminator_loss=0.2610975503921509\n",
            "step 2312: generator_loss=2.5324418544769287, discriminator_loss=0.24220219254493713\n",
            "step 2313: generator_loss=2.4896435737609863, discriminator_loss=0.21938374638557434\n",
            "step 2314: generator_loss=2.363807439804077, discriminator_loss=0.2610812187194824\n",
            "step 2315: generator_loss=2.597111225128174, discriminator_loss=0.1596546173095703\n",
            "step 2316: generator_loss=2.783517599105835, discriminator_loss=0.16636063158512115\n",
            "step 2317: generator_loss=2.8665027618408203, discriminator_loss=0.22810685634613037\n",
            "step 2318: generator_loss=2.5942182540893555, discriminator_loss=0.1748058944940567\n",
            "step 2319: generator_loss=2.942401647567749, discriminator_loss=0.17605283856391907\n",
            "step 2320: generator_loss=2.9366209506988525, discriminator_loss=0.17692434787750244\n",
            "step 2321: generator_loss=2.905287265777588, discriminator_loss=0.12439122051000595\n",
            "step 2322: generator_loss=3.0967044830322266, discriminator_loss=0.12193864583969116\n",
            "step 2323: generator_loss=3.1140410900115967, discriminator_loss=0.1437225639820099\n",
            "step 2324: generator_loss=3.011059284210205, discriminator_loss=0.13783612847328186\n",
            "step 2325: generator_loss=3.264901876449585, discriminator_loss=0.10651335120201111\n",
            "step 2326: generator_loss=3.01417875289917, discriminator_loss=0.10520801693201065\n",
            "step 2327: generator_loss=3.1947855949401855, discriminator_loss=0.13173896074295044\n",
            "step 2328: generator_loss=3.226527214050293, discriminator_loss=0.10149185359477997\n",
            "step 2329: generator_loss=3.3052353858947754, discriminator_loss=0.12843813002109528\n",
            "step 2330: generator_loss=3.449315071105957, discriminator_loss=0.11435726284980774\n",
            "step 2331: generator_loss=3.3538429737091064, discriminator_loss=0.13614991307258606\n",
            "step 2332: generator_loss=3.195122718811035, discriminator_loss=0.11921805888414383\n",
            "step 2333: generator_loss=3.1798579692840576, discriminator_loss=0.1306026726961136\n",
            "step 2334: generator_loss=3.0868208408355713, discriminator_loss=0.15580463409423828\n",
            "step 2335: generator_loss=3.111841917037964, discriminator_loss=0.14702191948890686\n",
            "step 2336: generator_loss=3.288766622543335, discriminator_loss=0.09925933182239532\n",
            "step 2337: generator_loss=3.1376476287841797, discriminator_loss=0.1514899730682373\n",
            "step 2338: generator_loss=2.926638603210449, discriminator_loss=0.17106476426124573\n",
            "step 2339: generator_loss=3.0181689262390137, discriminator_loss=0.13523995876312256\n",
            "step 2340: generator_loss=2.840641736984253, discriminator_loss=0.14828333258628845\n",
            "step 2341: generator_loss=2.695003032684326, discriminator_loss=0.17853200435638428\n",
            "step 2342: generator_loss=2.5419435501098633, discriminator_loss=0.16428983211517334\n",
            "step 2343: generator_loss=2.416444778442383, discriminator_loss=0.184269979596138\n",
            "step 2344: generator_loss=2.5784082412719727, discriminator_loss=0.1898488998413086\n",
            "step 2345: generator_loss=2.671623706817627, discriminator_loss=0.2060919851064682\n",
            "step 2346: generator_loss=2.7711191177368164, discriminator_loss=0.15538249909877777\n",
            "step 2347: generator_loss=2.6139161586761475, discriminator_loss=0.19241085648536682\n",
            "step 2348: generator_loss=2.545219659805298, discriminator_loss=0.1864590346813202\n",
            "step 2349: generator_loss=2.356377601623535, discriminator_loss=0.20281186699867249\n",
            "step 2350: generator_loss=2.1651363372802734, discriminator_loss=0.17958322167396545\n",
            "step 2351: generator_loss=1.9582223892211914, discriminator_loss=0.18331319093704224\n",
            "step 2352: generator_loss=1.883389949798584, discriminator_loss=0.18790096044540405\n",
            "step 2353: generator_loss=2.0941720008850098, discriminator_loss=0.17443951964378357\n",
            "step 2354: generator_loss=2.1603875160217285, discriminator_loss=0.16667012870311737\n",
            "step 2355: generator_loss=2.277324676513672, discriminator_loss=0.18811297416687012\n",
            "step 2356: generator_loss=2.5980114936828613, discriminator_loss=0.1705351620912552\n",
            "step 2357: generator_loss=2.4327902793884277, discriminator_loss=0.15181384980678558\n",
            "step 2358: generator_loss=2.308873414993286, discriminator_loss=0.17425599694252014\n",
            "step 2359: generator_loss=2.251556396484375, discriminator_loss=0.15571540594100952\n",
            "step 2360: generator_loss=2.1783366203308105, discriminator_loss=0.1746368408203125\n",
            "step 2361: generator_loss=2.071423053741455, discriminator_loss=0.15149149298667908\n",
            "step 2362: generator_loss=2.1970486640930176, discriminator_loss=0.14048276841640472\n",
            "step 2363: generator_loss=2.3406143188476562, discriminator_loss=0.15337607264518738\n",
            "step 2364: generator_loss=2.533604621887207, discriminator_loss=0.1354682296514511\n",
            "step 2365: generator_loss=2.4777607917785645, discriminator_loss=0.13828913867473602\n",
            "step 2366: generator_loss=2.627631187438965, discriminator_loss=0.13795903325080872\n",
            "step 2367: generator_loss=2.678703546524048, discriminator_loss=0.16067761182785034\n",
            "step 2368: generator_loss=2.5192856788635254, discriminator_loss=0.17736715078353882\n",
            "step 2369: generator_loss=2.3268747329711914, discriminator_loss=0.1776989996433258\n",
            "step 2370: generator_loss=2.3028647899627686, discriminator_loss=0.14003679156303406\n",
            "step 2371: generator_loss=2.30167555809021, discriminator_loss=0.15602007508277893\n",
            "step 2372: generator_loss=2.292419672012329, discriminator_loss=0.18118777871131897\n",
            "step 2373: generator_loss=2.3175883293151855, discriminator_loss=0.15926510095596313\n",
            "step 2374: generator_loss=2.3692190647125244, discriminator_loss=0.1790257841348648\n",
            "step 2375: generator_loss=2.403569459915161, discriminator_loss=0.13790059089660645\n",
            "step 2376: generator_loss=2.232494831085205, discriminator_loss=0.18187114596366882\n",
            "step 2377: generator_loss=2.342109441757202, discriminator_loss=0.18019148707389832\n",
            "step 2378: generator_loss=2.4060163497924805, discriminator_loss=0.17479616403579712\n",
            "step 2379: generator_loss=2.3076369762420654, discriminator_loss=0.17294734716415405\n",
            "step 2380: generator_loss=2.1874613761901855, discriminator_loss=0.19236686825752258\n",
            "step 2381: generator_loss=2.1296088695526123, discriminator_loss=0.19889101386070251\n",
            "step 2382: generator_loss=2.114854574203491, discriminator_loss=0.1860247701406479\n",
            "step 2383: generator_loss=2.1107122898101807, discriminator_loss=0.20403766632080078\n",
            "step 2384: generator_loss=2.3299684524536133, discriminator_loss=0.16926860809326172\n",
            "step 2385: generator_loss=2.3261983394622803, discriminator_loss=0.20263023674488068\n",
            "step 2386: generator_loss=2.1021323204040527, discriminator_loss=0.2741032838821411\n",
            "step 2387: generator_loss=2.0485501289367676, discriminator_loss=0.2225586622953415\n",
            "step 2388: generator_loss=1.8187832832336426, discriminator_loss=0.24222363531589508\n",
            "step 2389: generator_loss=1.8716282844543457, discriminator_loss=0.25836214423179626\n",
            "step 2390: generator_loss=1.9455335140228271, discriminator_loss=0.21682342886924744\n",
            "step 2391: generator_loss=2.2041566371917725, discriminator_loss=0.22579997777938843\n",
            "step 2392: generator_loss=2.2245731353759766, discriminator_loss=0.22416889667510986\n",
            "step 2393: generator_loss=2.1758832931518555, discriminator_loss=0.2337559461593628\n",
            "step 2394: generator_loss=2.18296217918396, discriminator_loss=0.21087300777435303\n",
            "step 2395: generator_loss=1.893377423286438, discriminator_loss=0.2620750069618225\n",
            "step 2396: generator_loss=1.9079457521438599, discriminator_loss=0.2632077932357788\n",
            "step 2397: generator_loss=1.7317827939987183, discriminator_loss=0.25345197319984436\n",
            "step 2398: generator_loss=1.8213738203048706, discriminator_loss=0.254517138004303\n",
            "step 2399: generator_loss=1.9890596866607666, discriminator_loss=0.2131437510251999\n",
            "step 2400: generator_loss=2.0734286308288574, discriminator_loss=0.27817708253860474\n",
            "step 2401: generator_loss=2.192854881286621, discriminator_loss=0.25385358929634094\n",
            "step 2402: generator_loss=2.0602307319641113, discriminator_loss=0.26617616415023804\n",
            "step 2403: generator_loss=1.9161434173583984, discriminator_loss=0.26190268993377686\n",
            "step 2404: generator_loss=1.8822375535964966, discriminator_loss=0.2510865032672882\n",
            "step 2405: generator_loss=1.8139958381652832, discriminator_loss=0.25613975524902344\n",
            "step 2406: generator_loss=1.9362785816192627, discriminator_loss=0.2967036962509155\n",
            "step 2407: generator_loss=2.024155378341675, discriminator_loss=0.2615640163421631\n",
            "step 2408: generator_loss=2.19716739654541, discriminator_loss=0.27645623683929443\n",
            "step 2409: generator_loss=2.4533629417419434, discriminator_loss=0.2457241714000702\n",
            "step 2410: generator_loss=2.427264451980591, discriminator_loss=0.3015746772289276\n",
            "step 2411: generator_loss=2.7276902198791504, discriminator_loss=0.24471744894981384\n",
            "step 2412: generator_loss=2.7454781532287598, discriminator_loss=0.23936524987220764\n",
            "step 2413: generator_loss=2.4473469257354736, discriminator_loss=0.29390668869018555\n",
            "step 2414: generator_loss=2.8368172645568848, discriminator_loss=0.23088482022285461\n",
            "step 2415: generator_loss=2.789025068283081, discriminator_loss=0.2908703684806824\n",
            "step 2416: generator_loss=3.016874313354492, discriminator_loss=0.25539714097976685\n",
            "step 2417: generator_loss=3.3758273124694824, discriminator_loss=0.25658777356147766\n",
            "step 2418: generator_loss=3.383408546447754, discriminator_loss=0.22591009736061096\n",
            "step 2419: generator_loss=3.00667667388916, discriminator_loss=0.2678479552268982\n",
            "step 2420: generator_loss=3.6405868530273438, discriminator_loss=0.23009809851646423\n",
            "step 2421: generator_loss=3.7719812393188477, discriminator_loss=0.1816411018371582\n",
            "step 2422: generator_loss=3.423935890197754, discriminator_loss=0.25709694623947144\n",
            "step 2423: generator_loss=4.42359733581543, discriminator_loss=0.15891282260417938\n",
            "step 2424: generator_loss=3.6134190559387207, discriminator_loss=0.20883285999298096\n",
            "step 2425: generator_loss=3.4336860179901123, discriminator_loss=0.22854743897914886\n",
            "step 2426: generator_loss=3.0621840953826904, discriminator_loss=0.23264048993587494\n",
            "step 2427: generator_loss=2.939411163330078, discriminator_loss=0.2840102016925812\n",
            "step 2428: generator_loss=3.2111032009124756, discriminator_loss=0.2549678683280945\n",
            "step 2429: generator_loss=3.4079315662384033, discriminator_loss=0.29485636949539185\n",
            "step 2430: generator_loss=3.2551627159118652, discriminator_loss=0.23750631511211395\n",
            "step 2431: generator_loss=3.0933451652526855, discriminator_loss=0.30588653683662415\n",
            "step 2432: generator_loss=3.1882646083831787, discriminator_loss=0.34210193157196045\n",
            "step 2433: generator_loss=2.933363437652588, discriminator_loss=0.3513461947441101\n",
            "step 2434: generator_loss=3.0968103408813477, discriminator_loss=0.4382295310497284\n",
            "step 2435: generator_loss=2.9473519325256348, discriminator_loss=0.4827493131160736\n",
            "step 2436: generator_loss=3.1497278213500977, discriminator_loss=0.43568167090415955\n",
            "step 2437: generator_loss=2.9091238975524902, discriminator_loss=0.6397650837898254\n",
            "step 2438: generator_loss=2.7730255126953125, discriminator_loss=0.5958235263824463\n",
            "step 2439: generator_loss=3.130333662033081, discriminator_loss=0.5556524395942688\n",
            "step 2440: generator_loss=3.585118055343628, discriminator_loss=0.4369732737541199\n",
            "step 2441: generator_loss=3.605644464492798, discriminator_loss=0.4429481029510498\n",
            "step 2442: generator_loss=3.0195693969726562, discriminator_loss=0.37904274463653564\n",
            "step 2443: generator_loss=3.444286823272705, discriminator_loss=0.2747407853603363\n",
            "step 2444: generator_loss=3.505720615386963, discriminator_loss=0.21415051817893982\n",
            "step 2445: generator_loss=3.429431200027466, discriminator_loss=0.17515933513641357\n",
            "step 2446: generator_loss=3.3904855251312256, discriminator_loss=0.14722400903701782\n",
            "step 2447: generator_loss=3.496170997619629, discriminator_loss=0.13364657759666443\n",
            "step 2448: generator_loss=3.193624973297119, discriminator_loss=0.14426101744174957\n",
            "step 2449: generator_loss=3.342167615890503, discriminator_loss=0.14790481328964233\n",
            "step 2450: generator_loss=3.295330047607422, discriminator_loss=0.15521523356437683\n",
            "step 2451: generator_loss=3.2483577728271484, discriminator_loss=0.1696828454732895\n",
            "step 2452: generator_loss=3.278390884399414, discriminator_loss=0.1461075246334076\n",
            "step 2453: generator_loss=3.421294689178467, discriminator_loss=0.1434479057788849\n",
            "step 2454: generator_loss=3.506514072418213, discriminator_loss=0.12358028441667557\n",
            "step 2455: generator_loss=3.360123634338379, discriminator_loss=0.18471676111221313\n",
            "step 2456: generator_loss=3.4365196228027344, discriminator_loss=0.18228617310523987\n",
            "step 2457: generator_loss=3.0881941318511963, discriminator_loss=0.1694599837064743\n",
            "step 2458: generator_loss=2.8862829208374023, discriminator_loss=0.18422147631645203\n",
            "step 2459: generator_loss=3.035273790359497, discriminator_loss=0.16745971143245697\n",
            "step 2460: generator_loss=2.978715419769287, discriminator_loss=0.17662936449050903\n",
            "step 2461: generator_loss=3.228353500366211, discriminator_loss=0.1392131894826889\n",
            "step 2462: generator_loss=3.7123303413391113, discriminator_loss=0.17920956015586853\n",
            "step 2463: generator_loss=3.910107135772705, discriminator_loss=0.15687541663646698\n",
            "step 2464: generator_loss=3.398186445236206, discriminator_loss=0.15415780246257782\n",
            "step 2465: generator_loss=3.14097261428833, discriminator_loss=0.19945120811462402\n",
            "step 2466: generator_loss=2.815890312194824, discriminator_loss=0.23255451023578644\n",
            "step 2467: generator_loss=2.4262354373931885, discriminator_loss=0.3387972414493561\n",
            "step 2468: generator_loss=2.850203514099121, discriminator_loss=0.305349737405777\n",
            "step 2469: generator_loss=3.291236400604248, discriminator_loss=0.30393701791763306\n",
            "step 2470: generator_loss=3.1892552375793457, discriminator_loss=0.3841969966888428\n",
            "step 2471: generator_loss=4.006869792938232, discriminator_loss=0.28398630023002625\n",
            "step 2472: generator_loss=4.079224586486816, discriminator_loss=0.33995240926742554\n",
            "step 2473: generator_loss=4.280360221862793, discriminator_loss=0.3836311101913452\n",
            "step 2474: generator_loss=3.967484712600708, discriminator_loss=0.36254042387008667\n",
            "step 2475: generator_loss=3.5560126304626465, discriminator_loss=0.4143965542316437\n",
            "step 2476: generator_loss=3.3160595893859863, discriminator_loss=0.38628482818603516\n",
            "step 2477: generator_loss=3.388619899749756, discriminator_loss=0.4390612244606018\n",
            "step 2478: generator_loss=3.5836150646209717, discriminator_loss=0.4551154673099518\n",
            "step 2479: generator_loss=3.1274518966674805, discriminator_loss=0.4704544246196747\n",
            "step 2480: generator_loss=4.196155548095703, discriminator_loss=0.43875324726104736\n",
            "step 2481: generator_loss=4.129294395446777, discriminator_loss=0.4001508057117462\n",
            "step 2482: generator_loss=4.818437576293945, discriminator_loss=0.362338125705719\n",
            "step 2483: generator_loss=4.661710739135742, discriminator_loss=0.36545199155807495\n",
            "step 2484: generator_loss=4.319588661193848, discriminator_loss=0.3620768189430237\n",
            "step 2485: generator_loss=4.175739288330078, discriminator_loss=0.25442734360694885\n",
            "step 2486: generator_loss=3.9603312015533447, discriminator_loss=0.3759956359863281\n",
            "step 2487: generator_loss=4.155080318450928, discriminator_loss=0.3042312264442444\n",
            "step 2488: generator_loss=3.655485153198242, discriminator_loss=0.2868906855583191\n",
            "step 2489: generator_loss=3.6436939239501953, discriminator_loss=0.26109859347343445\n",
            "step 2490: generator_loss=3.6549293994903564, discriminator_loss=0.23217374086380005\n",
            "step 2491: generator_loss=3.5156946182250977, discriminator_loss=0.18308386206626892\n",
            "step 2492: generator_loss=3.813835859298706, discriminator_loss=0.14801166951656342\n",
            "step 2493: generator_loss=3.491718292236328, discriminator_loss=0.19213153421878815\n",
            "step 2494: generator_loss=4.07352352142334, discriminator_loss=0.1930597424507141\n",
            "step 2495: generator_loss=4.040367603302002, discriminator_loss=0.13466230034828186\n",
            "step 2496: generator_loss=3.8635683059692383, discriminator_loss=0.15523916482925415\n",
            "step 2497: generator_loss=4.077794075012207, discriminator_loss=0.08767008036375046\n",
            "step 2498: generator_loss=3.9007678031921387, discriminator_loss=0.09791810810565948\n",
            "step 2499: generator_loss=3.603863477706909, discriminator_loss=0.09721145033836365\n",
            "step 2500: generator_loss=3.624413251876831, discriminator_loss=0.10160885751247406\n",
            "step 2501: generator_loss=3.460543632507324, discriminator_loss=0.10574948042631149\n",
            "step 2502: generator_loss=3.3533363342285156, discriminator_loss=0.11536748707294464\n",
            "step 2503: generator_loss=3.1357839107513428, discriminator_loss=0.1304786652326584\n",
            "step 2504: generator_loss=3.0121376514434814, discriminator_loss=0.11698556691408157\n",
            "step 2505: generator_loss=2.9421677589416504, discriminator_loss=0.14466030895709991\n",
            "step 2506: generator_loss=2.613015651702881, discriminator_loss=0.1585795283317566\n",
            "step 2507: generator_loss=2.6641576290130615, discriminator_loss=0.13104894757270813\n",
            "step 2508: generator_loss=2.6554691791534424, discriminator_loss=0.17776772379875183\n",
            "step 2509: generator_loss=2.4651238918304443, discriminator_loss=0.18971598148345947\n",
            "step 2510: generator_loss=2.6498773097991943, discriminator_loss=0.19914093613624573\n",
            "step 2511: generator_loss=2.4081361293792725, discriminator_loss=0.16044367849826813\n",
            "step 2512: generator_loss=2.3726515769958496, discriminator_loss=0.18365418910980225\n",
            "step 2513: generator_loss=2.2801589965820312, discriminator_loss=0.18373939394950867\n",
            "step 2514: generator_loss=2.552386999130249, discriminator_loss=0.19783583283424377\n",
            "step 2515: generator_loss=2.5296196937561035, discriminator_loss=0.21704912185668945\n",
            "step 2516: generator_loss=2.5961263179779053, discriminator_loss=0.18378114700317383\n",
            "step 2517: generator_loss=2.48345947265625, discriminator_loss=0.16638213396072388\n",
            "step 2518: generator_loss=2.8029026985168457, discriminator_loss=0.18109610676765442\n",
            "step 2519: generator_loss=2.4988105297088623, discriminator_loss=0.19746911525726318\n",
            "step 2520: generator_loss=2.768798351287842, discriminator_loss=0.19617220759391785\n",
            "step 2521: generator_loss=2.8363120555877686, discriminator_loss=0.21303090453147888\n",
            "step 2522: generator_loss=2.7574164867401123, discriminator_loss=0.26569294929504395\n",
            "step 2523: generator_loss=2.647068738937378, discriminator_loss=0.2843835651874542\n",
            "step 2524: generator_loss=2.8072235584259033, discriminator_loss=0.28180286288261414\n",
            "step 2525: generator_loss=2.860013723373413, discriminator_loss=0.2998587489128113\n",
            "step 2526: generator_loss=2.5160608291625977, discriminator_loss=0.3222748935222626\n",
            "step 2527: generator_loss=2.7500786781311035, discriminator_loss=0.29972994327545166\n",
            "step 2528: generator_loss=2.752225875854492, discriminator_loss=0.2910730838775635\n",
            "step 2529: generator_loss=2.248032331466675, discriminator_loss=0.34791526198387146\n",
            "step 2530: generator_loss=2.4493956565856934, discriminator_loss=0.3034621477127075\n",
            "step 2531: generator_loss=2.5736806392669678, discriminator_loss=0.3260497748851776\n",
            "step 2532: generator_loss=2.6631064414978027, discriminator_loss=0.27108871936798096\n",
            "step 2533: generator_loss=2.7518019676208496, discriminator_loss=0.32879480719566345\n",
            "step 2534: generator_loss=3.1089162826538086, discriminator_loss=0.2174714356660843\n",
            "step 2535: generator_loss=3.0074214935302734, discriminator_loss=0.2246941179037094\n",
            "step 2536: generator_loss=2.6300930976867676, discriminator_loss=0.23685434460639954\n",
            "step 2537: generator_loss=2.830522060394287, discriminator_loss=0.21090492606163025\n",
            "step 2538: generator_loss=2.514409303665161, discriminator_loss=0.26185888051986694\n",
            "step 2539: generator_loss=2.4365835189819336, discriminator_loss=0.22284290194511414\n",
            "step 2540: generator_loss=2.5381340980529785, discriminator_loss=0.2576442360877991\n",
            "step 2541: generator_loss=2.325395107269287, discriminator_loss=0.25922244787216187\n",
            "step 2542: generator_loss=2.605978012084961, discriminator_loss=0.26689308881759644\n",
            "step 2543: generator_loss=2.5275163650512695, discriminator_loss=0.28244319558143616\n",
            "step 2544: generator_loss=2.5299417972564697, discriminator_loss=0.333927184343338\n",
            "step 2545: generator_loss=2.585752487182617, discriminator_loss=0.33504459261894226\n",
            "step 2546: generator_loss=3.0483522415161133, discriminator_loss=0.36600321531295776\n",
            "step 2547: generator_loss=3.059903621673584, discriminator_loss=0.2858029007911682\n",
            "step 2548: generator_loss=2.844228982925415, discriminator_loss=0.2773865759372711\n",
            "step 2549: generator_loss=2.9722681045532227, discriminator_loss=0.28559762239456177\n",
            "step 2550: generator_loss=2.9408044815063477, discriminator_loss=0.2576156258583069\n",
            "step 2551: generator_loss=2.6007680892944336, discriminator_loss=0.22169649600982666\n",
            "step 2552: generator_loss=3.0477774143218994, discriminator_loss=0.21385610103607178\n",
            "step 2553: generator_loss=3.0280916690826416, discriminator_loss=0.19983606040477753\n",
            "step 2554: generator_loss=3.0763754844665527, discriminator_loss=0.16786599159240723\n",
            "step 2555: generator_loss=2.8829433917999268, discriminator_loss=0.20111900568008423\n",
            "step 2556: generator_loss=3.417613983154297, discriminator_loss=0.20223742723464966\n",
            "step 2557: generator_loss=3.513700246810913, discriminator_loss=0.19068367779254913\n",
            "step 2558: generator_loss=3.0747551918029785, discriminator_loss=0.19596800208091736\n",
            "step 2559: generator_loss=2.85609769821167, discriminator_loss=0.15170693397521973\n",
            "step 2560: generator_loss=2.9945943355560303, discriminator_loss=0.1355878859758377\n",
            "step 2561: generator_loss=2.486295700073242, discriminator_loss=0.15017788112163544\n",
            "step 2562: generator_loss=2.3315396308898926, discriminator_loss=0.14159893989562988\n",
            "step 2563: generator_loss=2.2386889457702637, discriminator_loss=0.17500892281532288\n",
            "step 2564: generator_loss=2.356966495513916, discriminator_loss=0.158877894282341\n",
            "step 2565: generator_loss=2.2623276710510254, discriminator_loss=0.14390864968299866\n",
            "step 2566: generator_loss=2.5686638355255127, discriminator_loss=0.16961106657981873\n",
            "step 2567: generator_loss=2.6904654502868652, discriminator_loss=0.14839911460876465\n",
            "step 2568: generator_loss=2.8552188873291016, discriminator_loss=0.16857527196407318\n",
            "step 2569: generator_loss=2.885300636291504, discriminator_loss=0.14567339420318604\n",
            "step 2570: generator_loss=2.8504106998443604, discriminator_loss=0.1371937096118927\n",
            "step 2571: generator_loss=2.7968873977661133, discriminator_loss=0.16866344213485718\n",
            "step 2572: generator_loss=2.6038246154785156, discriminator_loss=0.16744127869606018\n",
            "step 2573: generator_loss=2.709379196166992, discriminator_loss=0.13385018706321716\n",
            "step 2574: generator_loss=2.450202226638794, discriminator_loss=0.15412551164627075\n",
            "step 2575: generator_loss=2.259416103363037, discriminator_loss=0.15847551822662354\n",
            "step 2576: generator_loss=2.4161720275878906, discriminator_loss=0.14524579048156738\n",
            "step 2577: generator_loss=2.582439422607422, discriminator_loss=0.1369316577911377\n",
            "step 2578: generator_loss=2.796858072280884, discriminator_loss=0.15380287170410156\n",
            "step 2579: generator_loss=2.49346661567688, discriminator_loss=0.16268649697303772\n",
            "step 2580: generator_loss=2.4875080585479736, discriminator_loss=0.19370320439338684\n",
            "step 2581: generator_loss=2.550503969192505, discriminator_loss=0.15745992958545685\n",
            "step 2582: generator_loss=2.6455864906311035, discriminator_loss=0.14790239930152893\n",
            "step 2583: generator_loss=2.7414798736572266, discriminator_loss=0.18253421783447266\n",
            "step 2584: generator_loss=2.4929933547973633, discriminator_loss=0.16932827234268188\n",
            "step 2585: generator_loss=2.413534641265869, discriminator_loss=0.19246599078178406\n",
            "step 2586: generator_loss=2.437985897064209, discriminator_loss=0.17169620096683502\n",
            "step 2587: generator_loss=2.3625802993774414, discriminator_loss=0.20684340596199036\n",
            "step 2588: generator_loss=2.5157666206359863, discriminator_loss=0.22071588039398193\n",
            "step 2589: generator_loss=2.5725150108337402, discriminator_loss=0.2749667465686798\n",
            "step 2590: generator_loss=2.400064706802368, discriminator_loss=0.22981825470924377\n",
            "step 2591: generator_loss=2.52937388420105, discriminator_loss=0.27653706073760986\n",
            "step 2592: generator_loss=2.5274906158447266, discriminator_loss=0.25765562057495117\n",
            "step 2593: generator_loss=2.615622043609619, discriminator_loss=0.26709258556365967\n",
            "step 2594: generator_loss=2.4392857551574707, discriminator_loss=0.32627034187316895\n",
            "step 2595: generator_loss=2.584662437438965, discriminator_loss=0.3069729804992676\n",
            "step 2596: generator_loss=2.5023088455200195, discriminator_loss=0.3015121817588806\n",
            "step 2597: generator_loss=2.885331630706787, discriminator_loss=0.3176882565021515\n",
            "step 2598: generator_loss=2.6323397159576416, discriminator_loss=0.3185846209526062\n",
            "step 2599: generator_loss=2.821654796600342, discriminator_loss=0.2816055119037628\n",
            "step 2600: generator_loss=2.7090959548950195, discriminator_loss=0.33611539006233215\n",
            "step 2601: generator_loss=2.553976058959961, discriminator_loss=0.27840936183929443\n",
            "step 2602: generator_loss=2.665107250213623, discriminator_loss=0.25963330268859863\n",
            "step 2603: generator_loss=3.071721076965332, discriminator_loss=0.27442818880081177\n",
            "step 2604: generator_loss=2.9592738151550293, discriminator_loss=0.26351720094680786\n",
            "step 2605: generator_loss=3.062394618988037, discriminator_loss=0.2951200604438782\n",
            "step 2606: generator_loss=3.07787823677063, discriminator_loss=0.2654785215854645\n",
            "step 2607: generator_loss=3.1194424629211426, discriminator_loss=0.28376302123069763\n",
            "step 2608: generator_loss=3.1755805015563965, discriminator_loss=0.26833733916282654\n",
            "step 2609: generator_loss=3.6013131141662598, discriminator_loss=0.25774240493774414\n",
            "step 2610: generator_loss=3.229828357696533, discriminator_loss=0.3307153582572937\n",
            "step 2611: generator_loss=2.9472250938415527, discriminator_loss=0.28599849343299866\n",
            "step 2612: generator_loss=3.3059723377227783, discriminator_loss=0.2448393851518631\n",
            "step 2613: generator_loss=3.2079389095306396, discriminator_loss=0.2999453544616699\n",
            "step 2614: generator_loss=3.0479798316955566, discriminator_loss=0.25323131680488586\n",
            "step 2615: generator_loss=3.140231132507324, discriminator_loss=0.22631675004959106\n",
            "step 2616: generator_loss=2.7431857585906982, discriminator_loss=0.27928847074508667\n",
            "step 2617: generator_loss=2.6867103576660156, discriminator_loss=0.228520929813385\n",
            "step 2618: generator_loss=2.937839984893799, discriminator_loss=0.22096043825149536\n",
            "step 2619: generator_loss=2.61102294921875, discriminator_loss=0.2614850401878357\n",
            "step 2620: generator_loss=2.5431385040283203, discriminator_loss=0.24459977447986603\n",
            "step 2621: generator_loss=2.533916473388672, discriminator_loss=0.25812482833862305\n",
            "step 2622: generator_loss=2.37294864654541, discriminator_loss=0.20089301466941833\n",
            "step 2623: generator_loss=2.4450666904449463, discriminator_loss=0.229920893907547\n",
            "step 2624: generator_loss=2.392721176147461, discriminator_loss=0.2069072723388672\n",
            "step 2625: generator_loss=2.5141539573669434, discriminator_loss=0.23621398210525513\n",
            "step 2626: generator_loss=2.460233449935913, discriminator_loss=0.24385330080986023\n",
            "step 2627: generator_loss=2.342027187347412, discriminator_loss=0.21750418841838837\n",
            "step 2628: generator_loss=2.361849784851074, discriminator_loss=0.20127512514591217\n",
            "step 2629: generator_loss=2.1443557739257812, discriminator_loss=0.2073076069355011\n",
            "step 2630: generator_loss=2.2703328132629395, discriminator_loss=0.19099533557891846\n",
            "step 2631: generator_loss=2.0480475425720215, discriminator_loss=0.2431204915046692\n",
            "step 2632: generator_loss=2.142515182495117, discriminator_loss=0.22396671772003174\n",
            "step 2633: generator_loss=2.1688692569732666, discriminator_loss=0.23847027122974396\n",
            "step 2634: generator_loss=2.315807819366455, discriminator_loss=0.1991354525089264\n",
            "step 2635: generator_loss=2.363837718963623, discriminator_loss=0.20425951480865479\n",
            "step 2636: generator_loss=2.2070980072021484, discriminator_loss=0.21573637425899506\n",
            "step 2637: generator_loss=2.421945095062256, discriminator_loss=0.20620761811733246\n",
            "step 2638: generator_loss=2.257206439971924, discriminator_loss=0.17934000492095947\n",
            "step 2639: generator_loss=2.3243885040283203, discriminator_loss=0.20164558291435242\n",
            "step 2640: generator_loss=2.3773856163024902, discriminator_loss=0.20301765203475952\n",
            "step 2641: generator_loss=2.417428493499756, discriminator_loss=0.18684910237789154\n",
            "step 2642: generator_loss=2.4143166542053223, discriminator_loss=0.17363187670707703\n",
            "step 2643: generator_loss=2.4210028648376465, discriminator_loss=0.1990983486175537\n",
            "step 2644: generator_loss=2.310537576675415, discriminator_loss=0.17586295306682587\n",
            "step 2645: generator_loss=2.3791699409484863, discriminator_loss=0.14993810653686523\n",
            "step 2646: generator_loss=2.418911933898926, discriminator_loss=0.14204594492912292\n",
            "step 2647: generator_loss=2.199413776397705, discriminator_loss=0.1754152625799179\n",
            "step 2648: generator_loss=2.400424003601074, discriminator_loss=0.1559268683195114\n",
            "step 2649: generator_loss=2.3124442100524902, discriminator_loss=0.1738441437482834\n",
            "step 2650: generator_loss=2.3058786392211914, discriminator_loss=0.16472885012626648\n",
            "step 2651: generator_loss=2.29290771484375, discriminator_loss=0.18457922339439392\n",
            "step 2652: generator_loss=2.236867904663086, discriminator_loss=0.17664584517478943\n",
            "step 2653: generator_loss=2.1626968383789062, discriminator_loss=0.22179579734802246\n",
            "step 2654: generator_loss=2.028367042541504, discriminator_loss=0.1836080700159073\n",
            "step 2655: generator_loss=2.048646926879883, discriminator_loss=0.22450467944145203\n",
            "step 2656: generator_loss=1.9012837409973145, discriminator_loss=0.24138671159744263\n",
            "step 2657: generator_loss=2.1214370727539062, discriminator_loss=0.24791808426380157\n",
            "step 2658: generator_loss=2.1465554237365723, discriminator_loss=0.2554049491882324\n",
            "step 2659: generator_loss=1.9889062643051147, discriminator_loss=0.3193049132823944\n",
            "step 2660: generator_loss=2.1942310333251953, discriminator_loss=0.24764062464237213\n",
            "step 2661: generator_loss=2.0508203506469727, discriminator_loss=0.36160534620285034\n",
            "step 2662: generator_loss=1.8579155206680298, discriminator_loss=0.43331179022789\n",
            "step 2663: generator_loss=1.7967100143432617, discriminator_loss=0.49408456683158875\n",
            "step 2664: generator_loss=1.6432344913482666, discriminator_loss=0.4723275899887085\n",
            "step 2665: generator_loss=1.723753809928894, discriminator_loss=0.39465922117233276\n",
            "step 2666: generator_loss=2.0248026847839355, discriminator_loss=0.4079839587211609\n",
            "step 2667: generator_loss=1.7614350318908691, discriminator_loss=0.45034900307655334\n",
            "step 2668: generator_loss=1.870644450187683, discriminator_loss=0.4542738199234009\n",
            "step 2669: generator_loss=1.9958922863006592, discriminator_loss=0.432455837726593\n",
            "step 2670: generator_loss=1.8187766075134277, discriminator_loss=0.4426724314689636\n",
            "step 2671: generator_loss=1.9496071338653564, discriminator_loss=0.4200596213340759\n",
            "step 2672: generator_loss=2.1809210777282715, discriminator_loss=0.3953190743923187\n",
            "step 2673: generator_loss=1.975583791732788, discriminator_loss=0.4238383173942566\n",
            "step 2674: generator_loss=2.504136323928833, discriminator_loss=0.3359912633895874\n",
            "step 2675: generator_loss=2.31221866607666, discriminator_loss=0.35131949186325073\n",
            "step 2676: generator_loss=2.3731770515441895, discriminator_loss=0.3291744291782379\n",
            "step 2677: generator_loss=2.5655150413513184, discriminator_loss=0.24048450589179993\n",
            "step 2678: generator_loss=2.2340807914733887, discriminator_loss=0.3252299427986145\n",
            "step 2679: generator_loss=2.1800174713134766, discriminator_loss=0.3168407678604126\n",
            "step 2680: generator_loss=2.200645923614502, discriminator_loss=0.2650332450866699\n",
            "step 2681: generator_loss=2.2419209480285645, discriminator_loss=0.26094865798950195\n",
            "step 2682: generator_loss=1.9329570531845093, discriminator_loss=0.3071925938129425\n",
            "step 2683: generator_loss=2.175687074661255, discriminator_loss=0.22077426314353943\n",
            "step 2684: generator_loss=2.1985979080200195, discriminator_loss=0.21492913365364075\n",
            "step 2685: generator_loss=2.192711114883423, discriminator_loss=0.20181867480278015\n",
            "step 2686: generator_loss=2.4194650650024414, discriminator_loss=0.2226494997739792\n",
            "step 2687: generator_loss=2.5298023223876953, discriminator_loss=0.17383481562137604\n",
            "step 2688: generator_loss=2.417567014694214, discriminator_loss=0.2037883996963501\n",
            "step 2689: generator_loss=2.3198647499084473, discriminator_loss=0.18325772881507874\n",
            "step 2690: generator_loss=2.5685791969299316, discriminator_loss=0.17860521376132965\n",
            "step 2691: generator_loss=2.399932861328125, discriminator_loss=0.1910092830657959\n",
            "step 2692: generator_loss=2.2503514289855957, discriminator_loss=0.18800905346870422\n",
            "step 2693: generator_loss=2.3675637245178223, discriminator_loss=0.14732587337493896\n",
            "step 2694: generator_loss=2.091590404510498, discriminator_loss=0.17153576016426086\n",
            "step 2695: generator_loss=2.178745746612549, discriminator_loss=0.16673427820205688\n",
            "step 2696: generator_loss=2.2251102924346924, discriminator_loss=0.17650341987609863\n",
            "step 2697: generator_loss=2.3288681507110596, discriminator_loss=0.1807294487953186\n",
            "step 2698: generator_loss=2.421469211578369, discriminator_loss=0.17272929847240448\n",
            "step 2699: generator_loss=2.511070489883423, discriminator_loss=0.17481854557991028\n",
            "step 2700: generator_loss=2.5820465087890625, discriminator_loss=0.17237639427185059\n",
            "step 2701: generator_loss=2.514145851135254, discriminator_loss=0.17109939455986023\n",
            "step 2702: generator_loss=2.450366497039795, discriminator_loss=0.15469151735305786\n",
            "step 2703: generator_loss=2.3560900688171387, discriminator_loss=0.15532450377941132\n",
            "step 2704: generator_loss=2.3732504844665527, discriminator_loss=0.17636427283287048\n",
            "step 2705: generator_loss=2.4112863540649414, discriminator_loss=0.1647951900959015\n",
            "step 2706: generator_loss=2.4019625186920166, discriminator_loss=0.17159345746040344\n",
            "step 2707: generator_loss=2.37151837348938, discriminator_loss=0.20167148113250732\n",
            "step 2708: generator_loss=2.3490405082702637, discriminator_loss=0.16611990332603455\n",
            "step 2709: generator_loss=2.4028499126434326, discriminator_loss=0.14786891639232635\n",
            "step 2710: generator_loss=2.44417667388916, discriminator_loss=0.18867138028144836\n",
            "step 2711: generator_loss=2.3170790672302246, discriminator_loss=0.16152559220790863\n",
            "step 2712: generator_loss=2.4326748847961426, discriminator_loss=0.20920658111572266\n",
            "step 2713: generator_loss=2.3353047370910645, discriminator_loss=0.1701754778623581\n",
            "step 2714: generator_loss=2.4111714363098145, discriminator_loss=0.14600753784179688\n",
            "step 2715: generator_loss=2.250227928161621, discriminator_loss=0.15588660538196564\n",
            "step 2716: generator_loss=2.292914390563965, discriminator_loss=0.1584116816520691\n",
            "step 2717: generator_loss=2.0387563705444336, discriminator_loss=0.217312753200531\n",
            "step 2718: generator_loss=2.0305700302124023, discriminator_loss=0.2067280113697052\n",
            "step 2719: generator_loss=2.107168197631836, discriminator_loss=0.22881242632865906\n",
            "step 2720: generator_loss=2.1690406799316406, discriminator_loss=0.168990358710289\n",
            "step 2721: generator_loss=2.2582969665527344, discriminator_loss=0.18335899710655212\n",
            "step 2722: generator_loss=2.2354519367218018, discriminator_loss=0.20412492752075195\n",
            "step 2723: generator_loss=2.085231065750122, discriminator_loss=0.22730590403079987\n",
            "step 2724: generator_loss=2.1264307498931885, discriminator_loss=0.19596730172634125\n",
            "step 2725: generator_loss=1.905824065208435, discriminator_loss=0.22047042846679688\n",
            "step 2726: generator_loss=1.9050612449645996, discriminator_loss=0.22487209737300873\n",
            "step 2727: generator_loss=2.0030393600463867, discriminator_loss=0.20364117622375488\n",
            "step 2728: generator_loss=2.068124771118164, discriminator_loss=0.2097700983285904\n",
            "step 2729: generator_loss=2.0671346187591553, discriminator_loss=0.21879824995994568\n",
            "step 2730: generator_loss=2.093024253845215, discriminator_loss=0.2424965351819992\n",
            "step 2731: generator_loss=2.2305519580841064, discriminator_loss=0.22947664558887482\n",
            "step 2732: generator_loss=2.1394388675689697, discriminator_loss=0.2433418184518814\n",
            "step 2733: generator_loss=2.1500720977783203, discriminator_loss=0.209309384226799\n",
            "step 2734: generator_loss=2.1135597229003906, discriminator_loss=0.20642822980880737\n",
            "step 2735: generator_loss=1.938680648803711, discriminator_loss=0.22071152925491333\n",
            "step 2736: generator_loss=2.082791566848755, discriminator_loss=0.22570452094078064\n",
            "step 2737: generator_loss=2.1244475841522217, discriminator_loss=0.22631193697452545\n",
            "step 2738: generator_loss=2.079366683959961, discriminator_loss=0.2373381406068802\n",
            "step 2739: generator_loss=2.0041873455047607, discriminator_loss=0.21820062398910522\n",
            "step 2740: generator_loss=2.0611422061920166, discriminator_loss=0.1919889748096466\n",
            "step 2741: generator_loss=2.0402228832244873, discriminator_loss=0.2315828502178192\n",
            "step 2742: generator_loss=1.965130090713501, discriminator_loss=0.2542136311531067\n",
            "step 2743: generator_loss=1.9371497631072998, discriminator_loss=0.20622026920318604\n",
            "step 2744: generator_loss=1.739096760749817, discriminator_loss=0.27598968148231506\n",
            "step 2745: generator_loss=1.772629737854004, discriminator_loss=0.27024802565574646\n",
            "step 2746: generator_loss=1.779994010925293, discriminator_loss=0.30160796642303467\n",
            "step 2747: generator_loss=1.7052581310272217, discriminator_loss=0.31181100010871887\n",
            "step 2748: generator_loss=1.6961619853973389, discriminator_loss=0.2571786046028137\n",
            "step 2749: generator_loss=1.6446521282196045, discriminator_loss=0.30655795335769653\n",
            "step 2750: generator_loss=1.8142277002334595, discriminator_loss=0.2989266514778137\n",
            "step 2751: generator_loss=2.053765296936035, discriminator_loss=0.29302117228507996\n",
            "step 2752: generator_loss=2.1142568588256836, discriminator_loss=0.2710024416446686\n",
            "step 2753: generator_loss=2.004979372024536, discriminator_loss=0.2965596318244934\n",
            "step 2754: generator_loss=1.8124110698699951, discriminator_loss=0.3298361301422119\n",
            "step 2755: generator_loss=1.6939116716384888, discriminator_loss=0.36202019453048706\n",
            "step 2756: generator_loss=1.5138823986053467, discriminator_loss=0.4000079035758972\n",
            "step 2757: generator_loss=1.4683400392532349, discriminator_loss=0.41485321521759033\n",
            "step 2758: generator_loss=1.579688549041748, discriminator_loss=0.4033726155757904\n",
            "step 2759: generator_loss=1.7139966487884521, discriminator_loss=0.36428987979888916\n",
            "step 2760: generator_loss=1.7977591753005981, discriminator_loss=0.3325534462928772\n",
            "step 2761: generator_loss=1.7472162246704102, discriminator_loss=0.41286394000053406\n",
            "step 2762: generator_loss=1.7457917928695679, discriminator_loss=0.3213352560997009\n",
            "step 2763: generator_loss=1.7782025337219238, discriminator_loss=0.2859233021736145\n",
            "step 2764: generator_loss=1.7063579559326172, discriminator_loss=0.33519619703292847\n",
            "step 2765: generator_loss=1.7272632122039795, discriminator_loss=0.36890721321105957\n",
            "step 2766: generator_loss=1.700104832649231, discriminator_loss=0.26168346405029297\n",
            "step 2767: generator_loss=1.942104458808899, discriminator_loss=0.2575418949127197\n",
            "step 2768: generator_loss=2.0835940837860107, discriminator_loss=0.21949046850204468\n",
            "step 2769: generator_loss=2.282679557800293, discriminator_loss=0.2744652032852173\n",
            "step 2770: generator_loss=2.295252799987793, discriminator_loss=0.18943950533866882\n",
            "step 2771: generator_loss=2.4763565063476562, discriminator_loss=0.17709647119045258\n",
            "step 2772: generator_loss=2.4550280570983887, discriminator_loss=0.16295169293880463\n",
            "step 2773: generator_loss=2.4756009578704834, discriminator_loss=0.17220565676689148\n",
            "step 2774: generator_loss=2.5186848640441895, discriminator_loss=0.1507684290409088\n",
            "step 2775: generator_loss=2.6772375106811523, discriminator_loss=0.10979387909173965\n",
            "step 2776: generator_loss=2.6922919750213623, discriminator_loss=0.13293060660362244\n",
            "step 2777: generator_loss=2.796506643295288, discriminator_loss=0.1072428748011589\n",
            "step 2778: generator_loss=2.9848084449768066, discriminator_loss=0.12656620144844055\n",
            "step 2779: generator_loss=2.8076252937316895, discriminator_loss=0.1134137436747551\n",
            "step 2780: generator_loss=2.8916409015655518, discriminator_loss=0.12176121026277542\n",
            "step 2781: generator_loss=2.814785957336426, discriminator_loss=0.1043117344379425\n",
            "step 2782: generator_loss=2.796149492263794, discriminator_loss=0.0887279137969017\n",
            "step 2783: generator_loss=2.9057300090789795, discriminator_loss=0.12990155816078186\n",
            "step 2784: generator_loss=2.8623485565185547, discriminator_loss=0.10859315097332001\n",
            "step 2785: generator_loss=2.579662322998047, discriminator_loss=0.13124603033065796\n",
            "step 2786: generator_loss=2.55623197555542, discriminator_loss=0.13163192570209503\n",
            "step 2787: generator_loss=2.3575868606567383, discriminator_loss=0.14130118489265442\n",
            "step 2788: generator_loss=2.243821144104004, discriminator_loss=0.12550655007362366\n",
            "step 2789: generator_loss=2.1195855140686035, discriminator_loss=0.14791584014892578\n",
            "step 2790: generator_loss=2.2804908752441406, discriminator_loss=0.1692185401916504\n",
            "step 2791: generator_loss=2.225614070892334, discriminator_loss=0.1608399748802185\n",
            "step 2792: generator_loss=2.42883038520813, discriminator_loss=0.13011324405670166\n",
            "step 2793: generator_loss=2.579164981842041, discriminator_loss=0.10751287639141083\n",
            "step 2794: generator_loss=2.6143574714660645, discriminator_loss=0.13828018307685852\n",
            "step 2795: generator_loss=2.6845204830169678, discriminator_loss=0.14235223829746246\n",
            "step 2796: generator_loss=2.5816380977630615, discriminator_loss=0.16649949550628662\n",
            "step 2797: generator_loss=2.4498050212860107, discriminator_loss=0.15053853392601013\n",
            "step 2798: generator_loss=2.505134344100952, discriminator_loss=0.16120418906211853\n",
            "step 2799: generator_loss=2.3166913986206055, discriminator_loss=0.1410069763660431\n",
            "step 2800: generator_loss=2.457777976989746, discriminator_loss=0.13266801834106445\n",
            "step 2801: generator_loss=2.3136355876922607, discriminator_loss=0.1943182647228241\n",
            "step 2802: generator_loss=2.5717239379882812, discriminator_loss=0.1723358929157257\n",
            "step 2803: generator_loss=2.5438146591186523, discriminator_loss=0.18181270360946655\n",
            "step 2804: generator_loss=2.4973788261413574, discriminator_loss=0.19088181853294373\n",
            "step 2805: generator_loss=2.7042245864868164, discriminator_loss=0.19950470328330994\n",
            "step 2806: generator_loss=2.539485454559326, discriminator_loss=0.19631120562553406\n",
            "step 2807: generator_loss=2.32553768157959, discriminator_loss=0.20133328437805176\n",
            "step 2808: generator_loss=2.228506326675415, discriminator_loss=0.2217494249343872\n",
            "step 2809: generator_loss=2.14138126373291, discriminator_loss=0.19114035367965698\n",
            "step 2810: generator_loss=2.169271469116211, discriminator_loss=0.16840361058712006\n",
            "step 2811: generator_loss=2.380551338195801, discriminator_loss=0.17496153712272644\n",
            "step 2812: generator_loss=2.407015085220337, discriminator_loss=0.1840369701385498\n",
            "step 2813: generator_loss=2.5296506881713867, discriminator_loss=0.1581866294145584\n",
            "step 2814: generator_loss=2.7694854736328125, discriminator_loss=0.1714421957731247\n",
            "step 2815: generator_loss=2.6691536903381348, discriminator_loss=0.19918377697467804\n",
            "step 2816: generator_loss=2.5149874687194824, discriminator_loss=0.148362934589386\n",
            "step 2817: generator_loss=2.308518409729004, discriminator_loss=0.1888454258441925\n",
            "step 2818: generator_loss=2.2473223209381104, discriminator_loss=0.16304758191108704\n",
            "step 2819: generator_loss=2.200911045074463, discriminator_loss=0.14336101710796356\n",
            "step 2820: generator_loss=2.156259059906006, discriminator_loss=0.17441090941429138\n",
            "step 2821: generator_loss=2.23624324798584, discriminator_loss=0.18178680539131165\n",
            "step 2822: generator_loss=2.292740821838379, discriminator_loss=0.19588333368301392\n",
            "step 2823: generator_loss=2.4001379013061523, discriminator_loss=0.17285577952861786\n",
            "step 2824: generator_loss=2.430485725402832, discriminator_loss=0.19522449374198914\n",
            "step 2825: generator_loss=2.429703950881958, discriminator_loss=0.2551959753036499\n",
            "step 2826: generator_loss=2.2451629638671875, discriminator_loss=0.24183796346187592\n",
            "step 2827: generator_loss=2.3604469299316406, discriminator_loss=0.21907658874988556\n",
            "step 2828: generator_loss=2.3028371334075928, discriminator_loss=0.2692033648490906\n",
            "step 2829: generator_loss=2.527165412902832, discriminator_loss=0.2460886389017105\n",
            "step 2830: generator_loss=2.388669490814209, discriminator_loss=0.28801020979881287\n",
            "step 2831: generator_loss=2.640860080718994, discriminator_loss=0.2333013266324997\n",
            "step 2832: generator_loss=2.6116600036621094, discriminator_loss=0.2810041308403015\n",
            "step 2833: generator_loss=2.7432169914245605, discriminator_loss=0.2599499821662903\n",
            "step 2834: generator_loss=2.6686973571777344, discriminator_loss=0.23908589780330658\n",
            "step 2835: generator_loss=2.812706232070923, discriminator_loss=0.22745013236999512\n",
            "step 2836: generator_loss=2.53877592086792, discriminator_loss=0.23769786953926086\n",
            "step 2837: generator_loss=2.3989169597625732, discriminator_loss=0.27407556772232056\n",
            "step 2838: generator_loss=2.8065433502197266, discriminator_loss=0.20134320855140686\n",
            "step 2839: generator_loss=3.0030131340026855, discriminator_loss=0.218309685587883\n",
            "step 2840: generator_loss=3.0400142669677734, discriminator_loss=0.22842003405094147\n",
            "step 2841: generator_loss=3.380521297454834, discriminator_loss=0.2365659475326538\n",
            "step 2842: generator_loss=3.7389607429504395, discriminator_loss=0.2338165044784546\n",
            "step 2843: generator_loss=4.192439556121826, discriminator_loss=0.20255239307880402\n",
            "step 2844: generator_loss=3.945875406265259, discriminator_loss=0.2279132902622223\n",
            "step 2845: generator_loss=3.801588535308838, discriminator_loss=0.19260697066783905\n",
            "step 2846: generator_loss=3.4118995666503906, discriminator_loss=0.2019246369600296\n",
            "step 2847: generator_loss=3.815622329711914, discriminator_loss=0.2015380859375\n",
            "step 2848: generator_loss=3.470029830932617, discriminator_loss=0.16165705025196075\n",
            "step 2849: generator_loss=3.3575799465179443, discriminator_loss=0.17700231075286865\n",
            "step 2850: generator_loss=3.122255563735962, discriminator_loss=0.19393184781074524\n",
            "step 2851: generator_loss=2.7854928970336914, discriminator_loss=0.1897011250257492\n",
            "step 2852: generator_loss=3.0951359272003174, discriminator_loss=0.11306370049715042\n",
            "step 2853: generator_loss=2.8715415000915527, discriminator_loss=0.16141235828399658\n",
            "step 2854: generator_loss=2.909104824066162, discriminator_loss=0.135637566447258\n",
            "step 2855: generator_loss=3.1760830879211426, discriminator_loss=0.11839532852172852\n",
            "step 2856: generator_loss=3.2596654891967773, discriminator_loss=0.11253111064434052\n",
            "step 2857: generator_loss=3.226325750350952, discriminator_loss=0.11297029256820679\n",
            "step 2858: generator_loss=3.204378843307495, discriminator_loss=0.09267609566450119\n",
            "step 2859: generator_loss=3.51499080657959, discriminator_loss=0.11977529525756836\n",
            "step 2860: generator_loss=3.322849750518799, discriminator_loss=0.09459815919399261\n",
            "step 2861: generator_loss=3.2605724334716797, discriminator_loss=0.11576279997825623\n",
            "step 2862: generator_loss=3.2300689220428467, discriminator_loss=0.08994355797767639\n",
            "step 2863: generator_loss=2.8250865936279297, discriminator_loss=0.11603325605392456\n",
            "step 2864: generator_loss=2.8869550228118896, discriminator_loss=0.12378448247909546\n",
            "step 2865: generator_loss=2.6469154357910156, discriminator_loss=0.13442498445510864\n",
            "step 2866: generator_loss=3.0451724529266357, discriminator_loss=0.07435861229896545\n",
            "step 2867: generator_loss=2.9015698432922363, discriminator_loss=0.10704582929611206\n",
            "step 2868: generator_loss=2.9145941734313965, discriminator_loss=0.11290132254362106\n",
            "step 2869: generator_loss=3.272054672241211, discriminator_loss=0.10010181367397308\n",
            "step 2870: generator_loss=3.233957290649414, discriminator_loss=0.11605792492628098\n",
            "step 2871: generator_loss=3.1434173583984375, discriminator_loss=0.1009441390633583\n",
            "step 2872: generator_loss=3.3431248664855957, discriminator_loss=0.0999051183462143\n",
            "step 2873: generator_loss=3.08762264251709, discriminator_loss=0.11361081153154373\n",
            "step 2874: generator_loss=2.9368185997009277, discriminator_loss=0.12316809594631195\n",
            "step 2875: generator_loss=2.847207546234131, discriminator_loss=0.11767083406448364\n",
            "step 2876: generator_loss=2.563131332397461, discriminator_loss=0.14505602419376373\n",
            "step 2877: generator_loss=2.7911267280578613, discriminator_loss=0.1227596253156662\n",
            "step 2878: generator_loss=2.7362964153289795, discriminator_loss=0.1346726417541504\n",
            "step 2879: generator_loss=2.7738752365112305, discriminator_loss=0.11011335998773575\n",
            "step 2880: generator_loss=2.6484107971191406, discriminator_loss=0.12567444145679474\n",
            "step 2881: generator_loss=2.6321797370910645, discriminator_loss=0.13677054643630981\n",
            "step 2882: generator_loss=2.5895771980285645, discriminator_loss=0.12950003147125244\n",
            "step 2883: generator_loss=2.6272599697113037, discriminator_loss=0.10598176717758179\n",
            "step 2884: generator_loss=2.5960192680358887, discriminator_loss=0.10233773291110992\n",
            "step 2885: generator_loss=2.7414627075195312, discriminator_loss=0.09892899543046951\n",
            "step 2886: generator_loss=2.8450398445129395, discriminator_loss=0.1236841231584549\n",
            "step 2887: generator_loss=2.901583671569824, discriminator_loss=0.10348954796791077\n",
            "step 2888: generator_loss=2.74676775932312, discriminator_loss=0.11999931931495667\n",
            "step 2889: generator_loss=2.5732851028442383, discriminator_loss=0.11810881644487381\n",
            "step 2890: generator_loss=2.4528326988220215, discriminator_loss=0.12280711531639099\n",
            "step 2891: generator_loss=2.3426320552825928, discriminator_loss=0.12328414618968964\n",
            "step 2892: generator_loss=2.2987775802612305, discriminator_loss=0.12186257541179657\n",
            "step 2893: generator_loss=2.1700072288513184, discriminator_loss=0.16110295057296753\n",
            "step 2894: generator_loss=2.209758758544922, discriminator_loss=0.1265297681093216\n",
            "step 2895: generator_loss=2.2721569538116455, discriminator_loss=0.14846393465995789\n",
            "step 2896: generator_loss=2.2493979930877686, discriminator_loss=0.15818597376346588\n",
            "step 2897: generator_loss=2.293104648590088, discriminator_loss=0.1458374559879303\n",
            "step 2898: generator_loss=2.357203245162964, discriminator_loss=0.1658671349287033\n",
            "step 2899: generator_loss=2.2236804962158203, discriminator_loss=0.14948207139968872\n",
            "step 2900: generator_loss=2.2249200344085693, discriminator_loss=0.13463738560676575\n",
            "step 2901: generator_loss=2.0992913246154785, discriminator_loss=0.14990872144699097\n",
            "step 2902: generator_loss=2.220705509185791, discriminator_loss=0.14894312620162964\n",
            "step 2903: generator_loss=2.142873764038086, discriminator_loss=0.15569880604743958\n",
            "step 2904: generator_loss=2.3264527320861816, discriminator_loss=0.15155929327011108\n",
            "step 2905: generator_loss=2.2787108421325684, discriminator_loss=0.14717912673950195\n",
            "step 2906: generator_loss=2.3353610038757324, discriminator_loss=0.1685703694820404\n",
            "step 2907: generator_loss=2.2160515785217285, discriminator_loss=0.1852542757987976\n",
            "step 2908: generator_loss=2.2535622119903564, discriminator_loss=0.14549514651298523\n",
            "step 2909: generator_loss=2.439056396484375, discriminator_loss=0.14768639206886292\n",
            "step 2910: generator_loss=2.7336068153381348, discriminator_loss=0.13668562471866608\n",
            "step 2911: generator_loss=2.345384120941162, discriminator_loss=0.1569034457206726\n",
            "step 2912: generator_loss=2.2314186096191406, discriminator_loss=0.16109836101531982\n",
            "step 2913: generator_loss=2.4613993167877197, discriminator_loss=0.15769921243190765\n",
            "step 2914: generator_loss=2.2558584213256836, discriminator_loss=0.1434820294380188\n",
            "step 2915: generator_loss=2.4056105613708496, discriminator_loss=0.13961157202720642\n",
            "step 2916: generator_loss=2.320009708404541, discriminator_loss=0.20710179209709167\n",
            "step 2917: generator_loss=2.3990743160247803, discriminator_loss=0.16839206218719482\n",
            "step 2918: generator_loss=2.2324299812316895, discriminator_loss=0.1605079472064972\n",
            "step 2919: generator_loss=2.2110824584960938, discriminator_loss=0.19312602281570435\n",
            "step 2920: generator_loss=2.223069190979004, discriminator_loss=0.2598411440849304\n",
            "step 2921: generator_loss=2.283428192138672, discriminator_loss=0.24977350234985352\n",
            "step 2922: generator_loss=2.449423313140869, discriminator_loss=0.2534792423248291\n",
            "step 2923: generator_loss=2.5478222370147705, discriminator_loss=0.2219131737947464\n",
            "step 2924: generator_loss=2.4153409004211426, discriminator_loss=0.2820602059364319\n",
            "step 2925: generator_loss=2.1757822036743164, discriminator_loss=0.3482338786125183\n",
            "step 2926: generator_loss=2.1561696529388428, discriminator_loss=0.34092554450035095\n",
            "step 2927: generator_loss=2.020247459411621, discriminator_loss=0.351412296295166\n",
            "step 2928: generator_loss=2.1192970275878906, discriminator_loss=0.28364235162734985\n",
            "step 2929: generator_loss=2.433143138885498, discriminator_loss=0.256122350692749\n",
            "step 2930: generator_loss=2.73398494720459, discriminator_loss=0.29429706931114197\n",
            "step 2931: generator_loss=2.984766960144043, discriminator_loss=0.19270473718643188\n",
            "step 2932: generator_loss=2.8406338691711426, discriminator_loss=0.2194633185863495\n",
            "step 2933: generator_loss=3.094132423400879, discriminator_loss=0.17923641204833984\n",
            "step 2934: generator_loss=3.0420806407928467, discriminator_loss=0.17814114689826965\n",
            "step 2935: generator_loss=3.203296661376953, discriminator_loss=0.14269405603408813\n",
            "step 2936: generator_loss=3.2762765884399414, discriminator_loss=0.1299358606338501\n",
            "step 2937: generator_loss=3.0614335536956787, discriminator_loss=0.11551310122013092\n",
            "step 2938: generator_loss=2.956481456756592, discriminator_loss=0.1318977177143097\n",
            "step 2939: generator_loss=2.985214948654175, discriminator_loss=0.14761851727962494\n",
            "step 2940: generator_loss=2.967400074005127, discriminator_loss=0.13894784450531006\n",
            "step 2941: generator_loss=3.177140235900879, discriminator_loss=0.12417895346879959\n",
            "step 2942: generator_loss=3.076930046081543, discriminator_loss=0.13145826756954193\n",
            "step 2943: generator_loss=3.5227088928222656, discriminator_loss=0.1212090328335762\n",
            "step 2944: generator_loss=3.4018797874450684, discriminator_loss=0.11111294478178024\n",
            "step 2945: generator_loss=3.376749038696289, discriminator_loss=0.09505072981119156\n",
            "step 2946: generator_loss=3.2980117797851562, discriminator_loss=0.10247796773910522\n",
            "step 2947: generator_loss=3.366069793701172, discriminator_loss=0.11110299825668335\n",
            "step 2948: generator_loss=3.2768375873565674, discriminator_loss=0.1130513995885849\n",
            "step 2949: generator_loss=3.0030159950256348, discriminator_loss=0.09610813111066818\n",
            "step 2950: generator_loss=2.906647205352783, discriminator_loss=0.12551912665367126\n",
            "step 2951: generator_loss=3.0307505130767822, discriminator_loss=0.08894224464893341\n",
            "step 2952: generator_loss=3.017129421234131, discriminator_loss=0.10384760797023773\n",
            "step 2953: generator_loss=2.853543281555176, discriminator_loss=0.11289811879396439\n",
            "step 2954: generator_loss=2.8500192165374756, discriminator_loss=0.08860853314399719\n",
            "step 2955: generator_loss=2.7999181747436523, discriminator_loss=0.09917829930782318\n",
            "step 2956: generator_loss=2.813077688217163, discriminator_loss=0.12362406402826309\n",
            "step 2957: generator_loss=2.7637529373168945, discriminator_loss=0.1095040962100029\n",
            "step 2958: generator_loss=2.6685686111450195, discriminator_loss=0.1459188014268875\n",
            "step 2959: generator_loss=2.4414637088775635, discriminator_loss=0.1279454231262207\n",
            "step 2960: generator_loss=2.3822059631347656, discriminator_loss=0.1609698235988617\n",
            "step 2961: generator_loss=2.43084716796875, discriminator_loss=0.16893069446086884\n",
            "step 2962: generator_loss=2.5175628662109375, discriminator_loss=0.11140155047178268\n",
            "step 2963: generator_loss=2.3772926330566406, discriminator_loss=0.15918835997581482\n",
            "step 2964: generator_loss=2.3085365295410156, discriminator_loss=0.14653995633125305\n",
            "step 2965: generator_loss=2.3792433738708496, discriminator_loss=0.15038231015205383\n",
            "step 2966: generator_loss=2.329094648361206, discriminator_loss=0.16780535876750946\n",
            "step 2967: generator_loss=2.2683589458465576, discriminator_loss=0.15666458010673523\n",
            "step 2968: generator_loss=2.417919874191284, discriminator_loss=0.1832447648048401\n",
            "step 2969: generator_loss=2.2774181365966797, discriminator_loss=0.2098848819732666\n",
            "step 2970: generator_loss=2.3539857864379883, discriminator_loss=0.17643561959266663\n",
            "step 2971: generator_loss=2.3162412643432617, discriminator_loss=0.19439271092414856\n",
            "step 2972: generator_loss=2.7011356353759766, discriminator_loss=0.1530420184135437\n",
            "step 2973: generator_loss=2.6012463569641113, discriminator_loss=0.19524376094341278\n",
            "step 2974: generator_loss=2.383391857147217, discriminator_loss=0.2172083556652069\n",
            "step 2975: generator_loss=2.4145658016204834, discriminator_loss=0.2052249014377594\n",
            "step 2976: generator_loss=2.1217827796936035, discriminator_loss=0.2269825041294098\n",
            "step 2977: generator_loss=2.1871020793914795, discriminator_loss=0.240278422832489\n",
            "step 2978: generator_loss=2.2090396881103516, discriminator_loss=0.24907799065113068\n",
            "step 2979: generator_loss=2.082528591156006, discriminator_loss=0.24920840561389923\n",
            "step 2980: generator_loss=2.242051839828491, discriminator_loss=0.22282510995864868\n",
            "step 2981: generator_loss=2.26222825050354, discriminator_loss=0.25478193163871765\n",
            "step 2982: generator_loss=2.455449104309082, discriminator_loss=0.1994352787733078\n",
            "step 2983: generator_loss=2.52644944190979, discriminator_loss=0.25075563788414\n",
            "step 2984: generator_loss=2.522125720977783, discriminator_loss=0.2243337333202362\n",
            "step 2985: generator_loss=2.2420716285705566, discriminator_loss=0.27835845947265625\n",
            "step 2986: generator_loss=2.2760021686553955, discriminator_loss=0.3025320768356323\n",
            "step 2987: generator_loss=2.4635796546936035, discriminator_loss=0.28001466393470764\n",
            "step 2988: generator_loss=2.380939245223999, discriminator_loss=0.28594332933425903\n",
            "step 2989: generator_loss=2.19041109085083, discriminator_loss=0.34701991081237793\n",
            "step 2990: generator_loss=2.0995383262634277, discriminator_loss=0.3655746579170227\n",
            "step 2991: generator_loss=2.198716402053833, discriminator_loss=0.3681519329547882\n",
            "step 2992: generator_loss=2.6588196754455566, discriminator_loss=0.3417403995990753\n",
            "step 2993: generator_loss=3.0236129760742188, discriminator_loss=0.2780582308769226\n",
            "step 2994: generator_loss=2.6728734970092773, discriminator_loss=0.34584277868270874\n",
            "step 2995: generator_loss=3.2055323123931885, discriminator_loss=0.2959088385105133\n",
            "step 2996: generator_loss=3.1632347106933594, discriminator_loss=0.2360842376947403\n",
            "step 2997: generator_loss=3.3985819816589355, discriminator_loss=0.23287715017795563\n",
            "step 2998: generator_loss=3.694088935852051, discriminator_loss=0.21129176020622253\n",
            "step 2999: generator_loss=3.3982670307159424, discriminator_loss=0.17511789500713348\n",
            "step 3000: generator_loss=3.594498872756958, discriminator_loss=0.16801968216896057\n",
            "step 3001: generator_loss=3.4182887077331543, discriminator_loss=0.11529217660427094\n",
            "step 3002: generator_loss=3.1919636726379395, discriminator_loss=0.14822080731391907\n",
            "step 3003: generator_loss=2.809535503387451, discriminator_loss=0.12052527815103531\n",
            "step 3004: generator_loss=3.214621067047119, discriminator_loss=0.11499280482530594\n",
            "step 3005: generator_loss=2.9462320804595947, discriminator_loss=0.13602745532989502\n",
            "step 3006: generator_loss=3.1556825637817383, discriminator_loss=0.11354433000087738\n",
            "step 3007: generator_loss=3.0749950408935547, discriminator_loss=0.11149634420871735\n",
            "step 3008: generator_loss=3.3522748947143555, discriminator_loss=0.14343874156475067\n",
            "step 3009: generator_loss=3.1669821739196777, discriminator_loss=0.12895141541957855\n",
            "step 3010: generator_loss=3.1194329261779785, discriminator_loss=0.13763736188411713\n",
            "step 3011: generator_loss=2.910428524017334, discriminator_loss=0.14881131052970886\n",
            "step 3012: generator_loss=2.6140732765197754, discriminator_loss=0.17341214418411255\n",
            "step 3013: generator_loss=2.446850299835205, discriminator_loss=0.20704016089439392\n",
            "step 3014: generator_loss=2.2473886013031006, discriminator_loss=0.18772479891777039\n",
            "step 3015: generator_loss=2.080343246459961, discriminator_loss=0.18283063173294067\n",
            "step 3016: generator_loss=2.341698169708252, discriminator_loss=0.1710619330406189\n",
            "step 3017: generator_loss=2.1712303161621094, discriminator_loss=0.22404974699020386\n",
            "step 3018: generator_loss=2.4732632637023926, discriminator_loss=0.16011324524879456\n",
            "step 3019: generator_loss=2.276215076446533, discriminator_loss=0.1986989974975586\n",
            "step 3020: generator_loss=2.552428960800171, discriminator_loss=0.21136131882667542\n",
            "step 3021: generator_loss=2.293762683868408, discriminator_loss=0.2313169240951538\n",
            "step 3022: generator_loss=2.314145088195801, discriminator_loss=0.1825571358203888\n",
            "step 3023: generator_loss=2.1894679069519043, discriminator_loss=0.2073025107383728\n",
            "step 3024: generator_loss=2.1940383911132812, discriminator_loss=0.1666039228439331\n",
            "step 3025: generator_loss=2.1923446655273438, discriminator_loss=0.1863839030265808\n",
            "step 3026: generator_loss=2.1851742267608643, discriminator_loss=0.19650490581989288\n",
            "step 3027: generator_loss=2.254368305206299, discriminator_loss=0.19060519337654114\n",
            "step 3028: generator_loss=2.357999324798584, discriminator_loss=0.20153476297855377\n",
            "step 3029: generator_loss=2.293550968170166, discriminator_loss=0.20266224443912506\n",
            "step 3030: generator_loss=2.1223134994506836, discriminator_loss=0.25189024209976196\n",
            "step 3031: generator_loss=2.0145535469055176, discriminator_loss=0.20925480127334595\n",
            "step 3032: generator_loss=1.8858258724212646, discriminator_loss=0.261568546295166\n",
            "step 3033: generator_loss=1.9257352352142334, discriminator_loss=0.2444327026605606\n",
            "step 3034: generator_loss=1.9525967836380005, discriminator_loss=0.217455193400383\n",
            "step 3035: generator_loss=1.94231379032135, discriminator_loss=0.2984069585800171\n",
            "step 3036: generator_loss=1.8709858655929565, discriminator_loss=0.2803187966346741\n",
            "step 3037: generator_loss=1.81917405128479, discriminator_loss=0.33751869201660156\n",
            "step 3038: generator_loss=1.9624848365783691, discriminator_loss=0.2965514659881592\n",
            "step 3039: generator_loss=1.644132137298584, discriminator_loss=0.33273783326148987\n",
            "step 3040: generator_loss=1.564657211303711, discriminator_loss=0.3424653708934784\n",
            "step 3041: generator_loss=1.679335594177246, discriminator_loss=0.31581419706344604\n",
            "step 3042: generator_loss=1.6696197986602783, discriminator_loss=0.3060854971408844\n",
            "step 3043: generator_loss=1.8193998336791992, discriminator_loss=0.3245795667171478\n",
            "step 3044: generator_loss=2.001647472381592, discriminator_loss=0.27014994621276855\n",
            "step 3045: generator_loss=2.040478229522705, discriminator_loss=0.2564234137535095\n",
            "step 3046: generator_loss=1.999266266822815, discriminator_loss=0.2794765532016754\n",
            "step 3047: generator_loss=2.205721378326416, discriminator_loss=0.2566627562046051\n",
            "step 3048: generator_loss=2.096890449523926, discriminator_loss=0.2676811218261719\n",
            "step 3049: generator_loss=2.179962635040283, discriminator_loss=0.1848503053188324\n",
            "step 3050: generator_loss=1.9563956260681152, discriminator_loss=0.21689189970493317\n",
            "step 3051: generator_loss=1.9869248867034912, discriminator_loss=0.2250204086303711\n",
            "step 3052: generator_loss=1.9896950721740723, discriminator_loss=0.22432520985603333\n",
            "step 3053: generator_loss=2.084779739379883, discriminator_loss=0.22344905138015747\n",
            "step 3054: generator_loss=2.055968999862671, discriminator_loss=0.1960386335849762\n",
            "step 3055: generator_loss=2.238192081451416, discriminator_loss=0.21801435947418213\n",
            "step 3056: generator_loss=2.012099266052246, discriminator_loss=0.22869926691055298\n",
            "step 3057: generator_loss=1.8784852027893066, discriminator_loss=0.2123669683933258\n",
            "step 3058: generator_loss=1.9378182888031006, discriminator_loss=0.18760336935520172\n",
            "step 3059: generator_loss=1.9632803201675415, discriminator_loss=0.17867405712604523\n",
            "step 3060: generator_loss=2.0364205837249756, discriminator_loss=0.2411072850227356\n",
            "step 3061: generator_loss=2.190323829650879, discriminator_loss=0.18244564533233643\n",
            "step 3062: generator_loss=2.301870107650757, discriminator_loss=0.17095860838890076\n",
            "step 3063: generator_loss=2.2310056686401367, discriminator_loss=0.18831564486026764\n",
            "step 3064: generator_loss=2.231731414794922, discriminator_loss=0.18946141004562378\n",
            "step 3065: generator_loss=2.2267227172851562, discriminator_loss=0.17107191681861877\n",
            "step 3066: generator_loss=2.0446572303771973, discriminator_loss=0.16847023367881775\n",
            "step 3067: generator_loss=2.0005176067352295, discriminator_loss=0.21255044639110565\n",
            "step 3068: generator_loss=1.8365375995635986, discriminator_loss=0.21386821568012238\n",
            "step 3069: generator_loss=2.061479091644287, discriminator_loss=0.19155177474021912\n",
            "step 3070: generator_loss=2.198554515838623, discriminator_loss=0.1835901290178299\n",
            "step 3071: generator_loss=2.3431873321533203, discriminator_loss=0.18044012784957886\n",
            "step 3072: generator_loss=2.28585147857666, discriminator_loss=0.21696282923221588\n",
            "step 3073: generator_loss=2.1956324577331543, discriminator_loss=0.21341340243816376\n",
            "step 3074: generator_loss=2.0495448112487793, discriminator_loss=0.20539593696594238\n",
            "step 3075: generator_loss=1.8341575860977173, discriminator_loss=0.20422060787677765\n",
            "step 3076: generator_loss=1.7306421995162964, discriminator_loss=0.20904046297073364\n",
            "step 3077: generator_loss=1.6756823062896729, discriminator_loss=0.2294292449951172\n",
            "step 3078: generator_loss=1.7818279266357422, discriminator_loss=0.22097750008106232\n",
            "step 3079: generator_loss=1.8830631971359253, discriminator_loss=0.23319467902183533\n",
            "step 3080: generator_loss=1.953381896018982, discriminator_loss=0.2410583645105362\n",
            "step 3081: generator_loss=1.8780627250671387, discriminator_loss=0.2610068917274475\n",
            "step 3082: generator_loss=1.9921205043792725, discriminator_loss=0.21094074845314026\n",
            "step 3083: generator_loss=1.8694225549697876, discriminator_loss=0.2511669397354126\n",
            "step 3084: generator_loss=1.861046552658081, discriminator_loss=0.2313806116580963\n",
            "step 3085: generator_loss=1.7554717063903809, discriminator_loss=0.25211629271507263\n",
            "step 3086: generator_loss=1.7486246824264526, discriminator_loss=0.21393531560897827\n",
            "step 3087: generator_loss=1.8080366849899292, discriminator_loss=0.21311089396476746\n",
            "step 3088: generator_loss=2.1741201877593994, discriminator_loss=0.13052082061767578\n",
            "step 3089: generator_loss=2.255582332611084, discriminator_loss=0.17835234105587006\n",
            "step 3090: generator_loss=2.4793190956115723, discriminator_loss=0.1607227921485901\n",
            "step 3091: generator_loss=2.462873935699463, discriminator_loss=0.15053501725196838\n",
            "step 3092: generator_loss=2.47088360786438, discriminator_loss=0.13243381679058075\n",
            "step 3093: generator_loss=2.405947208404541, discriminator_loss=0.14943602681159973\n",
            "step 3094: generator_loss=2.2628633975982666, discriminator_loss=0.14185798168182373\n",
            "step 3095: generator_loss=2.1342761516571045, discriminator_loss=0.1672167330980301\n",
            "step 3096: generator_loss=2.1058316230773926, discriminator_loss=0.17741486430168152\n",
            "step 3097: generator_loss=2.2220048904418945, discriminator_loss=0.137759730219841\n",
            "step 3098: generator_loss=2.3347697257995605, discriminator_loss=0.19789376854896545\n",
            "step 3099: generator_loss=2.2552359104156494, discriminator_loss=0.23070703446865082\n",
            "step 3100: generator_loss=2.360106945037842, discriminator_loss=0.28327322006225586\n",
            "step 3101: generator_loss=2.2473301887512207, discriminator_loss=0.2512075901031494\n",
            "step 3102: generator_loss=1.9477505683898926, discriminator_loss=0.31411024928092957\n",
            "step 3103: generator_loss=1.976548671722412, discriminator_loss=0.2443992644548416\n",
            "step 3104: generator_loss=1.9554815292358398, discriminator_loss=0.26725757122039795\n",
            "step 3105: generator_loss=1.9971332550048828, discriminator_loss=0.24996928870677948\n",
            "step 3106: generator_loss=2.0969173908233643, discriminator_loss=0.2351117581129074\n",
            "step 3107: generator_loss=2.1689023971557617, discriminator_loss=0.24743863940238953\n",
            "step 3108: generator_loss=2.2267465591430664, discriminator_loss=0.21238911151885986\n",
            "step 3109: generator_loss=2.166200637817383, discriminator_loss=0.22033962607383728\n",
            "step 3110: generator_loss=2.0407350063323975, discriminator_loss=0.23786139488220215\n",
            "step 3111: generator_loss=2.278223991394043, discriminator_loss=0.1632540225982666\n",
            "step 3112: generator_loss=2.2677478790283203, discriminator_loss=0.18656006455421448\n",
            "step 3113: generator_loss=2.132286787033081, discriminator_loss=0.174054354429245\n",
            "step 3114: generator_loss=2.1862263679504395, discriminator_loss=0.16042636334896088\n",
            "step 3115: generator_loss=2.4555983543395996, discriminator_loss=0.11659778654575348\n",
            "step 3116: generator_loss=2.4768383502960205, discriminator_loss=0.12890967726707458\n",
            "step 3117: generator_loss=2.743447780609131, discriminator_loss=0.11130259931087494\n",
            "step 3118: generator_loss=2.845571994781494, discriminator_loss=0.10790348052978516\n",
            "step 3119: generator_loss=2.865572214126587, discriminator_loss=0.13202804327011108\n",
            "step 3120: generator_loss=2.740328550338745, discriminator_loss=0.11364975571632385\n",
            "step 3121: generator_loss=2.781114339828491, discriminator_loss=0.10516354441642761\n",
            "step 3122: generator_loss=2.7078614234924316, discriminator_loss=0.1128033697605133\n",
            "step 3123: generator_loss=2.6249170303344727, discriminator_loss=0.12400777637958527\n",
            "step 3124: generator_loss=2.4390995502471924, discriminator_loss=0.10749039053916931\n",
            "step 3125: generator_loss=2.496018171310425, discriminator_loss=0.13467808067798615\n",
            "step 3126: generator_loss=2.644843578338623, discriminator_loss=0.14729169011116028\n",
            "step 3127: generator_loss=2.5480995178222656, discriminator_loss=0.1637311577796936\n",
            "step 3128: generator_loss=3.019441843032837, discriminator_loss=0.113371342420578\n",
            "step 3129: generator_loss=2.8669629096984863, discriminator_loss=0.14590191841125488\n",
            "step 3130: generator_loss=2.82680082321167, discriminator_loss=0.15742772817611694\n",
            "step 3131: generator_loss=2.807847499847412, discriminator_loss=0.15740135312080383\n",
            "step 3132: generator_loss=2.855966806411743, discriminator_loss=0.15710614621639252\n",
            "step 3133: generator_loss=2.681812047958374, discriminator_loss=0.16844800114631653\n",
            "step 3134: generator_loss=2.8409950733184814, discriminator_loss=0.11084611713886261\n",
            "step 3135: generator_loss=2.5418639183044434, discriminator_loss=0.1758803129196167\n",
            "step 3136: generator_loss=2.5677080154418945, discriminator_loss=0.1778215616941452\n",
            "step 3137: generator_loss=2.8670520782470703, discriminator_loss=0.1696898341178894\n",
            "step 3138: generator_loss=3.021552562713623, discriminator_loss=0.17063046991825104\n",
            "step 3139: generator_loss=3.3691701889038086, discriminator_loss=0.13143230974674225\n",
            "step 3140: generator_loss=3.8898444175720215, discriminator_loss=0.09741932153701782\n",
            "step 3141: generator_loss=3.7800779342651367, discriminator_loss=0.12171641737222672\n",
            "step 3142: generator_loss=3.495972156524658, discriminator_loss=0.11412276327610016\n",
            "step 3143: generator_loss=3.6543054580688477, discriminator_loss=0.11658413708209991\n",
            "step 3144: generator_loss=3.2926251888275146, discriminator_loss=0.11262337863445282\n",
            "step 3145: generator_loss=3.211301326751709, discriminator_loss=0.14147406816482544\n",
            "step 3146: generator_loss=3.079610824584961, discriminator_loss=0.13216647505760193\n",
            "step 3147: generator_loss=2.923384666442871, discriminator_loss=0.11799672245979309\n",
            "step 3148: generator_loss=2.9480457305908203, discriminator_loss=0.11352398991584778\n",
            "step 3149: generator_loss=2.916424512863159, discriminator_loss=0.14318494498729706\n",
            "step 3150: generator_loss=2.8306381702423096, discriminator_loss=0.14722158014774323\n",
            "step 3151: generator_loss=3.1774682998657227, discriminator_loss=0.11221414804458618\n",
            "step 3152: generator_loss=3.176368236541748, discriminator_loss=0.10070574283599854\n",
            "step 3153: generator_loss=3.0256972312927246, discriminator_loss=0.12216939777135849\n",
            "step 3154: generator_loss=2.922670364379883, discriminator_loss=0.13695332407951355\n",
            "step 3155: generator_loss=2.8369317054748535, discriminator_loss=0.12254473567008972\n",
            "step 3156: generator_loss=2.491988182067871, discriminator_loss=0.12460837513208389\n",
            "step 3157: generator_loss=2.3782968521118164, discriminator_loss=0.11359094828367233\n",
            "step 3158: generator_loss=2.1528244018554688, discriminator_loss=0.1665285974740982\n",
            "step 3159: generator_loss=2.2593588829040527, discriminator_loss=0.13737210631370544\n",
            "step 3160: generator_loss=2.2460360527038574, discriminator_loss=0.15720073878765106\n",
            "step 3161: generator_loss=2.2656421661376953, discriminator_loss=0.16893219947814941\n",
            "step 3162: generator_loss=2.3277292251586914, discriminator_loss=0.13400056958198547\n",
            "step 3163: generator_loss=2.309481382369995, discriminator_loss=0.19111403822898865\n",
            "step 3164: generator_loss=2.3712592124938965, discriminator_loss=0.20029646158218384\n",
            "step 3165: generator_loss=2.3677315711975098, discriminator_loss=0.1551080048084259\n",
            "step 3166: generator_loss=2.278055429458618, discriminator_loss=0.19130131602287292\n",
            "step 3167: generator_loss=2.2554776668548584, discriminator_loss=0.24159006774425507\n",
            "step 3168: generator_loss=2.0955302715301514, discriminator_loss=0.2606472373008728\n",
            "step 3169: generator_loss=2.158745288848877, discriminator_loss=0.25783610343933105\n",
            "step 3170: generator_loss=2.190037727355957, discriminator_loss=0.24238239228725433\n",
            "step 3171: generator_loss=2.365109443664551, discriminator_loss=0.2736179232597351\n",
            "step 3172: generator_loss=2.123886823654175, discriminator_loss=0.3244999349117279\n",
            "step 3173: generator_loss=2.8180441856384277, discriminator_loss=0.23813748359680176\n",
            "step 3174: generator_loss=2.4688668251037598, discriminator_loss=0.26288002729415894\n",
            "step 3175: generator_loss=2.711953639984131, discriminator_loss=0.22812804579734802\n",
            "step 3176: generator_loss=2.4498627185821533, discriminator_loss=0.2501656115055084\n",
            "step 3177: generator_loss=3.0238518714904785, discriminator_loss=0.20090124011039734\n",
            "step 3178: generator_loss=3.306896209716797, discriminator_loss=0.2047903835773468\n",
            "step 3179: generator_loss=3.3382039070129395, discriminator_loss=0.1904689371585846\n",
            "step 3180: generator_loss=3.8303332328796387, discriminator_loss=0.15129032731056213\n",
            "step 3181: generator_loss=3.4713640213012695, discriminator_loss=0.12042497098445892\n",
            "step 3182: generator_loss=3.4944982528686523, discriminator_loss=0.15425193309783936\n",
            "step 3183: generator_loss=3.6938157081604004, discriminator_loss=0.12618336081504822\n",
            "step 3184: generator_loss=3.462677240371704, discriminator_loss=0.13093945384025574\n",
            "step 3185: generator_loss=3.155449867248535, discriminator_loss=0.13109305500984192\n",
            "step 3186: generator_loss=3.2069308757781982, discriminator_loss=0.1439877152442932\n",
            "step 3187: generator_loss=3.090620994567871, discriminator_loss=0.10769064724445343\n",
            "step 3188: generator_loss=2.646742820739746, discriminator_loss=0.14525888860225677\n",
            "step 3189: generator_loss=2.899442195892334, discriminator_loss=0.15304583311080933\n",
            "step 3190: generator_loss=2.8891994953155518, discriminator_loss=0.14137250185012817\n",
            "step 3191: generator_loss=3.107975482940674, discriminator_loss=0.1161889061331749\n",
            "step 3192: generator_loss=3.033304214477539, discriminator_loss=0.11450999975204468\n",
            "step 3193: generator_loss=3.1433143615722656, discriminator_loss=0.11869227886199951\n",
            "step 3194: generator_loss=3.278076171875, discriminator_loss=0.1026960238814354\n",
            "step 3195: generator_loss=3.204468250274658, discriminator_loss=0.13504420220851898\n",
            "step 3196: generator_loss=3.249603271484375, discriminator_loss=0.11600082367658615\n",
            "step 3197: generator_loss=3.531665325164795, discriminator_loss=0.12510131299495697\n",
            "step 3198: generator_loss=3.3319053649902344, discriminator_loss=0.1472095549106598\n",
            "step 3199: generator_loss=3.1583194732666016, discriminator_loss=0.17530228197574615\n",
            "step 3200: generator_loss=3.019351005554199, discriminator_loss=0.20333941280841827\n",
            "step 3201: generator_loss=2.7561373710632324, discriminator_loss=0.21425151824951172\n",
            "step 3202: generator_loss=2.798248767852783, discriminator_loss=0.1935766637325287\n",
            "step 3203: generator_loss=2.7328944206237793, discriminator_loss=0.21254554390907288\n",
            "step 3204: generator_loss=2.8012197017669678, discriminator_loss=0.2737789452075958\n",
            "step 3205: generator_loss=2.7643849849700928, discriminator_loss=0.3015682101249695\n",
            "step 3206: generator_loss=2.7645277976989746, discriminator_loss=0.29371318221092224\n",
            "step 3207: generator_loss=3.14434814453125, discriminator_loss=0.24075818061828613\n",
            "step 3208: generator_loss=3.082867383956909, discriminator_loss=0.2654920816421509\n",
            "step 3209: generator_loss=3.1482958793640137, discriminator_loss=0.21127384901046753\n",
            "step 3210: generator_loss=3.236929416656494, discriminator_loss=0.19219990074634552\n",
            "step 3211: generator_loss=3.0462417602539062, discriminator_loss=0.20148378610610962\n",
            "step 3212: generator_loss=2.8613672256469727, discriminator_loss=0.18774467706680298\n",
            "step 3213: generator_loss=2.834290027618408, discriminator_loss=0.15845224261283875\n",
            "step 3214: generator_loss=2.91200590133667, discriminator_loss=0.19531014561653137\n",
            "step 3215: generator_loss=2.8003294467926025, discriminator_loss=0.1730949580669403\n",
            "step 3216: generator_loss=2.629324436187744, discriminator_loss=0.15811744332313538\n",
            "step 3217: generator_loss=2.8961164951324463, discriminator_loss=0.14019887149333954\n",
            "step 3218: generator_loss=3.016080141067505, discriminator_loss=0.13291478157043457\n",
            "step 3219: generator_loss=2.5456833839416504, discriminator_loss=0.14380066096782684\n",
            "step 3220: generator_loss=2.9787511825561523, discriminator_loss=0.15389053523540497\n",
            "step 3221: generator_loss=2.7685256004333496, discriminator_loss=0.1629680097103119\n",
            "step 3222: generator_loss=2.8821442127227783, discriminator_loss=0.1611315906047821\n",
            "step 3223: generator_loss=2.5146608352661133, discriminator_loss=0.1864314079284668\n",
            "step 3224: generator_loss=2.345259666442871, discriminator_loss=0.15886595845222473\n",
            "step 3225: generator_loss=2.629338502883911, discriminator_loss=0.16917891800403595\n",
            "step 3226: generator_loss=2.4441561698913574, discriminator_loss=0.214939683675766\n",
            "step 3227: generator_loss=2.40376353263855, discriminator_loss=0.2077847719192505\n",
            "step 3228: generator_loss=2.523836612701416, discriminator_loss=0.17450998723506927\n",
            "step 3229: generator_loss=2.438401222229004, discriminator_loss=0.21183954179286957\n",
            "step 3230: generator_loss=2.591423988342285, discriminator_loss=0.16805203258991241\n",
            "step 3231: generator_loss=2.5811944007873535, discriminator_loss=0.16211262345314026\n",
            "step 3232: generator_loss=2.475524663925171, discriminator_loss=0.16072365641593933\n",
            "step 3233: generator_loss=2.613734722137451, discriminator_loss=0.15482580661773682\n",
            "step 3234: generator_loss=2.5080361366271973, discriminator_loss=0.19224762916564941\n",
            "step 3235: generator_loss=2.4549262523651123, discriminator_loss=0.1782730221748352\n",
            "step 3236: generator_loss=2.3735718727111816, discriminator_loss=0.13471999764442444\n",
            "step 3237: generator_loss=2.463289260864258, discriminator_loss=0.1262596696615219\n",
            "step 3238: generator_loss=2.4798672199249268, discriminator_loss=0.17976707220077515\n",
            "step 3239: generator_loss=2.3585457801818848, discriminator_loss=0.12362541258335114\n",
            "step 3240: generator_loss=2.688187599182129, discriminator_loss=0.10759139060974121\n",
            "step 3241: generator_loss=2.508202075958252, discriminator_loss=0.1336793601512909\n",
            "step 3242: generator_loss=2.7873528003692627, discriminator_loss=0.16513299942016602\n",
            "step 3243: generator_loss=2.611859083175659, discriminator_loss=0.1804489940404892\n",
            "step 3244: generator_loss=2.4852144718170166, discriminator_loss=0.16526219248771667\n",
            "step 3245: generator_loss=2.6346874237060547, discriminator_loss=0.14566493034362793\n",
            "step 3246: generator_loss=2.638021945953369, discriminator_loss=0.14795932173728943\n",
            "step 3247: generator_loss=2.6096949577331543, discriminator_loss=0.18566405773162842\n",
            "step 3248: generator_loss=2.461306095123291, discriminator_loss=0.16787776350975037\n",
            "step 3249: generator_loss=2.266566753387451, discriminator_loss=0.15480732917785645\n",
            "step 3250: generator_loss=2.086299180984497, discriminator_loss=0.2105012983083725\n",
            "step 3251: generator_loss=1.9760870933532715, discriminator_loss=0.17952895164489746\n",
            "step 3252: generator_loss=1.923494815826416, discriminator_loss=0.23455779254436493\n",
            "step 3253: generator_loss=1.9489362239837646, discriminator_loss=0.19650334119796753\n",
            "step 3254: generator_loss=2.2513673305511475, discriminator_loss=0.19380538165569305\n",
            "step 3255: generator_loss=2.111280918121338, discriminator_loss=0.19360843300819397\n",
            "step 3256: generator_loss=2.206960916519165, discriminator_loss=0.18810389935970306\n",
            "step 3257: generator_loss=2.383603572845459, discriminator_loss=0.18688702583312988\n",
            "step 3258: generator_loss=2.1829934120178223, discriminator_loss=0.26200756430625916\n",
            "step 3259: generator_loss=2.2691268920898438, discriminator_loss=0.21309825778007507\n",
            "step 3260: generator_loss=2.3650898933410645, discriminator_loss=0.2833908200263977\n",
            "step 3261: generator_loss=2.4263603687286377, discriminator_loss=0.2715604603290558\n",
            "step 3262: generator_loss=2.2711715698242188, discriminator_loss=0.28356707096099854\n",
            "step 3263: generator_loss=2.0904908180236816, discriminator_loss=0.32323575019836426\n",
            "step 3264: generator_loss=2.324512481689453, discriminator_loss=0.33600953221321106\n",
            "step 3265: generator_loss=2.0925283432006836, discriminator_loss=0.3733465373516083\n",
            "step 3266: generator_loss=2.158740520477295, discriminator_loss=0.32436418533325195\n",
            "step 3267: generator_loss=2.334958553314209, discriminator_loss=0.3915923237800598\n",
            "step 3268: generator_loss=2.6162116527557373, discriminator_loss=0.3148953318595886\n",
            "step 3269: generator_loss=2.632343053817749, discriminator_loss=0.3140128552913666\n",
            "step 3270: generator_loss=2.8670105934143066, discriminator_loss=0.293628454208374\n",
            "step 3271: generator_loss=2.4516494274139404, discriminator_loss=0.3765053153038025\n",
            "step 3272: generator_loss=2.498457431793213, discriminator_loss=0.3061369061470032\n",
            "step 3273: generator_loss=2.541490077972412, discriminator_loss=0.23671121895313263\n",
            "step 3274: generator_loss=2.304708480834961, discriminator_loss=0.2902618646621704\n",
            "step 3275: generator_loss=2.6297712326049805, discriminator_loss=0.2603453993797302\n",
            "step 3276: generator_loss=2.724588394165039, discriminator_loss=0.21912673115730286\n",
            "step 3277: generator_loss=2.823262929916382, discriminator_loss=0.19862033426761627\n",
            "step 3278: generator_loss=2.892090320587158, discriminator_loss=0.17092490196228027\n",
            "step 3279: generator_loss=2.844589948654175, discriminator_loss=0.15801554918289185\n",
            "step 3280: generator_loss=2.8325085639953613, discriminator_loss=0.2023579478263855\n",
            "step 3281: generator_loss=2.9171509742736816, discriminator_loss=0.1707543283700943\n",
            "step 3282: generator_loss=2.6776180267333984, discriminator_loss=0.18558773398399353\n",
            "step 3283: generator_loss=2.5797696113586426, discriminator_loss=0.2193903774023056\n",
            "step 3284: generator_loss=2.709792137145996, discriminator_loss=0.17729796469211578\n",
            "step 3285: generator_loss=2.5654702186584473, discriminator_loss=0.2018793523311615\n",
            "step 3286: generator_loss=2.756547689437866, discriminator_loss=0.1468219757080078\n",
            "step 3287: generator_loss=2.960219383239746, discriminator_loss=0.1296900510787964\n",
            "step 3288: generator_loss=2.9113059043884277, discriminator_loss=0.16163691878318787\n",
            "step 3289: generator_loss=3.0415353775024414, discriminator_loss=0.21101151406764984\n",
            "step 3290: generator_loss=2.8560409545898438, discriminator_loss=0.17752453684806824\n",
            "step 3291: generator_loss=2.751457691192627, discriminator_loss=0.17340636253356934\n",
            "step 3292: generator_loss=2.5847082138061523, discriminator_loss=0.26057496666908264\n",
            "step 3293: generator_loss=2.5806922912597656, discriminator_loss=0.1860208511352539\n",
            "step 3294: generator_loss=2.4911937713623047, discriminator_loss=0.22935238480567932\n",
            "step 3295: generator_loss=2.2248363494873047, discriminator_loss=0.2115137130022049\n",
            "step 3296: generator_loss=2.336996078491211, discriminator_loss=0.18173937499523163\n",
            "step 3297: generator_loss=2.211668014526367, discriminator_loss=0.16554850339889526\n",
            "step 3298: generator_loss=2.1909427642822266, discriminator_loss=0.1966775804758072\n",
            "step 3299: generator_loss=2.2864203453063965, discriminator_loss=0.24520157277584076\n",
            "step 3300: generator_loss=2.226494550704956, discriminator_loss=0.19573859870433807\n",
            "step 3301: generator_loss=2.1468238830566406, discriminator_loss=0.20520207285881042\n",
            "step 3302: generator_loss=2.0669097900390625, discriminator_loss=0.18199563026428223\n",
            "step 3303: generator_loss=2.2509920597076416, discriminator_loss=0.17428380250930786\n",
            "step 3304: generator_loss=2.279714584350586, discriminator_loss=0.15216238796710968\n",
            "step 3305: generator_loss=2.369462251663208, discriminator_loss=0.14188100397586823\n",
            "step 3306: generator_loss=2.372279644012451, discriminator_loss=0.15613213181495667\n",
            "step 3307: generator_loss=2.2010602951049805, discriminator_loss=0.20958080887794495\n",
            "step 3308: generator_loss=2.176603078842163, discriminator_loss=0.18233591318130493\n",
            "step 3309: generator_loss=2.2779111862182617, discriminator_loss=0.1538480669260025\n",
            "step 3310: generator_loss=2.3712520599365234, discriminator_loss=0.16922622919082642\n",
            "step 3311: generator_loss=2.1583595275878906, discriminator_loss=0.16072291135787964\n",
            "step 3312: generator_loss=2.077685594558716, discriminator_loss=0.18655258417129517\n",
            "step 3313: generator_loss=2.0432682037353516, discriminator_loss=0.1870374083518982\n",
            "step 3314: generator_loss=1.9631237983703613, discriminator_loss=0.19490379095077515\n",
            "step 3315: generator_loss=2.2802646160125732, discriminator_loss=0.23279158771038055\n",
            "step 3316: generator_loss=2.072622776031494, discriminator_loss=0.2143481969833374\n",
            "step 3317: generator_loss=2.057497978210449, discriminator_loss=0.21195515990257263\n",
            "step 3318: generator_loss=2.038242816925049, discriminator_loss=0.1891038417816162\n",
            "step 3319: generator_loss=2.222611904144287, discriminator_loss=0.18494218587875366\n",
            "step 3320: generator_loss=2.3085718154907227, discriminator_loss=0.18242177367210388\n",
            "step 3321: generator_loss=2.2369837760925293, discriminator_loss=0.21501004695892334\n",
            "step 3322: generator_loss=2.143740653991699, discriminator_loss=0.19456592202186584\n",
            "step 3323: generator_loss=2.1614785194396973, discriminator_loss=0.20783771574497223\n",
            "step 3324: generator_loss=1.8514257669448853, discriminator_loss=0.2682432234287262\n",
            "step 3325: generator_loss=1.7971885204315186, discriminator_loss=0.2215571105480194\n",
            "step 3326: generator_loss=1.7354848384857178, discriminator_loss=0.20177124440670013\n",
            "step 3327: generator_loss=2.0133936405181885, discriminator_loss=0.22065487504005432\n",
            "step 3328: generator_loss=2.0769927501678467, discriminator_loss=0.26791971921920776\n",
            "step 3329: generator_loss=2.1701431274414062, discriminator_loss=0.27046871185302734\n",
            "step 3330: generator_loss=2.243049383163452, discriminator_loss=0.23816077411174774\n",
            "step 3331: generator_loss=2.234409809112549, discriminator_loss=0.21611779928207397\n",
            "step 3332: generator_loss=1.9846752882003784, discriminator_loss=0.24746593832969666\n",
            "step 3333: generator_loss=1.9325056076049805, discriminator_loss=0.20590436458587646\n",
            "step 3334: generator_loss=1.8596241474151611, discriminator_loss=0.22168835997581482\n",
            "step 3335: generator_loss=1.9151771068572998, discriminator_loss=0.2141457200050354\n",
            "step 3336: generator_loss=1.9216126203536987, discriminator_loss=0.248566135764122\n",
            "step 3337: generator_loss=2.3678438663482666, discriminator_loss=0.26814472675323486\n",
            "step 3338: generator_loss=2.1773173809051514, discriminator_loss=0.24939830601215363\n",
            "step 3339: generator_loss=2.318458318710327, discriminator_loss=0.21396398544311523\n",
            "step 3340: generator_loss=2.138490676879883, discriminator_loss=0.270000696182251\n",
            "step 3341: generator_loss=2.0077309608459473, discriminator_loss=0.3016144037246704\n",
            "step 3342: generator_loss=2.0337562561035156, discriminator_loss=0.2397283911705017\n",
            "step 3343: generator_loss=1.9880675077438354, discriminator_loss=0.22891144454479218\n",
            "step 3344: generator_loss=2.0016987323760986, discriminator_loss=0.2433725893497467\n",
            "step 3345: generator_loss=1.9827229976654053, discriminator_loss=0.2949826121330261\n",
            "step 3346: generator_loss=2.455528497695923, discriminator_loss=0.20117422938346863\n",
            "step 3347: generator_loss=2.65738582611084, discriminator_loss=0.2103710025548935\n",
            "step 3348: generator_loss=2.8056092262268066, discriminator_loss=0.21290616691112518\n",
            "step 3349: generator_loss=2.6365575790405273, discriminator_loss=0.26441454887390137\n",
            "step 3350: generator_loss=2.367227077484131, discriminator_loss=0.23008331656455994\n",
            "step 3351: generator_loss=2.2532753944396973, discriminator_loss=0.18949273228645325\n",
            "step 3352: generator_loss=2.2633252143859863, discriminator_loss=0.17762491106987\n",
            "step 3353: generator_loss=1.949635624885559, discriminator_loss=0.26550546288490295\n",
            "step 3354: generator_loss=1.9620356559753418, discriminator_loss=0.2537781894207001\n",
            "step 3355: generator_loss=2.267970561981201, discriminator_loss=0.17737150192260742\n",
            "step 3356: generator_loss=2.176571846008301, discriminator_loss=0.2204468697309494\n",
            "step 3357: generator_loss=2.3533694744110107, discriminator_loss=0.2011888027191162\n",
            "step 3358: generator_loss=2.530302047729492, discriminator_loss=0.18883033096790314\n",
            "step 3359: generator_loss=2.4324636459350586, discriminator_loss=0.2053043693304062\n",
            "step 3360: generator_loss=2.364025115966797, discriminator_loss=0.1563318371772766\n",
            "step 3361: generator_loss=2.2343173027038574, discriminator_loss=0.21651457250118256\n",
            "step 3362: generator_loss=2.2645652294158936, discriminator_loss=0.1861414611339569\n",
            "step 3363: generator_loss=2.1383419036865234, discriminator_loss=0.18116334080696106\n",
            "step 3364: generator_loss=2.3532025814056396, discriminator_loss=0.1518426239490509\n",
            "step 3365: generator_loss=2.501382827758789, discriminator_loss=0.1577717661857605\n",
            "step 3366: generator_loss=2.3502254486083984, discriminator_loss=0.14443299174308777\n",
            "step 3367: generator_loss=2.4883203506469727, discriminator_loss=0.18953517079353333\n",
            "step 3368: generator_loss=2.560823917388916, discriminator_loss=0.1815168410539627\n",
            "step 3369: generator_loss=2.4721755981445312, discriminator_loss=0.1668723225593567\n",
            "step 3370: generator_loss=2.407233715057373, discriminator_loss=0.1400218904018402\n",
            "step 3371: generator_loss=2.339165210723877, discriminator_loss=0.16754305362701416\n",
            "step 3372: generator_loss=2.2124764919281006, discriminator_loss=0.16507332026958466\n",
            "step 3373: generator_loss=2.2502055168151855, discriminator_loss=0.14958786964416504\n",
            "step 3374: generator_loss=2.146156072616577, discriminator_loss=0.14112059772014618\n",
            "step 3375: generator_loss=2.387906551361084, discriminator_loss=0.164577454328537\n",
            "step 3376: generator_loss=2.4066953659057617, discriminator_loss=0.13434730470180511\n",
            "step 3377: generator_loss=2.5071961879730225, discriminator_loss=0.14927968382835388\n",
            "step 3378: generator_loss=2.542538642883301, discriminator_loss=0.16727787256240845\n",
            "step 3379: generator_loss=2.456176996231079, discriminator_loss=0.173948734998703\n",
            "step 3380: generator_loss=2.449949026107788, discriminator_loss=0.19545140862464905\n",
            "step 3381: generator_loss=2.5228099822998047, discriminator_loss=0.22319243848323822\n",
            "step 3382: generator_loss=2.634920120239258, discriminator_loss=0.2147592008113861\n",
            "step 3383: generator_loss=2.668889045715332, discriminator_loss=0.16195878386497498\n",
            "step 3384: generator_loss=2.7044451236724854, discriminator_loss=0.2212028056383133\n",
            "step 3385: generator_loss=2.772313356399536, discriminator_loss=0.26693350076675415\n",
            "step 3386: generator_loss=2.915475845336914, discriminator_loss=0.18459771573543549\n",
            "step 3387: generator_loss=2.742823600769043, discriminator_loss=0.2536899149417877\n",
            "step 3388: generator_loss=2.9040591716766357, discriminator_loss=0.19370320439338684\n",
            "step 3389: generator_loss=2.980457305908203, discriminator_loss=0.24705004692077637\n",
            "step 3390: generator_loss=3.2438721656799316, discriminator_loss=0.24415327608585358\n",
            "step 3391: generator_loss=3.2434473037719727, discriminator_loss=0.2068243771791458\n",
            "step 3392: generator_loss=3.6194815635681152, discriminator_loss=0.21750472486019135\n",
            "step 3393: generator_loss=3.436520576477051, discriminator_loss=0.22423698008060455\n",
            "step 3394: generator_loss=3.4030470848083496, discriminator_loss=0.23883789777755737\n",
            "step 3395: generator_loss=3.068441390991211, discriminator_loss=0.23197317123413086\n",
            "step 3396: generator_loss=3.26352596282959, discriminator_loss=0.1434858739376068\n",
            "step 3397: generator_loss=3.340147018432617, discriminator_loss=0.1550898253917694\n",
            "step 3398: generator_loss=3.5141286849975586, discriminator_loss=0.12333262711763382\n",
            "step 3399: generator_loss=3.6147806644439697, discriminator_loss=0.13864824175834656\n",
            "step 3400: generator_loss=3.2932288646698, discriminator_loss=0.13270510733127594\n",
            "step 3401: generator_loss=3.2319228649139404, discriminator_loss=0.13769014179706573\n",
            "step 3402: generator_loss=3.296841859817505, discriminator_loss=0.14423245191574097\n",
            "step 3403: generator_loss=2.9774208068847656, discriminator_loss=0.1402871012687683\n",
            "step 3404: generator_loss=2.997727394104004, discriminator_loss=0.12953442335128784\n",
            "step 3405: generator_loss=2.9823923110961914, discriminator_loss=0.10484407097101212\n",
            "step 3406: generator_loss=2.8822836875915527, discriminator_loss=0.13542072474956512\n",
            "step 3407: generator_loss=3.133863925933838, discriminator_loss=0.14793100953102112\n",
            "step 3408: generator_loss=3.0750913619995117, discriminator_loss=0.13394011557102203\n",
            "step 3409: generator_loss=3.0123229026794434, discriminator_loss=0.15574854612350464\n",
            "step 3410: generator_loss=3.030783176422119, discriminator_loss=0.15678304433822632\n",
            "step 3411: generator_loss=2.6473681926727295, discriminator_loss=0.19362959265708923\n",
            "step 3412: generator_loss=2.6841182708740234, discriminator_loss=0.12578915059566498\n",
            "step 3413: generator_loss=2.603407382965088, discriminator_loss=0.1473865658044815\n",
            "step 3414: generator_loss=2.36741304397583, discriminator_loss=0.18938764929771423\n",
            "step 3415: generator_loss=2.58366060256958, discriminator_loss=0.1422136425971985\n",
            "step 3416: generator_loss=2.6621170043945312, discriminator_loss=0.14129334688186646\n",
            "step 3417: generator_loss=2.802450656890869, discriminator_loss=0.10581515729427338\n",
            "step 3418: generator_loss=2.9981045722961426, discriminator_loss=0.11352288722991943\n",
            "step 3419: generator_loss=3.3032102584838867, discriminator_loss=0.11165279150009155\n",
            "step 3420: generator_loss=3.263364315032959, discriminator_loss=0.11316949129104614\n",
            "step 3421: generator_loss=3.2831313610076904, discriminator_loss=0.1097898930311203\n",
            "step 3422: generator_loss=3.016925811767578, discriminator_loss=0.11465686559677124\n",
            "step 3423: generator_loss=3.031221866607666, discriminator_loss=0.129463791847229\n",
            "step 3424: generator_loss=2.9266626834869385, discriminator_loss=0.10411665588617325\n",
            "step 3425: generator_loss=2.539597511291504, discriminator_loss=0.12167225778102875\n",
            "step 3426: generator_loss=2.4813785552978516, discriminator_loss=0.13127946853637695\n",
            "step 3427: generator_loss=2.7706031799316406, discriminator_loss=0.1281970739364624\n",
            "step 3428: generator_loss=2.807105541229248, discriminator_loss=0.11785328388214111\n",
            "step 3429: generator_loss=2.9575886726379395, discriminator_loss=0.11137232184410095\n",
            "step 3430: generator_loss=2.901456356048584, discriminator_loss=0.13269749283790588\n",
            "step 3431: generator_loss=3.2439980506896973, discriminator_loss=0.13255932927131653\n",
            "step 3432: generator_loss=2.9765024185180664, discriminator_loss=0.13913708925247192\n",
            "step 3433: generator_loss=2.8340439796447754, discriminator_loss=0.14060230553150177\n",
            "step 3434: generator_loss=2.6693966388702393, discriminator_loss=0.14958655834197998\n",
            "step 3435: generator_loss=2.507481813430786, discriminator_loss=0.1386054903268814\n",
            "step 3436: generator_loss=2.3774912357330322, discriminator_loss=0.15991339087486267\n",
            "step 3437: generator_loss=2.432170867919922, discriminator_loss=0.1365729570388794\n",
            "step 3438: generator_loss=2.670328140258789, discriminator_loss=0.12771879136562347\n",
            "step 3439: generator_loss=2.7619287967681885, discriminator_loss=0.13446229696273804\n",
            "step 3440: generator_loss=2.6511495113372803, discriminator_loss=0.11904630064964294\n",
            "step 3441: generator_loss=2.626378059387207, discriminator_loss=0.20054900646209717\n",
            "step 3442: generator_loss=2.63820481300354, discriminator_loss=0.15353518724441528\n",
            "step 3443: generator_loss=2.450136661529541, discriminator_loss=0.21221016347408295\n",
            "step 3444: generator_loss=2.473137378692627, discriminator_loss=0.23643088340759277\n",
            "step 3445: generator_loss=2.383955955505371, discriminator_loss=0.3133299946784973\n",
            "step 3446: generator_loss=2.5409862995147705, discriminator_loss=0.371860146522522\n",
            "step 3447: generator_loss=2.8973045349121094, discriminator_loss=0.37232130765914917\n",
            "step 3448: generator_loss=3.0985476970672607, discriminator_loss=0.3573986887931824\n",
            "step 3449: generator_loss=3.0694420337677, discriminator_loss=0.3377078175544739\n",
            "step 3450: generator_loss=2.411388397216797, discriminator_loss=0.5346081852912903\n",
            "step 3451: generator_loss=3.3127355575561523, discriminator_loss=0.3811606764793396\n",
            "step 3452: generator_loss=3.310681104660034, discriminator_loss=0.4579031467437744\n",
            "step 3453: generator_loss=3.107950210571289, discriminator_loss=0.41351640224456787\n",
            "step 3454: generator_loss=3.6012439727783203, discriminator_loss=0.40567582845687866\n",
            "step 3455: generator_loss=3.232511043548584, discriminator_loss=0.4355340600013733\n",
            "step 3456: generator_loss=2.950775623321533, discriminator_loss=0.45143938064575195\n",
            "step 3457: generator_loss=2.937471866607666, discriminator_loss=0.32367241382598877\n",
            "step 3458: generator_loss=3.0049548149108887, discriminator_loss=0.23877762258052826\n",
            "step 3459: generator_loss=3.12852144241333, discriminator_loss=0.19649232923984528\n",
            "step 3460: generator_loss=3.604576826095581, discriminator_loss=0.1652660220861435\n",
            "step 3461: generator_loss=3.824281692504883, discriminator_loss=0.11779245734214783\n",
            "step 3462: generator_loss=3.8181934356689453, discriminator_loss=0.11185690760612488\n",
            "step 3463: generator_loss=3.8948721885681152, discriminator_loss=0.1162988543510437\n",
            "step 3464: generator_loss=3.7587292194366455, discriminator_loss=0.09113234281539917\n",
            "step 3465: generator_loss=3.7255678176879883, discriminator_loss=0.10183773934841156\n",
            "step 3466: generator_loss=3.2579150199890137, discriminator_loss=0.08982591331005096\n",
            "step 3467: generator_loss=3.2322535514831543, discriminator_loss=0.11893667280673981\n",
            "step 3468: generator_loss=2.835463047027588, discriminator_loss=0.11085633933544159\n",
            "step 3469: generator_loss=3.078861713409424, discriminator_loss=0.1256607174873352\n",
            "step 3470: generator_loss=2.8090667724609375, discriminator_loss=0.15313485264778137\n",
            "step 3471: generator_loss=3.3791162967681885, discriminator_loss=0.13578635454177856\n",
            "step 3472: generator_loss=3.3208255767822266, discriminator_loss=0.11512656509876251\n",
            "step 3473: generator_loss=3.2752208709716797, discriminator_loss=0.15578599274158478\n",
            "step 3474: generator_loss=3.4697861671447754, discriminator_loss=0.18600237369537354\n",
            "step 3475: generator_loss=3.276451587677002, discriminator_loss=0.2050880789756775\n",
            "step 3476: generator_loss=3.1734867095947266, discriminator_loss=0.2125735729932785\n",
            "step 3477: generator_loss=3.1289896965026855, discriminator_loss=0.1574425995349884\n",
            "step 3478: generator_loss=2.8087964057922363, discriminator_loss=0.16601361334323883\n",
            "step 3479: generator_loss=2.9083847999572754, discriminator_loss=0.15224111080169678\n",
            "step 3480: generator_loss=2.510998249053955, discriminator_loss=0.1686486005783081\n",
            "step 3481: generator_loss=2.6732938289642334, discriminator_loss=0.13539177179336548\n",
            "step 3482: generator_loss=2.600832462310791, discriminator_loss=0.1422324776649475\n",
            "step 3483: generator_loss=2.5174620151519775, discriminator_loss=0.16135826706886292\n",
            "step 3484: generator_loss=2.8706605434417725, discriminator_loss=0.13986071944236755\n",
            "step 3485: generator_loss=2.573939323425293, discriminator_loss=0.12176549434661865\n",
            "step 3486: generator_loss=2.5758230686187744, discriminator_loss=0.1272159069776535\n",
            "step 3487: generator_loss=2.508525848388672, discriminator_loss=0.14276526868343353\n",
            "step 3488: generator_loss=2.4662656784057617, discriminator_loss=0.09939609467983246\n",
            "step 3489: generator_loss=2.7300190925598145, discriminator_loss=0.12149514257907867\n",
            "step 3490: generator_loss=2.84348201751709, discriminator_loss=0.1327865570783615\n",
            "step 3491: generator_loss=2.636132001876831, discriminator_loss=0.12059910595417023\n",
            "step 3492: generator_loss=2.6841955184936523, discriminator_loss=0.11965881288051605\n",
            "step 3493: generator_loss=2.5824365615844727, discriminator_loss=0.12628306448459625\n",
            "step 3494: generator_loss=2.848252773284912, discriminator_loss=0.11755984276533127\n",
            "step 3495: generator_loss=2.808197498321533, discriminator_loss=0.13998422026634216\n",
            "step 3496: generator_loss=2.823244094848633, discriminator_loss=0.11207476258277893\n",
            "step 3497: generator_loss=2.6761016845703125, discriminator_loss=0.12528330087661743\n",
            "step 3498: generator_loss=2.7965869903564453, discriminator_loss=0.12797954678535461\n",
            "step 3499: generator_loss=2.7917728424072266, discriminator_loss=0.11253795027732849\n",
            "step 3500: generator_loss=2.5210537910461426, discriminator_loss=0.14142891764640808\n",
            "step 3501: generator_loss=2.480367422103882, discriminator_loss=0.1095656231045723\n",
            "step 3502: generator_loss=2.328594207763672, discriminator_loss=0.1416347622871399\n",
            "step 3503: generator_loss=2.5365982055664062, discriminator_loss=0.12924981117248535\n",
            "step 3504: generator_loss=2.568458080291748, discriminator_loss=0.15255454182624817\n",
            "step 3505: generator_loss=2.7728707790374756, discriminator_loss=0.11920153349637985\n",
            "step 3506: generator_loss=2.7354862689971924, discriminator_loss=0.16016541421413422\n",
            "step 3507: generator_loss=3.0495896339416504, discriminator_loss=0.12547361850738525\n",
            "step 3508: generator_loss=2.6149003505706787, discriminator_loss=0.13581499457359314\n",
            "step 3509: generator_loss=2.604597806930542, discriminator_loss=0.13539639115333557\n",
            "step 3510: generator_loss=2.3521602153778076, discriminator_loss=0.15782493352890015\n",
            "step 3511: generator_loss=2.3546698093414307, discriminator_loss=0.165943443775177\n",
            "step 3512: generator_loss=2.45347261428833, discriminator_loss=0.14857859909534454\n",
            "step 3513: generator_loss=2.7002997398376465, discriminator_loss=0.15765446424484253\n",
            "step 3514: generator_loss=2.6969621181488037, discriminator_loss=0.18474465608596802\n",
            "step 3515: generator_loss=2.5392942428588867, discriminator_loss=0.18081942200660706\n",
            "step 3516: generator_loss=2.443169593811035, discriminator_loss=0.20008593797683716\n",
            "step 3517: generator_loss=2.148829460144043, discriminator_loss=0.19919057190418243\n",
            "step 3518: generator_loss=2.228679895401001, discriminator_loss=0.16803719103336334\n",
            "step 3519: generator_loss=2.5701181888580322, discriminator_loss=0.16416466236114502\n",
            "step 3520: generator_loss=2.494481086730957, discriminator_loss=0.1497679054737091\n",
            "step 3521: generator_loss=2.5913591384887695, discriminator_loss=0.2004876434803009\n",
            "step 3522: generator_loss=2.6308348178863525, discriminator_loss=0.18730655312538147\n",
            "step 3523: generator_loss=2.5855631828308105, discriminator_loss=0.15080320835113525\n",
            "step 3524: generator_loss=2.455385208129883, discriminator_loss=0.14649315178394318\n",
            "step 3525: generator_loss=2.5484814643859863, discriminator_loss=0.18140582740306854\n",
            "step 3526: generator_loss=2.2374634742736816, discriminator_loss=0.2123163491487503\n",
            "step 3527: generator_loss=2.1794848442077637, discriminator_loss=0.16175992786884308\n",
            "step 3528: generator_loss=2.224776029586792, discriminator_loss=0.22245849668979645\n",
            "step 3529: generator_loss=2.3136167526245117, discriminator_loss=0.154025137424469\n",
            "step 3530: generator_loss=2.3645195960998535, discriminator_loss=0.15042895078659058\n",
            "step 3531: generator_loss=2.4852962493896484, discriminator_loss=0.15499912202358246\n",
            "step 3532: generator_loss=2.403935432434082, discriminator_loss=0.18246068060398102\n",
            "step 3533: generator_loss=2.5647549629211426, discriminator_loss=0.1486605405807495\n",
            "step 3534: generator_loss=2.4854965209960938, discriminator_loss=0.15621158480644226\n",
            "step 3535: generator_loss=2.3613381385803223, discriminator_loss=0.17538148164749146\n",
            "step 3536: generator_loss=2.3486032485961914, discriminator_loss=0.20648644864559174\n",
            "step 3537: generator_loss=2.3250813484191895, discriminator_loss=0.1607734113931656\n",
            "step 3538: generator_loss=2.4036166667938232, discriminator_loss=0.1613016426563263\n",
            "step 3539: generator_loss=2.3642544746398926, discriminator_loss=0.1552017331123352\n",
            "step 3540: generator_loss=2.2867889404296875, discriminator_loss=0.18677130341529846\n",
            "step 3541: generator_loss=2.366672992706299, discriminator_loss=0.17556631565093994\n",
            "step 3542: generator_loss=2.3295352458953857, discriminator_loss=0.1716514229774475\n",
            "step 3543: generator_loss=2.3064815998077393, discriminator_loss=0.19074276089668274\n",
            "step 3544: generator_loss=2.3344461917877197, discriminator_loss=0.21566236019134521\n",
            "step 3545: generator_loss=2.366326332092285, discriminator_loss=0.15208536386489868\n",
            "step 3546: generator_loss=2.3220694065093994, discriminator_loss=0.18503248691558838\n",
            "step 3547: generator_loss=2.184873342514038, discriminator_loss=0.1870810091495514\n",
            "step 3548: generator_loss=2.0945498943328857, discriminator_loss=0.16298654675483704\n",
            "step 3549: generator_loss=1.985442042350769, discriminator_loss=0.19122786819934845\n",
            "step 3550: generator_loss=1.9278620481491089, discriminator_loss=0.1902793049812317\n",
            "step 3551: generator_loss=2.1061248779296875, discriminator_loss=0.2556999921798706\n",
            "step 3552: generator_loss=2.415524482727051, discriminator_loss=0.17961230874061584\n",
            "step 3553: generator_loss=2.29915189743042, discriminator_loss=0.19982871413230896\n",
            "step 3554: generator_loss=2.3155412673950195, discriminator_loss=0.24731019139289856\n",
            "step 3555: generator_loss=2.295656442642212, discriminator_loss=0.19298860430717468\n",
            "step 3556: generator_loss=2.1547226905822754, discriminator_loss=0.1886647492647171\n",
            "step 3557: generator_loss=2.034541368484497, discriminator_loss=0.2316938042640686\n",
            "step 3558: generator_loss=1.9100350141525269, discriminator_loss=0.1964125782251358\n",
            "step 3559: generator_loss=1.9557594060897827, discriminator_loss=0.2220870405435562\n",
            "step 3560: generator_loss=2.1918368339538574, discriminator_loss=0.18615153431892395\n",
            "step 3561: generator_loss=2.372103214263916, discriminator_loss=0.1888573169708252\n",
            "step 3562: generator_loss=2.393747329711914, discriminator_loss=0.20828507840633392\n",
            "step 3563: generator_loss=2.159376621246338, discriminator_loss=0.19678863883018494\n",
            "step 3564: generator_loss=1.915590524673462, discriminator_loss=0.19592252373695374\n",
            "step 3565: generator_loss=1.8812578916549683, discriminator_loss=0.18321773409843445\n",
            "step 3566: generator_loss=1.9417015314102173, discriminator_loss=0.17401352524757385\n",
            "step 3567: generator_loss=1.999255657196045, discriminator_loss=0.200199693441391\n",
            "step 3568: generator_loss=2.1790246963500977, discriminator_loss=0.16159546375274658\n",
            "step 3569: generator_loss=2.4925403594970703, discriminator_loss=0.17789945006370544\n",
            "step 3570: generator_loss=2.3736305236816406, discriminator_loss=0.16620151698589325\n",
            "step 3571: generator_loss=2.402263641357422, discriminator_loss=0.13127878308296204\n",
            "step 3572: generator_loss=2.3265695571899414, discriminator_loss=0.15621411800384521\n",
            "step 3573: generator_loss=2.3775553703308105, discriminator_loss=0.15034985542297363\n",
            "step 3574: generator_loss=2.2265353202819824, discriminator_loss=0.15066248178482056\n",
            "step 3575: generator_loss=2.1653480529785156, discriminator_loss=0.14282943308353424\n",
            "step 3576: generator_loss=2.1929523944854736, discriminator_loss=0.14194868505001068\n",
            "step 3577: generator_loss=2.401175022125244, discriminator_loss=0.12354636192321777\n",
            "step 3578: generator_loss=2.563614845275879, discriminator_loss=0.0956973060965538\n",
            "step 3579: generator_loss=2.6121115684509277, discriminator_loss=0.12130419909954071\n",
            "step 3580: generator_loss=2.7662084102630615, discriminator_loss=0.10878089815378189\n",
            "step 3581: generator_loss=2.7320666313171387, discriminator_loss=0.12334476411342621\n",
            "step 3582: generator_loss=2.662501573562622, discriminator_loss=0.11057297885417938\n",
            "step 3583: generator_loss=2.737004280090332, discriminator_loss=0.11135383695363998\n",
            "step 3584: generator_loss=2.7150373458862305, discriminator_loss=0.10501733422279358\n",
            "step 3585: generator_loss=2.736508846282959, discriminator_loss=0.08632025122642517\n",
            "step 3586: generator_loss=2.677015781402588, discriminator_loss=0.12116343528032303\n",
            "step 3587: generator_loss=2.699411153793335, discriminator_loss=0.09939123690128326\n",
            "step 3588: generator_loss=2.5685551166534424, discriminator_loss=0.09167232364416122\n",
            "step 3589: generator_loss=2.575831890106201, discriminator_loss=0.09090468287467957\n",
            "step 3590: generator_loss=2.609370708465576, discriminator_loss=0.08537578582763672\n",
            "step 3591: generator_loss=2.59968900680542, discriminator_loss=0.10682976990938187\n",
            "step 3592: generator_loss=2.6274259090423584, discriminator_loss=0.12085773050785065\n",
            "step 3593: generator_loss=2.7398316860198975, discriminator_loss=0.14119857549667358\n",
            "step 3594: generator_loss=2.728792667388916, discriminator_loss=0.11306770890951157\n",
            "step 3595: generator_loss=2.7854666709899902, discriminator_loss=0.11446605622768402\n",
            "step 3596: generator_loss=2.75248646736145, discriminator_loss=0.1072641909122467\n",
            "step 3597: generator_loss=2.59633731842041, discriminator_loss=0.10132726281881332\n",
            "step 3598: generator_loss=2.4341297149658203, discriminator_loss=0.11769288778305054\n",
            "step 3599: generator_loss=2.4462711811065674, discriminator_loss=0.11825472861528397\n",
            "step 3600: generator_loss=2.6113624572753906, discriminator_loss=0.10071928799152374\n",
            "step 3601: generator_loss=2.760796546936035, discriminator_loss=0.10317817330360413\n",
            "step 3602: generator_loss=2.7272629737854004, discriminator_loss=0.11755916476249695\n",
            "step 3603: generator_loss=2.6490862369537354, discriminator_loss=0.12734195590019226\n",
            "step 3604: generator_loss=2.5589051246643066, discriminator_loss=0.10082173347473145\n",
            "step 3605: generator_loss=2.4462814331054688, discriminator_loss=0.11949857324361801\n",
            "step 3606: generator_loss=2.365987777709961, discriminator_loss=0.12053297460079193\n",
            "step 3607: generator_loss=2.4103646278381348, discriminator_loss=0.13631673157215118\n",
            "step 3608: generator_loss=2.421731948852539, discriminator_loss=0.11586104333400726\n",
            "step 3609: generator_loss=2.420949697494507, discriminator_loss=0.11647266149520874\n",
            "step 3610: generator_loss=2.472994565963745, discriminator_loss=0.1177942082285881\n",
            "step 3611: generator_loss=2.8043344020843506, discriminator_loss=0.1157936379313469\n",
            "step 3612: generator_loss=2.733877182006836, discriminator_loss=0.1220899447798729\n",
            "step 3613: generator_loss=2.674539089202881, discriminator_loss=0.15190330147743225\n",
            "step 3614: generator_loss=2.5793895721435547, discriminator_loss=0.12024392187595367\n",
            "step 3615: generator_loss=2.73641300201416, discriminator_loss=0.11535049974918365\n",
            "step 3616: generator_loss=2.6417236328125, discriminator_loss=0.15090398490428925\n",
            "step 3617: generator_loss=2.548638343811035, discriminator_loss=0.13109086453914642\n",
            "step 3618: generator_loss=2.4737203121185303, discriminator_loss=0.14017252624034882\n",
            "step 3619: generator_loss=2.5636420249938965, discriminator_loss=0.10857376456260681\n",
            "step 3620: generator_loss=2.5905613899230957, discriminator_loss=0.12563493847846985\n",
            "step 3621: generator_loss=2.665562152862549, discriminator_loss=0.13926714658737183\n",
            "step 3622: generator_loss=2.6065216064453125, discriminator_loss=0.1668107509613037\n",
            "step 3623: generator_loss=2.7488112449645996, discriminator_loss=0.1471799612045288\n",
            "step 3624: generator_loss=2.5800490379333496, discriminator_loss=0.21986424922943115\n",
            "step 3625: generator_loss=2.613187313079834, discriminator_loss=0.18849578499794006\n",
            "step 3626: generator_loss=2.965428113937378, discriminator_loss=0.150875523686409\n",
            "step 3627: generator_loss=2.8161025047302246, discriminator_loss=0.21540838479995728\n",
            "step 3628: generator_loss=2.958528518676758, discriminator_loss=0.2962276339530945\n",
            "step 3629: generator_loss=3.1523540019989014, discriminator_loss=0.19878558814525604\n",
            "step 3630: generator_loss=3.20615291595459, discriminator_loss=0.19367365539073944\n",
            "step 3631: generator_loss=3.2555222511291504, discriminator_loss=0.21552932262420654\n",
            "step 3632: generator_loss=3.259399890899658, discriminator_loss=0.16294850409030914\n",
            "step 3633: generator_loss=3.0923736095428467, discriminator_loss=0.281976580619812\n",
            "step 3634: generator_loss=3.1496033668518066, discriminator_loss=0.22948366403579712\n",
            "step 3635: generator_loss=3.089522361755371, discriminator_loss=0.2053000032901764\n",
            "step 3636: generator_loss=3.6903486251831055, discriminator_loss=0.16571757197380066\n",
            "step 3637: generator_loss=3.5202784538269043, discriminator_loss=0.19006796181201935\n",
            "step 3638: generator_loss=3.6664388179779053, discriminator_loss=0.1515229344367981\n",
            "step 3639: generator_loss=3.8085575103759766, discriminator_loss=0.1528540402650833\n",
            "step 3640: generator_loss=3.8934383392333984, discriminator_loss=0.11042758822441101\n",
            "step 3641: generator_loss=3.7051758766174316, discriminator_loss=0.11177367717027664\n",
            "step 3642: generator_loss=3.8178234100341797, discriminator_loss=0.09499236941337585\n",
            "step 3643: generator_loss=4.029605865478516, discriminator_loss=0.09488364309072495\n",
            "step 3644: generator_loss=3.7949624061584473, discriminator_loss=0.08036582916975021\n",
            "step 3645: generator_loss=3.4222252368927, discriminator_loss=0.10420118272304535\n",
            "step 3646: generator_loss=3.5535216331481934, discriminator_loss=0.1184326708316803\n",
            "step 3647: generator_loss=3.135958671569824, discriminator_loss=0.12883827090263367\n",
            "step 3648: generator_loss=3.3337838649749756, discriminator_loss=0.11046621948480606\n",
            "step 3649: generator_loss=3.5647616386413574, discriminator_loss=0.09969057142734528\n",
            "step 3650: generator_loss=3.6380434036254883, discriminator_loss=0.09314589202404022\n",
            "step 3651: generator_loss=3.7613863945007324, discriminator_loss=0.10340149700641632\n",
            "step 3652: generator_loss=3.81722092628479, discriminator_loss=0.07320019602775574\n",
            "step 3653: generator_loss=3.6138553619384766, discriminator_loss=0.11948701739311218\n",
            "step 3654: generator_loss=3.553072929382324, discriminator_loss=0.11181971430778503\n",
            "step 3655: generator_loss=3.376250743865967, discriminator_loss=0.10998887568712234\n",
            "step 3656: generator_loss=2.9886674880981445, discriminator_loss=0.1208476573228836\n",
            "step 3657: generator_loss=3.382735252380371, discriminator_loss=0.09973004460334778\n",
            "step 3658: generator_loss=3.3251583576202393, discriminator_loss=0.10997596383094788\n",
            "step 3659: generator_loss=3.5384280681610107, discriminator_loss=0.12444937229156494\n",
            "step 3660: generator_loss=3.5151305198669434, discriminator_loss=0.09853687882423401\n",
            "step 3661: generator_loss=3.411083459854126, discriminator_loss=0.1368750035762787\n",
            "step 3662: generator_loss=3.521270275115967, discriminator_loss=0.11736072599887848\n",
            "step 3663: generator_loss=3.6097724437713623, discriminator_loss=0.1314876526594162\n",
            "step 3664: generator_loss=3.7304656505584717, discriminator_loss=0.12104188650846481\n",
            "step 3665: generator_loss=3.5452866554260254, discriminator_loss=0.171920046210289\n",
            "step 3666: generator_loss=3.531834840774536, discriminator_loss=0.1691558063030243\n",
            "step 3667: generator_loss=3.4787349700927734, discriminator_loss=0.19455614686012268\n",
            "step 3668: generator_loss=3.286259651184082, discriminator_loss=0.23762711882591248\n",
            "step 3669: generator_loss=3.459083080291748, discriminator_loss=0.17832344770431519\n",
            "step 3670: generator_loss=3.460705280303955, discriminator_loss=0.18516838550567627\n",
            "step 3671: generator_loss=3.587338447570801, discriminator_loss=0.20933037996292114\n",
            "step 3672: generator_loss=3.2911579608917236, discriminator_loss=0.2383614480495453\n",
            "step 3673: generator_loss=3.2053349018096924, discriminator_loss=0.2385941445827484\n",
            "step 3674: generator_loss=3.2816238403320312, discriminator_loss=0.25533097982406616\n",
            "step 3675: generator_loss=3.3018741607666016, discriminator_loss=0.20144113898277283\n",
            "step 3676: generator_loss=3.1837620735168457, discriminator_loss=0.2311614602804184\n",
            "step 3677: generator_loss=3.315765857696533, discriminator_loss=0.21149849891662598\n",
            "step 3678: generator_loss=3.3560128211975098, discriminator_loss=0.19540290534496307\n",
            "step 3679: generator_loss=3.8105392456054688, discriminator_loss=0.22769087553024292\n",
            "step 3680: generator_loss=3.7712559700012207, discriminator_loss=0.21374022960662842\n",
            "step 3681: generator_loss=3.7092785835266113, discriminator_loss=0.1822921633720398\n",
            "step 3682: generator_loss=3.662179708480835, discriminator_loss=0.18228936195373535\n",
            "step 3683: generator_loss=3.323537826538086, discriminator_loss=0.1843014359474182\n",
            "step 3684: generator_loss=3.3227341175079346, discriminator_loss=0.2024821937084198\n",
            "step 3685: generator_loss=3.096827507019043, discriminator_loss=0.13000808656215668\n",
            "step 3686: generator_loss=2.968766450881958, discriminator_loss=0.16026052832603455\n",
            "step 3687: generator_loss=2.7406911849975586, discriminator_loss=0.1312621384859085\n",
            "step 3688: generator_loss=3.059365749359131, discriminator_loss=0.15188059210777283\n",
            "step 3689: generator_loss=2.7678380012512207, discriminator_loss=0.19034546613693237\n",
            "step 3690: generator_loss=2.9818406105041504, discriminator_loss=0.145675390958786\n",
            "step 3691: generator_loss=2.7816925048828125, discriminator_loss=0.1527787744998932\n",
            "step 3692: generator_loss=2.7623062133789062, discriminator_loss=0.13238057494163513\n",
            "step 3693: generator_loss=2.617870330810547, discriminator_loss=0.12472668290138245\n",
            "step 3694: generator_loss=2.489765167236328, discriminator_loss=0.12297341227531433\n",
            "step 3695: generator_loss=2.8127055168151855, discriminator_loss=0.08578480035066605\n",
            "step 3696: generator_loss=2.976325750350952, discriminator_loss=0.09945048391819\n",
            "step 3697: generator_loss=2.922250747680664, discriminator_loss=0.12735450267791748\n",
            "step 3698: generator_loss=2.9280312061309814, discriminator_loss=0.13395215570926666\n",
            "step 3699: generator_loss=2.875962734222412, discriminator_loss=0.1239367350935936\n",
            "step 3700: generator_loss=2.6169958114624023, discriminator_loss=0.1330834925174713\n",
            "step 3701: generator_loss=2.811434745788574, discriminator_loss=0.10764646530151367\n",
            "step 3702: generator_loss=2.8648338317871094, discriminator_loss=0.12030401080846786\n",
            "step 3703: generator_loss=2.897930145263672, discriminator_loss=0.11642125993967056\n",
            "step 3704: generator_loss=3.0738401412963867, discriminator_loss=0.13856241106987\n",
            "step 3705: generator_loss=2.9324426651000977, discriminator_loss=0.09709863364696503\n",
            "step 3706: generator_loss=2.8752965927124023, discriminator_loss=0.12312573194503784\n",
            "step 3707: generator_loss=2.7517776489257812, discriminator_loss=0.14054037630558014\n",
            "step 3708: generator_loss=2.7254624366760254, discriminator_loss=0.1380046308040619\n",
            "step 3709: generator_loss=2.8192672729492188, discriminator_loss=0.1258753538131714\n",
            "step 3710: generator_loss=2.8699421882629395, discriminator_loss=0.13604077696800232\n",
            "step 3711: generator_loss=2.8170855045318604, discriminator_loss=0.15973280370235443\n",
            "step 3712: generator_loss=2.856623649597168, discriminator_loss=0.12474427372217178\n",
            "step 3713: generator_loss=2.96901273727417, discriminator_loss=0.14874199032783508\n",
            "step 3714: generator_loss=2.6797690391540527, discriminator_loss=0.16939714550971985\n",
            "step 3715: generator_loss=2.6884236335754395, discriminator_loss=0.1670989692211151\n",
            "step 3716: generator_loss=2.610063314437866, discriminator_loss=0.17463746666908264\n",
            "step 3717: generator_loss=2.782376766204834, discriminator_loss=0.16288214921951294\n",
            "step 3718: generator_loss=2.83809232711792, discriminator_loss=0.14283765852451324\n",
            "step 3719: generator_loss=2.7013769149780273, discriminator_loss=0.17785993218421936\n",
            "step 3720: generator_loss=2.495321273803711, discriminator_loss=0.17761866748332977\n",
            "step 3721: generator_loss=2.547846794128418, discriminator_loss=0.17310671508312225\n",
            "step 3722: generator_loss=2.5906124114990234, discriminator_loss=0.16059763729572296\n",
            "step 3723: generator_loss=2.4696483612060547, discriminator_loss=0.1728246808052063\n",
            "step 3724: generator_loss=2.481977939605713, discriminator_loss=0.17531782388687134\n",
            "step 3725: generator_loss=2.5010170936584473, discriminator_loss=0.19888430833816528\n",
            "step 3726: generator_loss=2.657773017883301, discriminator_loss=0.18131548166275024\n",
            "step 3727: generator_loss=2.531633138656616, discriminator_loss=0.17847095429897308\n",
            "step 3728: generator_loss=2.6435227394104004, discriminator_loss=0.12729103863239288\n",
            "step 3729: generator_loss=2.52980899810791, discriminator_loss=0.16120460629463196\n",
            "step 3730: generator_loss=2.780163288116455, discriminator_loss=0.17184048891067505\n",
            "step 3731: generator_loss=2.827911138534546, discriminator_loss=0.1520901620388031\n",
            "step 3732: generator_loss=2.580941677093506, discriminator_loss=0.19154629111289978\n",
            "step 3733: generator_loss=2.5921053886413574, discriminator_loss=0.16696202754974365\n",
            "step 3734: generator_loss=2.337634801864624, discriminator_loss=0.20242425799369812\n",
            "step 3735: generator_loss=2.312840700149536, discriminator_loss=0.2062387764453888\n",
            "step 3736: generator_loss=2.35750150680542, discriminator_loss=0.20043790340423584\n",
            "step 3737: generator_loss=2.6848068237304688, discriminator_loss=0.17408005893230438\n",
            "step 3738: generator_loss=2.6015281677246094, discriminator_loss=0.17373746633529663\n",
            "step 3739: generator_loss=2.5986108779907227, discriminator_loss=0.2066769301891327\n",
            "step 3740: generator_loss=2.5673043727874756, discriminator_loss=0.2404605746269226\n",
            "step 3741: generator_loss=2.706939697265625, discriminator_loss=0.20631346106529236\n",
            "step 3742: generator_loss=2.408971071243286, discriminator_loss=0.23092249035835266\n",
            "step 3743: generator_loss=2.4967055320739746, discriminator_loss=0.22218354046344757\n",
            "step 3744: generator_loss=2.3503763675689697, discriminator_loss=0.2691922187805176\n",
            "step 3745: generator_loss=2.4598217010498047, discriminator_loss=0.24118152260780334\n",
            "step 3746: generator_loss=2.34871768951416, discriminator_loss=0.3110879957675934\n",
            "step 3747: generator_loss=2.5159740447998047, discriminator_loss=0.34544724225997925\n",
            "step 3748: generator_loss=2.578873634338379, discriminator_loss=0.3035138249397278\n",
            "step 3749: generator_loss=2.9535794258117676, discriminator_loss=0.32517433166503906\n",
            "step 3750: generator_loss=2.8318493366241455, discriminator_loss=0.4129689037799835\n",
            "step 3751: generator_loss=3.3122100830078125, discriminator_loss=0.3245094120502472\n",
            "step 3752: generator_loss=2.99845290184021, discriminator_loss=0.2920534014701843\n",
            "step 3753: generator_loss=3.1588611602783203, discriminator_loss=0.3303069472312927\n",
            "step 3754: generator_loss=3.204169988632202, discriminator_loss=0.386887788772583\n",
            "step 3755: generator_loss=3.3547966480255127, discriminator_loss=0.30392393469810486\n",
            "step 3756: generator_loss=3.4156482219696045, discriminator_loss=0.2647690176963806\n",
            "step 3757: generator_loss=2.7235264778137207, discriminator_loss=0.3677830398082733\n",
            "step 3758: generator_loss=3.089545965194702, discriminator_loss=0.3691437840461731\n",
            "step 3759: generator_loss=2.994704008102417, discriminator_loss=0.5158818960189819\n",
            "step 3760: generator_loss=3.653916835784912, discriminator_loss=0.38903242349624634\n",
            "step 3761: generator_loss=3.8553380966186523, discriminator_loss=0.31244152784347534\n",
            "step 3762: generator_loss=3.9385948181152344, discriminator_loss=0.23478350043296814\n",
            "step 3763: generator_loss=3.952934980392456, discriminator_loss=0.2292543351650238\n",
            "step 3764: generator_loss=3.5766377449035645, discriminator_loss=0.27191856503486633\n",
            "step 3765: generator_loss=3.6671018600463867, discriminator_loss=0.20809301733970642\n",
            "step 3766: generator_loss=3.8076205253601074, discriminator_loss=0.1688005030155182\n",
            "step 3767: generator_loss=4.012814521789551, discriminator_loss=0.14758476614952087\n",
            "step 3768: generator_loss=3.565972328186035, discriminator_loss=0.17047062516212463\n",
            "step 3769: generator_loss=3.1908926963806152, discriminator_loss=0.1460222750902176\n",
            "step 3770: generator_loss=3.2426414489746094, discriminator_loss=0.17989856004714966\n",
            "step 3771: generator_loss=3.410216808319092, discriminator_loss=0.14098890125751495\n",
            "step 3772: generator_loss=3.40938663482666, discriminator_loss=0.13423866033554077\n",
            "step 3773: generator_loss=3.1552071571350098, discriminator_loss=0.15155914425849915\n",
            "step 3774: generator_loss=3.4256858825683594, discriminator_loss=0.12405698001384735\n",
            "step 3775: generator_loss=3.4608123302459717, discriminator_loss=0.12631767988204956\n",
            "step 3776: generator_loss=3.3529298305511475, discriminator_loss=0.12827204167842865\n",
            "step 3777: generator_loss=3.216089963912964, discriminator_loss=0.14897692203521729\n",
            "step 3778: generator_loss=3.3784987926483154, discriminator_loss=0.1624806523323059\n",
            "step 3779: generator_loss=3.1771066188812256, discriminator_loss=0.1830800622701645\n",
            "step 3780: generator_loss=3.5739636421203613, discriminator_loss=0.14008422195911407\n",
            "step 3781: generator_loss=3.115264415740967, discriminator_loss=0.15538010001182556\n",
            "step 3782: generator_loss=3.1343202590942383, discriminator_loss=0.15605100989341736\n",
            "step 3783: generator_loss=2.912113666534424, discriminator_loss=0.10188660770654678\n",
            "step 3784: generator_loss=3.3488709926605225, discriminator_loss=0.09665138274431229\n",
            "step 3785: generator_loss=3.3324413299560547, discriminator_loss=0.10108359158039093\n",
            "step 3786: generator_loss=3.2694249153137207, discriminator_loss=0.09001514315605164\n",
            "step 3787: generator_loss=3.272641658782959, discriminator_loss=0.11251051723957062\n",
            "step 3788: generator_loss=3.2656569480895996, discriminator_loss=0.13450604677200317\n",
            "step 3789: generator_loss=3.048123836517334, discriminator_loss=0.15552052855491638\n",
            "step 3790: generator_loss=2.9041085243225098, discriminator_loss=0.1331729292869568\n",
            "step 3791: generator_loss=2.628657341003418, discriminator_loss=0.1620464026927948\n",
            "step 3792: generator_loss=2.547060966491699, discriminator_loss=0.14523503184318542\n",
            "step 3793: generator_loss=2.8094396591186523, discriminator_loss=0.16686594486236572\n",
            "step 3794: generator_loss=2.7198805809020996, discriminator_loss=0.16025811433792114\n",
            "step 3795: generator_loss=2.732795238494873, discriminator_loss=0.20044705271720886\n",
            "step 3796: generator_loss=3.0570240020751953, discriminator_loss=0.17297205328941345\n",
            "step 3797: generator_loss=3.028557538986206, discriminator_loss=0.20351526141166687\n",
            "step 3798: generator_loss=2.6663050651550293, discriminator_loss=0.21927466988563538\n",
            "step 3799: generator_loss=2.7061285972595215, discriminator_loss=0.2257392704486847\n",
            "step 3800: generator_loss=2.602980375289917, discriminator_loss=0.31705307960510254\n",
            "step 3801: generator_loss=2.8136978149414062, discriminator_loss=0.36757558584213257\n",
            "step 3802: generator_loss=3.094982147216797, discriminator_loss=0.30002525448799133\n",
            "step 3803: generator_loss=3.2428812980651855, discriminator_loss=0.3224160671234131\n",
            "step 3804: generator_loss=3.650355100631714, discriminator_loss=0.35838931798934937\n",
            "step 3805: generator_loss=3.3514719009399414, discriminator_loss=0.35080593824386597\n",
            "step 3806: generator_loss=3.2443056106567383, discriminator_loss=0.3040814995765686\n",
            "step 3807: generator_loss=2.943028450012207, discriminator_loss=0.3419435918331146\n",
            "step 3808: generator_loss=2.909829616546631, discriminator_loss=0.3113369345664978\n",
            "step 3809: generator_loss=3.0645503997802734, discriminator_loss=0.26080426573753357\n",
            "step 3810: generator_loss=3.3106913566589355, discriminator_loss=0.2735217213630676\n",
            "step 3811: generator_loss=3.5110583305358887, discriminator_loss=0.30493447184562683\n",
            "step 3812: generator_loss=3.681363821029663, discriminator_loss=0.2779182195663452\n",
            "step 3813: generator_loss=3.5445005893707275, discriminator_loss=0.21672137081623077\n",
            "step 3814: generator_loss=3.826141357421875, discriminator_loss=0.23390862345695496\n",
            "step 3815: generator_loss=3.8749752044677734, discriminator_loss=0.20183610916137695\n",
            "step 3816: generator_loss=3.5123724937438965, discriminator_loss=0.19078141450881958\n",
            "step 3817: generator_loss=2.7848925590515137, discriminator_loss=0.2641601860523224\n",
            "step 3818: generator_loss=2.939364433288574, discriminator_loss=0.16673246026039124\n",
            "step 3819: generator_loss=3.060925006866455, discriminator_loss=0.18201908469200134\n",
            "step 3820: generator_loss=3.152388095855713, discriminator_loss=0.19127768278121948\n",
            "step 3821: generator_loss=3.317546844482422, discriminator_loss=0.15198840200901031\n",
            "step 3822: generator_loss=3.634571075439453, discriminator_loss=0.16766801476478577\n",
            "step 3823: generator_loss=3.763723373413086, discriminator_loss=0.16817918419837952\n",
            "step 3824: generator_loss=3.588573694229126, discriminator_loss=0.1353587657213211\n",
            "step 3825: generator_loss=3.3997721672058105, discriminator_loss=0.1342340111732483\n",
            "step 3826: generator_loss=3.2447943687438965, discriminator_loss=0.09751801192760468\n",
            "step 3827: generator_loss=2.6644999980926514, discriminator_loss=0.15205436944961548\n",
            "step 3828: generator_loss=2.9068665504455566, discriminator_loss=0.10870964080095291\n",
            "step 3829: generator_loss=2.7579455375671387, discriminator_loss=0.1335427463054657\n",
            "step 3830: generator_loss=2.633533239364624, discriminator_loss=0.11916288733482361\n",
            "step 3831: generator_loss=2.7296767234802246, discriminator_loss=0.12318838387727737\n",
            "step 3832: generator_loss=2.6223373413085938, discriminator_loss=0.18409983813762665\n",
            "step 3833: generator_loss=2.5944764614105225, discriminator_loss=0.148196280002594\n",
            "step 3834: generator_loss=2.8322043418884277, discriminator_loss=0.15358887612819672\n",
            "step 3835: generator_loss=2.7203001976013184, discriminator_loss=0.15855717658996582\n",
            "step 3836: generator_loss=2.6798410415649414, discriminator_loss=0.16571982204914093\n",
            "step 3837: generator_loss=2.71742844581604, discriminator_loss=0.1299281120300293\n",
            "step 3838: generator_loss=2.645042657852173, discriminator_loss=0.1406053602695465\n",
            "step 3839: generator_loss=2.5179741382598877, discriminator_loss=0.1699986308813095\n",
            "step 3840: generator_loss=2.437664747238159, discriminator_loss=0.19559656083583832\n",
            "step 3841: generator_loss=2.223268508911133, discriminator_loss=0.25787511467933655\n",
            "step 3842: generator_loss=2.0654473304748535, discriminator_loss=0.24041225016117096\n",
            "step 3843: generator_loss=2.044498920440674, discriminator_loss=0.2136366069316864\n",
            "step 3844: generator_loss=2.1860125064849854, discriminator_loss=0.20255479216575623\n",
            "step 3845: generator_loss=2.34372615814209, discriminator_loss=0.16570991277694702\n",
            "step 3846: generator_loss=2.169510841369629, discriminator_loss=0.22245490550994873\n",
            "step 3847: generator_loss=2.222895622253418, discriminator_loss=0.20089048147201538\n",
            "step 3848: generator_loss=2.362758159637451, discriminator_loss=0.17423366010189056\n",
            "step 3849: generator_loss=2.1957898139953613, discriminator_loss=0.17437689006328583\n",
            "step 3850: generator_loss=2.35670804977417, discriminator_loss=0.20884135365486145\n",
            "step 3851: generator_loss=2.2824349403381348, discriminator_loss=0.21013228595256805\n",
            "step 3852: generator_loss=2.322978973388672, discriminator_loss=0.19453485310077667\n",
            "step 3853: generator_loss=2.5269525051116943, discriminator_loss=0.15996672213077545\n",
            "step 3854: generator_loss=2.553149938583374, discriminator_loss=0.16850793361663818\n",
            "step 3855: generator_loss=2.2379307746887207, discriminator_loss=0.18189752101898193\n",
            "step 3856: generator_loss=2.449869155883789, discriminator_loss=0.1895257979631424\n",
            "step 3857: generator_loss=2.2527952194213867, discriminator_loss=0.21262338757514954\n",
            "step 3858: generator_loss=2.4558653831481934, discriminator_loss=0.18086180090904236\n",
            "step 3859: generator_loss=2.2206783294677734, discriminator_loss=0.20243439078330994\n",
            "step 3860: generator_loss=2.583277940750122, discriminator_loss=0.21523669362068176\n",
            "step 3861: generator_loss=2.7254457473754883, discriminator_loss=0.2667957842350006\n",
            "step 3862: generator_loss=2.6616108417510986, discriminator_loss=0.1891852617263794\n",
            "step 3863: generator_loss=2.4943747520446777, discriminator_loss=0.21793803572654724\n",
            "step 3864: generator_loss=2.3034167289733887, discriminator_loss=0.304451048374176\n",
            "step 3865: generator_loss=2.4109864234924316, discriminator_loss=0.24035100638866425\n",
            "step 3866: generator_loss=2.6861462593078613, discriminator_loss=0.26321861147880554\n",
            "step 3867: generator_loss=2.862632989883423, discriminator_loss=0.26303645968437195\n",
            "step 3868: generator_loss=2.8545494079589844, discriminator_loss=0.31994307041168213\n",
            "step 3869: generator_loss=2.955683708190918, discriminator_loss=0.2705700695514679\n",
            "step 3870: generator_loss=2.883056402206421, discriminator_loss=0.34809887409210205\n",
            "step 3871: generator_loss=2.5577304363250732, discriminator_loss=0.3470346927642822\n",
            "step 3872: generator_loss=2.6063671112060547, discriminator_loss=0.34856361150741577\n",
            "step 3873: generator_loss=3.081458568572998, discriminator_loss=0.3003712296485901\n",
            "step 3874: generator_loss=2.689004421234131, discriminator_loss=0.31183940172195435\n",
            "step 3875: generator_loss=3.0627758502960205, discriminator_loss=0.30566197633743286\n",
            "step 3876: generator_loss=2.8349556922912598, discriminator_loss=0.2587067186832428\n",
            "step 3877: generator_loss=2.5867762565612793, discriminator_loss=0.2903113067150116\n",
            "step 3878: generator_loss=2.8869335651397705, discriminator_loss=0.28088176250457764\n",
            "step 3879: generator_loss=3.2126097679138184, discriminator_loss=0.21402092278003693\n",
            "step 3880: generator_loss=2.7470688819885254, discriminator_loss=0.264136403799057\n",
            "step 3881: generator_loss=3.0165247917175293, discriminator_loss=0.22553953528404236\n",
            "step 3882: generator_loss=2.927884578704834, discriminator_loss=0.16960108280181885\n",
            "step 3883: generator_loss=2.6459133625030518, discriminator_loss=0.18961191177368164\n",
            "step 3884: generator_loss=2.835944414138794, discriminator_loss=0.17126591503620148\n",
            "step 3885: generator_loss=2.8692917823791504, discriminator_loss=0.14097794890403748\n",
            "step 3886: generator_loss=2.95943546295166, discriminator_loss=0.13019509613513947\n",
            "step 3887: generator_loss=2.9858250617980957, discriminator_loss=0.15311096608638763\n",
            "step 3888: generator_loss=3.1220452785491943, discriminator_loss=0.15264317393302917\n",
            "step 3889: generator_loss=3.3839969635009766, discriminator_loss=0.11359452456235886\n",
            "step 3890: generator_loss=3.049746513366699, discriminator_loss=0.13649587333202362\n",
            "step 3891: generator_loss=3.058396339416504, discriminator_loss=0.12422969937324524\n",
            "step 3892: generator_loss=2.9553351402282715, discriminator_loss=0.16541145741939545\n",
            "step 3893: generator_loss=2.918828248977661, discriminator_loss=0.1641160249710083\n",
            "step 3894: generator_loss=3.1324987411499023, discriminator_loss=0.11749322712421417\n",
            "step 3895: generator_loss=2.7108068466186523, discriminator_loss=0.22412410378456116\n",
            "step 3896: generator_loss=2.6166529655456543, discriminator_loss=0.189825639128685\n",
            "step 3897: generator_loss=2.4594874382019043, discriminator_loss=0.20372004806995392\n",
            "step 3898: generator_loss=2.561962366104126, discriminator_loss=0.2028137743473053\n",
            "step 3899: generator_loss=2.793999671936035, discriminator_loss=0.1825273334980011\n",
            "step 3900: generator_loss=2.8101205825805664, discriminator_loss=0.1739630550146103\n",
            "step 3901: generator_loss=2.752136468887329, discriminator_loss=0.18133625388145447\n",
            "step 3902: generator_loss=2.9068546295166016, discriminator_loss=0.19399482011795044\n",
            "step 3903: generator_loss=2.6000752449035645, discriminator_loss=0.15830567479133606\n",
            "step 3904: generator_loss=2.5510363578796387, discriminator_loss=0.2134391963481903\n",
            "step 3905: generator_loss=2.198699712753296, discriminator_loss=0.21025368571281433\n",
            "step 3906: generator_loss=2.316277027130127, discriminator_loss=0.16165974736213684\n",
            "step 3907: generator_loss=2.5397839546203613, discriminator_loss=0.1765764057636261\n",
            "step 3908: generator_loss=2.685473918914795, discriminator_loss=0.21037200093269348\n",
            "step 3909: generator_loss=2.6531686782836914, discriminator_loss=0.19499942660331726\n",
            "step 3910: generator_loss=2.5580027103424072, discriminator_loss=0.21200141310691833\n",
            "step 3911: generator_loss=2.5860044956207275, discriminator_loss=0.21368271112442017\n",
            "step 3912: generator_loss=2.747467279434204, discriminator_loss=0.20440083742141724\n",
            "step 3913: generator_loss=2.6877353191375732, discriminator_loss=0.17802658677101135\n",
            "step 3914: generator_loss=2.5798466205596924, discriminator_loss=0.18268734216690063\n",
            "step 3915: generator_loss=2.272914409637451, discriminator_loss=0.20764030516147614\n",
            "step 3916: generator_loss=2.142899990081787, discriminator_loss=0.22612209618091583\n",
            "step 3917: generator_loss=2.1377131938934326, discriminator_loss=0.24410222470760345\n",
            "step 3918: generator_loss=2.1567487716674805, discriminator_loss=0.2192893773317337\n",
            "step 3919: generator_loss=2.2751588821411133, discriminator_loss=0.2139607071876526\n",
            "step 3920: generator_loss=2.446104049682617, discriminator_loss=0.2241363823413849\n",
            "step 3921: generator_loss=2.21805477142334, discriminator_loss=0.2498517632484436\n",
            "step 3922: generator_loss=2.3893544673919678, discriminator_loss=0.20221883058547974\n",
            "step 3923: generator_loss=2.272613048553467, discriminator_loss=0.25113800168037415\n",
            "step 3924: generator_loss=2.4337847232818604, discriminator_loss=0.19150510430335999\n",
            "step 3925: generator_loss=2.372581958770752, discriminator_loss=0.22037562727928162\n",
            "step 3926: generator_loss=2.290663719177246, discriminator_loss=0.21394005417823792\n",
            "step 3927: generator_loss=2.3213748931884766, discriminator_loss=0.20526742935180664\n",
            "step 3928: generator_loss=2.32887601852417, discriminator_loss=0.20391452312469482\n",
            "step 3929: generator_loss=2.4350414276123047, discriminator_loss=0.18140752613544464\n",
            "step 3930: generator_loss=2.483941078186035, discriminator_loss=0.11953054368495941\n",
            "step 3931: generator_loss=2.466352701187134, discriminator_loss=0.15019145607948303\n",
            "step 3932: generator_loss=2.5076241493225098, discriminator_loss=0.16788144409656525\n",
            "step 3933: generator_loss=2.5458202362060547, discriminator_loss=0.1659696251153946\n",
            "step 3934: generator_loss=2.5774762630462646, discriminator_loss=0.16300198435783386\n",
            "step 3935: generator_loss=2.521005868911743, discriminator_loss=0.17467541992664337\n",
            "step 3936: generator_loss=2.495936870574951, discriminator_loss=0.16869115829467773\n",
            "step 3937: generator_loss=2.581193447113037, discriminator_loss=0.14725933969020844\n",
            "step 3938: generator_loss=2.6737658977508545, discriminator_loss=0.13573545217514038\n",
            "step 3939: generator_loss=2.4969077110290527, discriminator_loss=0.19451138377189636\n",
            "step 3940: generator_loss=2.532776117324829, discriminator_loss=0.1605544537305832\n",
            "step 3941: generator_loss=2.4888336658477783, discriminator_loss=0.132155641913414\n",
            "step 3942: generator_loss=2.588207721710205, discriminator_loss=0.11269742250442505\n",
            "step 3943: generator_loss=2.70668888092041, discriminator_loss=0.14037062227725983\n",
            "step 3944: generator_loss=2.764892339706421, discriminator_loss=0.16930454969406128\n",
            "step 3945: generator_loss=2.8816134929656982, discriminator_loss=0.12313901633024216\n",
            "step 3946: generator_loss=2.8470826148986816, discriminator_loss=0.1186736524105072\n",
            "step 3947: generator_loss=2.7523202896118164, discriminator_loss=0.17759132385253906\n",
            "step 3948: generator_loss=2.610891819000244, discriminator_loss=0.13013219833374023\n",
            "step 3949: generator_loss=2.4771156311035156, discriminator_loss=0.13607285916805267\n",
            "step 3950: generator_loss=2.418748378753662, discriminator_loss=0.1539052426815033\n",
            "step 3951: generator_loss=2.430326461791992, discriminator_loss=0.1368146538734436\n",
            "step 3952: generator_loss=2.5334832668304443, discriminator_loss=0.14299288392066956\n",
            "step 3953: generator_loss=2.6624889373779297, discriminator_loss=0.14330045878887177\n",
            "step 3954: generator_loss=2.7015886306762695, discriminator_loss=0.1443626582622528\n",
            "step 3955: generator_loss=2.947596549987793, discriminator_loss=0.15067556500434875\n",
            "step 3956: generator_loss=2.840074300765991, discriminator_loss=0.12032625824213028\n",
            "step 3957: generator_loss=2.9489850997924805, discriminator_loss=0.139497309923172\n",
            "step 3958: generator_loss=2.8159093856811523, discriminator_loss=0.126176655292511\n",
            "step 3959: generator_loss=2.542262077331543, discriminator_loss=0.20206929743289948\n",
            "step 3960: generator_loss=2.624128818511963, discriminator_loss=0.19574815034866333\n",
            "step 3961: generator_loss=2.3835601806640625, discriminator_loss=0.23140466213226318\n",
            "step 3962: generator_loss=2.5993165969848633, discriminator_loss=0.22687353193759918\n",
            "step 3963: generator_loss=2.786489248275757, discriminator_loss=0.29658401012420654\n",
            "step 3964: generator_loss=2.7250423431396484, discriminator_loss=0.2586190104484558\n",
            "step 3965: generator_loss=2.7936158180236816, discriminator_loss=0.2848689556121826\n",
            "step 3966: generator_loss=3.1677346229553223, discriminator_loss=0.1972651481628418\n",
            "step 3967: generator_loss=3.124614715576172, discriminator_loss=0.23896321654319763\n",
            "step 3968: generator_loss=2.9123733043670654, discriminator_loss=0.28961166739463806\n",
            "step 3969: generator_loss=2.8973751068115234, discriminator_loss=0.3240337669849396\n",
            "step 3970: generator_loss=3.1299471855163574, discriminator_loss=0.2850527763366699\n",
            "step 3971: generator_loss=3.0422463417053223, discriminator_loss=0.32821595668792725\n",
            "step 3972: generator_loss=3.2098071575164795, discriminator_loss=0.2900170683860779\n",
            "step 3973: generator_loss=3.4423680305480957, discriminator_loss=0.2714579701423645\n",
            "step 3974: generator_loss=3.5887365341186523, discriminator_loss=0.23646819591522217\n",
            "step 3975: generator_loss=3.722006320953369, discriminator_loss=0.24461562931537628\n",
            "step 3976: generator_loss=4.557705402374268, discriminator_loss=0.17663323879241943\n",
            "step 3977: generator_loss=4.542795181274414, discriminator_loss=0.2146562933921814\n",
            "step 3978: generator_loss=4.241450786590576, discriminator_loss=0.17014697194099426\n",
            "step 3979: generator_loss=4.120038986206055, discriminator_loss=0.17387354373931885\n",
            "step 3980: generator_loss=4.118264198303223, discriminator_loss=0.17209504544734955\n",
            "step 3981: generator_loss=4.098185062408447, discriminator_loss=0.17486533522605896\n",
            "step 3982: generator_loss=3.3921918869018555, discriminator_loss=0.2084672451019287\n",
            "step 3983: generator_loss=3.5406112670898438, discriminator_loss=0.34408625960350037\n",
            "step 3984: generator_loss=3.696931838989258, discriminator_loss=0.2855057716369629\n",
            "step 3985: generator_loss=4.250057697296143, discriminator_loss=0.30155450105667114\n",
            "step 3986: generator_loss=4.221909999847412, discriminator_loss=0.3101816773414612\n",
            "step 3987: generator_loss=4.533725738525391, discriminator_loss=0.3227330148220062\n",
            "step 3988: generator_loss=4.228321552276611, discriminator_loss=0.3610864281654358\n",
            "step 3989: generator_loss=3.656153440475464, discriminator_loss=0.22231900691986084\n",
            "step 3990: generator_loss=3.360405683517456, discriminator_loss=0.2586575746536255\n",
            "step 3991: generator_loss=3.3123345375061035, discriminator_loss=0.21331608295440674\n",
            "step 3992: generator_loss=3.2703356742858887, discriminator_loss=0.17192772030830383\n",
            "step 3993: generator_loss=3.186998128890991, discriminator_loss=0.1328967958688736\n",
            "step 3994: generator_loss=3.5428152084350586, discriminator_loss=0.13885840773582458\n",
            "step 3995: generator_loss=3.578211784362793, discriminator_loss=0.15345719456672668\n",
            "step 3996: generator_loss=3.523797035217285, discriminator_loss=0.1339680701494217\n",
            "step 3997: generator_loss=3.519406318664551, discriminator_loss=0.15371157228946686\n",
            "step 3998: generator_loss=3.3893675804138184, discriminator_loss=0.13659493625164032\n",
            "step 3999: generator_loss=2.9971508979797363, discriminator_loss=0.1292845755815506\n",
            "step 4000: generator_loss=3.063602924346924, discriminator_loss=0.1600331962108612\n",
            "step 4001: generator_loss=2.9891819953918457, discriminator_loss=0.13934509456157684\n",
            "step 4002: generator_loss=2.8577349185943604, discriminator_loss=0.11953113973140717\n",
            "step 4003: generator_loss=2.509197235107422, discriminator_loss=0.1958610713481903\n",
            "step 4004: generator_loss=2.774007797241211, discriminator_loss=0.19009526073932648\n",
            "step 4005: generator_loss=3.0767650604248047, discriminator_loss=0.14015451073646545\n",
            "step 4006: generator_loss=2.5981016159057617, discriminator_loss=0.1569136381149292\n",
            "step 4007: generator_loss=2.953455924987793, discriminator_loss=0.18730735778808594\n",
            "step 4008: generator_loss=3.0723695755004883, discriminator_loss=0.16792556643486023\n",
            "step 4009: generator_loss=2.964672565460205, discriminator_loss=0.175803080201149\n",
            "step 4010: generator_loss=2.8627140522003174, discriminator_loss=0.13928045332431793\n",
            "step 4011: generator_loss=2.6197681427001953, discriminator_loss=0.22012287378311157\n",
            "step 4012: generator_loss=2.846168279647827, discriminator_loss=0.17372778058052063\n",
            "step 4013: generator_loss=2.7420477867126465, discriminator_loss=0.14921358227729797\n",
            "step 4014: generator_loss=2.966860055923462, discriminator_loss=0.13699690997600555\n",
            "step 4015: generator_loss=2.9776244163513184, discriminator_loss=0.13956712186336517\n",
            "step 4016: generator_loss=2.750742197036743, discriminator_loss=0.17090699076652527\n",
            "step 4017: generator_loss=2.864481210708618, discriminator_loss=0.19275058805942535\n",
            "step 4018: generator_loss=2.676927089691162, discriminator_loss=0.18765269219875336\n",
            "step 4019: generator_loss=2.5599894523620605, discriminator_loss=0.16914212703704834\n",
            "step 4020: generator_loss=2.760989189147949, discriminator_loss=0.15400879085063934\n",
            "step 4021: generator_loss=2.720762252807617, discriminator_loss=0.19704481959342957\n",
            "step 4022: generator_loss=2.8715193271636963, discriminator_loss=0.16614575684070587\n",
            "step 4023: generator_loss=2.700808048248291, discriminator_loss=0.20289303362369537\n",
            "step 4024: generator_loss=2.6364376544952393, discriminator_loss=0.23730142414569855\n",
            "step 4025: generator_loss=2.3968422412872314, discriminator_loss=0.1907060444355011\n",
            "step 4026: generator_loss=2.4144396781921387, discriminator_loss=0.2171919047832489\n",
            "step 4027: generator_loss=2.326416492462158, discriminator_loss=0.2882111668586731\n",
            "step 4028: generator_loss=2.492213726043701, discriminator_loss=0.23498445749282837\n",
            "step 4029: generator_loss=2.5051913261413574, discriminator_loss=0.24121960997581482\n",
            "step 4030: generator_loss=2.687939167022705, discriminator_loss=0.2915116548538208\n",
            "step 4031: generator_loss=2.627598524093628, discriminator_loss=0.23610568046569824\n",
            "step 4032: generator_loss=2.58060359954834, discriminator_loss=0.27728894352912903\n",
            "step 4033: generator_loss=2.918146848678589, discriminator_loss=0.32652583718299866\n",
            "step 4034: generator_loss=2.861523389816284, discriminator_loss=0.26676684617996216\n",
            "step 4035: generator_loss=2.803921937942505, discriminator_loss=0.3181489109992981\n",
            "step 4036: generator_loss=2.784579277038574, discriminator_loss=0.45219671726226807\n",
            "step 4037: generator_loss=3.594027042388916, discriminator_loss=0.2726336419582367\n",
            "step 4038: generator_loss=3.6359872817993164, discriminator_loss=0.3535391092300415\n",
            "step 4039: generator_loss=4.067649841308594, discriminator_loss=0.319364070892334\n",
            "step 4040: generator_loss=3.8041276931762695, discriminator_loss=0.3950551152229309\n",
            "step 4041: generator_loss=4.1234564781188965, discriminator_loss=0.33250799775123596\n",
            "step 4042: generator_loss=4.402501583099365, discriminator_loss=0.27354153990745544\n",
            "step 4043: generator_loss=4.14301872253418, discriminator_loss=0.26645639538764954\n",
            "step 4044: generator_loss=4.067478179931641, discriminator_loss=0.2677771747112274\n",
            "step 4045: generator_loss=4.498618125915527, discriminator_loss=0.21827583014965057\n",
            "step 4046: generator_loss=4.174256324768066, discriminator_loss=0.1650184541940689\n",
            "step 4047: generator_loss=4.492250442504883, discriminator_loss=0.15292924642562866\n",
            "step 4048: generator_loss=4.271788597106934, discriminator_loss=0.1305767148733139\n",
            "step 4049: generator_loss=4.187574863433838, discriminator_loss=0.11121277511119843\n",
            "step 4050: generator_loss=3.7743237018585205, discriminator_loss=0.1272062361240387\n",
            "step 4051: generator_loss=3.549532413482666, discriminator_loss=0.12044572830200195\n",
            "step 4052: generator_loss=3.2765841484069824, discriminator_loss=0.13668137788772583\n",
            "step 4053: generator_loss=3.354860782623291, discriminator_loss=0.09488077461719513\n",
            "step 4054: generator_loss=3.207097291946411, discriminator_loss=0.11229535937309265\n",
            "step 4055: generator_loss=3.191014528274536, discriminator_loss=0.11415378749370575\n",
            "step 4056: generator_loss=3.5917282104492188, discriminator_loss=0.11802040040493011\n",
            "step 4057: generator_loss=3.3703036308288574, discriminator_loss=0.10209669917821884\n",
            "step 4058: generator_loss=3.5543510913848877, discriminator_loss=0.1517629623413086\n",
            "step 4059: generator_loss=3.5773887634277344, discriminator_loss=0.16281306743621826\n",
            "step 4060: generator_loss=3.220107316970825, discriminator_loss=0.12857796251773834\n",
            "step 4061: generator_loss=3.3750696182250977, discriminator_loss=0.12225651741027832\n",
            "step 4062: generator_loss=3.242124319076538, discriminator_loss=0.1635129749774933\n",
            "step 4063: generator_loss=3.201420307159424, discriminator_loss=0.1307079792022705\n",
            "step 4064: generator_loss=2.9713845252990723, discriminator_loss=0.19105643033981323\n",
            "step 4065: generator_loss=3.2197425365448, discriminator_loss=0.13946032524108887\n",
            "step 4066: generator_loss=3.1916112899780273, discriminator_loss=0.11326596885919571\n",
            "step 4067: generator_loss=3.0245137214660645, discriminator_loss=0.1912660300731659\n",
            "step 4068: generator_loss=2.922313928604126, discriminator_loss=0.1410265862941742\n",
            "step 4069: generator_loss=2.9566187858581543, discriminator_loss=0.16005045175552368\n",
            "step 4070: generator_loss=2.772481918334961, discriminator_loss=0.13303223252296448\n",
            "step 4071: generator_loss=2.7240986824035645, discriminator_loss=0.14580008387565613\n",
            "step 4072: generator_loss=2.617887020111084, discriminator_loss=0.15363359451293945\n",
            "step 4073: generator_loss=2.448476552963257, discriminator_loss=0.14367833733558655\n",
            "step 4074: generator_loss=2.3521809577941895, discriminator_loss=0.22186769545078278\n",
            "step 4075: generator_loss=2.6698226928710938, discriminator_loss=0.1498645544052124\n",
            "step 4076: generator_loss=2.694594383239746, discriminator_loss=0.18981797993183136\n",
            "step 4077: generator_loss=2.913471221923828, discriminator_loss=0.16069771349430084\n",
            "step 4078: generator_loss=2.720381736755371, discriminator_loss=0.19140362739562988\n",
            "step 4079: generator_loss=2.498467206954956, discriminator_loss=0.23869967460632324\n",
            "step 4080: generator_loss=2.2854385375976562, discriminator_loss=0.22995921969413757\n",
            "step 4081: generator_loss=2.0255751609802246, discriminator_loss=0.2342020720243454\n",
            "step 4082: generator_loss=1.9960434436798096, discriminator_loss=0.25773847103118896\n",
            "step 4083: generator_loss=1.9575233459472656, discriminator_loss=0.2841165065765381\n",
            "step 4084: generator_loss=2.3044233322143555, discriminator_loss=0.17993532121181488\n",
            "step 4085: generator_loss=2.4199705123901367, discriminator_loss=0.25230392813682556\n",
            "step 4086: generator_loss=2.6516520977020264, discriminator_loss=0.19412076473236084\n",
            "step 4087: generator_loss=2.587667465209961, discriminator_loss=0.24795156717300415\n",
            "step 4088: generator_loss=2.39924955368042, discriminator_loss=0.2995378375053406\n",
            "step 4089: generator_loss=2.1689929962158203, discriminator_loss=0.24299341440200806\n",
            "step 4090: generator_loss=1.9004062414169312, discriminator_loss=0.3021598160266876\n",
            "step 4091: generator_loss=1.7359362840652466, discriminator_loss=0.3416593074798584\n",
            "step 4092: generator_loss=1.859131097793579, discriminator_loss=0.2959909439086914\n",
            "step 4093: generator_loss=2.0565977096557617, discriminator_loss=0.33095893263816833\n",
            "step 4094: generator_loss=2.4200668334960938, discriminator_loss=0.24988079071044922\n",
            "step 4095: generator_loss=2.5792417526245117, discriminator_loss=0.2923833429813385\n",
            "step 4096: generator_loss=2.2134127616882324, discriminator_loss=0.3404456377029419\n",
            "step 4097: generator_loss=1.9652173519134521, discriminator_loss=0.3164862394332886\n",
            "step 4098: generator_loss=2.152087688446045, discriminator_loss=0.2750612497329712\n",
            "step 4099: generator_loss=1.9909634590148926, discriminator_loss=0.2853843569755554\n",
            "step 4100: generator_loss=2.2116801738739014, discriminator_loss=0.2417914867401123\n",
            "step 4101: generator_loss=2.381272077560425, discriminator_loss=0.20455163717269897\n",
            "step 4102: generator_loss=2.6292614936828613, discriminator_loss=0.20096099376678467\n",
            "step 4103: generator_loss=2.723054885864258, discriminator_loss=0.19936612248420715\n",
            "step 4104: generator_loss=2.8104076385498047, discriminator_loss=0.26657673716545105\n",
            "step 4105: generator_loss=2.6821625232696533, discriminator_loss=0.1772749125957489\n",
            "step 4106: generator_loss=2.3564882278442383, discriminator_loss=0.24518753588199615\n",
            "step 4107: generator_loss=2.0759143829345703, discriminator_loss=0.18911588191986084\n",
            "step 4108: generator_loss=2.166245460510254, discriminator_loss=0.2035764753818512\n",
            "step 4109: generator_loss=2.1101744174957275, discriminator_loss=0.2579987347126007\n",
            "step 4110: generator_loss=2.320875883102417, discriminator_loss=0.1977769434452057\n",
            "step 4111: generator_loss=2.458176851272583, discriminator_loss=0.229404017329216\n",
            "step 4112: generator_loss=2.5252978801727295, discriminator_loss=0.15687745809555054\n",
            "step 4113: generator_loss=2.746952533721924, discriminator_loss=0.21549955010414124\n",
            "step 4114: generator_loss=2.5332961082458496, discriminator_loss=0.20165181159973145\n",
            "step 4115: generator_loss=2.531675338745117, discriminator_loss=0.18261271715164185\n",
            "step 4116: generator_loss=2.5862174034118652, discriminator_loss=0.18217286467552185\n",
            "step 4117: generator_loss=2.5117149353027344, discriminator_loss=0.1633109599351883\n",
            "step 4118: generator_loss=2.589249610900879, discriminator_loss=0.14950396120548248\n",
            "step 4119: generator_loss=2.5470147132873535, discriminator_loss=0.14443178474903107\n",
            "step 4120: generator_loss=2.957244873046875, discriminator_loss=0.13496875762939453\n",
            "step 4121: generator_loss=2.669346809387207, discriminator_loss=0.15998108685016632\n",
            "step 4122: generator_loss=2.521681308746338, discriminator_loss=0.14997263252735138\n",
            "step 4123: generator_loss=2.515687942504883, discriminator_loss=0.16035878658294678\n",
            "step 4124: generator_loss=2.51714825630188, discriminator_loss=0.18473879992961884\n",
            "step 4125: generator_loss=2.427150249481201, discriminator_loss=0.17955273389816284\n",
            "step 4126: generator_loss=2.4301605224609375, discriminator_loss=0.21856923401355743\n",
            "step 4127: generator_loss=2.314887523651123, discriminator_loss=0.18206587433815002\n",
            "step 4128: generator_loss=2.192842960357666, discriminator_loss=0.20044493675231934\n",
            "step 4129: generator_loss=2.2495527267456055, discriminator_loss=0.21912658214569092\n",
            "step 4130: generator_loss=2.354414939880371, discriminator_loss=0.17468175292015076\n",
            "step 4131: generator_loss=2.5160012245178223, discriminator_loss=0.18528735637664795\n",
            "step 4132: generator_loss=2.5826218128204346, discriminator_loss=0.1630958616733551\n",
            "step 4133: generator_loss=2.587855339050293, discriminator_loss=0.13127313554286957\n",
            "step 4134: generator_loss=2.517449378967285, discriminator_loss=0.1773402839899063\n",
            "step 4135: generator_loss=2.542562484741211, discriminator_loss=0.14952127635478973\n",
            "step 4136: generator_loss=2.5644426345825195, discriminator_loss=0.15971410274505615\n",
            "step 4137: generator_loss=2.5678091049194336, discriminator_loss=0.16148720681667328\n",
            "step 4138: generator_loss=2.6611480712890625, discriminator_loss=0.14436911046504974\n",
            "step 4139: generator_loss=2.506918430328369, discriminator_loss=0.12909114360809326\n",
            "step 4140: generator_loss=2.618070602416992, discriminator_loss=0.10888078063726425\n",
            "step 4141: generator_loss=2.6077489852905273, discriminator_loss=0.12340385466814041\n",
            "step 4142: generator_loss=2.766681671142578, discriminator_loss=0.12854230403900146\n",
            "step 4143: generator_loss=2.895962715148926, discriminator_loss=0.13538067042827606\n",
            "step 4144: generator_loss=2.829765796661377, discriminator_loss=0.11199727654457092\n",
            "step 4145: generator_loss=2.943538188934326, discriminator_loss=0.11731310933828354\n",
            "step 4146: generator_loss=2.8908209800720215, discriminator_loss=0.09139622747898102\n",
            "step 4147: generator_loss=2.773798704147339, discriminator_loss=0.12261088192462921\n",
            "step 4148: generator_loss=2.6153321266174316, discriminator_loss=0.09113524854183197\n",
            "step 4149: generator_loss=2.7775466442108154, discriminator_loss=0.11142700165510178\n",
            "step 4150: generator_loss=2.7027335166931152, discriminator_loss=0.12646466493606567\n",
            "step 4151: generator_loss=2.8097901344299316, discriminator_loss=0.11383932828903198\n",
            "step 4152: generator_loss=2.7574596405029297, discriminator_loss=0.1314992606639862\n",
            "step 4153: generator_loss=2.6352860927581787, discriminator_loss=0.11056332290172577\n",
            "step 4154: generator_loss=2.4634995460510254, discriminator_loss=0.1551298201084137\n",
            "step 4155: generator_loss=2.603586196899414, discriminator_loss=0.1425783932209015\n",
            "step 4156: generator_loss=2.4492053985595703, discriminator_loss=0.1411047726869583\n",
            "step 4157: generator_loss=2.5289862155914307, discriminator_loss=0.1493832767009735\n",
            "step 4158: generator_loss=2.5115389823913574, discriminator_loss=0.14717739820480347\n",
            "step 4159: generator_loss=2.297368049621582, discriminator_loss=0.15366406738758087\n",
            "step 4160: generator_loss=2.2879650592803955, discriminator_loss=0.17852984368801117\n",
            "step 4161: generator_loss=2.584566593170166, discriminator_loss=0.144230455160141\n",
            "step 4162: generator_loss=2.4847168922424316, discriminator_loss=0.1271658092737198\n",
            "step 4163: generator_loss=2.640777587890625, discriminator_loss=0.1316794753074646\n",
            "step 4164: generator_loss=2.6886868476867676, discriminator_loss=0.12613369524478912\n",
            "step 4165: generator_loss=2.6892282962799072, discriminator_loss=0.12405815720558167\n",
            "step 4166: generator_loss=2.8795080184936523, discriminator_loss=0.10498790442943573\n",
            "step 4167: generator_loss=2.6526904106140137, discriminator_loss=0.13522571325302124\n",
            "step 4168: generator_loss=2.458707809448242, discriminator_loss=0.1400986760854721\n",
            "step 4169: generator_loss=2.2318427562713623, discriminator_loss=0.13306495547294617\n",
            "step 4170: generator_loss=2.410999298095703, discriminator_loss=0.10845905542373657\n",
            "step 4171: generator_loss=2.4644927978515625, discriminator_loss=0.1284671425819397\n",
            "step 4172: generator_loss=2.479069471359253, discriminator_loss=0.10910959541797638\n",
            "step 4173: generator_loss=2.5894553661346436, discriminator_loss=0.13847753405570984\n",
            "step 4174: generator_loss=2.666149377822876, discriminator_loss=0.13272295892238617\n",
            "step 4175: generator_loss=2.783538341522217, discriminator_loss=0.13538821041584015\n",
            "step 4176: generator_loss=2.5931692123413086, discriminator_loss=0.11989744007587433\n",
            "step 4177: generator_loss=2.5206995010375977, discriminator_loss=0.12132339179515839\n",
            "step 4178: generator_loss=2.484678030014038, discriminator_loss=0.13542617857456207\n",
            "step 4179: generator_loss=2.2830469608306885, discriminator_loss=0.14031246304512024\n",
            "step 4180: generator_loss=2.2467072010040283, discriminator_loss=0.14364926517009735\n",
            "step 4181: generator_loss=2.278902530670166, discriminator_loss=0.11185241490602493\n",
            "step 4182: generator_loss=2.3610377311706543, discriminator_loss=0.15283352136611938\n",
            "step 4183: generator_loss=2.4144949913024902, discriminator_loss=0.13175660371780396\n",
            "step 4184: generator_loss=2.535064697265625, discriminator_loss=0.13921593129634857\n",
            "step 4185: generator_loss=2.464718818664551, discriminator_loss=0.14354781806468964\n",
            "step 4186: generator_loss=2.348060131072998, discriminator_loss=0.14179277420043945\n",
            "step 4187: generator_loss=2.274482488632202, discriminator_loss=0.14413371682167053\n",
            "step 4188: generator_loss=2.297194480895996, discriminator_loss=0.14823231101036072\n",
            "step 4189: generator_loss=2.429168939590454, discriminator_loss=0.12243110686540604\n",
            "step 4190: generator_loss=2.470582962036133, discriminator_loss=0.13682952523231506\n",
            "step 4191: generator_loss=2.4401369094848633, discriminator_loss=0.14067870378494263\n",
            "step 4192: generator_loss=2.6164560317993164, discriminator_loss=0.1255996823310852\n",
            "step 4193: generator_loss=2.6200437545776367, discriminator_loss=0.11772280931472778\n",
            "step 4194: generator_loss=2.5707595348358154, discriminator_loss=0.10698850452899933\n",
            "step 4195: generator_loss=2.513998508453369, discriminator_loss=0.1186302974820137\n",
            "step 4196: generator_loss=2.552074670791626, discriminator_loss=0.11130635440349579\n",
            "step 4197: generator_loss=2.5521979331970215, discriminator_loss=0.11792916804552078\n",
            "step 4198: generator_loss=2.6187751293182373, discriminator_loss=0.09394077956676483\n",
            "step 4199: generator_loss=2.708073616027832, discriminator_loss=0.09280463308095932\n",
            "step 4200: generator_loss=2.714782238006592, discriminator_loss=0.08868266642093658\n",
            "step 4201: generator_loss=2.7604148387908936, discriminator_loss=0.08325521647930145\n",
            "step 4202: generator_loss=2.9239964485168457, discriminator_loss=0.09457013756036758\n",
            "step 4203: generator_loss=3.091055393218994, discriminator_loss=0.07792938500642776\n",
            "step 4204: generator_loss=2.9342148303985596, discriminator_loss=0.0787692666053772\n",
            "step 4205: generator_loss=2.7940423488616943, discriminator_loss=0.09586785733699799\n",
            "step 4206: generator_loss=2.989659309387207, discriminator_loss=0.102139912545681\n",
            "step 4207: generator_loss=3.054577112197876, discriminator_loss=0.0851653590798378\n",
            "step 4208: generator_loss=2.8175272941589355, discriminator_loss=0.10498246550559998\n",
            "step 4209: generator_loss=2.690786838531494, discriminator_loss=0.1129528284072876\n",
            "step 4210: generator_loss=2.6649863719940186, discriminator_loss=0.1300475150346756\n",
            "step 4211: generator_loss=2.665560722351074, discriminator_loss=0.13228164613246918\n",
            "step 4212: generator_loss=2.7799649238586426, discriminator_loss=0.0983017310500145\n",
            "step 4213: generator_loss=2.899292469024658, discriminator_loss=0.10728862136602402\n",
            "step 4214: generator_loss=2.9462199211120605, discriminator_loss=0.1088293045759201\n",
            "step 4215: generator_loss=2.848863363265991, discriminator_loss=0.11974706500768661\n",
            "step 4216: generator_loss=2.966035842895508, discriminator_loss=0.0899876058101654\n",
            "step 4217: generator_loss=2.846384286880493, discriminator_loss=0.095423124730587\n",
            "step 4218: generator_loss=2.895106792449951, discriminator_loss=0.09862230718135834\n",
            "step 4219: generator_loss=3.1664958000183105, discriminator_loss=0.0776691660284996\n",
            "step 4220: generator_loss=3.305701971054077, discriminator_loss=0.06416721642017365\n",
            "step 4221: generator_loss=3.230957508087158, discriminator_loss=0.09134610742330551\n",
            "step 4222: generator_loss=3.5064077377319336, discriminator_loss=0.07454943656921387\n",
            "step 4223: generator_loss=3.567589282989502, discriminator_loss=0.08802825212478638\n",
            "step 4224: generator_loss=3.9883556365966797, discriminator_loss=0.04539880156517029\n",
            "step 4225: generator_loss=4.044126987457275, discriminator_loss=0.05878187716007233\n",
            "step 4226: generator_loss=4.059764862060547, discriminator_loss=0.07191260159015656\n",
            "step 4227: generator_loss=3.934152126312256, discriminator_loss=0.08855438232421875\n",
            "step 4228: generator_loss=3.90153169631958, discriminator_loss=0.09117359668016434\n",
            "step 4229: generator_loss=3.803417205810547, discriminator_loss=0.09244783222675323\n",
            "step 4230: generator_loss=3.7534642219543457, discriminator_loss=0.08496010303497314\n",
            "step 4231: generator_loss=3.68965744972229, discriminator_loss=0.10637262463569641\n",
            "step 4232: generator_loss=3.792257308959961, discriminator_loss=0.08846669644117355\n",
            "step 4233: generator_loss=3.8096864223480225, discriminator_loss=0.12460671365261078\n",
            "step 4234: generator_loss=3.8132457733154297, discriminator_loss=0.1154826432466507\n",
            "step 4235: generator_loss=3.8113412857055664, discriminator_loss=0.12440400570631027\n",
            "step 4236: generator_loss=3.9255523681640625, discriminator_loss=0.1305067390203476\n",
            "step 4237: generator_loss=4.136990547180176, discriminator_loss=0.11551114171743393\n",
            "step 4238: generator_loss=4.007519721984863, discriminator_loss=0.09594495594501495\n",
            "step 4239: generator_loss=3.4767322540283203, discriminator_loss=0.14374491572380066\n",
            "step 4240: generator_loss=3.4260120391845703, discriminator_loss=0.11251258850097656\n",
            "step 4241: generator_loss=3.5532422065734863, discriminator_loss=0.10043857246637344\n",
            "step 4242: generator_loss=3.304975986480713, discriminator_loss=0.12960457801818848\n",
            "step 4243: generator_loss=3.4443228244781494, discriminator_loss=0.08258987963199615\n",
            "step 4244: generator_loss=3.3692116737365723, discriminator_loss=0.09675253927707672\n",
            "step 4245: generator_loss=3.386619806289673, discriminator_loss=0.12714244425296783\n",
            "step 4246: generator_loss=3.583148241043091, discriminator_loss=0.10097827017307281\n",
            "step 4247: generator_loss=3.4172024726867676, discriminator_loss=0.13738200068473816\n",
            "step 4248: generator_loss=3.622162342071533, discriminator_loss=0.1235729455947876\n",
            "step 4249: generator_loss=3.3793559074401855, discriminator_loss=0.11669574677944183\n",
            "step 4250: generator_loss=3.317762851715088, discriminator_loss=0.1398116499185562\n",
            "step 4251: generator_loss=3.3034138679504395, discriminator_loss=0.1256132423877716\n",
            "step 4252: generator_loss=3.4451992511749268, discriminator_loss=0.08084411919116974\n",
            "step 4253: generator_loss=3.105556011199951, discriminator_loss=0.10948716849088669\n",
            "step 4254: generator_loss=3.1916377544403076, discriminator_loss=0.12647242844104767\n",
            "step 4255: generator_loss=3.2839622497558594, discriminator_loss=0.10701656341552734\n",
            "step 4256: generator_loss=3.502582550048828, discriminator_loss=0.11334779858589172\n",
            "step 4257: generator_loss=3.50618314743042, discriminator_loss=0.10479441285133362\n",
            "step 4258: generator_loss=3.2793354988098145, discriminator_loss=0.15375596284866333\n",
            "step 4259: generator_loss=2.860424518585205, discriminator_loss=0.1535339057445526\n",
            "step 4260: generator_loss=2.5710549354553223, discriminator_loss=0.13235488533973694\n",
            "step 4261: generator_loss=2.586146116256714, discriminator_loss=0.1394081860780716\n",
            "step 4262: generator_loss=2.548238754272461, discriminator_loss=0.14778339862823486\n",
            "step 4263: generator_loss=2.691740036010742, discriminator_loss=0.1416294425725937\n",
            "step 4264: generator_loss=2.897435426712036, discriminator_loss=0.10248173773288727\n",
            "step 4265: generator_loss=3.0828869342803955, discriminator_loss=0.11155706644058228\n",
            "step 4266: generator_loss=3.072495460510254, discriminator_loss=0.1782892346382141\n",
            "step 4267: generator_loss=3.3232016563415527, discriminator_loss=0.07400456070899963\n",
            "step 4268: generator_loss=3.1986489295959473, discriminator_loss=0.14670507609844208\n",
            "step 4269: generator_loss=3.0257139205932617, discriminator_loss=0.142744779586792\n",
            "step 4270: generator_loss=2.774686336517334, discriminator_loss=0.15558266639709473\n",
            "step 4271: generator_loss=2.754366397857666, discriminator_loss=0.13971245288848877\n",
            "step 4272: generator_loss=2.751936912536621, discriminator_loss=0.16380827128887177\n",
            "step 4273: generator_loss=2.584587574005127, discriminator_loss=0.22671470046043396\n",
            "step 4274: generator_loss=2.9346890449523926, discriminator_loss=0.24465429782867432\n",
            "step 4275: generator_loss=3.023710250854492, discriminator_loss=0.2880449593067169\n",
            "step 4276: generator_loss=3.348665237426758, discriminator_loss=0.19101455807685852\n",
            "step 4277: generator_loss=3.260173797607422, discriminator_loss=0.2827206254005432\n",
            "step 4278: generator_loss=3.6142807006835938, discriminator_loss=0.27081722021102905\n",
            "step 4279: generator_loss=3.3826918601989746, discriminator_loss=0.3864234685897827\n",
            "step 4280: generator_loss=3.8299145698547363, discriminator_loss=0.2870655357837677\n",
            "step 4281: generator_loss=4.289200782775879, discriminator_loss=0.24111489951610565\n",
            "step 4282: generator_loss=4.485572338104248, discriminator_loss=0.17797939479351044\n",
            "step 4283: generator_loss=3.717299222946167, discriminator_loss=0.22225598990917206\n",
            "step 4284: generator_loss=4.207266807556152, discriminator_loss=0.18233796954154968\n",
            "step 4285: generator_loss=4.2627973556518555, discriminator_loss=0.1344563066959381\n",
            "step 4286: generator_loss=4.105086326599121, discriminator_loss=0.12810444831848145\n",
            "step 4287: generator_loss=4.266040325164795, discriminator_loss=0.10072040557861328\n",
            "step 4288: generator_loss=4.234853744506836, discriminator_loss=0.1268695443868637\n",
            "step 4289: generator_loss=4.384382247924805, discriminator_loss=0.07067301124334335\n",
            "step 4290: generator_loss=3.9942448139190674, discriminator_loss=0.08545351028442383\n",
            "step 4291: generator_loss=3.6314992904663086, discriminator_loss=0.13101474940776825\n",
            "step 4292: generator_loss=3.34598445892334, discriminator_loss=0.11367356032133102\n",
            "step 4293: generator_loss=3.4150567054748535, discriminator_loss=0.12369056046009064\n",
            "step 4294: generator_loss=3.0663976669311523, discriminator_loss=0.12434710562229156\n",
            "step 4295: generator_loss=3.0030908584594727, discriminator_loss=0.14047929644584656\n",
            "step 4296: generator_loss=2.9920308589935303, discriminator_loss=0.14449086785316467\n",
            "step 4297: generator_loss=3.426821231842041, discriminator_loss=0.14611953496932983\n",
            "step 4298: generator_loss=3.374263286590576, discriminator_loss=0.20252391695976257\n",
            "step 4299: generator_loss=3.293572425842285, discriminator_loss=0.19288747012615204\n",
            "step 4300: generator_loss=3.602384090423584, discriminator_loss=0.21985816955566406\n",
            "step 4301: generator_loss=3.5425519943237305, discriminator_loss=0.22396668791770935\n",
            "step 4302: generator_loss=3.2618374824523926, discriminator_loss=0.22715887427330017\n",
            "step 4303: generator_loss=3.018505334854126, discriminator_loss=0.2304506152868271\n",
            "step 4304: generator_loss=2.947173833847046, discriminator_loss=0.22762887179851532\n",
            "step 4305: generator_loss=3.3289685249328613, discriminator_loss=0.2243380844593048\n",
            "step 4306: generator_loss=3.095444917678833, discriminator_loss=0.2310498207807541\n",
            "step 4307: generator_loss=3.6383233070373535, discriminator_loss=0.1988983154296875\n",
            "step 4308: generator_loss=3.8815460205078125, discriminator_loss=0.2301267683506012\n",
            "step 4309: generator_loss=3.8568761348724365, discriminator_loss=0.22292231023311615\n",
            "step 4310: generator_loss=4.000889778137207, discriminator_loss=0.17165935039520264\n",
            "step 4311: generator_loss=3.8649868965148926, discriminator_loss=0.1690206676721573\n",
            "step 4312: generator_loss=3.665271759033203, discriminator_loss=0.2283181995153427\n",
            "step 4313: generator_loss=3.6672520637512207, discriminator_loss=0.22761407494544983\n",
            "step 4314: generator_loss=3.5094358921051025, discriminator_loss=0.2125842124223709\n",
            "step 4315: generator_loss=3.5260021686553955, discriminator_loss=0.17268478870391846\n",
            "step 4316: generator_loss=3.23773193359375, discriminator_loss=0.22403445839881897\n",
            "step 4317: generator_loss=3.4755067825317383, discriminator_loss=0.18096880614757538\n",
            "step 4318: generator_loss=3.716129779815674, discriminator_loss=0.14375898241996765\n",
            "step 4319: generator_loss=3.3341808319091797, discriminator_loss=0.15408320724964142\n",
            "step 4320: generator_loss=3.112877368927002, discriminator_loss=0.22523930668830872\n",
            "step 4321: generator_loss=3.1764869689941406, discriminator_loss=0.18833181262016296\n",
            "step 4322: generator_loss=2.7635769844055176, discriminator_loss=0.20942947268486023\n",
            "step 4323: generator_loss=2.82305908203125, discriminator_loss=0.19884255528450012\n",
            "step 4324: generator_loss=3.1211130619049072, discriminator_loss=0.20577089488506317\n",
            "step 4325: generator_loss=3.466431140899658, discriminator_loss=0.18503794074058533\n",
            "step 4326: generator_loss=3.3315839767456055, discriminator_loss=0.18545827269554138\n",
            "step 4327: generator_loss=3.235111713409424, discriminator_loss=0.158219113945961\n",
            "step 4328: generator_loss=2.9216527938842773, discriminator_loss=0.20996418595314026\n",
            "step 4329: generator_loss=3.175455093383789, discriminator_loss=0.19144944846630096\n",
            "step 4330: generator_loss=3.264756202697754, discriminator_loss=0.19230738282203674\n",
            "step 4331: generator_loss=2.767350196838379, discriminator_loss=0.19546586275100708\n",
            "step 4332: generator_loss=3.055565357208252, discriminator_loss=0.2194272130727768\n",
            "step 4333: generator_loss=3.1359405517578125, discriminator_loss=0.14828360080718994\n",
            "step 4334: generator_loss=3.1355748176574707, discriminator_loss=0.1292308270931244\n",
            "step 4335: generator_loss=3.2672159671783447, discriminator_loss=0.13484029471874237\n",
            "step 4336: generator_loss=3.7872180938720703, discriminator_loss=0.16432137787342072\n",
            "step 4337: generator_loss=3.835554599761963, discriminator_loss=0.1519322693347931\n",
            "step 4338: generator_loss=3.6123719215393066, discriminator_loss=0.1147443950176239\n",
            "step 4339: generator_loss=3.240940809249878, discriminator_loss=0.15483474731445312\n",
            "step 4340: generator_loss=3.2464475631713867, discriminator_loss=0.16913890838623047\n",
            "step 4341: generator_loss=3.090405225753784, discriminator_loss=0.14140906929969788\n",
            "step 4342: generator_loss=2.997680425643921, discriminator_loss=0.13133510947227478\n",
            "step 4343: generator_loss=3.179361343383789, discriminator_loss=0.13761690258979797\n",
            "step 4344: generator_loss=2.984712600708008, discriminator_loss=0.13586054742336273\n",
            "step 4345: generator_loss=3.0001888275146484, discriminator_loss=0.13113532960414886\n",
            "step 4346: generator_loss=3.1393587589263916, discriminator_loss=0.12055423855781555\n",
            "step 4347: generator_loss=3.3306050300598145, discriminator_loss=0.12543559074401855\n",
            "step 4348: generator_loss=3.2826266288757324, discriminator_loss=0.14891506731510162\n",
            "step 4349: generator_loss=3.2124900817871094, discriminator_loss=0.12043315172195435\n",
            "step 4350: generator_loss=3.0231006145477295, discriminator_loss=0.15961319208145142\n",
            "step 4351: generator_loss=2.6748387813568115, discriminator_loss=0.14334604144096375\n",
            "step 4352: generator_loss=2.4747910499572754, discriminator_loss=0.18397380411624908\n",
            "step 4353: generator_loss=2.6085188388824463, discriminator_loss=0.146839439868927\n",
            "step 4354: generator_loss=2.9696741104125977, discriminator_loss=0.1221216470003128\n",
            "step 4355: generator_loss=2.954923391342163, discriminator_loss=0.1438196301460266\n",
            "step 4356: generator_loss=2.754537343978882, discriminator_loss=0.17070230841636658\n",
            "step 4357: generator_loss=2.687084674835205, discriminator_loss=0.21212536096572876\n",
            "step 4358: generator_loss=2.344189167022705, discriminator_loss=0.18937000632286072\n",
            "step 4359: generator_loss=2.460296630859375, discriminator_loss=0.1704137623310089\n",
            "step 4360: generator_loss=2.260509967803955, discriminator_loss=0.26019972562789917\n",
            "step 4361: generator_loss=2.3944549560546875, discriminator_loss=0.24257461726665497\n",
            "step 4362: generator_loss=2.1610677242279053, discriminator_loss=0.2120009958744049\n",
            "step 4363: generator_loss=2.2302634716033936, discriminator_loss=0.216729998588562\n",
            "step 4364: generator_loss=2.242853879928589, discriminator_loss=0.19687750935554504\n",
            "step 4365: generator_loss=2.359684944152832, discriminator_loss=0.19311818480491638\n",
            "step 4366: generator_loss=2.470224618911743, discriminator_loss=0.2062331736087799\n",
            "step 4367: generator_loss=2.1192870140075684, discriminator_loss=0.24562954902648926\n",
            "step 4368: generator_loss=2.433490753173828, discriminator_loss=0.18481630086898804\n",
            "step 4369: generator_loss=2.333888053894043, discriminator_loss=0.23234014213085175\n",
            "step 4370: generator_loss=2.272960662841797, discriminator_loss=0.25454312562942505\n",
            "step 4371: generator_loss=2.1810693740844727, discriminator_loss=0.2306900918483734\n",
            "step 4372: generator_loss=1.782512903213501, discriminator_loss=0.2889609932899475\n",
            "step 4373: generator_loss=2.0365512371063232, discriminator_loss=0.21153758466243744\n",
            "step 4374: generator_loss=2.2111597061157227, discriminator_loss=0.29401469230651855\n",
            "step 4375: generator_loss=2.4301114082336426, discriminator_loss=0.2934127151966095\n",
            "step 4376: generator_loss=3.0754010677337646, discriminator_loss=0.2800362706184387\n",
            "step 4377: generator_loss=2.8278090953826904, discriminator_loss=0.39145416021347046\n",
            "step 4378: generator_loss=3.2525782585144043, discriminator_loss=0.38363057374954224\n",
            "step 4379: generator_loss=3.1184773445129395, discriminator_loss=0.37684983015060425\n",
            "step 4380: generator_loss=2.917083740234375, discriminator_loss=0.36712920665740967\n",
            "step 4381: generator_loss=2.817394256591797, discriminator_loss=0.4019091725349426\n",
            "step 4382: generator_loss=2.4910833835601807, discriminator_loss=0.33275386691093445\n",
            "step 4383: generator_loss=2.848039150238037, discriminator_loss=0.35413670539855957\n",
            "step 4384: generator_loss=2.947253704071045, discriminator_loss=0.29049152135849\n",
            "step 4385: generator_loss=3.2705612182617188, discriminator_loss=0.2132132649421692\n",
            "step 4386: generator_loss=3.4022579193115234, discriminator_loss=0.2132653445005417\n",
            "step 4387: generator_loss=3.5371885299682617, discriminator_loss=0.2110854983329773\n",
            "step 4388: generator_loss=3.9129858016967773, discriminator_loss=0.1104363352060318\n",
            "step 4389: generator_loss=3.832963466644287, discriminator_loss=0.14987251162528992\n",
            "step 4390: generator_loss=3.523239850997925, discriminator_loss=0.11195769906044006\n",
            "step 4391: generator_loss=3.5298638343811035, discriminator_loss=0.12049096822738647\n",
            "step 4392: generator_loss=3.352525472640991, discriminator_loss=0.11888788640499115\n",
            "step 4393: generator_loss=3.4607694149017334, discriminator_loss=0.0997084304690361\n",
            "step 4394: generator_loss=3.2748918533325195, discriminator_loss=0.10199861228466034\n",
            "step 4395: generator_loss=3.3257689476013184, discriminator_loss=0.10478568822145462\n",
            "step 4396: generator_loss=3.6404924392700195, discriminator_loss=0.08572690933942795\n",
            "step 4397: generator_loss=3.5813260078430176, discriminator_loss=0.11522632092237473\n",
            "step 4398: generator_loss=3.733203887939453, discriminator_loss=0.12080761790275574\n",
            "step 4399: generator_loss=3.6732535362243652, discriminator_loss=0.12228428572416306\n",
            "step 4400: generator_loss=3.80220890045166, discriminator_loss=0.12368635088205338\n",
            "step 4401: generator_loss=4.00731086730957, discriminator_loss=0.11650915443897247\n",
            "step 4402: generator_loss=3.562962055206299, discriminator_loss=0.13799409568309784\n",
            "step 4403: generator_loss=3.246882915496826, discriminator_loss=0.14965179562568665\n",
            "step 4404: generator_loss=3.226581573486328, discriminator_loss=0.13313162326812744\n",
            "step 4405: generator_loss=2.7071402072906494, discriminator_loss=0.15338510274887085\n",
            "step 4406: generator_loss=2.714320421218872, discriminator_loss=0.15018124878406525\n",
            "step 4407: generator_loss=2.807342290878296, discriminator_loss=0.12502539157867432\n",
            "step 4408: generator_loss=2.8872361183166504, discriminator_loss=0.13873018324375153\n",
            "step 4409: generator_loss=2.7981982231140137, discriminator_loss=0.13181039690971375\n",
            "step 4410: generator_loss=2.812959909439087, discriminator_loss=0.0902680903673172\n",
            "step 4411: generator_loss=2.7554423809051514, discriminator_loss=0.14121457934379578\n",
            "step 4412: generator_loss=2.766663074493408, discriminator_loss=0.1291896402835846\n",
            "step 4413: generator_loss=3.0113396644592285, discriminator_loss=0.14229047298431396\n",
            "step 4414: generator_loss=2.840442180633545, discriminator_loss=0.15241068601608276\n",
            "step 4415: generator_loss=3.0665483474731445, discriminator_loss=0.13613440096378326\n",
            "step 4416: generator_loss=2.7918827533721924, discriminator_loss=0.15278375148773193\n",
            "step 4417: generator_loss=2.7906136512756348, discriminator_loss=0.11940835416316986\n",
            "step 4418: generator_loss=2.769592046737671, discriminator_loss=0.15004494786262512\n",
            "step 4419: generator_loss=2.438764810562134, discriminator_loss=0.14838039875030518\n",
            "step 4420: generator_loss=2.623929023742676, discriminator_loss=0.12208594381809235\n",
            "step 4421: generator_loss=2.5636329650878906, discriminator_loss=0.13624443113803864\n",
            "step 4422: generator_loss=2.6537222862243652, discriminator_loss=0.1734900176525116\n",
            "step 4423: generator_loss=2.6221792697906494, discriminator_loss=0.1706743836402893\n",
            "step 4424: generator_loss=2.447206974029541, discriminator_loss=0.17290997505187988\n",
            "step 4425: generator_loss=2.542400360107422, discriminator_loss=0.169525146484375\n",
            "step 4426: generator_loss=2.372443199157715, discriminator_loss=0.17482729256153107\n",
            "step 4427: generator_loss=2.3989529609680176, discriminator_loss=0.12612950801849365\n",
            "step 4428: generator_loss=2.3550467491149902, discriminator_loss=0.23644664883613586\n",
            "step 4429: generator_loss=2.631077766418457, discriminator_loss=0.21762633323669434\n",
            "step 4430: generator_loss=2.8391027450561523, discriminator_loss=0.1600487232208252\n",
            "step 4431: generator_loss=2.732395887374878, discriminator_loss=0.21478375792503357\n",
            "step 4432: generator_loss=2.7374629974365234, discriminator_loss=0.2934245467185974\n",
            "step 4433: generator_loss=2.591925621032715, discriminator_loss=0.22470375895500183\n",
            "step 4434: generator_loss=2.44909930229187, discriminator_loss=0.25943443179130554\n",
            "step 4435: generator_loss=2.5261878967285156, discriminator_loss=0.21037985384464264\n",
            "step 4436: generator_loss=2.5322415828704834, discriminator_loss=0.293209046125412\n",
            "step 4437: generator_loss=2.942661762237549, discriminator_loss=0.2560840845108032\n",
            "step 4438: generator_loss=2.9508609771728516, discriminator_loss=0.280495822429657\n",
            "step 4439: generator_loss=3.074601411819458, discriminator_loss=0.24058789014816284\n",
            "step 4440: generator_loss=3.1608023643493652, discriminator_loss=0.2654862403869629\n",
            "step 4441: generator_loss=2.935016393661499, discriminator_loss=0.2931748628616333\n",
            "step 4442: generator_loss=3.193509817123413, discriminator_loss=0.2777606248855591\n",
            "step 4443: generator_loss=3.0084757804870605, discriminator_loss=0.2593233585357666\n",
            "step 4444: generator_loss=3.176604747772217, discriminator_loss=0.24639944732189178\n",
            "step 4445: generator_loss=2.895703077316284, discriminator_loss=0.25112757086753845\n",
            "step 4446: generator_loss=2.9090747833251953, discriminator_loss=0.2284911572933197\n",
            "step 4447: generator_loss=2.9505252838134766, discriminator_loss=0.19279435276985168\n",
            "step 4448: generator_loss=3.2167563438415527, discriminator_loss=0.17444297671318054\n",
            "step 4449: generator_loss=3.436936616897583, discriminator_loss=0.16140034794807434\n",
            "step 4450: generator_loss=3.333874225616455, discriminator_loss=0.1821446567773819\n",
            "step 4451: generator_loss=3.3993213176727295, discriminator_loss=0.18221008777618408\n",
            "step 4452: generator_loss=3.326735019683838, discriminator_loss=0.2048187553882599\n",
            "step 4453: generator_loss=3.3169608116149902, discriminator_loss=0.1542314887046814\n",
            "step 4454: generator_loss=2.966069221496582, discriminator_loss=0.18866771459579468\n",
            "step 4455: generator_loss=3.137801170349121, discriminator_loss=0.2087257206439972\n",
            "step 4456: generator_loss=3.254870653152466, discriminator_loss=0.1873379498720169\n",
            "step 4457: generator_loss=3.183969020843506, discriminator_loss=0.19141757488250732\n",
            "step 4458: generator_loss=3.095485210418701, discriminator_loss=0.2116875946521759\n",
            "step 4459: generator_loss=2.6750564575195312, discriminator_loss=0.2384510636329651\n",
            "step 4460: generator_loss=2.776653289794922, discriminator_loss=0.21796248853206635\n",
            "step 4461: generator_loss=2.5869741439819336, discriminator_loss=0.27385127544403076\n",
            "step 4462: generator_loss=2.5566508769989014, discriminator_loss=0.20828858017921448\n",
            "step 4463: generator_loss=2.478644847869873, discriminator_loss=0.23074620962142944\n",
            "step 4464: generator_loss=2.4610795974731445, discriminator_loss=0.25560522079467773\n",
            "step 4465: generator_loss=2.943535566329956, discriminator_loss=0.2598631978034973\n",
            "step 4466: generator_loss=2.6309328079223633, discriminator_loss=0.3149474263191223\n",
            "step 4467: generator_loss=2.882096290588379, discriminator_loss=0.22649112343788147\n",
            "step 4468: generator_loss=2.7763049602508545, discriminator_loss=0.2485148161649704\n",
            "step 4469: generator_loss=2.618391990661621, discriminator_loss=0.32418012619018555\n",
            "step 4470: generator_loss=2.3234364986419678, discriminator_loss=0.3212960958480835\n",
            "step 4471: generator_loss=2.3370234966278076, discriminator_loss=0.35667574405670166\n",
            "step 4472: generator_loss=2.4688000679016113, discriminator_loss=0.34609127044677734\n",
            "step 4473: generator_loss=2.6686763763427734, discriminator_loss=0.3655892312526703\n",
            "step 4474: generator_loss=2.6431403160095215, discriminator_loss=0.39274346828460693\n",
            "step 4475: generator_loss=2.7975239753723145, discriminator_loss=0.3499051332473755\n",
            "step 4476: generator_loss=2.7448761463165283, discriminator_loss=0.3415716588497162\n",
            "step 4477: generator_loss=3.1391544342041016, discriminator_loss=0.2514086663722992\n",
            "step 4478: generator_loss=2.376680850982666, discriminator_loss=0.33357569575309753\n",
            "step 4479: generator_loss=2.7246992588043213, discriminator_loss=0.2393588423728943\n",
            "step 4480: generator_loss=2.8489885330200195, discriminator_loss=0.18432044982910156\n",
            "step 4481: generator_loss=2.907042980194092, discriminator_loss=0.19101062417030334\n",
            "step 4482: generator_loss=2.877424716949463, discriminator_loss=0.16583476960659027\n",
            "step 4483: generator_loss=2.7554407119750977, discriminator_loss=0.19044619798660278\n",
            "step 4484: generator_loss=3.24845290184021, discriminator_loss=0.2106805294752121\n",
            "step 4485: generator_loss=3.1303763389587402, discriminator_loss=0.16631543636322021\n",
            "step 4486: generator_loss=3.359527826309204, discriminator_loss=0.15371814370155334\n",
            "step 4487: generator_loss=3.6128766536712646, discriminator_loss=0.20713448524475098\n",
            "step 4488: generator_loss=3.4427077770233154, discriminator_loss=0.16529406607151031\n",
            "step 4489: generator_loss=3.5806593894958496, discriminator_loss=0.1313752830028534\n",
            "step 4490: generator_loss=3.3796439170837402, discriminator_loss=0.21209044754505157\n",
            "step 4491: generator_loss=3.041987180709839, discriminator_loss=0.2527381181716919\n",
            "step 4492: generator_loss=3.245753288269043, discriminator_loss=0.29848480224609375\n",
            "step 4493: generator_loss=3.1855294704437256, discriminator_loss=0.25640058517456055\n",
            "step 4494: generator_loss=3.1424930095672607, discriminator_loss=0.2510312795639038\n",
            "step 4495: generator_loss=3.48093318939209, discriminator_loss=0.373579204082489\n",
            "step 4496: generator_loss=3.1269984245300293, discriminator_loss=0.3703201711177826\n",
            "step 4497: generator_loss=3.789625883102417, discriminator_loss=0.23967012763023376\n",
            "step 4498: generator_loss=3.6126437187194824, discriminator_loss=0.30030715465545654\n",
            "step 4499: generator_loss=3.7693307399749756, discriminator_loss=0.2576521933078766\n",
            "step 4500: generator_loss=4.040603160858154, discriminator_loss=0.18498414754867554\n",
            "step 4501: generator_loss=3.860187530517578, discriminator_loss=0.20069098472595215\n",
            "step 4502: generator_loss=4.095122337341309, discriminator_loss=0.22360911965370178\n",
            "step 4503: generator_loss=4.228476524353027, discriminator_loss=0.14021635055541992\n",
            "step 4504: generator_loss=4.482598781585693, discriminator_loss=0.136955127120018\n",
            "step 4505: generator_loss=4.246087074279785, discriminator_loss=0.12777821719646454\n",
            "step 4506: generator_loss=4.065920829772949, discriminator_loss=0.14232999086380005\n",
            "step 4507: generator_loss=3.6209256649017334, discriminator_loss=0.1324714720249176\n",
            "step 4508: generator_loss=3.5995452404022217, discriminator_loss=0.17898830771446228\n",
            "step 4509: generator_loss=3.415571689605713, discriminator_loss=0.14185309410095215\n",
            "step 4510: generator_loss=3.2993757724761963, discriminator_loss=0.1317528635263443\n",
            "step 4511: generator_loss=3.474030017852783, discriminator_loss=0.11049988865852356\n",
            "step 4512: generator_loss=3.600583553314209, discriminator_loss=0.16206254065036774\n",
            "step 4513: generator_loss=3.5674521923065186, discriminator_loss=0.11593834310770035\n",
            "step 4514: generator_loss=3.3191261291503906, discriminator_loss=0.12705305218696594\n",
            "step 4515: generator_loss=3.2960891723632812, discriminator_loss=0.1434483826160431\n",
            "step 4516: generator_loss=3.0942509174346924, discriminator_loss=0.13298660516738892\n",
            "step 4517: generator_loss=2.9097743034362793, discriminator_loss=0.1404426395893097\n",
            "step 4518: generator_loss=3.152477264404297, discriminator_loss=0.1988808810710907\n",
            "step 4519: generator_loss=3.0026583671569824, discriminator_loss=0.15219412744045258\n",
            "step 4520: generator_loss=2.7498199939727783, discriminator_loss=0.19853024184703827\n",
            "step 4521: generator_loss=2.6677284240722656, discriminator_loss=0.16942845284938812\n",
            "step 4522: generator_loss=2.5050668716430664, discriminator_loss=0.21980050206184387\n",
            "step 4523: generator_loss=2.7203383445739746, discriminator_loss=0.16648025810718536\n",
            "step 4524: generator_loss=2.7880516052246094, discriminator_loss=0.1380779892206192\n",
            "step 4525: generator_loss=2.7031681537628174, discriminator_loss=0.14627747237682343\n",
            "step 4526: generator_loss=2.8518381118774414, discriminator_loss=0.15829989314079285\n",
            "step 4527: generator_loss=2.8749890327453613, discriminator_loss=0.17960605025291443\n",
            "step 4528: generator_loss=2.7075257301330566, discriminator_loss=0.1864684820175171\n",
            "step 4529: generator_loss=2.7729763984680176, discriminator_loss=0.18259894847869873\n",
            "step 4530: generator_loss=2.6639208793640137, discriminator_loss=0.16375285387039185\n",
            "step 4531: generator_loss=2.852081298828125, discriminator_loss=0.16159898042678833\n",
            "step 4532: generator_loss=2.8078677654266357, discriminator_loss=0.14347173273563385\n",
            "step 4533: generator_loss=2.781824827194214, discriminator_loss=0.2037145495414734\n",
            "step 4534: generator_loss=2.7444088459014893, discriminator_loss=0.1480822116136551\n",
            "step 4535: generator_loss=2.5463004112243652, discriminator_loss=0.18199440836906433\n",
            "step 4536: generator_loss=2.401684045791626, discriminator_loss=0.19039702415466309\n",
            "step 4537: generator_loss=2.4862446784973145, discriminator_loss=0.17259883880615234\n",
            "step 4538: generator_loss=2.535553455352783, discriminator_loss=0.13883273303508759\n",
            "step 4539: generator_loss=2.6418728828430176, discriminator_loss=0.15058645606040955\n",
            "step 4540: generator_loss=2.6930575370788574, discriminator_loss=0.22105710208415985\n",
            "step 4541: generator_loss=2.7968294620513916, discriminator_loss=0.1925956904888153\n",
            "step 4542: generator_loss=2.6916680335998535, discriminator_loss=0.19156086444854736\n",
            "step 4543: generator_loss=2.213163375854492, discriminator_loss=0.2045954018831253\n",
            "step 4544: generator_loss=2.4439187049865723, discriminator_loss=0.1668156236410141\n",
            "step 4545: generator_loss=2.1038970947265625, discriminator_loss=0.24838028848171234\n",
            "step 4546: generator_loss=2.344608783721924, discriminator_loss=0.21115046739578247\n",
            "step 4547: generator_loss=2.773355484008789, discriminator_loss=0.16746504604816437\n",
            "step 4548: generator_loss=2.5112743377685547, discriminator_loss=0.20275375247001648\n",
            "step 4549: generator_loss=2.798563003540039, discriminator_loss=0.16241705417633057\n",
            "step 4550: generator_loss=2.7077653408050537, discriminator_loss=0.21073609590530396\n",
            "step 4551: generator_loss=2.507129669189453, discriminator_loss=0.17527279257774353\n",
            "step 4552: generator_loss=2.27156662940979, discriminator_loss=0.2224421501159668\n",
            "step 4553: generator_loss=2.2402989864349365, discriminator_loss=0.2277667075395584\n",
            "step 4554: generator_loss=2.267364025115967, discriminator_loss=0.19578872621059418\n",
            "step 4555: generator_loss=2.088621139526367, discriminator_loss=0.24480324983596802\n",
            "step 4556: generator_loss=2.3582167625427246, discriminator_loss=0.20802819728851318\n",
            "step 4557: generator_loss=2.6340835094451904, discriminator_loss=0.19391773641109467\n",
            "step 4558: generator_loss=2.4181907176971436, discriminator_loss=0.2395211011171341\n",
            "step 4559: generator_loss=2.551551103591919, discriminator_loss=0.21817341446876526\n",
            "step 4560: generator_loss=2.3553102016448975, discriminator_loss=0.224087655544281\n",
            "step 4561: generator_loss=2.345673084259033, discriminator_loss=0.23690927028656006\n",
            "step 4562: generator_loss=2.0975985527038574, discriminator_loss=0.2632363736629486\n",
            "step 4563: generator_loss=2.2049832344055176, discriminator_loss=0.2754758596420288\n",
            "step 4564: generator_loss=2.1533799171447754, discriminator_loss=0.24124780297279358\n",
            "step 4565: generator_loss=2.4225215911865234, discriminator_loss=0.20551030337810516\n",
            "step 4566: generator_loss=2.539851188659668, discriminator_loss=0.19054639339447021\n",
            "step 4567: generator_loss=2.523730993270874, discriminator_loss=0.23972764611244202\n",
            "step 4568: generator_loss=2.516960382461548, discriminator_loss=0.2176019549369812\n",
            "step 4569: generator_loss=2.5910966396331787, discriminator_loss=0.18196451663970947\n",
            "step 4570: generator_loss=2.583099126815796, discriminator_loss=0.18866750597953796\n",
            "step 4571: generator_loss=2.438985824584961, discriminator_loss=0.17372876405715942\n",
            "step 4572: generator_loss=2.2984681129455566, discriminator_loss=0.21048368513584137\n",
            "step 4573: generator_loss=2.620277166366577, discriminator_loss=0.16264799237251282\n",
            "step 4574: generator_loss=2.918388843536377, discriminator_loss=0.15502160787582397\n",
            "step 4575: generator_loss=3.4165475368499756, discriminator_loss=0.1425737589597702\n",
            "step 4576: generator_loss=3.4228663444519043, discriminator_loss=0.16909843683242798\n",
            "step 4577: generator_loss=3.441983222961426, discriminator_loss=0.12670651078224182\n",
            "step 4578: generator_loss=3.2539870738983154, discriminator_loss=0.16536590456962585\n",
            "step 4579: generator_loss=2.8123254776000977, discriminator_loss=0.13391798734664917\n",
            "step 4580: generator_loss=2.5870821475982666, discriminator_loss=0.14251373708248138\n",
            "step 4581: generator_loss=2.508486747741699, discriminator_loss=0.16937023401260376\n",
            "step 4582: generator_loss=2.632080078125, discriminator_loss=0.1411125808954239\n",
            "step 4583: generator_loss=2.6991636753082275, discriminator_loss=0.1351528912782669\n",
            "step 4584: generator_loss=3.072214126586914, discriminator_loss=0.1099262684583664\n",
            "step 4585: generator_loss=3.2626423835754395, discriminator_loss=0.10891924053430557\n",
            "step 4586: generator_loss=3.274935722351074, discriminator_loss=0.10151989758014679\n",
            "step 4587: generator_loss=3.4512686729431152, discriminator_loss=0.12312633544206619\n",
            "step 4588: generator_loss=3.396420478820801, discriminator_loss=0.08314082026481628\n",
            "step 4589: generator_loss=3.0330259799957275, discriminator_loss=0.1465756893157959\n",
            "step 4590: generator_loss=2.5841736793518066, discriminator_loss=0.1426050066947937\n",
            "step 4591: generator_loss=2.2669906616210938, discriminator_loss=0.15161889791488647\n",
            "step 4592: generator_loss=2.3264923095703125, discriminator_loss=0.15613219141960144\n",
            "step 4593: generator_loss=2.314286708831787, discriminator_loss=0.1469065546989441\n",
            "step 4594: generator_loss=2.3954594135284424, discriminator_loss=0.18255791068077087\n",
            "step 4595: generator_loss=2.7175559997558594, discriminator_loss=0.1604182869195938\n",
            "step 4596: generator_loss=2.683563709259033, discriminator_loss=0.19903747737407684\n",
            "step 4597: generator_loss=2.533020496368408, discriminator_loss=0.23462270200252533\n",
            "step 4598: generator_loss=2.4603424072265625, discriminator_loss=0.25786900520324707\n",
            "step 4599: generator_loss=2.362976551055908, discriminator_loss=0.2413269281387329\n",
            "step 4600: generator_loss=2.2789061069488525, discriminator_loss=0.2684634327888489\n",
            "step 4601: generator_loss=1.9258356094360352, discriminator_loss=0.2714236378669739\n",
            "step 4602: generator_loss=2.0161027908325195, discriminator_loss=0.3316318690776825\n",
            "step 4603: generator_loss=2.214001417160034, discriminator_loss=0.2981038987636566\n",
            "step 4604: generator_loss=2.4046831130981445, discriminator_loss=0.25199922919273376\n",
            "step 4605: generator_loss=2.520216941833496, discriminator_loss=0.2768935561180115\n",
            "step 4606: generator_loss=2.535675048828125, discriminator_loss=0.25491437315940857\n",
            "step 4607: generator_loss=2.536212921142578, discriminator_loss=0.21254391968250275\n",
            "step 4608: generator_loss=2.6344168186187744, discriminator_loss=0.16322101652622223\n",
            "step 4609: generator_loss=2.5244789123535156, discriminator_loss=0.14005056023597717\n",
            "step 4610: generator_loss=2.3173041343688965, discriminator_loss=0.16430363059043884\n",
            "step 4611: generator_loss=2.377241373062134, discriminator_loss=0.17157220840454102\n",
            "step 4612: generator_loss=2.3954520225524902, discriminator_loss=0.15237191319465637\n",
            "step 4613: generator_loss=2.4557933807373047, discriminator_loss=0.14972738921642303\n",
            "step 4614: generator_loss=2.5626869201660156, discriminator_loss=0.16661584377288818\n",
            "step 4615: generator_loss=2.778167724609375, discriminator_loss=0.1542338728904724\n",
            "step 4616: generator_loss=3.0040457248687744, discriminator_loss=0.11587237566709518\n",
            "step 4617: generator_loss=2.832247734069824, discriminator_loss=0.1479923129081726\n",
            "step 4618: generator_loss=2.9545273780822754, discriminator_loss=0.16398292779922485\n",
            "step 4619: generator_loss=2.9457895755767822, discriminator_loss=0.12105929851531982\n",
            "step 4620: generator_loss=2.8070614337921143, discriminator_loss=0.1228727251291275\n",
            "step 4621: generator_loss=2.9868083000183105, discriminator_loss=0.12382964789867401\n",
            "step 4622: generator_loss=2.91365909576416, discriminator_loss=0.12530715763568878\n",
            "step 4623: generator_loss=2.8507955074310303, discriminator_loss=0.1288863867521286\n",
            "step 4624: generator_loss=2.7082571983337402, discriminator_loss=0.13971386849880219\n",
            "step 4625: generator_loss=2.636946678161621, discriminator_loss=0.175601989030838\n",
            "step 4626: generator_loss=2.628857135772705, discriminator_loss=0.15872272849082947\n",
            "step 4627: generator_loss=2.7308006286621094, discriminator_loss=0.19069091975688934\n",
            "step 4628: generator_loss=2.805603504180908, discriminator_loss=0.16695678234100342\n",
            "step 4629: generator_loss=2.7354848384857178, discriminator_loss=0.22088950872421265\n",
            "step 4630: generator_loss=2.563443422317505, discriminator_loss=0.23562729358673096\n",
            "step 4631: generator_loss=2.58061146736145, discriminator_loss=0.2429262399673462\n",
            "step 4632: generator_loss=2.619349956512451, discriminator_loss=0.25795674324035645\n",
            "step 4633: generator_loss=2.8923516273498535, discriminator_loss=0.25370973348617554\n",
            "step 4634: generator_loss=2.7977371215820312, discriminator_loss=0.2767350673675537\n",
            "step 4635: generator_loss=3.0068297386169434, discriminator_loss=0.2206396758556366\n",
            "step 4636: generator_loss=3.039694309234619, discriminator_loss=0.24045321345329285\n",
            "step 4637: generator_loss=3.0853447914123535, discriminator_loss=0.32622262835502625\n",
            "step 4638: generator_loss=3.0468242168426514, discriminator_loss=0.26919710636138916\n",
            "step 4639: generator_loss=3.237511396408081, discriminator_loss=0.3051297962665558\n",
            "step 4640: generator_loss=3.415957450866699, discriminator_loss=0.303622841835022\n",
            "step 4641: generator_loss=3.860170841217041, discriminator_loss=0.3384541869163513\n",
            "step 4642: generator_loss=3.26041841506958, discriminator_loss=0.2982369661331177\n",
            "step 4643: generator_loss=3.996748924255371, discriminator_loss=0.21902485191822052\n",
            "step 4644: generator_loss=4.147794246673584, discriminator_loss=0.22292658686637878\n",
            "step 4645: generator_loss=3.1990585327148438, discriminator_loss=0.2922218441963196\n",
            "step 4646: generator_loss=3.3817062377929688, discriminator_loss=0.3010095953941345\n",
            "step 4647: generator_loss=3.7975566387176514, discriminator_loss=0.24856308102607727\n",
            "step 4648: generator_loss=3.8476028442382812, discriminator_loss=0.1942497193813324\n",
            "step 4649: generator_loss=3.7527613639831543, discriminator_loss=0.3119909167289734\n",
            "step 4650: generator_loss=3.590590476989746, discriminator_loss=0.29663950204849243\n",
            "step 4651: generator_loss=3.9126415252685547, discriminator_loss=0.23004436492919922\n",
            "step 4652: generator_loss=3.83628511428833, discriminator_loss=0.19753149151802063\n",
            "step 4653: generator_loss=4.4207892417907715, discriminator_loss=0.20622140169143677\n",
            "step 4654: generator_loss=3.8832192420959473, discriminator_loss=0.18053892254829407\n",
            "step 4655: generator_loss=3.915069103240967, discriminator_loss=0.21403196454048157\n",
            "step 4656: generator_loss=3.782550096511841, discriminator_loss=0.1729363352060318\n",
            "step 4657: generator_loss=3.7242093086242676, discriminator_loss=0.12988193333148956\n",
            "step 4658: generator_loss=3.816193103790283, discriminator_loss=0.15816369652748108\n",
            "step 4659: generator_loss=3.597297430038452, discriminator_loss=0.1270262748003006\n",
            "step 4660: generator_loss=3.9103331565856934, discriminator_loss=0.11747345328330994\n",
            "step 4661: generator_loss=3.7008490562438965, discriminator_loss=0.13940316438674927\n",
            "step 4662: generator_loss=3.80279541015625, discriminator_loss=0.12609736621379852\n",
            "step 4663: generator_loss=4.092766761779785, discriminator_loss=0.12712383270263672\n",
            "step 4664: generator_loss=4.296513557434082, discriminator_loss=0.13561749458312988\n",
            "step 4665: generator_loss=3.8602354526519775, discriminator_loss=0.1081785038113594\n",
            "step 4666: generator_loss=3.5750620365142822, discriminator_loss=0.17950496077537537\n",
            "step 4667: generator_loss=3.601835012435913, discriminator_loss=0.19006022810935974\n",
            "step 4668: generator_loss=3.42985463142395, discriminator_loss=0.19410037994384766\n",
            "step 4669: generator_loss=3.3513922691345215, discriminator_loss=0.17892053723335266\n",
            "step 4670: generator_loss=2.8631651401519775, discriminator_loss=0.2406856268644333\n",
            "step 4671: generator_loss=3.2978248596191406, discriminator_loss=0.24701575934886932\n",
            "step 4672: generator_loss=3.0857391357421875, discriminator_loss=0.21762633323669434\n",
            "step 4673: generator_loss=3.2441070079803467, discriminator_loss=0.23353156447410583\n",
            "step 4674: generator_loss=3.1298229694366455, discriminator_loss=0.2724863290786743\n",
            "step 4675: generator_loss=3.444584369659424, discriminator_loss=0.23250798881053925\n",
            "step 4676: generator_loss=3.268338203430176, discriminator_loss=0.12420011311769485\n",
            "step 4677: generator_loss=3.3032045364379883, discriminator_loss=0.15356379747390747\n",
            "step 4678: generator_loss=3.346813201904297, discriminator_loss=0.1484452188014984\n",
            "step 4679: generator_loss=3.3478591442108154, discriminator_loss=0.15587949752807617\n",
            "step 4680: generator_loss=3.23128080368042, discriminator_loss=0.167766273021698\n",
            "step 4681: generator_loss=3.3602845668792725, discriminator_loss=0.1150631383061409\n",
            "step 4682: generator_loss=3.338334083557129, discriminator_loss=0.13717052340507507\n",
            "step 4683: generator_loss=3.6785240173339844, discriminator_loss=0.13004741072654724\n",
            "step 4684: generator_loss=3.2346713542938232, discriminator_loss=0.17156526446342468\n",
            "step 4685: generator_loss=3.355635643005371, discriminator_loss=0.18449603021144867\n",
            "step 4686: generator_loss=3.11885929107666, discriminator_loss=0.17041853070259094\n",
            "step 4687: generator_loss=3.3218398094177246, discriminator_loss=0.16355954110622406\n",
            "step 4688: generator_loss=2.765451431274414, discriminator_loss=0.2283516377210617\n",
            "step 4689: generator_loss=2.7860145568847656, discriminator_loss=0.1847590208053589\n",
            "step 4690: generator_loss=2.8844454288482666, discriminator_loss=0.19562864303588867\n",
            "step 4691: generator_loss=3.0580265522003174, discriminator_loss=0.18839122354984283\n",
            "step 4692: generator_loss=3.125128984451294, discriminator_loss=0.2314072847366333\n",
            "step 4693: generator_loss=3.222593307495117, discriminator_loss=0.1398726999759674\n",
            "step 4694: generator_loss=2.9224154949188232, discriminator_loss=0.15460112690925598\n",
            "step 4695: generator_loss=2.6614747047424316, discriminator_loss=0.18054941296577454\n",
            "step 4696: generator_loss=2.835759401321411, discriminator_loss=0.15478640794754028\n",
            "step 4697: generator_loss=3.0082812309265137, discriminator_loss=0.17831891775131226\n",
            "step 4698: generator_loss=2.5793209075927734, discriminator_loss=0.19251981377601624\n",
            "step 4699: generator_loss=2.629058361053467, discriminator_loss=0.19796843826770782\n",
            "step 4700: generator_loss=2.599414825439453, discriminator_loss=0.1938892900943756\n",
            "step 4701: generator_loss=2.6671142578125, discriminator_loss=0.1694951355457306\n",
            "step 4702: generator_loss=2.729954242706299, discriminator_loss=0.15207263827323914\n",
            "step 4703: generator_loss=2.7344717979431152, discriminator_loss=0.17293620109558105\n",
            "step 4704: generator_loss=2.662296772003174, discriminator_loss=0.18604369461536407\n",
            "step 4705: generator_loss=2.58431077003479, discriminator_loss=0.16344138979911804\n",
            "step 4706: generator_loss=2.6934924125671387, discriminator_loss=0.22268985211849213\n",
            "step 4707: generator_loss=2.666027784347534, discriminator_loss=0.2123682200908661\n",
            "step 4708: generator_loss=2.8918960094451904, discriminator_loss=0.19433832168579102\n",
            "step 4709: generator_loss=2.6886253356933594, discriminator_loss=0.20354142785072327\n",
            "step 4710: generator_loss=2.7249529361724854, discriminator_loss=0.23596270382404327\n",
            "step 4711: generator_loss=2.5847482681274414, discriminator_loss=0.21130552887916565\n",
            "step 4712: generator_loss=2.5294501781463623, discriminator_loss=0.16787640750408173\n",
            "step 4713: generator_loss=2.591158151626587, discriminator_loss=0.16695711016654968\n",
            "step 4714: generator_loss=2.676997661590576, discriminator_loss=0.18296170234680176\n",
            "step 4715: generator_loss=2.785975217819214, discriminator_loss=0.14493346214294434\n",
            "step 4716: generator_loss=2.821709394454956, discriminator_loss=0.1553371548652649\n",
            "step 4717: generator_loss=2.9462764263153076, discriminator_loss=0.18506479263305664\n",
            "step 4718: generator_loss=2.8987934589385986, discriminator_loss=0.19218909740447998\n",
            "step 4719: generator_loss=2.8370070457458496, discriminator_loss=0.15151052176952362\n",
            "step 4720: generator_loss=2.577103614807129, discriminator_loss=0.18032348155975342\n",
            "step 4721: generator_loss=2.6005334854125977, discriminator_loss=0.14546439051628113\n",
            "step 4722: generator_loss=2.4628825187683105, discriminator_loss=0.16479681432247162\n",
            "step 4723: generator_loss=2.395958185195923, discriminator_loss=0.1858672797679901\n",
            "step 4724: generator_loss=2.6377158164978027, discriminator_loss=0.2045293152332306\n",
            "step 4725: generator_loss=2.569507122039795, discriminator_loss=0.21768222749233246\n",
            "step 4726: generator_loss=2.8301949501037598, discriminator_loss=0.1692676544189453\n",
            "step 4727: generator_loss=2.7147951126098633, discriminator_loss=0.16868922114372253\n",
            "step 4728: generator_loss=2.6262147426605225, discriminator_loss=0.17887702584266663\n",
            "step 4729: generator_loss=2.762613296508789, discriminator_loss=0.17334146797657013\n",
            "step 4730: generator_loss=2.575611114501953, discriminator_loss=0.19504767656326294\n",
            "step 4731: generator_loss=2.5638961791992188, discriminator_loss=0.19573581218719482\n",
            "step 4732: generator_loss=2.2710394859313965, discriminator_loss=0.29021865129470825\n",
            "step 4733: generator_loss=1.9681867361068726, discriminator_loss=0.3402138352394104\n",
            "step 4734: generator_loss=2.0439443588256836, discriminator_loss=0.2640206217765808\n",
            "step 4735: generator_loss=1.9309778213500977, discriminator_loss=0.2865523397922516\n",
            "step 4736: generator_loss=2.200270652770996, discriminator_loss=0.21199430525302887\n",
            "step 4737: generator_loss=2.607611656188965, discriminator_loss=0.20939481258392334\n",
            "step 4738: generator_loss=2.7361369132995605, discriminator_loss=0.24525569379329681\n",
            "step 4739: generator_loss=2.7743663787841797, discriminator_loss=0.24902307987213135\n",
            "step 4740: generator_loss=2.571216106414795, discriminator_loss=0.2799924612045288\n",
            "step 4741: generator_loss=2.586320400238037, discriminator_loss=0.20117022097110748\n",
            "step 4742: generator_loss=2.164353370666504, discriminator_loss=0.25152522325515747\n",
            "step 4743: generator_loss=2.1465137004852295, discriminator_loss=0.1901254504919052\n",
            "step 4744: generator_loss=2.439007043838501, discriminator_loss=0.19419874250888824\n",
            "step 4745: generator_loss=2.5448813438415527, discriminator_loss=0.22098752856254578\n",
            "step 4746: generator_loss=2.9327497482299805, discriminator_loss=0.19066643714904785\n",
            "step 4747: generator_loss=3.099555015563965, discriminator_loss=0.17626887559890747\n",
            "step 4748: generator_loss=2.9446864128112793, discriminator_loss=0.19610658288002014\n",
            "step 4749: generator_loss=3.042766571044922, discriminator_loss=0.15677410364151\n",
            "step 4750: generator_loss=2.709594964981079, discriminator_loss=0.20857404172420502\n",
            "step 4751: generator_loss=2.7385332584381104, discriminator_loss=0.19999347627162933\n",
            "step 4752: generator_loss=2.2013533115386963, discriminator_loss=0.2706897258758545\n",
            "step 4753: generator_loss=2.233011484146118, discriminator_loss=0.20536136627197266\n",
            "step 4754: generator_loss=2.046123743057251, discriminator_loss=0.2850106358528137\n",
            "step 4755: generator_loss=2.0842440128326416, discriminator_loss=0.26722732186317444\n",
            "step 4756: generator_loss=2.202622413635254, discriminator_loss=0.2870248258113861\n",
            "step 4757: generator_loss=2.140270233154297, discriminator_loss=0.28661811351776123\n",
            "step 4758: generator_loss=2.245846748352051, discriminator_loss=0.22915509343147278\n",
            "step 4759: generator_loss=2.569047689437866, discriminator_loss=0.20186910033226013\n",
            "step 4760: generator_loss=2.4838337898254395, discriminator_loss=0.20910492539405823\n",
            "step 4761: generator_loss=2.756723165512085, discriminator_loss=0.2195453643798828\n",
            "step 4762: generator_loss=2.776089668273926, discriminator_loss=0.20273704826831818\n",
            "step 4763: generator_loss=2.920539617538452, discriminator_loss=0.20215405523777008\n",
            "step 4764: generator_loss=3.0239028930664062, discriminator_loss=0.1427358239889145\n",
            "step 4765: generator_loss=2.778960943222046, discriminator_loss=0.15007616579532623\n",
            "step 4766: generator_loss=2.7628445625305176, discriminator_loss=0.17427578568458557\n",
            "step 4767: generator_loss=2.5795938968658447, discriminator_loss=0.1369086503982544\n",
            "step 4768: generator_loss=2.5982303619384766, discriminator_loss=0.12204910069704056\n",
            "step 4769: generator_loss=2.669869899749756, discriminator_loss=0.1567000448703766\n",
            "step 4770: generator_loss=3.152334690093994, discriminator_loss=0.11685728281736374\n",
            "step 4771: generator_loss=3.240081310272217, discriminator_loss=0.1043042242527008\n",
            "step 4772: generator_loss=3.398068904876709, discriminator_loss=0.11579707264900208\n",
            "step 4773: generator_loss=3.17669677734375, discriminator_loss=0.15156406164169312\n",
            "step 4774: generator_loss=3.1040050983428955, discriminator_loss=0.14047715067863464\n",
            "step 4775: generator_loss=2.678814649581909, discriminator_loss=0.16480425000190735\n",
            "step 4776: generator_loss=2.610745906829834, discriminator_loss=0.17550881206989288\n",
            "step 4777: generator_loss=2.3950307369232178, discriminator_loss=0.22612963616847992\n",
            "step 4778: generator_loss=2.677241325378418, discriminator_loss=0.2029339075088501\n",
            "step 4779: generator_loss=2.8682446479797363, discriminator_loss=0.20853176712989807\n",
            "step 4780: generator_loss=3.2592475414276123, discriminator_loss=0.2055061310529709\n",
            "step 4781: generator_loss=3.3176989555358887, discriminator_loss=0.3118273615837097\n",
            "step 4782: generator_loss=3.3787779808044434, discriminator_loss=0.2861582040786743\n",
            "step 4783: generator_loss=3.509427309036255, discriminator_loss=0.26423436403274536\n",
            "step 4784: generator_loss=3.4118316173553467, discriminator_loss=0.31196290254592896\n",
            "step 4785: generator_loss=3.633721113204956, discriminator_loss=0.30855876207351685\n",
            "step 4786: generator_loss=4.173081874847412, discriminator_loss=0.2059027999639511\n",
            "step 4787: generator_loss=3.8086366653442383, discriminator_loss=0.2264244258403778\n",
            "step 4788: generator_loss=4.205256462097168, discriminator_loss=0.24361231923103333\n",
            "step 4789: generator_loss=4.3218302726745605, discriminator_loss=0.1955789029598236\n",
            "step 4790: generator_loss=4.6901397705078125, discriminator_loss=0.23974309861660004\n",
            "step 4791: generator_loss=5.393683433532715, discriminator_loss=0.21673303842544556\n",
            "step 4792: generator_loss=5.643502235412598, discriminator_loss=0.24544470012187958\n",
            "step 4793: generator_loss=5.6334028244018555, discriminator_loss=0.18896807730197906\n",
            "step 4794: generator_loss=5.8789167404174805, discriminator_loss=0.16200554370880127\n",
            "step 4795: generator_loss=5.1123762130737305, discriminator_loss=0.20814211666584015\n",
            "step 4796: generator_loss=4.925899982452393, discriminator_loss=0.19575922191143036\n",
            "step 4797: generator_loss=4.370388031005859, discriminator_loss=0.2488422840833664\n",
            "step 4798: generator_loss=4.300854682922363, discriminator_loss=0.28073248267173767\n",
            "step 4799: generator_loss=4.83419942855835, discriminator_loss=0.18611711263656616\n",
            "step 4800: generator_loss=4.400883197784424, discriminator_loss=0.16815125942230225\n",
            "step 4801: generator_loss=4.467495918273926, discriminator_loss=0.14404486119747162\n",
            "step 4802: generator_loss=4.273944854736328, discriminator_loss=0.14008057117462158\n",
            "step 4803: generator_loss=4.086893558502197, discriminator_loss=0.15316109359264374\n",
            "step 4804: generator_loss=3.76692533493042, discriminator_loss=0.17802058160305023\n",
            "step 4805: generator_loss=3.687325954437256, discriminator_loss=0.14428262412548065\n",
            "step 4806: generator_loss=3.578270435333252, discriminator_loss=0.1959986686706543\n",
            "step 4807: generator_loss=3.7646312713623047, discriminator_loss=0.14808477461338043\n",
            "step 4808: generator_loss=3.562534809112549, discriminator_loss=0.1827394962310791\n",
            "step 4809: generator_loss=3.394698143005371, discriminator_loss=0.20938065648078918\n",
            "step 4810: generator_loss=3.1382381916046143, discriminator_loss=0.2799336314201355\n",
            "step 4811: generator_loss=3.2199764251708984, discriminator_loss=0.22411438822746277\n",
            "step 4812: generator_loss=3.445864200592041, discriminator_loss=0.32021528482437134\n",
            "step 4813: generator_loss=3.1938557624816895, discriminator_loss=0.3253822326660156\n",
            "step 4814: generator_loss=3.0946335792541504, discriminator_loss=0.31934791803359985\n",
            "step 4815: generator_loss=3.286449909210205, discriminator_loss=0.2851080894470215\n",
            "step 4816: generator_loss=3.461594581604004, discriminator_loss=0.24592962861061096\n",
            "step 4817: generator_loss=3.706282138824463, discriminator_loss=0.20582079887390137\n",
            "step 4818: generator_loss=3.429542064666748, discriminator_loss=0.28028470277786255\n",
            "step 4819: generator_loss=3.626267671585083, discriminator_loss=0.20442456007003784\n",
            "step 4820: generator_loss=3.554666042327881, discriminator_loss=0.22934770584106445\n",
            "step 4821: generator_loss=3.6235713958740234, discriminator_loss=0.2000730186700821\n",
            "step 4822: generator_loss=3.6179165840148926, discriminator_loss=0.18947017192840576\n",
            "step 4823: generator_loss=3.420670509338379, discriminator_loss=0.1655874252319336\n",
            "step 4824: generator_loss=3.4297666549682617, discriminator_loss=0.1516730934381485\n",
            "step 4825: generator_loss=3.8825409412384033, discriminator_loss=0.12461705505847931\n",
            "step 4826: generator_loss=3.8153295516967773, discriminator_loss=0.13573569059371948\n",
            "step 4827: generator_loss=3.6832332611083984, discriminator_loss=0.12073533236980438\n",
            "step 4828: generator_loss=3.6748127937316895, discriminator_loss=0.1381395310163498\n",
            "step 4829: generator_loss=3.7098917961120605, discriminator_loss=0.14533297717571259\n",
            "step 4830: generator_loss=3.5161967277526855, discriminator_loss=0.11129624396562576\n",
            "step 4831: generator_loss=3.771409034729004, discriminator_loss=0.11021752655506134\n",
            "step 4832: generator_loss=3.6657824516296387, discriminator_loss=0.15379270911216736\n",
            "step 4833: generator_loss=3.5804009437561035, discriminator_loss=0.14431890845298767\n",
            "step 4834: generator_loss=3.366665840148926, discriminator_loss=0.1549486666917801\n",
            "step 4835: generator_loss=3.492183208465576, discriminator_loss=0.16892792284488678\n",
            "step 4836: generator_loss=3.4843249320983887, discriminator_loss=0.124727264046669\n",
            "step 4837: generator_loss=3.456005334854126, discriminator_loss=0.14705494046211243\n",
            "step 4838: generator_loss=3.709167957305908, discriminator_loss=0.1368066370487213\n",
            "step 4839: generator_loss=3.6976842880249023, discriminator_loss=0.1227860078215599\n",
            "step 4840: generator_loss=3.603923797607422, discriminator_loss=0.14035455882549286\n",
            "step 4841: generator_loss=3.465573310852051, discriminator_loss=0.13398174941539764\n",
            "step 4842: generator_loss=3.597715377807617, discriminator_loss=0.11318927258253098\n",
            "step 4843: generator_loss=3.195897102355957, discriminator_loss=0.11496778577566147\n",
            "step 4844: generator_loss=3.3388049602508545, discriminator_loss=0.1233096495270729\n",
            "step 4845: generator_loss=3.164714813232422, discriminator_loss=0.1300496608018875\n",
            "step 4846: generator_loss=3.267479181289673, discriminator_loss=0.13320228457450867\n",
            "step 4847: generator_loss=3.0639638900756836, discriminator_loss=0.15476655960083008\n",
            "step 4848: generator_loss=3.4641075134277344, discriminator_loss=0.10920695215463638\n",
            "step 4849: generator_loss=3.3079099655151367, discriminator_loss=0.11375949531793594\n",
            "step 4850: generator_loss=3.3472166061401367, discriminator_loss=0.11046431958675385\n",
            "step 4851: generator_loss=3.4254584312438965, discriminator_loss=0.13319644331932068\n",
            "step 4852: generator_loss=3.16562557220459, discriminator_loss=0.11991696059703827\n",
            "step 4853: generator_loss=3.172598361968994, discriminator_loss=0.11492777615785599\n",
            "step 4854: generator_loss=3.1742756366729736, discriminator_loss=0.11699303984642029\n",
            "step 4855: generator_loss=2.9484338760375977, discriminator_loss=0.13192525506019592\n",
            "step 4856: generator_loss=2.826688051223755, discriminator_loss=0.13596729934215546\n",
            "step 4857: generator_loss=2.854173183441162, discriminator_loss=0.1654524952173233\n",
            "step 4858: generator_loss=2.9066436290740967, discriminator_loss=0.1926872283220291\n",
            "step 4859: generator_loss=2.8418960571289062, discriminator_loss=0.24048593640327454\n",
            "step 4860: generator_loss=2.678046226501465, discriminator_loss=0.1939340978860855\n",
            "step 4861: generator_loss=2.4396371841430664, discriminator_loss=0.2966303527355194\n",
            "step 4862: generator_loss=2.3228275775909424, discriminator_loss=0.24840447306632996\n",
            "step 4863: generator_loss=2.445375919342041, discriminator_loss=0.2661231458187103\n",
            "step 4864: generator_loss=2.6253232955932617, discriminator_loss=0.30440211296081543\n",
            "step 4865: generator_loss=2.954533100128174, discriminator_loss=0.24816156923770905\n",
            "step 4866: generator_loss=2.753174066543579, discriminator_loss=0.36236292123794556\n",
            "step 4867: generator_loss=3.005709648132324, discriminator_loss=0.3490617275238037\n",
            "step 4868: generator_loss=2.621502637863159, discriminator_loss=0.36316633224487305\n",
            "step 4869: generator_loss=2.7488503456115723, discriminator_loss=0.3316654562950134\n",
            "step 4870: generator_loss=2.7719178199768066, discriminator_loss=0.33601686358451843\n",
            "step 4871: generator_loss=2.8233370780944824, discriminator_loss=0.34439200162887573\n",
            "step 4872: generator_loss=2.6216444969177246, discriminator_loss=0.31278762221336365\n",
            "step 4873: generator_loss=2.608311414718628, discriminator_loss=0.34917086362838745\n",
            "step 4874: generator_loss=2.944162368774414, discriminator_loss=0.31334388256073\n",
            "step 4875: generator_loss=2.833470582962036, discriminator_loss=0.4120479226112366\n",
            "step 4876: generator_loss=3.142518997192383, discriminator_loss=0.42325058579444885\n",
            "step 4877: generator_loss=3.4477195739746094, discriminator_loss=0.3048788905143738\n",
            "step 4878: generator_loss=3.611426591873169, discriminator_loss=0.39028307795524597\n",
            "step 4879: generator_loss=3.5980587005615234, discriminator_loss=0.3074076175689697\n",
            "step 4880: generator_loss=3.1648902893066406, discriminator_loss=0.3882606625556946\n",
            "step 4881: generator_loss=3.2923760414123535, discriminator_loss=0.3267759084701538\n",
            "step 4882: generator_loss=3.323378324508667, discriminator_loss=0.28957808017730713\n",
            "step 4883: generator_loss=3.1034064292907715, discriminator_loss=0.3663627505302429\n",
            "step 4884: generator_loss=3.053412437438965, discriminator_loss=0.27668604254722595\n",
            "step 4885: generator_loss=3.53145694732666, discriminator_loss=0.2982123792171478\n",
            "step 4886: generator_loss=3.698490619659424, discriminator_loss=0.29438215494155884\n",
            "step 4887: generator_loss=3.661881923675537, discriminator_loss=0.31866776943206787\n",
            "step 4888: generator_loss=4.040728569030762, discriminator_loss=0.2637450397014618\n",
            "step 4889: generator_loss=3.6754932403564453, discriminator_loss=0.2559919059276581\n",
            "step 4890: generator_loss=3.6531152725219727, discriminator_loss=0.2615438401699066\n",
            "step 4891: generator_loss=3.6205594539642334, discriminator_loss=0.23431396484375\n",
            "step 4892: generator_loss=3.3522982597351074, discriminator_loss=0.18379542231559753\n",
            "step 4893: generator_loss=2.982760429382324, discriminator_loss=0.22309750318527222\n",
            "step 4894: generator_loss=3.0804595947265625, discriminator_loss=0.17424605786800385\n",
            "step 4895: generator_loss=3.101577043533325, discriminator_loss=0.18464821577072144\n",
            "step 4896: generator_loss=3.046431064605713, discriminator_loss=0.1448722779750824\n",
            "step 4897: generator_loss=2.971622943878174, discriminator_loss=0.15006941556930542\n",
            "step 4898: generator_loss=3.3541111946105957, discriminator_loss=0.20004349946975708\n",
            "step 4899: generator_loss=3.292327642440796, discriminator_loss=0.1779899001121521\n",
            "step 4900: generator_loss=3.417929172515869, discriminator_loss=0.14645594358444214\n",
            "step 4901: generator_loss=3.378326416015625, discriminator_loss=0.14963912963867188\n",
            "step 4902: generator_loss=3.323075294494629, discriminator_loss=0.13440757989883423\n",
            "step 4903: generator_loss=3.2926902770996094, discriminator_loss=0.12735268473625183\n",
            "step 4904: generator_loss=3.3535494804382324, discriminator_loss=0.16194695234298706\n",
            "step 4905: generator_loss=3.1670150756835938, discriminator_loss=0.11781176924705505\n",
            "step 4906: generator_loss=3.28598952293396, discriminator_loss=0.18845705687999725\n",
            "step 4907: generator_loss=3.046724319458008, discriminator_loss=0.1736077219247818\n",
            "step 4908: generator_loss=2.916351318359375, discriminator_loss=0.16071605682373047\n",
            "step 4909: generator_loss=3.1440987586975098, discriminator_loss=0.15592899918556213\n",
            "step 4910: generator_loss=2.893214702606201, discriminator_loss=0.17008565366268158\n",
            "step 4911: generator_loss=2.8303308486938477, discriminator_loss=0.21757161617279053\n",
            "step 4912: generator_loss=2.832582473754883, discriminator_loss=0.20009836554527283\n",
            "step 4913: generator_loss=2.9707674980163574, discriminator_loss=0.17439903318881989\n",
            "step 4914: generator_loss=2.846118927001953, discriminator_loss=0.21996386349201202\n",
            "step 4915: generator_loss=2.546250104904175, discriminator_loss=0.23098739981651306\n",
            "step 4916: generator_loss=2.5298237800598145, discriminator_loss=0.2544010281562805\n",
            "step 4917: generator_loss=2.5021982192993164, discriminator_loss=0.21826466917991638\n",
            "step 4918: generator_loss=2.5659279823303223, discriminator_loss=0.239955335855484\n",
            "step 4919: generator_loss=2.512401580810547, discriminator_loss=0.2783578038215637\n",
            "step 4920: generator_loss=2.3208465576171875, discriminator_loss=0.2176932990550995\n",
            "step 4921: generator_loss=2.238629102706909, discriminator_loss=0.2599495053291321\n",
            "step 4922: generator_loss=2.400019645690918, discriminator_loss=0.2027142345905304\n",
            "step 4923: generator_loss=2.556281089782715, discriminator_loss=0.2913716733455658\n",
            "step 4924: generator_loss=2.59563946723938, discriminator_loss=0.2349473237991333\n",
            "step 4925: generator_loss=2.4451119899749756, discriminator_loss=0.24271363019943237\n",
            "step 4926: generator_loss=2.2353529930114746, discriminator_loss=0.2582533359527588\n",
            "step 4927: generator_loss=2.261335849761963, discriminator_loss=0.23340457677841187\n",
            "step 4928: generator_loss=2.247896432876587, discriminator_loss=0.299793541431427\n",
            "step 4929: generator_loss=2.570565700531006, discriminator_loss=0.2866305708885193\n",
            "step 4930: generator_loss=2.52651309967041, discriminator_loss=0.25638702511787415\n",
            "step 4931: generator_loss=3.0059118270874023, discriminator_loss=0.2268408089876175\n",
            "step 4932: generator_loss=2.5100221633911133, discriminator_loss=0.31031686067581177\n",
            "step 4933: generator_loss=2.4801268577575684, discriminator_loss=0.35672372579574585\n",
            "step 4934: generator_loss=2.512497663497925, discriminator_loss=0.3321155905723572\n",
            "step 4935: generator_loss=2.7114648818969727, discriminator_loss=0.29518818855285645\n",
            "step 4936: generator_loss=2.5254907608032227, discriminator_loss=0.4127095639705658\n",
            "step 4937: generator_loss=3.028587579727173, discriminator_loss=0.3481218218803406\n",
            "step 4938: generator_loss=3.360568046569824, discriminator_loss=0.3500974178314209\n",
            "step 4939: generator_loss=2.855196475982666, discriminator_loss=0.3870514929294586\n",
            "step 4940: generator_loss=3.376676559448242, discriminator_loss=0.45904213190078735\n",
            "step 4941: generator_loss=3.071979522705078, discriminator_loss=0.3833751082420349\n",
            "step 4942: generator_loss=2.943995475769043, discriminator_loss=0.4636198878288269\n",
            "step 4943: generator_loss=3.1174285411834717, discriminator_loss=0.36918967962265015\n",
            "step 4944: generator_loss=2.869384288787842, discriminator_loss=0.46830829977989197\n",
            "step 4945: generator_loss=2.8130433559417725, discriminator_loss=0.45646893978118896\n",
            "step 4946: generator_loss=3.029860019683838, discriminator_loss=0.4379327893257141\n",
            "step 4947: generator_loss=3.151169538497925, discriminator_loss=0.3900710344314575\n",
            "step 4948: generator_loss=3.3220748901367188, discriminator_loss=0.40833204984664917\n",
            "step 4949: generator_loss=3.495882749557495, discriminator_loss=0.297619104385376\n",
            "step 4950: generator_loss=3.311378240585327, discriminator_loss=0.3869623839855194\n",
            "step 4951: generator_loss=3.59967303276062, discriminator_loss=0.2897377014160156\n",
            "step 4952: generator_loss=3.1318206787109375, discriminator_loss=0.46152248978614807\n",
            "step 4953: generator_loss=3.513092041015625, discriminator_loss=0.30031847953796387\n",
            "step 4954: generator_loss=3.6361145973205566, discriminator_loss=0.3502016067504883\n",
            "step 4955: generator_loss=3.6170363426208496, discriminator_loss=0.3912390470504761\n",
            "step 4956: generator_loss=3.892789363861084, discriminator_loss=0.3549922704696655\n",
            "step 4957: generator_loss=4.156780242919922, discriminator_loss=0.2815444767475128\n",
            "step 4958: generator_loss=3.9788355827331543, discriminator_loss=0.3141402006149292\n",
            "step 4959: generator_loss=3.5134921073913574, discriminator_loss=0.31212836503982544\n",
            "step 4960: generator_loss=3.4911797046661377, discriminator_loss=0.2867829203605652\n",
            "step 4961: generator_loss=3.478351593017578, discriminator_loss=0.28146547079086304\n",
            "step 4962: generator_loss=3.6475791931152344, discriminator_loss=0.20045748353004456\n",
            "step 4963: generator_loss=3.405566930770874, discriminator_loss=0.21364697813987732\n",
            "step 4964: generator_loss=3.41043758392334, discriminator_loss=0.23407533764839172\n",
            "step 4965: generator_loss=3.342480421066284, discriminator_loss=0.1614045649766922\n",
            "step 4966: generator_loss=3.597748279571533, discriminator_loss=0.15113744139671326\n",
            "step 4967: generator_loss=3.2424285411834717, discriminator_loss=0.13484109938144684\n",
            "step 4968: generator_loss=3.4858758449554443, discriminator_loss=0.15257379412651062\n",
            "step 4969: generator_loss=3.2038216590881348, discriminator_loss=0.2105523645877838\n",
            "step 4970: generator_loss=3.438533306121826, discriminator_loss=0.19463858008384705\n",
            "step 4971: generator_loss=3.5384411811828613, discriminator_loss=0.17731621861457825\n",
            "step 4972: generator_loss=3.448456287384033, discriminator_loss=0.16209721565246582\n",
            "step 4973: generator_loss=3.58860182762146, discriminator_loss=0.15708276629447937\n",
            "step 4974: generator_loss=3.1259779930114746, discriminator_loss=0.1717623472213745\n",
            "step 4975: generator_loss=2.7096152305603027, discriminator_loss=0.19801190495491028\n",
            "step 4976: generator_loss=2.845353841781616, discriminator_loss=0.2099623680114746\n",
            "step 4977: generator_loss=2.812884569168091, discriminator_loss=0.22578692436218262\n",
            "step 4978: generator_loss=2.627354145050049, discriminator_loss=0.18019549548625946\n",
            "step 4979: generator_loss=2.6239826679229736, discriminator_loss=0.23832088708877563\n",
            "step 4980: generator_loss=3.162567138671875, discriminator_loss=0.2143774926662445\n",
            "step 4981: generator_loss=2.89333438873291, discriminator_loss=0.19490385055541992\n",
            "step 4982: generator_loss=2.8964319229125977, discriminator_loss=0.24181108176708221\n",
            "step 4983: generator_loss=2.971144199371338, discriminator_loss=0.22285115718841553\n",
            "step 4984: generator_loss=2.6379871368408203, discriminator_loss=0.23308327794075012\n",
            "step 4985: generator_loss=2.5426201820373535, discriminator_loss=0.21190288662910461\n",
            "step 4986: generator_loss=2.2009308338165283, discriminator_loss=0.2505476772785187\n",
            "step 4987: generator_loss=2.7585678100585938, discriminator_loss=0.22805431485176086\n",
            "step 4988: generator_loss=2.8387770652770996, discriminator_loss=0.2359781265258789\n",
            "step 4989: generator_loss=2.717513084411621, discriminator_loss=0.23191115260124207\n",
            "step 4990: generator_loss=2.8472633361816406, discriminator_loss=0.22012746334075928\n",
            "step 4991: generator_loss=2.729489803314209, discriminator_loss=0.23611462116241455\n",
            "step 4992: generator_loss=2.612623929977417, discriminator_loss=0.2368391454219818\n",
            "step 4993: generator_loss=2.542569637298584, discriminator_loss=0.25071215629577637\n",
            "step 4994: generator_loss=2.5969252586364746, discriminator_loss=0.2502593994140625\n",
            "step 4995: generator_loss=2.4744415283203125, discriminator_loss=0.252701073884964\n",
            "step 4996: generator_loss=2.421133518218994, discriminator_loss=0.2147277444601059\n",
            "step 4997: generator_loss=2.4826083183288574, discriminator_loss=0.23878039419651031\n",
            "step 4998: generator_loss=2.2798404693603516, discriminator_loss=0.25896814465522766\n",
            "step 4999: generator_loss=2.321465015411377, discriminator_loss=0.2042578160762787\n",
            "step 5000: generator_loss=2.379453659057617, discriminator_loss=0.22471946477890015\n"
          ]
        }
      ],
      "source": [
        "# Convenience: run the full experiment for both loss types\n",
        "\n",
        "results_by_loss_type = {}\n",
        "for lt in [\"saturating\", \"nonsaturating\"]:\n",
        "    results_by_loss_type[lt] = run_experiment_for_loss_type(\n",
        "        loss_type=lt,\n",
        "        train_data=train_data,\n",
        "        learning_rate=1e-3,\n",
        "        batch_size=128,\n",
        "        latent_dim=64,\n",
        "        n_steps=5_000,\n",
        "        steps_per_save=250,\n",
        "        seed=0,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4a819429",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x200 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_experiment_for_loss_type(results_by_loss_type[\"saturating\"], train_data)\n",
        "plot_experiment_for_loss_type(results_by_loss_type[\"nonsaturating\"], train_data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "egt-lab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
